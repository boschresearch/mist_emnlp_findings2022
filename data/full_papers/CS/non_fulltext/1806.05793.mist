#0
IEEE	_	_
TRANSACTIONS	_	_
ON	_	_
GEOSCIENCE	_	_
AND	_	_
REMOTE	_	_
SENSING	_	_
,	_	_
VOL	_	_
.	_	_

#1
X	_	_
,	_	_
NO	_	_
.	_	_

#2
X	_	_
,	_	_
MONTH	_	_
2017	_	_
1	_	_
Recurrent	_	_
Multiresolution	_	_
Convolutional	_	_
Networks	_	_
for	_	_
VHR	_	_
Image	_	_
Classification	_	_
John	_	_
Ray	_	_
Bergado	_	_
,	_	_
Claudio	_	_
Persello	_	_
,	_	_
Senior	_	_
Member	_	_
,	_	_
IEEE	_	_
,	_	_
and	_	_
Alfred	_	_
Stein	_	_
Abstract—Classification	_	_
of	_	_
very	_	_
high	_	_
resolution	_	_
(	_	_
VHR	_	_
)	_	_
satellite	_	_
images	_	_
has	_	_
three	_	_
major	_	_
challenges	_	_
:	_	_
1	_	_
)	_	_
inherent	_	_
low	_	_
intra-class	_	_
and	_	_
high	_	_
inter-class	_	_
spectral	_	_
similarities	_	_
,	_	_
2	_	_
)	_	_
mismatching	_	_
resolution	_	_
of	_	_
available	_	_
bands	_	_
,	_	_
and	_	_
3	_	_
)	_	_
the	_	_
need	_	_
to	_	_
regularize	_	_
noisy	_	_
classification	_	_
maps	_	_
.	_	_

#3
Conventional	_	_
methods	_	_
have	_	_
addressed	_	_
these	_	_
challenges	_	_
by	_	_
adopting	_	_
separate	_	_
stages	_	_
of	_	_
image	_	_
fusion	_	_
,	_	_
feature	_	_
extraction	_	_
,	_	_
and	_	_
post-classification	_	_
map	_	_
regularization	_	_
.	_	_

#4
These	_	_
processing	_	_
stages	_	_
,	_	_
however	_	_
,	_	_
are	_	_
not	_	_
jointly	_	_
optimizing	_	_
the	_	_
classification	_	_
task	_	_
at	_	_
hand	_	_
.	_	_

#5
In	_	_
this	_	_
study	_	_
,	_	_
we	_	_
propose	_	_
a	_	_
single-stage	_	_
framework	_	_
embedding	_	_
the	_	_
processing	_	_
stages	_	_
in	_	_
a	_	_
recurrent	_	_
multiresolution	_	_
convolutional	_	_
network	_	_
trained	_	_
in	_	_
an	_	_
end-to-end	_	_
manner	_	_
.	_	_

#6
The	_	_
feedforward	_	_
version	_	_
of	_	_
the	_	_
network	_	_
,	_	_
called	_	_
FuseNet	_	_
,	_	_
aims	_	_
to	_	_
match	_	_
the	_	_
resolution	_	_
of	_	_
the	_	_
panchromatic	_	_
and	_	_
multispectral	_	_
bands	_	_
in	_	_
a	_	_
VHR	_	_
image	_	_
using	_	_
convolutional	_	_
layers	_	_
with	_	_
corresponding	_	_
downsampling	_	_
and	_	_
upsampling	_	_
operations	_	_
.	_	_

#7
Contextual	_	_
label	_	_
information	_	_
is	_	_
incorporated	_	_
into	_	_
FuseNet	_	_
by	_	_
means	_	_
of	_	_
a	_	_
recurrent	_	_
version	_	_
called	_	_
ReuseNet	_	_
.	_	_

#8
We	_	_
compared	_	_
FuseNet	_	_
and	_	_
ReuseNet	_	_
against	_	_
the	_	_
use	_	_
of	_	_
separate	_	_
processing	_	_
steps	_	_
for	_	_
both	_	_
image	_	_
fusion	_	_
,	_	_
e.g.	_	_
pansharpening	_	_
and	_	_
resampling	_	_
through	_	_
interpolation	_	_
,	_	_
and	_	_
map	_	_
regularization	_	_
such	_	_
as	_	_
conditional	_	_
random	_	_
fields	_	_
.	_	_

#9
We	_	_
carried	_	_
out	_	_
our	_	_
experiments	_	_
on	_	_
a	_	_
land	_	_
cover	_	_
classification	_	_
task	_	_
using	_	_
a	_	_
Worldview-03	_	_
image	_	_
of	_	_
Quezon	_	_
City	_	_
,	_	_
Philippines	_	_
and	_	_
the	_	_
ISPRS	_	_
2D	_	_
semantic	_	_
labeling	_	_
benchmark	_	_
dataset	_	_
of	_	_
Vaihingen	_	_
,	_	_
Germany	_	_
.	_	_

#10
FuseNet	_	_
and	_	_
ReuseNet	_	_
surpass	_	_
the	_	_
baseline	_	_
approaches	_	_
in	_	_
both	_	_
quantitative	_	_
and	_	_
qualitative	_	_
results	_	_
.	_	_

#11
Index	_	_
Terms—Convolutional	_	_
networks	_	_
,	_	_
recurrent	_	_
networks	_	_
,	_	_
land	_	_
cover	_	_
classification	_	_
,	_	_
VHR	_	_
image	_	_
,	_	_
deep	_	_
learning	_	_
.	_	_

#12
I	_	_
.	_	_

#13
INTRODUCTION	_	_
CLASSIFICATION	_	_
of	_	_
very	_	_
high	_	_
resolution	_	_
(	_	_
VHR	_	_
)	_	_
remotely	_	_
sensed	_	_
images	_	_
allows	_	_
us	_	_
to	_	_
automatically	_	_
produce	_	_
maps	_	_
at	_	_
a	_	_
level	_	_
of	_	_
detail	_	_
comparable	_	_
to	_	_
conventional	_	_
in-situ	_	_
mapping	_	_
methods	_	_
.	_	_

#14
Due	_	_
to	_	_
the	_	_
high	_	_
spatial	_	_
resolution	_	_
of	_	_
such	_	_
images	_	_
,	_	_
automated	_	_
classification	_	_
comes	_	_
with	_	_
a	_	_
set	_	_
of	_	_
challenges	_	_
.	_	_

#15
One	_	_
challenge	_	_
is	_	_
the	_	_
inherent	_	_
low	_	_
intra-class	_	_
and	_	_
high	_	_
inter-class	_	_
spectral	_	_
similarities	_	_
,	_	_
inhibiting	_	_
discrimination	_	_
of	_	_
the	_	_
classes	_	_
of	_	_
interest	_	_
.	_	_

#16
Conventional	_	_
methods	_	_
address	_	_
this	_	_
challenge	_	_
by	_	_
extracting	_	_
spatial-contextual	_	_
features	_	_
from	_	_
the	_	_
image	_	_
such	_	_
as	_	_
texture-describing	_	_
measures	_	_
,	_	_
e.g.	_	_
gray	_	_
level	_	_
co-occurrence	_	_
matrix	_	_
(	_	_
GLCM	_	_
)	_	_
[	_	_
1	_	_
]	_	_
and	_	_
local	_	_
binary	_	_
patterns	_	_
(	_	_
LBP	_	_
)	_	_
[	_	_
2	_	_
]	_	_
,	_	_
or	_	_
products	_	_
of	_	_
morphological	_	_
operators	_	_
[	_	_
3	_	_
]	_	_
,	_	_
[	_	_
4	_	_
]	_	_
.	_	_

#17
This	_	_
step	_	_
is	_	_
crucial	_	_
for	_	_
obtaining	_	_
discriminative	_	_
features	_	_
and	_	_
accurate	_	_
classification	_	_
.	_	_

#18
However	_	_
,	_	_
such	_	_
feature	_	_
extraction	_	_
methods	_	_
are	_	_
often	_	_
disjoint	_	_
from	_	_
the	_	_
supervised	_	_
classifier	_	_
,	_	_
and	_	_
,	_	_
hence	_	_
,	_	_
not	_	_
optimized	_	_
for	_	_
the	_	_
task	_	_
at	_	_
hand	_	_
.	_	_

#19
Deep	_	_
learning	_	_
offers	_	_
a	_	_
framework	_	_
to	_	_
build	_	_
end-to-end	_	_
classifiers—directly	_	_
learning	_	_
the	_	_
predictions	_	_
from	_	_
the	_	_
inputs	_	_
with	_	_
minimal	_	_
or	_	_
no	_	_
pre-classification	_	_
and	_	_
post-classification	_	_
steps	_	_
.	_	_

#20
Features	_	_
automatically	_	_
extracted	_	_
by	_	_
deep	_	_
learning	_	_
based	_	_
classifiers	_	_
such	_	_
Acknowledgement	_	_
here	_	_
.	_	_

#21
Manuscript	_	_
received	_	_
Month	_	_
DD	_	_
,	_	_
2017	_	_
;	_	_
revised	_	_
Month	_	_
DD	_	_
,	_	_
2017	_	_
.	_	_

#22
Fig.	_	_
1	_	_
.	_	_

#23
Illustration	_	_
comparing	_	_
a	_	_
standard	_	_
(	_	_
a	_	_
)	_	_
,	_	_
state-of-the-art	_	_
(	_	_
b	_	_
)	_	_
,	_	_
and	_	_
proposed	_	_
(	_	_
c	_	_
)	_	_
piplelines	_	_
for	_	_
classifying	_	_
multiresolution	_	_
VHR	_	_
images	_	_
.	_	_

#24
as	_	_
convolutional	_	_
neural	_	_
networks	_	_
(	_	_
CNN	_	_
)	_	_
[	_	_
5	_	_
]	_	_
perform	_	_
better	_	_
than	_	_
intermediate	_	_
handcrafted	_	_
features	_	_
[	_	_
6	_	_
]	_	_
,	_	_
[	_	_
7	_	_
]	_	_
.	_	_

#25
These	_	_
networks	_	_
automatically	_	_
learn	_	_
spatial-contextual	_	_
features	_	_
directly	_	_
from	_	_
the	_	_
input	_	_
VHR	_	_
image—effectively	_	_
integrating	_	_
the	_	_
feature	_	_
extraction	_	_
step	_	_
into	_	_
the	_	_
training	_	_
of	_	_
the	_	_
classifier	_	_
as	_	_
shown	_	_
in	_	_
Figure	_	_
1	_	_
(	_	_
b	_	_
)	_	_
.	_	_

#26
The	_	_
design	_	_
of	_	_
network	_	_
architecture	_	_
,	_	_
inspired	_	_
by	_	_
the	_	_
model	_	_
of	_	_
the	_	_
visual	_	_
cortex	_	_
[	_	_
8	_	_
]	_	_
,	_	_
makes	_	_
CNN	_	_
suitable	_	_
for	_	_
image	_	_
analysis	_	_
and	_	_
land	_	_
cover	_	_
classification	_	_
.	_	_

#27
Another	_	_
challenge	_	_
in	_	_
the	_	_
classification	_	_
of	_	_
VHR	_	_
images	_	_
is	_	_
the	_	_
multiresolution	_	_
nature	_	_
of	_	_
the	_	_
images	_	_
acquired	_	_
by	_	_
space-borne	_	_
sensors	_	_
.	_	_

#28
Most	_	_
VHR	_	_
satellite	_	_
images	_	_
(	_	_
e.g.	_	_
Quickbird	_	_
,	_	_
Worldview	_	_
,	_	_
IKONOS	_	_
,	_	_
and	_	_
Pleiades	_	_
)	_	_
capture	_	_
panchromatic	_	_
(	_	_
PAN	_	_
)	_	_
images	_	_
in	_	_
a	_	_
spatial	_	_
resolution	_	_
four	_	_
times	_	_
of	_	_
the	_	_
multi-spectral	_	_
(	_	_
MS	_	_
)	_	_
bands	_	_
.	_	_

#29
Such	_	_
mismatch	_	_
in	_	_
spatial	_	_
resolution	_	_
of	_	_
the	_	_
images	_	_
requires	_	_
an	_	_
additional	_	_
step	_	_
to	_	_
fuse	_	_
these	_	_
images	_	_
before	_	_
performing	_	_
the	_	_
semantic	_	_
analysis	_	_
.	_	_

#30
Pansharpening	_	_
and	_	_
interpolation-based	_	_
resampling	_	_
are	_	_
common	_	_
techniques	_	_
for	_	_
fusing	_	_
a	_	_
multiresolution	_	_
image	_	_
[	_	_
9	_	_
]	_	_
.	_	_

#31
Similar	_	_
to	_	_
conventional	_	_
feature	_	_
extraction	_	_
methods	_	_
,	_	_
the	_	_
operations	_	_
to	_	_
fuse	_	_
multiresolution	_	_
bands	_	_
of	_	_
a	_	_
VHR	_	_
image	_	_
add	_	_
another	_	_
separate	_	_
pre-classification	_	_
step	_	_
that	_	_
is	_	_
disjoint	_	_
from	_	_
the	_	_
training	_	_
of	_	_
the	_	_
supervised	_	_
classifier	_	_
,	_	_
and	_	_
,	_	_
hence	_	_
,	_	_
may	_	_
not	_	_
be	_	_
optimal	_	_
for	_	_
the	_	_
task	_	_
at	_	_
hand	_	_
.	_	_

#32
CNN	_	_
extracts	_	_
a	_	_
hierarchy	_	_
of	_	_
spatial	_	_
features	_	_
at	_	_
different	_	_
resolutions	_	_
.	_	_

#33
We	_	_
can	_	_
exploit	_	_
the	_	_
multiresolution	_	_
nature	_	_
of	_	_
the	_	_
VHR	_	_
data	_	_
to	_	_
design	_	_
a	_	_
CNN	_	_
that	_	_
performs	_	_
fusion	_	_
and	_	_
feature	_	_
extraction	_	_
at	_	_
the	_	_
same	_	_
time	_	_
.	_	_

#34
Literature	_	_
shows	_	_
that	_	_
classification	_	_
accuracy	_	_
can	_	_
be	_	_
improved	_	_
by	_	_
using	_	_
post-classification	_	_
spatial	_	_
regularization	_	_
[	_	_
10	_	_
]	_	_
,	_	_
[	_	_
11	_	_
]	_	_
,	_	_
[	_	_
12	_	_
]	_	_
.	_	_

#35
Methods	_	_
employing	_	_
graphical	_	_
models	_	_
,	_	_
such	_	_
as	_	_
conditional	_	_
random	_	_
fields	_	_
(	_	_
CRF	_	_
)	_	_
and	_	_
Markov	_	_
random	_	_
fields	_	_
(	_	_
MRF	_	_
)	_	_
,	_	_
provide	_	_
a	_	_
way	_	_
to	_	_
perform	_	_
this	_	_
spatial	_	_
regularization	_	_
step	_	_
.	_	_

#36
Similar	_	_
to	_	_
the	_	_
two	_	_
pre-classification	_	_
steps	_	_
described	_	_
above	_	_
,	_	_
a	_	_
post-classification	_	_
map	_	_
regularization	_	_
technique	_	_
adds	_	_
another	_	_
step	_	_
independent	_	_
of	_	_
the	_	_
training	_	_
of	_	_
the	_	_
classifier	_	_
ar	_	_
X	_	_
iv	_	_
:1	_	_
6	_	_
.	_	_

#37
3v	_	_
1	_	_
[	_	_
cs	_	_
.C	_	_
V	_	_
]	_	_
1	_	_
5	_	_
Ju	_	_
n	_	_
IEEE	_	_
TRANSACTIONS	_	_
ON	_	_
GEOSCIENCE	_	_
AND	_	_
REMOTE	_	_
SENSING	_	_
,	_	_
VOL	_	_
.	_	_

#38
X	_	_
,	_	_
NO	_	_
.	_	_

#39
X	_	_
,	_	_
MONTH	_	_
2017	_	_
2	_	_
itself—further	_	_
including	_	_
a	_	_
separate	_	_
objective	_	_
function	_	_
to	_	_
be	_	_
optimized	_	_
.	_	_

#40
For	_	_
classifying	_	_
a	_	_
multiresolution	_	_
VHR	_	_
image	_	_
,	_	_
a	_	_
typical	_	_
classification	_	_
pipeline	_	_
would	_	_
be	_	_
composed	_	_
of	_	_
three	_	_
main	_	_
stages	_	_
:	_	_
a	_	_
pre-classification	_	_
step	_	_
performing	_	_
image	_	_
fusion	_	_
and	_	_
feature	_	_
extraction	_	_
,	_	_
a	_	_
supervised	_	_
learning	_	_
algorithm	_	_
performing	_	_
the	_	_
classification	_	_
,	_	_
and	_	_
a	_	_
post-classification	_	_
step	_	_
regularizing	_	_
the	_	_
maps	_	_
obtained	_	_
from	_	_
the	_	_
supervised	_	_
classification	_	_
algorithm	_	_
.	_	_

#41
This	_	_
conventional	_	_
approach	_	_
is	_	_
shown	_	_
in	_	_
Figure	_	_
1	_	_
(	_	_
a	_	_
)	_	_
.	_	_

#42
Convolutional	_	_
networks	_	_
have	_	_
been	_	_
recently	_	_
applied	_	_
to	_	_
classify	_	_
remotely	_	_
sensed	_	_
images	_	_
with	_	_
very	_	_
high	_	_
resolution	_	_
[	_	_
11	_	_
]	_	_
,	_	_
[	_	_
13	_	_
]	_	_
,	_	_
[	_	_
14	_	_
]	_	_
,	_	_
[	_	_
7	_	_
]	_	_
,	_	_
[	_	_
15	_	_
]	_	_
,	_	_
[	_	_
16	_	_
]	_	_
,	_	_
[	_	_
17	_	_
]	_	_
.	_	_

#43
But	_	_
,	_	_
aside	_	_
from	_	_
[	_	_
18	_	_
]	_	_
which	_	_
used	_	_
a	_	_
combination	_	_
of	_	_
patch-based	_	_
CNN	_	_
and	_	_
stacked	_	_
autoencoders	_	_
to	_	_
fuse	_	_
PAN	_	_
and	_	_
MS	_	_
images	_	_
,	_	_
the	_	_
majority	_	_
of	_	_
the	_	_
works	_	_
did	_	_
not	_	_
address	_	_
the	_	_
problem	_	_
of	_	_
multiresolution	_	_
VHR	_	_
images	_	_
.	_	_

#44
A	_	_
patch-based	_	_
CNN	_	_
[	_	_
7	_	_
]	_	_
and	_	_
a	_	_
fully	_	_
convolutional	_	_
network	_	_
(	_	_
FCN	_	_
)	_	_
[	_	_
15	_	_
]	_	_
were	_	_
used	_	_
to	_	_
detect	_	_
informal	_	_
settlements	_	_
from	_	_
a	_	_
pansharpened	_	_
VHR	_	_
image	_	_
.	_	_

#45
Fully	_	_
convolutional	_	_
networks	_	_
were	_	_
also	_	_
used	_	_
to	_	_
classify	_	_
urban	_	_
objects	_	_
in	_	_
VHR	_	_
images	_	_
both	_	_
acquired	_	_
in	_	_
aerial	_	_
and	_	_
space-borne	_	_
sensors	_	_
[	_	_
11	_	_
]	_	_
,	_	_
[	_	_
13	_	_
]	_	_
,	_	_
[	_	_
14	_	_
]	_	_
,	_	_
[	_	_
16	_	_
]	_	_
.	_	_

#46
Moreover	_	_
,	_	_
[	_	_
11	_	_
]	_	_
,	_	_
[	_	_
13	_	_
]	_	_
,	_	_
[	_	_
17	_	_
]	_	_
also	_	_
utilized	_	_
a	_	_
separate	_	_
post-classification	_	_
step	_	_
for	_	_
map	_	_
regularization	_	_
.	_	_

#47
In	_	_
this	_	_
paper	_	_
,	_	_
we	_	_
design	_	_
a	_	_
novel	_	_
single-stage	_	_
network	_	_
performing	_	_
image	_	_
fusion	_	_
,	_	_
classification	_	_
,	_	_
and	_	_
map	_	_
regularization	_	_
of	_	_
a	_	_
multiresolution	_	_
VHR	_	_
image	_	_
in	_	_
an	_	_
end-to-end	_	_
manner	_	_
.	_	_

#48
A	_	_
.	_	_

#49
Contributions	_	_
We	_	_
propose	_	_
a	_	_
multiresolution	_	_
convolutional	_	_
network	_	_
,	_	_
called	_	_
FuseNet	_	_
,	_	_
and	_	_
its	_	_
recurrent	_	_
version	_	_
,	_	_
called	_	_
ReuseNet	_	_
,	_	_
to	_	_
perform	_	_
image	_	_
fusion	_	_
,	_	_
classification	_	_
,	_	_
and	_	_
map	_	_
regularization	_	_
of	_	_
a	_	_
multiresolution	_	_
VHR	_	_
image	_	_
in	_	_
an	_	_
end-to-end	_	_
fashion	_	_
.	_	_

#50
We	_	_
summarize	_	_
the	_	_
main	_	_
contributions	_	_
of	_	_
this	_	_
paper	_	_
in	_	_
:	_	_
image	_	_
fusion	_	_
,	_	_
map	_	_
regularization	_	_
,	_	_
and	_	_
sensitivity	_	_
analysis	_	_
of	_	_
network	_	_
parameters	_	_
.	_	_

#51
1	_	_
)	_	_
Image	_	_
fusion	_	_
:	_	_
We	_	_
propose	_	_
a	_	_
convolutional	_	_
network	_	_
learning	_	_
how	_	_
to	_	_
fuse	_	_
a	_	_
multiresolution	_	_
VHR	_	_
image	_	_
,	_	_
extract	_	_
spatial	_	_
features	_	_
,	_	_
and	_	_
classify	_	_
the	_	_
latter	_	_
into	_	_
classes	_	_
of	_	_
interest	_	_
all	_	_
at	_	_
the	_	_
same	_	_
time	_	_
.	_	_

#52
We	_	_
call	_	_
this	_	_
network	_	_
FuseNet	_	_
.	_	_

#53
It	_	_
uses	_	_
convolutional	_	_
layers	_	_
with	_	_
corresponding	_	_
downsampling	_	_
and	_	_
upsampling	_	_
operations	_	_
to	_	_
learn	_	_
to	_	_
match	_	_
and	_	_
fuse	_	_
the	_	_
multiresolution	_	_
channels	_	_
of	_	_
a	_	_
multispectral	_	_
VHR	_	_
image	_	_
.	_	_

#54
2	_	_
)	_	_
Contextual	_	_
label	_	_
dependency	_	_
through	_	_
network	_	_
recurrence	_	_
:	_	_
We	_	_
incorporate	_	_
recurrence	_	_
in	_	_
the	_	_
FuseNet	_	_
architecture	_	_
to	_	_
model	_	_
contextual	_	_
label-to-label	_	_
dependencies	_	_
and	_	_
effectively	_	_
regularize	_	_
classification	_	_
maps	_	_
.	_	_

#55
We	_	_
call	_	_
this	_	_
improved	_	_
version	_	_
ReuseNet	_	_
.	_	_

#56
Contextual	_	_
label	_	_
dependencies	_	_
are	_	_
incorporated	_	_
in	_	_
ReuseNet	_	_
by	_	_
feeding	_	_
classification	_	_
scores	_	_
of	_	_
a	_	_
previous	_	_
FuseNet	_	_
instance	_	_
to	_	_
a	_	_
succeeding	_	_
one	_	_
.	_	_

#57
Moreover	_	_
,	_	_
we	_	_
introduce	_	_
and	_	_
compare	_	_
a	_	_
novel	_	_
method	_	_
to	_	_
initialize	_	_
the	_	_
parameters	_	_
and	_	_
initial	_	_
score	_	_
maps	_	_
of	_	_
a	_	_
ReuseNet	_	_
.	_	_

#58
3	_	_
)	_	_
Sensitivity	_	_
analysis	_	_
:	_	_
We	_	_
analyze	_	_
the	_	_
sensitivity	_	_
of	_	_
the	_	_
network	_	_
to	_	_
some	_	_
of	_	_
its	_	_
chosen	_	_
hyperparameters	_	_
.	_	_

#59
We	_	_
investigate	_	_
the	_	_
effect	_	_
of	_	_
varying	_	_
a	_	_
number	_	_
of	_	_
hyperparameters	_	_
of	_	_
our	_	_
network	_	_
to	_	_
the	_	_
classification	_	_
performance	_	_
.	_	_

#60
The	_	_
considered	_	_
hyperparameters	_	_
are	_	_
:	_	_
the	_	_
bottleneck	_	_
feature	_	_
map	_	_
dimensions	_	_
,	_	_
the	_	_
number	_	_
of	_	_
convolutional	_	_
layers	_	_
,	_	_
the	_	_
input	_	_
patch	_	_
sizes	_	_
,	_	_
the	_	_
upsampling	_	_
operations	_	_
,	_	_
and	_	_
the	_	_
number	_	_
of	_	_
FuseNet	_	_
instances	_	_
within	_	_
a	_	_
ReuseNet	_	_
.	_	_

#61
II	_	_
.	_	_

#62
CONVOLUTIONAL	_	_
NETWORKS	_	_
A	_	_
.	_	_

#63
Background	_	_
Convolutional	_	_
neural	_	_
networks	_	_
are	_	_
a	_	_
variant	_	_
of	_	_
artificial	_	_
neural	_	_
networks	_	_
connected	_	_
in	_	_
a	_	_
sequential	_	_
feedforward	_	_
fashion	_	_
employing	_	_
convolutional	_	_
and	_	_
pooling	_	_
(	_	_
aggregational	_	_
)	_	_
operations	_	_
.	_	_

#64
Convolutional	_	_
operations	_	_
greatly	_	_
reduce	_	_
the	_	_
number	_	_
of	_	_
learnable	_	_
parameters	_	_
and	_	_
allows	_	_
the	_	_
network	_	_
to	_	_
use	_	_
the	_	_
same	_	_
filter	_	_
to	_	_
detect	_	_
the	_	_
same	_	_
spatial	_	_
pattern	_	_
over	_	_
different	_	_
parts	_	_
of	_	_
an	_	_
image	_	_
.	_	_

#65
Pooling	_	_
with	_	_
downsampling	_	_
enables	_	_
the	_	_
network	_	_
to	_	_
learn	_	_
some	_	_
degree	_	_
of	_	_
translational	_	_
invariance	_	_
.	_	_

#66
Recurrent	_	_
neural	_	_
networks	_	_
are	_	_
artificial	_	_
neural	_	_
networks	_	_
employing	_	_
feedback	_	_
connection	_	_
,	_	_
i.e.	_	_
connections	_	_
form	_	_
a	_	_
directed	_	_
cycle	_	_
.	_	_

#67
For	_	_
example	_	_
,	_	_
the	_	_
Jordan	_	_
network	_	_
[	_	_
19	_	_
]	_	_
has	_	_
connections	_	_
from	_	_
the	_	_
output	_	_
units	_	_
back	_	_
to	_	_
the	_	_
hidden	_	_
units	_	_
.	_	_

#68
Two	_	_
key	_	_
concepts	_	_
namely	_	_
,	_	_
parameter	_	_
sharing	_	_
and	_	_
graph	_	_
unfolding	_	_
[	_	_
20	_	_
,	_	_
pp	_	_
.	_	_

#69
369–372	_	_
]	_	_
,	_	_
allow	_	_
these	_	_
networks	_	_
to	_	_
accept	_	_
input	_	_
sequences	_	_
of	_	_
variable	_	_
lengths	_	_
while	_	_
maintaining	_	_
model	_	_
complexity—	_	_
making	_	_
recurrent	_	_
networks	_	_
widely	_	_
applied	_	_
to	_	_
sequential	_	_
data	_	_
.	_	_

#70
However	_	_
,	_	_
parameter	_	_
sharing	_	_
and	_	_
graph	_	_
unfolding	_	_
can	_	_
also	_	_
be	_	_
used	_	_
to	_	_
design	_	_
networks	_	_
for	_	_
different	_	_
purposes	_	_
,	_	_
e.g.	_	_
application	_	_
to	_	_
non-sequential	_	_
data	_	_
,	_	_
while	_	_
still	_	_
taking	_	_
advantage	_	_
of	_	_
the	_	_
benefits	_	_
,	_	_
such	_	_
as	_	_
model	_	_
compactness	_	_
,	_	_
from	_	_
the	_	_
two	_	_
concepts	_	_
[	_	_
21	_	_
]	_	_
.	_	_

#71
B	_	_
.	_	_

#72
Deep	_	_
Networks	_	_
as	_	_
Data-flow	_	_
Graphs	_	_
We	_	_
can	_	_
generalize	_	_
any	_	_
variant	_	_
of	_	_
deep	_	_
networks	_	_
by	_	_
seeing	_	_
them	_	_
as	_	_
data-flow	_	_
graphs—a	_	_
graph	_	_
representing	_	_
how	_	_
a	_	_
set	_	_
of	_	_
input	_	_
data	_	_
are	_	_
processed	_	_
along	_	_
a	_	_
possibly	_	_
branching	_	_
chain	_	_
of	_	_
functions	_	_
,	_	_
in	_	_
the	_	_
end	_	_
producing	_	_
a	_	_
final	_	_
set	_	_
of	_	_
outputs	_	_
.	_	_

#73
Using	_	_
such	_	_
a	_	_
model	_	_
,	_	_
we	_	_
define	_	_
the	_	_
networks	_	_
by	_	_
three	_	_
elements	_	_
:	_	_
the	_	_
sets	_	_
of	_	_
data	_	_
they	_	_
take	_	_
as	_	_
an	_	_
input	_	_
,	_	_
the	_	_
operations	_	_
they	_	_
perform	_	_
in	_	_
each	_	_
function	_	_
block	_	_
,	_	_
and	_	_
the	_	_
intermediate	_	_
and	_	_
final	_	_
set	_	_
of	_	_
outputs	_	_
they	_	_
produce	_	_
.	_	_

#74
Aside	_	_
from	_	_
these	_	_
three	_	_
key	_	_
elements	_	_
of	_	_
data-flow	_	_
graphs	_	_
,	_	_
details	_	_
of	_	_
a	_	_
unique	_	_
configuration	_	_
and	_	_
instance	_	_
of	_	_
a	_	_
convolutional	_	_
network	_	_
are	_	_
defined	_	_
by	_	_
its	_	_
hyperparameters	_	_
and	_	_
parameters	_	_
respectively	_	_
.	_	_

#75
Hyperparameters	_	_
are	_	_
associated	_	_
with	_	_
the	_	_
configuration	_	_
of	_	_
a	_	_
network	_	_
architecture	_	_
and	_	_
are	_	_
set	_	_
to	_	_
fixed	_	_
values	_	_
before	_	_
training	_	_
the	_	_
network	_	_
.	_	_

#76
Parameters	_	_
are	_	_
values	_	_
associated	_	_
to	_	_
a	_	_
specific	_	_
network	_	_
instance	_	_
and	_	_
are	_	_
learned	_	_
during	_	_
network	_	_
training	_	_
.	_	_

#77
1	_	_
)	_	_
Input	_	_
:	_	_
A	_	_
convolutional	_	_
network	_	_
receives	_	_
as	_	_
an	_	_
input	_	_
either	_	_
the	_	_
whole	_	_
image	_	_
itself	_	_
to	_	_
be	_	_
classified	_	_
or	_	_
a	_	_
subset	_	_
of	_	_
it	_	_
,	_	_
called	_	_
an	_	_
input	_	_
patch	_	_
.	_	_

#78
The	_	_
dimension	_	_
of	_	_
this	_	_
patch	_	_
is	_	_
defined	_	_
by	_	_
the	_	_
patch	_	_
size	_	_
hyperparameter	_	_
M	_	_
and	_	_
the	_	_
number	_	_
of	_	_
bands	_	_
B	_	_
.	_	_

#79
A	_	_
convolutional	_	_
network	_	_
accepts	_	_
an	_	_
N×B×M×M	_	_
array	_	_
of	_	_
pixel	_	_
values	_	_
as	_	_
an	_	_
input	_	_
(	_	_
in	_	_
the	_	_
case	_	_
of	_	_
the	_	_
image	_	_
patches	_	_
having	_	_
equal	_	_
height	_	_
and	_	_
width	_	_
)	_	_
,	_	_
N	_	_
being	_	_
the	_	_
number	_	_
of	_	_
patches	_	_
processed	_	_
by	_	_
the	_	_
network	_	_
in	_	_
parallel	_	_
.	_	_

#80
Aside	_	_
from	_	_
the	_	_
input	_	_
image	_	_
patch	_	_
,	_	_
the	_	_
corresponding	_	_
reference	_	_
image	_	_
can	_	_
also	_	_
be	_	_
considered	_	_
as	_	_
an	_	_
input	_	_
in	_	_
terms	_	_
of	_	_
data-flow	_	_
graphs	_	_
since	_	_
no	_	_
operation	_	_
precedes	_	_
it	_	_
.	_	_

#81
2	_	_
)	_	_
Operations	_	_
:	_	_
Convolutions	_	_
are	_	_
the	_	_
main	_	_
operations	_	_
used	_	_
by	_	_
convolutional	_	_
networks	_	_
.	_	_

#82
A	_	_
convolution	_	_
applies	_	_
a	_	_
linear	_	_
operation	_	_
on	_	_
an	_	_
input	_	_
image/feature	_	_
map	_	_
using	_	_
a	_	_
set	_	_
of	_	_
K	_	_
′	_	_
learnable	_	_
kernels	_	_
.	_	_

#83
Applying	_	_
a	_	_
kernel	_	_
w	_	_
,	_	_
composed	_	_
of	_	_
a	_	_
K×K	_	_
′×G×G	_	_
array	_	_
of	_	_
learnable	_	_
parameters	_	_
,	_	_
on	_	_
a	_	_
K×H×W	_	_
input	_	_
feature	_	_
map	_	_
x	_	_
,	_	_
where	_	_
G	_	_
is	_	_
the	_	_
kernel	_	_
size	_	_
,	_	_
K	_	_
is	_	_
the	_	_
IEEE	_	_
TRANSACTIONS	_	_
ON	_	_
GEOSCIENCE	_	_
AND	_	_
REMOTE	_	_
SENSING	_	_
,	_	_
VOL	_	_
.	_	_

#84
X	_	_
,	_	_
NO	_	_
.	_	_

#85
X	_	_
,	_	_
MONTH	_	_
2017	_	_
3	_	_
number	_	_
of	_	_
kernels	_	_
in	_	_
each	_	_
set	_	_
of	_	_
kernels	_	_
,	_	_
and	_	_
H	_	_
and	_	_
W	_	_
are	_	_
the	_	_
height	_	_
and	_	_
width	_	_
of	_	_
the	_	_
feature	_	_
map	_	_
,	_	_
produces	_	_
a	_	_
K	_	_
′×H	_	_
′×W	_	_
′	_	_
output	_	_
feature	_	_
map	_	_
x′	_	_
.	_	_

#86
The	_	_
output	_	_
at	_	_
the	_	_
i′	_	_
row	_	_
and	_	_
j′	_	_
column	_	_
of	_	_
the	_	_
k′	_	_
feature	_	_
map	_	_
is	_	_
given	_	_
by	_	_
:	_	_
x′k′i′j′	_	_
=	_	_
K∑	_	_
k=1	_	_
G∑	_	_
p=1	_	_
G∑	_	_
q=1	_	_
xkij	_	_
·wkk′pq	_	_
+	_	_
bk′	_	_
(	_	_
1a	_	_
)	_	_
i	_	_
=	_	_
i′	_	_
+	_	_
p−	_	_
dG	_	_
e	_	_
(	_	_
1b	_	_
)	_	_
j	_	_
=	_	_
j′	_	_
+	_	_
q	_	_
−	_	_
dG	_	_
e	_	_
(	_	_
1c	_	_
)	_	_
where	_	_
bk′	_	_
is	_	_
the	_	_
learnable	_	_
bias	_	_
parameter	_	_
associated	_	_
with	_	_
the	_	_
k′	_	_
feature	_	_
map	_	_
.	_	_

#87
The	_	_
width	_	_
and	_	_
height	_	_
of	_	_
the	_	_
output	_	_
feature	_	_
map	_	_
are	_	_
given	_	_
by	_	_
:	_	_
H	_	_
′	_	_
=	_	_
bH	_	_
−G+	_	_
2Z	_	_
S	_	_
+	_	_
1c	_	_
(	_	_
2a	_	_
)	_	_
W	_	_
′	_	_
=	_	_
bW	_	_
−G+	_	_
2Z	_	_
S	_	_
+	_	_
1c	_	_
(	_	_
2b	_	_
)	_	_
where	_	_
the	_	_
zero-padding	_	_
Z	_	_
is	_	_
the	_	_
number	_	_
of	_	_
rows	_	_
and	_	_
columns	_	_
of	_	_
zeros	_	_
added	_	_
to	_	_
the	_	_
border	_	_
of	_	_
the	_	_
input	_	_
feature	_	_
map	_	_
and	_	_
the	_	_
convolutional	_	_
stride	_	_
S	_	_
is	_	_
the	_	_
number	_	_
of	_	_
units	_	_
separating	_	_
contiguous	_	_
receptive	_	_
fields	_	_
of	_	_
the	_	_
kernel	_	_
on	_	_
the	_	_
input	_	_
feature	_	_
map	_	_
.	_	_

#88
Nonlinearity	_	_
is	_	_
applied	_	_
after	_	_
the	_	_
linear	_	_
operation	_	_
of	_	_
a	_	_
convolution	_	_
.	_	_

#89
Since	_	_
applying	_	_
a	_	_
series	_	_
of	_	_
linear	_	_
operations	_	_
can	_	_
be	_	_
reduced	_	_
to	_	_
a	_	_
single	_	_
linear	_	_
operation	_	_
,	_	_
an	_	_
elementwise	_	_
nonlinear	_	_
function	_	_
applied	_	_
between	_	_
each	_	_
convolution	_	_
allows	_	_
the	_	_
network	_	_
to	_	_
learn	_	_
more	_	_
complex	_	_
input	_	_
to	_	_
output	_	_
mapping	_	_
.	_	_

#90
A	_	_
common	_	_
choice	_	_
is	_	_
the	_	_
rectifier	_	_
function	_	_
x′i′j′k′	_	_
=	_	_
max	_	_
(	_	_
0	_	_
,	_	_
xijk	_	_
)	_	_
(	_	_
3	_	_
)	_	_
or	_	_
a	_	_
variation	_	_
of	_	_
it	_	_
[	_	_
22	_	_
]	_	_
,	_	_
[	_	_
23	_	_
]	_	_
,	_	_
[	_	_
24	_	_
]	_	_
.	_	_

#91
Pooling	_	_
takes	_	_
an	_	_
aggregate	_	_
of	_	_
values	_	_
over	_	_
local	_	_
regions	_	_
of	_	_
the	_	_
input	_	_
.	_	_

#92
A	_	_
common	_	_
choice	_	_
of	_	_
a	_	_
pooling	_	_
function	_	_
is	_	_
the	_	_
average	_	_
or	_	_
maximum	_	_
function	_	_
.	_	_

#93
In	_	_
contrast	_	_
to	_	_
convolution	_	_
,	_	_
a	_	_
basic	_	_
pooling	_	_
does	_	_
not	_	_
have	_	_
any	_	_
learnable	_	_
parameters	_	_
.	_	_

#94
Originally	_	_
,	_	_
pooling	_	_
was	_	_
used	_	_
to	_	_
give	_	_
the	_	_
network	_	_
a	_	_
small	_	_
degree	_	_
of	_	_
translation	_	_
invariance	_	_
by	_	_
summarizing	_	_
values	_	_
of	_	_
the	_	_
input	_	_
on	_	_
non-overlapping	_	_
windows	_	_
(	_	_
S	_	_
=	_	_
G	_	_
)	_	_
—also	_	_
downsampling	_	_
the	_	_
input	_	_
by	_	_
a	_	_
factor	_	_
of	_	_
S	_	_
,	_	_
with	_	_
proper	_	_
zero-padding	_	_
.	_	_

#95
Upsampling	_	_
operations	_	_
are	_	_
applied	_	_
to	_	_
increase	_	_
the	_	_
spatial	_	_
dimensions	_	_
of	_	_
input	_	_
feature	_	_
maps	_	_
.	_	_

#96
Upsampling	_	_
is	_	_
important	_	_
specifically	_	_
if	_	_
the	_	_
network	_	_
needs	_	_
to	_	_
produce	_	_
output	_	_
predictions	_	_
of	_	_
the	_	_
same	_	_
size	_	_
as	_	_
the	_	_
input	_	_
,	_	_
i.e.	_	_
we	_	_
want	_	_
to	_	_
produce	_	_
a	_	_
label	_	_
for	_	_
each	_	_
pixel	_	_
in	_	_
the	_	_
M×M	_	_
input	_	_
patch	_	_
.	_	_

#97
One	_	_
way	_	_
to	_	_
upsample	_	_
is	_	_
by	_	_
employing	_	_
resampling	_	_
techniques	_	_
such	_	_
as	_	_
nearest	_	_
neighbor	_	_
or	_	_
bilinear	_	_
interpolation	_	_
[	_	_
10	_	_
]	_	_
.	_	_

#98
The	_	_
original	_	_
fully	_	_
convolutional	_	_
network	_	_
(	_	_
FCN	_	_
)	_	_
[	_	_
25	_	_
]	_	_
learns	_	_
the	_	_
upsampling	_	_
operation	_	_
using	_	_
backwards	_	_
convolution	_	_
(	_	_
or	_	_
more	_	_
technically	_	_
fitting	_	_
called	_	_
transposed	_	_
convolution	_	_
)	_	_
.	_	_

#99
Merging	_	_
combines	_	_
two	_	_
or	_	_
more	_	_
sets	_	_
of	_	_
feature	_	_
maps	_	_
in	_	_
a	_	_
network	_	_
either	_	_
by	_	_
addition	_	_
or	_	_
by	_	_
concatenation	_	_
.	_	_

#100
Addition	_	_
is	_	_
an	_	_
elementwise	_	_
operation	_	_
performed	_	_
between	_	_
feature	_	_
maps	_	_
—	_	_
adding	_	_
each	_	_
unit	_	_
with	_	_
corresponding	_	_
indices	_	_
—	_	_
hence	_	_
,	_	_
all	_	_
the	_	_
three	_	_
dimensions	_	_
(	_	_
K	_	_
,	_	_
H	_	_
,	_	_
W	_	_
)	_	_
must	deontic	_
be	_	_
the	_	_
same	_	_
for	_	_
all	_	_
inputs	_	_
[	_	_
25	_	_
]	_	_
.	_	_

#101
Concatenation	_	_
stacks	_	_
the	_	_
input	_	_
feature	_	_
maps	_	_
depthwise—hence	_	_
,	_	_
only	_	_
the	_	_
spatial	_	_
dimensions	_	_
(	_	_
H	_	_
,	_	_
W	_	_
)	_	_
must	deontic	_
be	_	_
the	_	_
same	_	_
.	_	_

#102
3	_	_
)	_	_
Outputs	_	_
:	_	_
In	_	_
data-flow	_	_
graph	_	_
terms	_	_
,	_	_
the	_	_
outputs	_	_
of	_	_
a	_	_
convolutional	_	_
network	_	_
consist	_	_
of	_	_
all	_	_
the	_	_
intermediate	_	_
feature	_	_
maps	_	_
,	_	_
the	_	_
final	_	_
class	_	_
score	_	_
maps	_	_
,	_	_
and	_	_
the	_	_
corresponding	_	_
loss	_	_
and	_	_
accuracy	_	_
calculated	_	_
using	_	_
the	_	_
class	_	_
score	_	_
maps	_	_
and	_	_
the	_	_
reference	_	_
labels	_	_
.	_	_

#103
Final	_	_
class	_	_
score	_	_
maps	_	_
correspond	_	_
to	_	_
the	_	_
units	_	_
in	_	_
the	_	_
last	_	_
layer	_	_
of	_	_
a	_	_
neural	_	_
network	_	_
and	_	_
its	_	_
dimension	_	_
depends	_	_
on	_	_
how	_	_
the	_	_
task	_	_
is	_	_
defined	_	_
.	_	_

#104
Authors	_	_
in	_	_
[	_	_
16	_	_
]	_	_
categorize	_	_
the	_	_
approaches	_	_
to	_	_
this	_	_
task	_	_
into	_	_
three	_	_
variants	_	_
:	_	_
1	_	_
)	_	_
patch	_	_
classification	_	_
,	_	_
2	_	_
)	_	_
subpatch	_	_
labeling	_	_
,	_	_
and	_	_
3	_	_
)	_	_
full	_	_
patch	_	_
labeling	_	_
.	_	_

#105
In	_	_
patch	_	_
classification	_	_
,	_	_
we	_	_
assign	_	_
a	_	_
single	_	_
label	_	_
to	_	_
the	_	_
patch	_	_
,	_	_
i.e.	_	_
the	_	_
label	_	_
corresponds	_	_
to	_	_
the	_	_
class	_	_
of	_	_
the	_	_
central	_	_
pixel	_	_
of	_	_
the	_	_
patch	_	_
[	_	_
6	_	_
]	_	_
,	_	_
[	_	_
16	_	_
]	_	_
,	_	_
[	_	_
7	_	_
]	_	_
.	_	_

#106
In	_	_
subpatch	_	_
labeling	_	_
,	_	_
we	_	_
assign	_	_
labels	_	_
on	_	_
a	_	_
smaller	_	_
part	_	_
of	_	_
the	_	_
patch	_	_
corresponding	_	_
to	_	_
the	_	_
area	_	_
near	_	_
the	_	_
center	_	_
of	_	_
the	_	_
patch	_	_
[	_	_
16	_	_
]	_	_
.	_	_

#107
Finally	_	_
,	_	_
in	_	_
full	_	_
patch	_	_
labeling	_	_
,	_	_
we	_	_
assign	_	_
labels	_	_
to	_	_
all	_	_
the	_	_
pixels	_	_
in	_	_
the	_	_
patch	_	_
[	_	_
25	_	_
]	_	_
,	_	_
[	_	_
13	_	_
]	_	_
,	_	_
[	_	_
26	_	_
]	_	_
,	_	_
[	_	_
16	_	_
]	_	_
,	_	_
[	_	_
15	_	_
]	_	_
.	_	_

#108
The	_	_
last	_	_
method	_	_
,	_	_
aside	_	_
from	_	_
being	_	_
more	_	_
efficient	_	_
,	_	_
also	_	_
decouples	_	_
the	_	_
limit	_	_
of	_	_
the	_	_
input	_	_
patch	_	_
size	_	_
to	_	_
the	_	_
number	_	_
of	_	_
downsampling	_	_
operations	_	_
in	_	_
the	_	_
network	_	_
.	_	_

#109
C.	_	_
Training	_	_
Deep	_	_
Networks	_	_
We	_	_
train	_	_
the	_	_
network	_	_
by	_	_
minimizing	_	_
an	_	_
objective	_	_
function	_	_
in	_	_
terms	_	_
of	_	_
the	_	_
parameters	_	_
of	_	_
the	_	_
network	_	_
.	_	_

#110
For	_	_
classification	_	_
involving	_	_
C	_	_
classes	_	_
,	_	_
a	_	_
cross-entropy	_	_
loss	_	_
function	_	_
is	_	_
often	_	_
used	_	_
given	_	_
by	_	_
:	_	_
EN	_	_
(	_	_
w	_	_
)	_	_
=	_	_
−	_	_
N∑	_	_
n=1	_	_
tn	_	_
·	_	_
log	_	_
(	_	_
yn	_	_
)	_	_
(	_	_
4	_	_
)	_	_
where	_	_
E	_	_
is	_	_
the	_	_
loss	_	_
function	_	_
value	_	_
evaluated	_	_
over	_	_
N	_	_
samples	_	_
,	_	_
tn	_	_
is	_	_
a	_	_
binary	_	_
vector	_	_
encoding	_	_
the	_	_
the	_	_
target	_	_
class	_	_
labels	_	_
(	_	_
with	_	_
the	_	_
index	_	_
corrresponding	_	_
to	_	_
a	_	_
class	_	_
having	_	_
a	_	_
value	_	_
of	_	_
1	_	_
and	_	_
0	_	_
otherwise	_	_
)	_	_
,	_	_
·	_	_
denotes	_	_
the	_	_
dot	_	_
product	_	_
,	_	_
and	_	_
yn	_	_
is	_	_
the	_	_
class	_	_
score	_	_
maps	_	_
of	_	_
a	_	_
sample	_	_
n	_	_
calculated	_	_
using	_	_
a	_	_
softmax	_	_
activation	_	_
function	_	_
:	_	_
ykij	_	_
=	_	_
exp	_	_
(	_	_
xkij	_	_
)	_	_
C∑	_	_
c=1	_	_
exp	_	_
(	_	_
xcij	_	_
)	_	_
.	_	_

#111
(	_	_
5	_	_
)	_	_
In	_	_
this	_	_
equation	_	_
,	_	_
y	_	_
is	_	_
the	_	_
softmax	_	_
score	_	_
and	_	_
x	_	_
is	_	_
the	_	_
last	_	_
set	_	_
of	_	_
feature	_	_
maps	_	_
containing	_	_
unnormalized	_	_
class	_	_
scores	_	_
at	_	_
location	_	_
ij	_	_
.	_	_

#112
A	_	_
stochastic	_	_
version	_	_
of	_	_
the	_	_
backpropagation	_	_
with	_	_
gradient	_	_
descent	_	_
algorithm	_	_
is	_	_
often	_	_
used	_	_
to	_	_
minimize	_	_
the	_	_
objective	_	_
function	_	_
[	_	_
27	_	_
]	_	_
.	_	_

#113
The	_	_
training	_	_
is	_	_
finished	_	_
after	_	_
a	_	_
fixed	_	_
number	_	_
of	_	_
epoch	_	_
or	_	_
when	_	_
a	_	_
certain	_	_
convergence	_	_
criterion	_	_
is	_	_
met	_	_
.	_	_

#114
We	_	_
can	_	_
infer	_	_
predictions	_	_
from	_	_
the	_	_
final	_	_
trained	_	_
network	_	_
instance	_	_
by	_	_
truncating	_	_
the	_	_
loss	_	_
evaluation	_	_
in	_	_
the	_	_
computational	_	_
graph	_	_
and	_	_
taking	_	_
the	_	_
index	_	_
of	_	_
the	_	_
maximum	_	_
class	_	_
score	_	_
map	_	_
value	_	_
along	_	_
the	_	_
class	_	_
score	_	_
dimension	_	_
by	_	_
yij	_	_
=	_	_
argmax	_	_
c	_	_
ycij	_	_
(	_	_
6	_	_
)	_	_
where	_	_
y	_	_
and	_	_
y	_	_
are	_	_
the	_	_
class	_	_
score	_	_
and	_	_
prediction	_	_
for	_	_
location	_	_
ij	_	_
respectively	_	_
.	_	_

#115
D.	_	_
Regularizing	_	_
Deep	_	_
Networks	_	_
Deep	_	_
networks	_	_
are	_	_
often	_	_
prone	_	_
to	_	_
overfit	_	_
the	_	_
training	_	_
set	_	_
.	_	_

#116
Overfitting	_	_
occurs	_	_
when	_	_
a	_	_
model	_	_
reports	_	_
high	_	_
accuracy	_	_
during	_	_
IEEE	_	_
TRANSACTIONS	_	_
ON	_	_
GEOSCIENCE	_	_
AND	_	_
REMOTE	_	_
SENSING	_	_
,	_	_
VOL	_	_
.	_	_

#117
X	_	_
,	_	_
NO	_	_
.	_	_

#118
X	_	_
,	_	_
MONTH	_	_
2017	_	_
4	_	_
training	_	_
but	_	_
performs	_	_
poorly	_	_
on	_	_
unseen	_	_
test	_	_
data	_	_
.	_	_

#119
Regularization	_	_
approaches	_	_
address	_	_
the	_	_
overfitting	_	_
problem	_	_
using	_	_
three	_	_
common	_	_
methods	_	_
:	_	_
data	_	_
augmentation	_	_
,	_	_
weight	_	_
decay	_	_
,	_	_
and	_	_
early-stopping	_	_
.	_	_

#120
Data	_	_
augmentation	_	_
technique	_	_
increases	_	_
the	_	_
number	_	_
of	_	_
training	_	_
samples	_	_
by	_	_
permuting	_	_
them	_	_
with	_	_
applicable	_	_
rotational	_	_
and/or	_	_
translational	_	_
transformations	_	_
.	_	_

#121
Data	_	_
augmentation	_	_
helps	_	_
the	_	_
network	_	_
to	_	_
learn	_	_
relevant	_	_
invariances	_	_
that	_	_
may	_	_
be	_	_
present	_	_
in	_	_
the	_	_
input	_	_
.	_	_

#122
Weight	_	_
decay	_	_
modifies	_	_
the	_	_
loss	_	_
function	_	_
by	_	_
Q	_	_
(	_	_
w	_	_
)	_	_
=	_	_
E	_	_
(	_	_
w	_	_
)	_	_
+	_	_
λ‖w‖22	_	_
(	_	_
7	_	_
)	_	_
adding	_	_
a	_	_
penalty	_	_
proportional	_	_
to	_	_
the	_	_
square	_	_
of	_	_
the	_	_
l2	_	_
-norm	_	_
of	_	_
the	_	_
weight	_	_
vector	_	_
w.	_	_
The	_	_
weight	_	_
decay	_	_
λ	_	_
hyperparameter	_	_
controls	_	_
the	_	_
contribution	_	_
of	_	_
this	_	_
penalty	_	_
to	_	_
the	_	_
loss	_	_
function	_	_
.	_	_

#123
Early	_	_
stopping	_	_
prematurely	_	_
stops	_	_
the	_	_
training	_	_
when	_	_
a	_	_
criterion	_	_
measured	_	_
from	_	_
a	_	_
validation	_	_
set	_	_
is	_	_
met	_	_
.	_	_

#124
III	_	_
.	_	_

#125
PROPOSED	_	_
APPROACH	_	_
In	_	_
this	_	_
paper	_	_
,	_	_
we	_	_
propose	_	_
a	_	_
multiresolution	_	_
convolutional	_	_
network	_	_
,	_	_
called	_	_
FuseNet	_	_
,	_	_
and	_	_
its	_	_
recurrent	_	_
version	_	_
,	_	_
called	_	_
ReuseNet	_	_
,	_	_
to	_	_
perform	_	_
an	_	_
end-to-end	_	_
fusion	_	_
,	_	_
classification	_	_
,	_	_
and	_	_
map	_	_
regularization	_	_
of	_	_
a	_	_
multi-resolution	_	_
VHR	_	_
image	_	_
.	_	_

#126
ReuseNet	_	_
is	_	_
built	_	_
on	_	_
top	_	_
of	_	_
a	_	_
fully	_	_
convolutional	_	_
network	_	_
architecture	_	_
learning	_	_
to	_	_
:	_	_
1	_	_
)	_	_
fuse	_	_
PAN	_	_
and	_	_
MS	_	_
bands	_	_
of	_	_
a	_	_
VHR	_	_
image	_	_
,	_	_
2	_	_
)	_	_
perform	_	_
land	_	_
cover	_	_
classification	_	_
on	_	_
the	_	_
fused	_	_
images	_	_
,	_	_
and	_	_
3	_	_
)	_	_
spatially	_	_
regularize	_	_
the	_	_
resulting	_	_
classification	_	_
.	_	_

#127
A.	_	_
FuseNet	_	_
The	_	_
architecture	_	_
of	_	_
FuseNet	_	_
is	_	_
inspired	_	_
by	_	_
several	_	_
encoder-decoder	_	_
like	_	_
convolutional	_	_
network	_	_
structures	_	_
[	_	_
28	_	_
]	_	_
,	_	_
[	_	_
26	_	_
]	_	_
,	_	_
[	_	_
16	_	_
]	_	_
where	_	_
the	_	_
first	_	_
set	_	_
of	_	_
layers	_	_
learn	_	_
deep	_	_
features	_	_
by	_	_
a	_	_
series	_	_
of	_	_
convolution	_	_
,	_	_
nonlinearity	_	_
,	_	_
and	_	_
maximum	_	_
pooling	_	_
with	_	_
downsampling	_	_
operations	_	_
,	_	_
followed	_	_
by	_	_
a	_	_
second	_	_
set	_	_
of	_	_
layers	_	_
using	_	_
upsampling	_	_
and	_	_
nonlinearity	_	_
operations	_	_
to	_	_
restore	_	_
the	_	_
resolution	_	_
of	_	_
the	_	_
original	_	_
input	_	_
image	_	_
.	_	_

#128
The	_	_
main	_	_
difference	_	_
of	_	_
FuseNet	_	_
with	_	_
these	_	_
encoder-decoder	_	_
architectures	_	_
is	_	_
the	_	_
two	_	_
initial	_	_
separate	_	_
streams	_	_
of	_	_
the	_	_
downsampling	_	_
part	_	_
of	_	_
the	_	_
network	_	_
that	_	_
learns	_	_
how	_	_
to	_	_
fuse	_	_
two	_	_
images	_	_
of	_	_
different	_	_
resolution	_	_
.	_	_

#129
FuseNet	_	_
is	_	_
specifically	_	_
designed	_	_
for	_	_
VHR	_	_
satellite	_	_
images	_	_
with	_	_
PAN	_	_
band	_	_
and	_	_
MS	_	_
bands	_	_
of	_	_
ground	_	_
sampling	_	_
distance	_	_
ratio	_	_
of	_	_
four	_	_
(	_	_
e.g.	_	_
Quickbird	_	_
,	_	_
Worldview	_	_
2/3	_	_
,	_	_
Pleiades	_	_
,	_	_
Ikonos	_	_
)	_	_
.	_	_

#130
But	_	_
the	_	_
architecture	_	_
can	_	_
be	_	_
further	_	_
generalized	_	_
to	_	_
fuse	_	_
any	_	_
number	_	_
of	_	_
images	_	_
with	_	_
different	_	_
spatial	_	_
resolutions	_	_
.	_	_

#131
FuseNet	_	_
accepts	_	_
two	_	_
sets	_	_
of	_	_
input	_	_
:	_	_
an	_	_
image	_	_
patch	_	_
xPAN	_	_
of	_	_
dimensions	_	_
N×1×4M×4M	_	_
taken	_	_
from	_	_
PAN	_	_
image	_	_
and	_	_
another	_	_
patch	_	_
xMS	_	_
of	_	_
dimensions	_	_
N×4×M×M	_	_
taken	_	_
from	_	_
the	_	_
corresponding	_	_
location	_	_
in	_	_
the	_	_
MS	_	_
image	_	_
.	_	_

#132
It	_	_
performs	_	_
two	_	_
series	_	_
of	_	_
convolution	_	_
,	_	_
nonlinearity	_	_
,	_	_
and	_	_
maximum	_	_
pooling	_	_
with	_	_
downsampling	_	_
to	_	_
xPAN	_	_
such	_	_
that	_	_
the	_	_
spatial	_	_
dimensions	_	_
of	_	_
the	_	_
intermediate	_	_
feature	_	_
maps	_	_
match	_	_
the	_	_
spatial	_	_
dimensions	_	_
of	_	_
xMS	_	_
.	_	_

#133
The	_	_
nonlinearity	_	_
operations	_	_
use	_	_
an	_	_
exponential	_	_
linear	_	_
activation	_	_
function	_	_
[	_	_
24	_	_
]	_	_
.	_	_

#134
The	_	_
second	_	_
input	_	_
is	_	_
linearly	_	_
projected	_	_
in	_	_
k	_	_
dimensions	_	_
using	_	_
1×1	_	_
convolutions	_	_
such	_	_
that	_	_
k	_	_
matches	_	_
the	_	_
number	_	_
of	_	_
intermediate	_	_
feature	_	_
maps	_	_
extracted	_	_
from	_	_
the	_	_
first	_	_
set	_	_
of	_	_
input—ensuring	_	_
a	_	_
balanced	_	_
contribution	_	_
from	_	_
the	_	_
two	_	_
streams	_	_
of	_	_
feature	_	_
.	_	_

#135
FuseNet	_	_
then	_	_
merges	_	_
the	_	_
linear	_	_
projection	_	_
of	_	_
xMS	_	_
with	_	_
intermediate	_	_
feature	_	_
maps	_	_
extracted	_	_
from	_	_
xPAN	_	_
via	_	_
a	_	_
concatenation	_	_
operation	_	_
.	_	_

#136
Additional	_	_
series	_	_
of	_	_
convolution	_	_
,	_	_
nonlinearity	_	_
,	_	_
and	_	_
maximum	_	_
pooling	_	_
with	_	_
downsampling	_	_
operations	_	_
are	_	_
applied	_	_
to	_	_
the	_	_
merged	_	_
feature	_	_
maps	_	_
producing	_	_
the	_	_
set	_	_
of	_	_
feature	_	_
maps	_	_
with	_	_
smallest	_	_
spatial	_	_
dimensions—called	_	_
bottleneck	_	_
[	_	_
16	_	_
]	_	_
.	_	_

#137
FuseNet	_	_
then	_	_
upsamples	_	_
the	_	_
bottleneck	_	_
back	_	_
to	_	_
the	_	_
resolution	_	_
of	_	_
xPAN	_	_
using	_	_
transposed	_	_
convolutions	_	_
.	_	_

#138
The	_	_
resulting	_	_
set	_	_
of	_	_
feature	_	_
maps	_	_
is	_	_
linearly	_	_
projected	_	_
again	_	_
using	_	_
1×1	_	_
convolutions	_	_
such	_	_
that	_	_
the	_	_
number	_	_
of	_	_
feature	_	_
maps	_	_
matches	_	_
C.	_	_
The	_	_
final	_	_
class	_	_
score	_	_
maps	_	_
yscores	_	_
are	_	_
obtained	_	_
by	_	_
applying	_	_
a	_	_
softmax	_	_
activation	_	_
function	_	_
.	_	_

#139
This	_	_
series	_	_
of	_	_
operations	_	_
can	_	_
be	_	_
formulated	_	_
as	_	_
a	_	_
function	_	_
composition	_	_
given	_	_
by	_	_
:	_	_
yscores	_	_
=	_	_
s	_	_
(	_	_
l1	_	_
(	_	_
u	_	_
(	_	_
d1	_	_
(	_	_
d0	_	_
(	_	_
xPAN	_	_
)	_	_
⊕	_	_
l0	_	_
(	_	_
xMS	_	_
)	_	_
)	_	_
)	_	_
)	_	_
)	_	_
(	_	_
8	_	_
)	_	_
where	_	_
di	_	_
is	_	_
a	_	_
series	_	_
of	_	_
convolution	_	_
,	_	_
nonlinearity	_	_
,	_	_
and	_	_
maximum	_	_
pooling	_	_
with	_	_
downsampling	_	_
operations	_	_
,	_	_
u	_	_
is	_	_
the	_	_
series	_	_
of	_	_
upsampling	_	_
operations	_	_
via	_	_
transposed	_	_
convolution	_	_
,	_	_
li	_	_
are	_	_
the	_	_
linear	_	_
projections	_	_
via	_	_
1×1	_	_
convolutions	_	_
,	_	_
s	_	_
is	_	_
the	_	_
softmax	_	_
function	_	_
,	_	_
and	_	_
⊕	_	_
denotes	_	_
merging	_	_
via	_	_
concatenation	_	_
.	_	_

#140
Details	_	_
of	_	_
each	_	_
operation	_	_
,	_	_
including	_	_
the	_	_
hyperparameter	_	_
values	_	_
and	_	_
dimensions	_	_
of	_	_
some	_	_
chosen	_	_
intermediate	_	_
feature	_	_
maps	_	_
,	_	_
are	_	_
provided	_	_
in	_	_
Table	_	_
I	_	_
.	_	_

#141
A	_	_
cross-entropy	_	_
function	_	_
following	_	_
Equation	_	_
4	_	_
is	_	_
used	_	_
to	_	_
compute	_	_
the	_	_
loss	_	_
in	_	_
each	_	_
iteration	_	_
.	_	_

#142
Unlabeled	_	_
pixels	_	_
are	_	_
assigned	_	_
a	_	_
loss	_	_
function	_	_
value	_	_
of	_	_
zero	_	_
.	_	_

#143
We	_	_
described	_	_
above	_	_
the	_	_
default	_	_
configuration	_	_
of	_	_
FuseNet	_	_
,	_	_
called	_	_
FuseNetlow	_	_
,	_	_
performing	_	_
the	_	_
fusion	_	_
at	_	_
the	_	_
lower	_	_
(	_	_
MS	_	_
image	_	_
)	_	_
resolution	_	_
.	_	_

#144
We	_	_
also	_	_
tested	_	_
a	_	_
network	_	_
,	_	_
called	_	_
FuseNetskip	_	_
,	_	_
adding	_	_
skip	_	_
connections	_	_
to	_	_
some	_	_
lower-level	_	_
feature	_	_
maps	_	_
of	_	_
FuseNetlow	_	_
[	_	_
25	_	_
]	_	_
.	_	_

#145
Figure	_	_
2	_	_
shows	_	_
a	_	_
diagram	_	_
illustrating	_	_
the	_	_
general	_	_
architecture	_	_
of	_	_
FuseNetskip	_	_
.	_	_

#146
Additionally	_	_
,	_	_
we	_	_
experimented	_	_
with	_	_
a	_	_
FuseNet	_	_
performing	_	_
the	_	_
fusion	_	_
at	_	_
the	_	_
resolution	_	_
of	_	_
the	_	_
PAN	_	_
image	_	_
,	_	_
called	_	_
FuseNethigh	_	_
which	_	_
is	_	_
more	_	_
similar	_	_
to	_	_
pansharpening—upsampling	_	_
xMS	_	_
first	_	_
before	_	_
fusing	_	_
them	_	_
with	_	_
xPAN	_	_
.	_	_

#147
Tables	_	_
I	_	_
and	_	_
II	_	_
show	_	_
details	_	_
of	_	_
the	_	_
operations	_	_
,	_	_
including	_	_
dimensions	_	_
of	_	_
intermediate	_	_
output	_	_
feature	_	_
maps	_	_
,	_	_
used	_	_
by	_	_
the	_	_
FuseNet	_	_
variants	_	_
.	_	_

#148
The	_	_
format	_	_
is	_	_
adapted	_	_
from	_	_
[	_	_
29	_	_
]	_	_
.	_	_

#149
xPAN	_	_
and	_	_
xMS	_	_
denote	_	_
input	_	_
patches	_	_
from	_	_
the	_	_
PAN	_	_
and	_	_
MS	_	_
images	_	_
respectively	_	_
.	_	_

#150
IFM	_	_
and	_	_
BFM	_	_
correspond	_	_
to	_	_
intermediate	_	_
and	_	_
bottleneck	_	_
feature	_	_
maps	_	_
.	_	_

#151
Convolutions	_	_
are	_	_
denoted	_	_
as	_	_
“conv〈kernel	_	_
size	_	_
G〉-〈number	_	_
of	_	_
kernels	_	_
K〉”	_	_
.	_	_

#152
Maximum	_	_
pooling	_	_
operations	_	_
(	_	_
maxpool	_	_
)	_	_
are	_	_
fixed	_	_
to	_	_
have	_	_
pooling	_	_
size	_	_
Gp	_	_
and	_	_
stride	_	_
Sp	_	_
equal	_	_
to	_	_
two	_	_
.	_	_

#153
Upsampling	_	_
operations	_	_
are	_	_
denoted	_	_
as	_	_
“ups〈number	_	_
of	_	_
kernels	_	_
K〉-〈upsampling	_	_
factor〉”	_	_
.	_	_

#154
Merging	_	_
operations	_	_
are	_	_
denoted	_	_
as	_	_
concat	_	_
for	_	_
concatenation	_	_
and	_	_
add	_	_
for	_	_
addition	_	_
.	_	_

#155
Fixed	_	_
upsampling	_	_
can	_	_
either	_	_
be	_	_
via	_	_
pansharpening	_	_
or	_	_
bilinear	_	_
interpolation	_	_
.	_	_

#156
Consecutive	_	_
Batch	_	_
Normalization	_	_
[	_	_
30	_	_
]	_	_
and	_	_
exponential	_	_
linear	_	_
activation	_	_
[	_	_
24	_	_
]	_	_
operations	_	_
between	_	_
convolutions	_	_
and	_	_
pooling	_	_
are	_	_
omitted	_	_
for	_	_
brevity	_	_
.	_	_

#157
Finally	_	_
,	_	_
operations	_	_
shared	_	_
by	_	_
separate	_	_
streams	_	_
of	_	_
feature	_	_
align	_	_
with	_	_
the	_	_
columns	_	_
of	_	_
these	_	_
streams	_	_
.	_	_

#158
FuseNet	_	_
implements	_	_
a	_	_
full	_	_
patch	_	_
labeling	_	_
approach	_	_
since	_	_
it	_	_
produces	_	_
labeled	_	_
image	_	_
patches	_	_
of	_	_
the	_	_
same	_	_
dimensions	_	_
as	_	_
the	_	_
input	_	_
PAN	_	_
image	_	_
patch	_	_
.	_	_

#159
Inference	_	_
of	_	_
final	_	_
classification	_	_
map	_	_
is	_	_
given	_	_
by	_	_
Equation	_	_
6	_	_
and	_	_
can	_	_
be	_	_
applied	_	_
to	_	_
an	_	_
input	_	_
image	_	_
of	_	_
variable	_	_
spatial	_	_
dimension	_	_
.	_	_

#160
Application	_	_
to	_	_
input	_	_
of	_	_
variable	_	_
size	_	_
is	_	_
made	_	_
possible	_	_
by	_	_
the	_	_
fully-convolutional	_	_
nature	_	_
of	_	_
the	_	_
network	_	_
[	_	_
25	_	_
]	_	_
—allowing	_	_
it	_	_
to	_	_
be	_	_
applied	_	_
as	_	_
an	_	_
image	_	_
filter	_	_
[	_	_
13	_	_
]	_	_
IEEE	_	_
TRANSACTIONS	_	_
ON	_	_
GEOSCIENCE	_	_
AND	_	_
REMOTE	_	_
SENSING	_	_
,	_	_
VOL	_	_
.	_	_

#161
X	_	_
,	_	_
NO	_	_
.	_	_

#162
X	_	_
,	_	_
MONTH	_	_
2017	_	_
5	_	_
Fig.	_	_
2	_	_
.	_	_

#163
The	_	_
general	_	_
architecture	_	_
of	_	_
FuseNet	_	_
with	_	_
skip	_	_
connections	_	_
(	_	_
FuseNetskip	_	_
)	_	_
.	_	_

#164
FuseNet	_	_
accepts	_	_
two	_	_
streams	_	_
of	_	_
input	_	_
:	_	_
one	_	_
from	_	_
PAN	_	_
image	_	_
patches	_	_
and	_	_
another	_	_
from	_	_
MS	_	_
image	_	_
patches	_	_
.	_	_

#165
It	_	_
applies	_	_
convolutional	_	_
and	_	_
pooling	_	_
layers	_	_
with	_	_
downsampling	_	_
to	_	_
extract	_	_
spatial	_	_
features	_	_
and	_	_
at	_	_
the	_	_
same	_	_
time	_	_
match	_	_
the	_	_
resolution	_	_
of	_	_
the	_	_
two	_	_
streams	_	_
of	_	_
input	_	_
.	_	_

#166
Similar	_	_
operations	_	_
are	_	_
performed	_	_
to	_	_
the	_	_
output	_	_
of	_	_
the	_	_
merged	_	_
streams	_	_
of	_	_
input	_	_
arriving	_	_
at	_	_
a	_	_
feature	_	_
map	_	_
with	_	_
smallest	_	_
spatial	_	_
dimensions	_	_
(	_	_
bottleneck	_	_
)	_	_
.	_	_

#167
From	_	_
there	_	_
,	_	_
upsampling	_	_
operations	_	_
using	_	_
transposed	_	_
convolutions	_	_
are	_	_
performed	_	_
to	_	_
restore	_	_
the	_	_
resolution	_	_
back	_	_
to	_	_
the	_	_
resolution	_	_
of	_	_
the	_	_
PAN	_	_
image	_	_
patches	_	_
.	_	_

#168
Skip	_	_
connections	_	_
are	_	_
implemented	_	_
using	_	_
appropriate	_	_
upsampling	_	_
and	_	_
linear	_	_
projections	_	_
.	_	_

#169
TABLE	_	_
I	_	_
DETAILED	_	_
OPERATIONS	_	_
OF	_	_
FUSENETlow	_	_
,	_	_
FUSENEThigh	_	_
,	_	_
AND	_	_
FUSENETpansharp/bilinear	_	_
.	_	_

#170
FuseNetlow	_	_
FuseNethigh	_	_
Netpansharp/bilinear	_	_
xPAN	_	_
(	_	_
1×4M×4M	_	_
)	_	_
xMS	_	_
(	_	_
4×M×M	_	_
)	_	_
xPAN	_	_
(	_	_
1×4M×4M	_	_
)	_	_
xMS	_	_
(	_	_
4×M×M	_	_
)	_	_
xPAN	_	_
(	_	_
1×4M×4M	_	_
)	_	_
xMS	_	_
(	_	_
4×M×M	_	_
)	_	_
conv13-16	_	_
conv1-32	_	_
ups2-16	_	_
maxpool	_	_
ups2-8	_	_
fixed	_	_
conv7-32	_	_
conv1-4	_	_
upsampling	_	_
maxpool	_	_
IFM1	_	_
(	_	_
5×4M×4M	_	_
)	_	_
concat	_	_
concat	_	_
IFM3	_	_
(	_	_
5×4M×4M	_	_
)	_	_
IFM3	_	_
(	_	_
4×4M×4M	_	_
)	_	_
conv13-16	_	_
IFM1	_	_
(	_	_
32×M×M	_	_
)	_	_
IFM2	_	_
(	_	_
32×M×M	_	_
)	_	_
maxpool	_	_
concat	_	_
conv32-7	_	_
IFM3	_	_
(	_	_
64×M×M	_	_
)	_	_
maxpool	_	_
conv3-64	_	_
maxpool	_	_
conv3-128	_	_
maxpool	_	_
BFM	_	_
(	_	_
128×M	_	_
/4×M	_	_
/4	_	_
)	_	_
ups2-128	_	_
ups2-64	_	_
ups2-32	_	_
ups2-16	_	_
conv1-6	_	_
IFM4	_	_
(	_	_
6×4M×4M	_	_
)	_	_
softmax	_	_
to	_	_
any	_	_
input	_	_
with	_	_
spatial	_	_
dimensions	_	_
of	_	_
at	_	_
least	_	_
equal	_	_
to	_	_
the	_	_
FCN’s	_	_
effective	_	_
receptive	_	_
field	_	_
.	_	_

#171
B.	_	_
ReuseNet	_	_
ReuseNet	_	_
builds	_	_
on	_	_
top	_	_
of	_	_
the	_	_
architecture	_	_
of	_	_
FuseNet	_	_
by	_	_
incorporating	_	_
recurrent	_	_
connections	_	_
.	_	_

#172
Incorporation	_	_
of	_	_
this	_	_
recurrent	_	_
architecture	_	_
in	_	_
a	_	_
full	_	_
patch	_	_
labeling	_	_
approach	_	_
enables	_	_
the	_	_
network	_	_
to	_	_
learn	_	_
contextual	_	_
label-to-label	_	_
dependencies	_	_
by	_	_
feeding	_	_
output	_	_
score	_	_
maps	_	_
of	_	_
a	_	_
FuseNet	_	_
instance	_	_
to	_	_
another	_	_
instance	_	_
of	_	_
itself	_	_
as	_	_
an	_	_
input	_	_
.	_	_

#173
Such	_	_
dependencies	_	_
are	_	_
similar	_	_
to	_	_
what	_	_
graphical	_	_
model	_	_
(	_	_
e.g.	_	_
CRF/MRF	_	_
)	_	_
based	_	_
methods	_	_
learn	_	_
in	_	_
a	_	_
post-classification	_	_
regularization	_	_
inference	_	_
.	_	_

#174
For	_	_
instance	_	_
,	_	_
a	_	_
fully-connected	_	_
CRF	_	_
[	_	_
31	_	_
]	_	_
solves	_	_
an	_	_
energy	_	_
function	_	_
that	_	_
penalizes	_	_
label	_	_
configurations	_	_
based	_	_
on	_	_
a	_	_
unary	_	_
term	_	_
,	_	_
often	_	_
IEEE	_	_
TRANSACTIONS	_	_
ON	_	_
GEOSCIENCE	_	_
AND	_	_
REMOTE	_	_
SENSING	_	_
,	_	_
VOL	_	_
.	_	_

#175
X	_	_
,	_	_
NO	_	_
.	_	_

#176
X	_	_
,	_	_
MONTH	_	_
2017	_	_
6	_	_
TABLE	_	_
II	_	_
DETAILED	_	_
OPERATIONS	_	_
OF	_	_
FUSENETskip	_	_
.	_	_

#177
FuseNetskip	_	_
xPAN	_	_
(	_	_
1×4M×4M	_	_
)	_	_
xMS	_	_
(	_	_
4×M×M	_	_
)	_	_
Skip-connected	_	_
layers	_	_
conv13-16	_	_
conv1-32	_	_
maxpool	_	_
conv7-32	_	_
maxpool	_	_
IFM1	_	_
(	_	_
32×M×M	_	_
)	_	_
IFM2	_	_
(	_	_
32×M×M	_	_
)	_	_
concat	_	_
IFM3	_	_
(	_	_
64×M×M	_	_
)	_	_
conv3-64	_	_
maxpool	_	_
conv3-128	_	_
maxpool	_	_
BFM	_	_
(	_	_
128×M	_	_
/4×M	_	_
/4	_	_
)	_	_
ups2-128	_	_
ups2-64	_	_
ups2-32	_	_
ups2-16	_	_
IFM1	_	_
IFM5	_	_
conv1-6	_	_
ups6-4	_	_
ups6-8	_	_
IFM6	_	_
(	_	_
6×4M×4M	_	_
)	_	_
IFM7	_	_
(	_	_
6×4M×4M	_	_
)	_	_
IFM8	_	_
(	_	_
6×4M×4M	_	_
)	_	_
add	_	_
IFM4	_	_
(	_	_
6×4M×4M	_	_
)	_	_
softmax	_	_
Fig.	_	_
3	_	_
.	_	_

#178
The	_	_
general	_	_
architecture	_	_
of	_	_
ReuseNet	_	_
with	_	_
R	_	_
FuseNet+	_	_
instances	_	_
.	_	_

#179
FuseNet+	_	_
employs	_	_
exactly	_	_
the	_	_
same	_	_
operations	_	_
as	_	_
FuseNet	_	_
except	_	_
for	_	_
the	_	_
first	_	_
layer	_	_
applying	_	_
additional	_	_
sets	_	_
of	_	_
convolutional	_	_
filters	_	_
on	_	_
the	_	_
input	_	_
score	_	_
maps	_	_
.	_	_

#180
ReuseNet	_	_
accepts	_	_
three	_	_
streams	_	_
of	_	_
input	_	_
:	_	_
1	_	_
)	_	_
xPAN	_	_
,	_	_
2	_	_
)	_	_
xMS	_	_
,	_	_
and	_	_
3	_	_
)	_	_
score	_	_
maps	_	_
of	_	_
the	_	_
same	_	_
resolution	_	_
as	_	_
xPAN	_	_
.	_	_

#181
It	_	_
applies	_	_
the	_	_
same	_	_
operations	_	_
employed	_	_
by	_	_
a	_	_
FuseNet	_	_
in	_	_
R	_	_
cycles	_	_
,	_	_
taking	_	_
the	_	_
output	_	_
score	_	_
map	_	_
of	_	_
the	_	_
previous	_	_
cycle	_	_
as	_	_
an	_	_
input	_	_
.	_	_

#182
taken	_	_
as	_	_
the	_	_
negative	_	_
logarithm	_	_
of	_	_
the	_	_
class	_	_
scores	_	_
[	_	_
10	_	_
]	_	_
,	_	_
and	_	_
a	_	_
pairwise	_	_
term	_	_
,	_	_
adding	_	_
a	_	_
penalization	_	_
for	_	_
pixels	_	_
with	_	_
different	_	_
labels	_	_
based	_	_
on	_	_
image-space	_	_
and	_	_
feature-space	_	_
distances	_	_
.	_	_

#183
For	_	_
ease	_	_
of	_	_
notation	_	_
,	_	_
let	_	_
the	_	_
series	_	_
of	_	_
operations	_	_
performed	_	_
by	_	_
FuseNet	_	_
(	_	_
Equation	_	_
8	_	_
)	_	_
be	_	_
given	_	_
by	_	_
the	_	_
function	_	_
f	_	_
:	_	_
y	_	_
=	_	_
f	_	_
(	_	_
xPAN	_	_
,	_	_
xMS	_	_
)	_	_
(	_	_
9	_	_
)	_	_
where	_	_
the	_	_
x’s	_	_
are	_	_
the	_	_
input	_	_
of	_	_
FuseNet	_	_
,	_	_
and	_	_
y	_	_
is	_	_
the	_	_
class	_	_
score	_	_
map	_	_
resulting	_	_
from	_	_
this	_	_
input	_	_
.	_	_

#184
The	_	_
operations	_	_
performed	_	_
by	_	_
ReuseNet	_	_
are	_	_
given	_	_
by	_	_
a	_	_
recurrent	_	_
variant	_	_
g	_	_
:	_	_
y1	_	_
=	_	_
g	_	_
(	_	_
xPAN	_	_
⊕	_	_
y0	_	_
,	_	_
xMS	_	_
)	_	_
(	_	_
10a	_	_
)	_	_
yr	_	_
=	_	_
g	_	_
(	_	_
xPAN	_	_
⊕	_	_
yr−1	_	_
,	_	_
xMS	_	_
)	_	_
(	_	_
10b	_	_
)	_	_
where	_	_
the	_	_
r	_	_
score	_	_
map	_	_
is	_	_
obtained	_	_
by	_	_
applying	_	_
the	_	_
same	_	_
function	_	_
to	_	_
a	_	_
combination	_	_
of	_	_
the	_	_
previous	_	_
r	_	_
−	_	_
1	_	_
score	_	_
map	_	_
and	_	_
the	_	_
original	_	_
FuseNet	_	_
input	_	_
as	_	_
a	_	_
new	_	_
input	_	_
.	_	_

#185
The	_	_
recurrent	_	_
variant	_	_
g	_	_
(	_	_
denoted	_	_
as	_	_
FuseNet+	_	_
in	_	_
Figure	_	_
3	_	_
)	_	_
applies	_	_
exactly	_	_
the	_	_
same	_	_
operations	_	_
as	_	_
f	_	_
except	_	_
for	_	_
the	_	_
first	_	_
operation	_	_
that	_	_
instead	_	_
of	_	_
only	_	_
taking	_	_
xPAN	_	_
as	_	_
an	_	_
input	_	_
,	_	_
this	_	_
operation	_	_
takes	_	_
the	_	_
concatenation	_	_
of	_	_
xPAN	_	_
and	_	_
a	_	_
class	_	_
score	_	_
map	_	_
yr	_	_
associated	_	_
to	_	_
the	_	_
network	_	_
instance	_	_
r.	_	_
Figure	_	_
3	_	_
shows	_	_
a	_	_
diagram	_	_
illustrating	_	_
the	_	_
general	_	_
architecture	_	_
of	_	_
ReuseNet	_	_
.	_	_

#186
We	_	_
tested	_	_
ReuseNet	_	_
with	_	_
several	_	_
number	_	_
of	_	_
FuseNet	_	_
instances	_	_
(	_	_
2	_	_
,	_	_
3	_	_
,	_	_
and	_	_
4	_	_
)	_	_
,	_	_
calling	_	_
each	_	_
ReuseNet-R	_	_
where	_	_
R	_	_
is	_	_
the	_	_
number	_	_
of	_	_
FuseNet	_	_
instances	_	_
within	_	_
the	_	_
ReuseNet	_	_
.	_	_

#187
We	_	_
also	_	_
investigated	_	_
various	_	_
methods	_	_
for	_	_
initializing	_	_
weights	_	_
and	_	_
initial	_	_
score	_	_
maps	_	_
y0	_	_
of	_	_
ReuseNet	_	_
.	_	_

#188
Plain	_	_
ReuseNet	_	_
initializes	_	_
the	_	_
score	_	_
maps	_	_
with	_	_
zeros	_	_
,	_	_
while	_	_
ReuseNetmap−init	_	_
initializes	_	_
the	_	_
score	_	_
maps	_	_
using	_	_
scores	_	_
from	_	_
a	_	_
pre-trained	_	_
FuseNet	_	_
showing	_	_
the	_	_
best	_	_
results	_	_
in	_	_
the	_	_
fusion	_	_
comparison	_	_
experiments	_	_
.	_	_

#189
We	_	_
IEEE	_	_
TRANSACTIONS	_	_
ON	_	_
GEOSCIENCE	_	_
AND	_	_
REMOTE	_	_
SENSING	_	_
,	_	_
VOL	_	_
.	_	_

#190
X	_	_
,	_	_
NO	_	_
.	_	_

#191
X	_	_
,	_	_
MONTH	_	_
2017	_	_
7	_	_
further	_	_
extend	_	_
ReuseNetmap−init	_	_
by	_	_
initializing	_	_
the	_	_
weights	_	_
of	_	_
the	_	_
FuseNet	_	_
instance	_	_
in	_	_
the	_	_
ReuseNet	_	_
with	_	_
the	_	_
same	_	_
FuseNet	_	_
that	_	_
provides	_	_
the	_	_
initial	_	_
score	_	_
maps	_	_
.	_	_

#192
We	_	_
call	_	_
this	_	_
extension	_	_
ReuseNetmap−weights−init	_	_
.	_	_

#193
C.	_	_
Perspective	_	_
on	_	_
Learning	_	_
the	_	_
Fusion	_	_
Approach	_	_
and	_	_
Incorporating	_	_
Recurrence	_	_
Conventional	_	_
approaches	_	_
to	_	_
classify	_	_
multiresolution	_	_
images	_	_
require	_	_
a	_	_
separate	_	_
step	_	_
to	_	_
match	_	_
the	_	_
resolution	_	_
of	_	_
the	_	_
images	_	_
.	_	_

#194
One	_	_
way	_	_
is	_	_
to	_	_
spatially	_	_
sharpen	_	_
the	_	_
MS	_	_
images	_	_
using	_	_
the	_	_
PAN	_	_
image	_	_
(	_	_
also	_	_
called	_	_
pansharpening	_	_
)	_	_
[	_	_
32	_	_
]	_	_
.	_	_

#195
Another	_	_
possible	_	_
way	_	_
is	_	_
to	_	_
resample	_	_
images	_	_
to	_	_
match	_	_
a	_	_
specific	_	_
resolution	_	_
using	_	_
nearest	_	_
neighbor	_	_
or	_	_
bilinear	_	_
interpolation	_	_
.	_	_

#196
However	_	_
,	_	_
these	_	_
standard	_	_
fusion	_	_
techniques	_	_
are	_	_
performed	_	_
independently	_	_
from	_	_
the	_	_
classification	_	_
problem	_	_
and	_	_
are	_	_
suboptimal	_	_
.	_	_

#197
FuseNet	_	_
provides	_	_
a	_	_
streamlined	_	_
approach	_	_
including	_	_
the	_	_
fusion	_	_
of	_	_
the	_	_
multiresolution	_	_
images	_	_
within	_	_
the	_	_
learning	_	_
of	_	_
the	_	_
classifier	_	_
.	_	_

#198
We	_	_
expect	_	_
that	_	_
coupling	_	_
and	_	_
learning	_	_
the	_	_
fusion	_	_
method	_	_
within	_	_
a	_	_
supervised	_	_
classifier	_	_
will	_	_
outperform	_	_
an	_	_
approach	_	_
based	_	_
on	_	_
a	_	_
separate	_	_
fusion	_	_
method	_	_
.	_	_

#199
The	_	_
parameter	_	_
sharing	_	_
across	_	_
FuseNet	_	_
instances	_	_
in	_	_
a	_	_
ReuseNet	_	_
is	_	_
consistent	_	_
with	_	_
the	_	_
definition	_	_
of	_	_
a	_	_
recurrent	_	_
network	_	_
,	_	_
i.e.	_	_
a	_	_
recurrent	_	_
network	_	_
is	_	_
a	_	_
feedforward	_	_
network	_	_
that	_	_
keeps	_	_
on	_	_
reusing	_	_
the	_	_
same	_	_
set	_	_
of	_	_
weights	_	_
to	_	_
cycle	_	_
through	_	_
a	_	_
sequence	_	_
.	_	_

#200
The	_	_
authors	_	_
in	_	_
[	_	_
21	_	_
]	_	_
view	_	_
such	_	_
incorporation	_	_
of	_	_
recurrence	_	_
as	_	_
a	_	_
way	_	_
to	_	_
increase	_	_
the	_	_
contextual	_	_
window	_	_
size	_	_
,	_	_
equivalent	_	_
to	_	_
the	_	_
patch	_	_
size	_	_
M	_	_
in	_	_
a	_	_
patch	_	_
classification	_	_
approach	_	_
,	_	_
of	_	_
their	_	_
patch	_	_
classification	_	_
based	_	_
approach	_	_
while	_	_
controlling	_	_
the	_	_
capacity	_	_
of	_	_
the	_	_
network	_	_
via	_	_
inter-instance	_	_
weight	_	_
sharing	_	_
.	_	_

#201
While	_	_
both	_	_
increase	_	_
in	_	_
contextual	_	_
window	_	_
size	_	_
and	_	_
capacity	_	_
control	_	_
of	_	_
a	_	_
CNN-based	_	_
image	_	_
patch	_	_
classifier	_	_
helps	_	_
to	_	_
improve	_	_
the	_	_
latter’s	_	_
performance	_	_
,	_	_
the	_	_
first	_	_
benefit	_	_
is	_	_
lost	_	_
in	_	_
a	_	_
full	_	_
patch	_	_
labeling	_	_
approach	_	_
.	_	_

#202
In	_	_
a	_	_
fully	_	_
convolutional	_	_
network	_	_
implementing	_	_
full	_	_
patch	_	_
labeling	_	_
,	_	_
the	_	_
contextual	_	_
window	_	_
size	_	_
does	_	_
not	_	_
change	_	_
as	_	_
recurrent	_	_
operations	_	_
are	_	_
added	_	_
to	_	_
the	_	_
network	_	_
since	_	_
the	_	_
contextual	_	_
window	_	_
size	_	_
is	_	_
equivalent	_	_
to	_	_
the	_	_
effective	_	_
size	_	_
of	_	_
the	_	_
receptive	_	_
field	_	_
of	_	_
the	_	_
network	_	_
.	_	_

#203
The	_	_
effective	_	_
size	_	_
of	_	_
the	_	_
receptive	_	_
field	_	_
of	_	_
the	_	_
network	_	_
depends	_	_
on	_	_
kernel	_	_
sizes	_	_
and	_	_
strides	_	_
of	_	_
the	_	_
network’s	_	_
convolutional	_	_
and	_	_
pooling	_	_
operations	_	_
,	_	_
which	_	_
are	_	_
fixed	_	_
and	_	_
the	_	_
same	_	_
across	_	_
instances	_	_
.	_	_

#204
In	_	_
the	_	_
proposed	_	_
ReuseNet	_	_
,	_	_
recurrence	_	_
integrates	_	_
contextual	_	_
label	_	_
information	_	_
to	_	_
our	_	_
model	_	_
by	_	_
considering	_	_
class	_	_
score	_	_
maps	_	_
as	_	_
inputs	_	_
to	_	_
each	_	_
FuseNet	_	_
instance	_	_
.	_	_

#205
This	_	_
allows	_	_
the	_	_
model	_	_
to	_	_
learn	_	_
label-to-label	_	_
dependencies	_	_
in	_	_
addition	_	_
to	_	_
the	_	_
spatial	_	_
contextual	_	_
information	_	_
learned	_	_
from	_	_
the	_	_
pixel	_	_
values	_	_
,	_	_
pixel-to-label	_	_
dependencies	_	_
.	_	_

#206
This	_	_
is	_	_
a	_	_
form	_	_
of	_	_
structured	_	_
output	_	_
prediction	_	_
[	_	_
33	_	_
]	_	_
where	_	_
interdependencies	_	_
between	_	_
outputs	_	_
may	_	_
be	_	_
expressed	_	_
in	_	_
terms	_	_
of	_	_
constraints	_	_
restricting	_	_
permissible	_	_
output	_	_
combinations	_	_
or	_	_
a	_	_
more	_	_
flexible	_	_
form	_	_
such	_	_
as	_	_
spatial	_	_
dependencies	_	_
across	_	_
different	_	_
output	_	_
variables	_	_
.	_	_

#207
Graphical	_	_
models	_	_
such	_	_
as	_	_
conditional	_	_
random	_	_
fields	_	_
[	_	_
34	_	_
]	_	_
are	_	_
commonly	_	_
used	_	_
for	_	_
such	_	_
structured	_	_
prediction	_	_
tasks	_	_
.	_	_

#208
ReuseNet	_	_
uses	_	_
operations	_	_
in	_	_
a	_	_
deep	_	_
convolutional	_	_
network	_	_
to	_	_
learn	_	_
features	_	_
from	_	_
both	_	_
the	_	_
input	_	_
image	_	_
and	_	_
class	_	_
scores—integrating	_	_
the	_	_
learning	_	_
of	_	_
label-to-label	_	_
dependencies	_	_
from	_	_
the	_	_
data	_	_
instead	_	_
of	_	_
explicit	_	_
image-space	_	_
and	_	_
feature-space	_	_
distances	_	_
as	_	_
represented	_	_
in	_	_
a	_	_
Fig.	_	_
4	_	_
.	_	_

#209
Figure	_	_
showing	_	_
the	_	_
true	_	_
color	_	_
VHR	_	_
image	_	_
together	_	_
with	_	_
the	_	_
locations	_	_
of	_	_
the	_	_
labeled	_	_
tiles	_	_
(	_	_
in	_	_
blue	_	_
squares	_	_
)	_	_
and	_	_
the	_	_
study	_	_
area	_	_
:	_	_
Quezon	_	_
City	_	_
,	_	_
Philippines	_	_
.	_	_

#210
TABLE	_	_
III	_	_
NUMBER	_	_
OF	_	_
LABELED	_	_
PIXELS	_	_
IN	_	_
EACH	_	_
TILE	_	_
Tile	_	_
Number	_	_
of	_	_
labeled	_	_
pixels	_	_
Set	_	_
100	_	_
2178768	_	_
Training	_	_
105	_	_
2173602	_	_
Training	_	_
45	_	_
2063971	_	_
Validation	_	_
78	_	_
1977336	_	_
Test	_	_
82	_	_
1961955	_	_
Test	_	_
pairwise	_	_
potential	_	_
of	_	_
CRF	_	_
.	_	_

#211
This	_	_
allows	_	_
ReuseNet	_	_
to	_	_
be	_	_
trained	_	_
end-to-end	_	_
as	_	_
opposed	_	_
to	_	_
a	_	_
two-stage	_	_
approach	_	_
applying	_	_
a	_	_
post-classification	_	_
MRF/CRF	_	_
as	_	_
done	_	_
in	_	_
[	_	_
35	_	_
]	_	_
and	_	_
[	_	_
13	_	_
]	_	_
.	_	_

#212
IV	_	_
.	_	_

#213
DATA	_	_
AND	_	_
EXPERIMENTAL	_	_
SETUP	_	_
A.	_	_
Dataset	_	_
Description	_	_
1	_	_
)	_	_
Worldview-03	_	_
Quezon	_	_
City	_	_
dataset	_	_
:	_	_
we	_	_
evaluated	_	_
the	_	_
proposed	_	_
networks	_	_
in	_	_
the	_	_
land	_	_
cover	_	_
classification	_	_
of	_	_
a	_	_
dataset	_	_
covering	_	_
Quezon	_	_
City	_	_
,	_	_
Philippines	_	_
.	_	_

#214
The	_	_
dataset	_	_
is	_	_
composed	_	_
of	_	_
a	_	_
Worldview-03	_	_
satellite	_	_
image	_	_
of	_	_
the	_	_
city	_	_
acquired	_	_
on	_	_
17th	_	_
April	_	_
2016	_	_
and	_	_
corresponding	_	_
manually	_	_
prepared	_	_
reference	_	_
images	_	_
for	_	_
five	_	_
chosen	_	_
tiles	_	_
(	_	_
subsets	_	_
)	_	_
of	_	_
the	_	_
satellite	_	_
image	_	_
.	_	_

#215
The	_	_
satellite	_	_
image	_	_
has	_	_
a	_	_
PAN	_	_
band	_	_
of	_	_
0.3	_	_
m	_	_
resolution	_	_
and	_	_
four	_	_
MS	_	_
bands	_	_
(	_	_
near-infrared	_	_
,	_	_
red	_	_
,	_	_
green	_	_
,	_	_
and	_	_
blue	_	_
)	_	_
of	_	_
1.2	_	_
m	_	_
resolution	_	_
.	_	_

#216
Reference	_	_
images	_	_
were	_	_
prepared	_	_
via	_	_
photointerpretation	_	_
and	_	_
set	_	_
to	_	_
have	_	_
the	_	_
same	_	_
spatial	_	_
resolution	_	_
as	_	_
the	_	_
PAN	_	_
image	_	_
.	_	_

#217
The	_	_
whole	_	_
satellite	_	_
image	_	_
was	_	_
first	_	_
divided	_	_
into	_	_
regularly-sized	_	_
image	_	_
tiles	_	_
.	_	_

#218
PAN	_	_
image	_	_
tiles	_	_
have	_	_
a	_	_
dimension	_	_
of	_	_
3200	_	_
pixels	_	_
×	_	_
3200	_	_
pixels	_	_
,	_	_
while	_	_
MS	_	_
image	_	_
tiles	_	_
have	_	_
a	_	_
dimension	_	_
of	_	_
800	_	_
pixels	_	_
×	_	_
800	_	_
pixels	_	_
.	_	_

#219
Five	_	_
non-adjacent	_	_
tiles	_	_
were	_	_
sparsely	_	_
labeled—annotating	_	_
a	_	_
pixel	_	_
with	_	_
a	_	_
label	_	_
belonging	_	_
to	_	_
one	_	_
of	_	_
the	_	_
following	_	_
six	_	_
classes	_	_
:	_	_
impervious	_	_
surface	_	_
,	_	_
building	_	_
,	_	_
low	_	_
vegetation	_	_
,	_	_
tree	_	_
,	_	_
car	_	_
,	_	_
and	_	_
clutter	_	_
.	_	_

#220
Two	_	_
of	_	_
the	_	_
five	_	_
labeled	_	_
tiles	_	_
were	_	_
used	_	_
for	_	_
training	_	_
(	_	_
100	_	_
and	_	_
105	_	_
)	_	_
,	_	_
one	_	_
for	_	_
validation	_	_
(	_	_
45	_	_
)	_	_
,	_	_
and	_	_
the	_	_
remaining	_	_
two	_	_
for	_	_
testing	_	_
(	_	_
78	_	_
and	_	_
82	_	_
)	_	_
.	_	_

#221
Training	_	_
samples	_	_
are	_	_
composed	_	_
of	_	_
pairs	_	_
of	_	_
image	_	_
patches	_	_
with	_	_
dimensions	_	_
M×M	_	_
(	_	_
taken	_	_
from	_	_
the	_	_
MS	_	_
image	_	_
)	_	_
and	_	_
4M×4M	_	_
(	_	_
taken	_	_
from	_	_
the	_	_
PAN	_	_
image	_	_
tile	_	_
)	_	_
.	_	_

#222
Figure	_	_
4	_	_
shows	_	_
the	_	_
VHR	_	_
image	_	_
and	_	_
the	_	_
corresponding	_	_
locations	_	_
of	_	_
labeled	_	_
tiles	_	_
IEEE	_	_
TRANSACTIONS	_	_
ON	_	_
GEOSCIENCE	_	_
AND	_	_
REMOTE	_	_
SENSING	_	_
,	_	_
VOL	_	_
.	_	_

#223
X	_	_
,	_	_
NO	_	_
.	_	_

#224
X	_	_
,	_	_
MONTH	_	_
2017	_	_
8	_	_
in	_	_
the	_	_
study	_	_
area	_	_
while	_	_
Table	_	_
III	_	_
shows	_	_
the	_	_
number	_	_
of	_	_
labeled	_	_
pixels	_	_
in	_	_
each	_	_
image	_	_
tile	_	_
.	_	_

#225
Training	_	_
samples	_	_
were	_	_
normalized	_	_
to	_	_
have	_	_
a	_	_
value	_	_
between	_	_
zero	_	_
and	_	_
one	_	_
.	_	_

#226
The	_	_
reference	_	_
image	_	_
patches	_	_
have	_	_
been	_	_
converted	_	_
into	_	_
a	_	_
“one-hot”	_	_
encoding—a	_	_
vector	_	_
having	_	_
zero	_	_
values	_	_
except	_	_
for	_	_
the	_	_
index	_	_
corresponding	_	_
to	_	_
the	_	_
code	_	_
of	_	_
the	_	_
class	_	_
.	_	_

#227
2	_	_
)	_	_
ISPRS	_	_
Vaihingen	_	_
dataset	_	_
:	_	_
for	_	_
the	_	_
ReuseNet	_	_
experiments	_	_
,	_	_
we	_	_
utilized	_	_
the	_	_
ISPRS	_	_
2D	_	_
semantic	_	_
labeling	_	_
benchmark	_	_
dataset	_	_
of	_	_
Vaihingen	_	_
as	_	_
an	_	_
additional	_	_
dataset	_	_
[	_	_
36	_	_
]	_	_
.	_	_

#228
We	_	_
adopted	_	_
the	_	_
experimental	_	_
setup	_	_
used	_	_
in	_	_
[	_	_
13	_	_
]	_	_
,	_	_
[	_	_
16	_	_
]	_	_
,	_	_
employing	_	_
the	_	_
same	_	_
training	_	_
and	_	_
validation	_	_
tiles	_	_
,	_	_
to	_	_
provide	_	_
comparable	_	_
results	_	_
.	_	_

#229
We	_	_
followed	_	_
the	_	_
sampling	_	_
done	_	_
in	_	_
[	_	_
13	_	_
]	_	_
,	_	_
except	_	_
that	_	_
data	_	_
augmentation	_	_
was	_	_
not	_	_
applied—resulting	_	_
in	_	_
less	_	_
training	_	_
samples	_	_
.	_	_

#230
The	_	_
method	_	_
discussed	_	_
in	_	_
[	_	_
37	_	_
]	_	_
was	_	_
employed	_	_
to	_	_
extract	_	_
the	_	_
normalized	_	_
DSM	_	_
.	_	_

#231
B	_	_
.	_	_

#232
Comparison	_	_
of	_	_
methods	_	_
For	_	_
the	_	_
image	_	_
fusion	_	_
part	_	_
,	_	_
we	_	_
compared	_	_
FuseNet	_	_
against	_	_
two	_	_
other	_	_
baseline	_	_
approaches	_	_
:	_	_
one	_	_
using	_	_
pansherpening	_	_
and	_	_
another	_	_
using	_	_
bilinear	_	_
interpolation	_	_
to	_	_
match	_	_
the	_	_
resolution	_	_
of	_	_
xMS	_	_
to	_	_
the	_	_
resolution	_	_
of	_	_
xPAN	_	_
.	_	_

#233
We	_	_
call	_	_
these	_	_
two	_	_
baseline	_	_
approaches	_	_
Netpansharp	_	_
and	_	_
Netbilinear	_	_
.	_	_

#234
Netpansharp	_	_
applies	_	_
Gram-Schmidt	_	_
pansharpening	_	_
technique	_	_
[	_	_
38	_	_
]	_	_
.	_	_

#235
Only	_	_
the	_	_
pansharpened	_	_
image	_	_
is	_	_
fed	_	_
as	_	_
an	_	_
input	_	_
to	_	_
Netpansharp	_	_
.	_	_

#236
Netbilinear	_	_
upsamples	_	_
the	_	_
resolution	_	_
of	_	_
the	_	_
MS	_	_
image	_	_
to	_	_
match	_	_
the	_	_
resolution	_	_
of	_	_
the	_	_
PAN	_	_
image	_	_
using	_	_
bilinear	_	_
interpolation	_	_
.	_	_

#237
The	_	_
upsampled	_	_
MS	_	_
images	_	_
are	_	_
then	_	_
merged	_	_
to	_	_
the	_	_
PAN	_	_
image	_	_
using	_	_
concatenation	_	_
.	_	_

#238
The	_	_
architecture	_	_
of	_	_
the	_	_
network	_	_
after	_	_
the	_	_
fusion	_	_
is	_	_
kept	_	_
the	_	_
same	_	_
to	_	_
have	_	_
a	_	_
fair	_	_
comparison	_	_
among	_	_
the	_	_
different	_	_
approaches	_	_
(	_	_
see	_	_
details	_	_
of	_	_
the	_	_
FuseNet	_	_
variants	_	_
in	_	_
Table	_	_
I	_	_
)	_	_
.	_	_

#239
Additionally	_	_
,	_	_
we	_	_
compared	_	_
a	_	_
SegNet	_	_
[	_	_
26	_	_
]	_	_
trained	_	_
on	_	_
the	_	_
first	_	_
three	_	_
principal	_	_
components	_	_
of	_	_
the	_	_
pansharpened	_	_
image	_	_
,	_	_
since	_	_
SegNet	_	_
only	_	_
accepts	_	_
three	_	_
inputs	_	_
.	_	_

#240
We	_	_
found	_	_
that	_	_
discarding	_	_
one	_	_
band	_	_
(	_	_
NIR	_	_
)	_	_
considerably	_	_
degrades	_	_
the	_	_
results	_	_
.	_	_

#241
We	_	_
compared	_	_
ReuseNet	_	_
against	_	_
FuseNet	_	_
using	_	_
fully-connected	_	_
CRF	_	_
[	_	_
31	_	_
]	_	_
(	_	_
FuseNet+CRF	_	_
)	_	_
to	_	_
assess	_	_
the	_	_
capability	_	_
of	_	_
our	_	_
classifiers	_	_
to	_	_
spatially	_	_
regularize	_	_
the	_	_
classification	_	_
results	_	_
.	_	_

#242
The	_	_
FuseNet+CRF	_	_
baseline	_	_
is	_	_
similar	_	_
to	_	_
the	_	_
approach	_	_
adopted	_	_
in	_	_
[	_	_
10	_	_
]	_	_
,	_	_
[	_	_
13	_	_
]	_	_
but	_	_
applied	_	_
to	_	_
PAN	_	_
and	_	_
MS	_	_
images	_	_
with	_	_
different	_	_
spatial	_	_
resolutions	_	_
.	_	_

#243
Spatial	_	_
and	_	_
feature	_	_
space	_	_
distances	_	_
in	_	_
the	_	_
pairwise	_	_
potentials	_	_
of	_	_
the	_	_
fully-connected	_	_
CRF	_	_
are	_	_
computed	_	_
from	_	_
the	_	_
PAN	_	_
image	_	_
.	_	_

#244
We	_	_
performed	_	_
a	_	_
grid-search	_	_
of	_	_
the	_	_
CRF	_	_
parameters	_	_
,	_	_
i.e.	_	_
the	_	_
weights	_	_
and	_	_
standard	_	_
deviations	_	_
of	_	_
the	_	_
appearance	_	_
and	_	_
smoothness	_	_
kernels	_	_
,	_	_
and	_	_
used	_	_
the	_	_
set	_	_
of	_	_
the	_	_
parameters	_	_
with	_	_
the	_	_
highest	_	_
accuracy	_	_
on	_	_
the	_	_
validation	_	_
tile	_	_
.	_	_

#245
We	_	_
fixed	_	_
the	_	_
number	_	_
of	_	_
iterations	_	_
to	_	_
10	_	_
for	_	_
the	_	_
mean	_	_
field	_	_
approximation	_	_
algorithm	_	_
used	_	_
to	_	_
perform	_	_
inference	_	_
in	_	_
a	_	_
fully-connected	_	_
CRF	_	_
.	_	_

#246
We	_	_
also	_	_
performed	_	_
a	_	_
sensitivity	_	_
analysis	_	_
of	_	_
a	_	_
few	_	_
chosen	_	_
hyperparameters	_	_
of	_	_
FuseNetlow	_	_
.	_	_

#247
We	_	_
varied	_	_
the	_	_
bottleneck	_	_
feature	_	_
map	_	_
dimensions	_	_
,	_	_
number	_	_
of	_	_
convolutional	_	_
layers	_	_
(	_	_
in	_	_
the	_	_
downsampling	_	_
part	_	_
of	_	_
the	_	_
network	_	_
)	_	_
,	_	_
input	_	_
patch	_	_
sizes	_	_
,	_	_
and	_	_
upsampling	_	_
methods—performing	_	_
the	_	_
experiments	_	_
in	_	_
this	_	_
order	_	_
.	_	_

#248
We	_	_
took	_	_
the	_	_
hyperparameter	_	_
value	_	_
that	_	_
maximizes	_	_
the	_	_
overall	_	_
accuracy	_	_
on	_	_
the	_	_
validation	_	_
tile	_	_
and	_	_
fix	_	_
it	_	_
for	_	_
the	_	_
succeeding	_	_
sets	_	_
of	_	_
experiments	_	_
.	_	_

#249
We	_	_
experimented	_	_
using	_	_
bottleneck	_	_
feature	_	_
map	_	_
dimensions	_	_
:	_	_
16×16	_	_
,	_	_
8×8	_	_
,	_	_
4×4	_	_
,	_	_
2×2	_	_
,	_	_
and	_	_
1×	_	_
1	_	_
.	_	_

#250
After	_	_
fixing	_	_
the	_	_
bottleneck	_	_
feature	_	_
map	_	_
dimension	_	_
,	_	_
we	_	_
increased	_	_
the	_	_
number	_	_
of	_	_
convolutional	_	_
layers	_	_
preceding	_	_
the	_	_
last	_	_
downsampling	_	_
operation—effectively	_	_
increasing	_	_
the	_	_
number	_	_
of	_	_
convolutional	_	_
layers	_	_
from	_	_
8	_	_
to	_	_
14	_	_
in	_	_
steps	_	_
of	_	_
two	_	_
.	_	_

#251
We	_	_
investigated	_	_
varying	_	_
patch	_	_
sizes	_	_
of	_	_
(	_	_
4M	_	_
,	_	_
M	_	_
)	_	_
:	_	_
(	_	_
32	_	_
,	_	_
8	_	_
)	_	_
,	_	_
(	_	_
64	_	_
,	_	_
16	_	_
)	_	_
,	_	_
(	_	_
96	_	_
,	_	_
24	_	_
)	_	_
,	_	_
(	_	_
128	_	_
,	_	_
32	_	_
)	_	_
.	_	_

#252
For	_	_
the	_	_
upsampling	_	_
operations	_	_
,	_	_
we	_	_
explored	_	_
two	_	_
additional	_	_
methods	_	_
using	_	_
nearest	_	_
neighbor	_	_
and	_	_
bilinear	_	_
interpolation	_	_
to	_	_
upsample	_	_
the	_	_
feature	_	_
map	_	_
and	_	_
then	_	_
performing	_	_
3×3	_	_
convolutions	_	_
after	_	_
each	_	_
upsampling	_	_
operation	_	_
.	_	_

#253
We	_	_
trained	_	_
all	_	_
the	_	_
networks	_	_
using	_	_
a	_	_
set	_	_
of	_	_
17409	_	_
image	_	_
patches	_	_
taken	_	_
from	_	_
the	_	_
training	_	_
tiles	_	_
and	_	_
used	_	_
8255	_	_
image	_	_
patches	_	_
taken	_	_
from	_	_
the	_	_
validation	_	_
tile	_	_
for	_	_
early-stopping	_	_
.	_	_

#254
We	_	_
performed	_	_
a	_	_
random	_	_
sampling	_	_
with	_	_
the	_	_
constraint	_	_
that	_	_
the	_	_
pixel	_	_
near	_	_
the	_	_
center	_	_
of	_	_
the	_	_
image	_	_
patch	_	_
is	_	_
labeled	_	_
.	_	_

#255
This	_	_
may	_	_
produce	_	_
overlapping	_	_
patches	_	_
unlike	_	_
the	_	_
systematic	_	_
gridwise	_	_
sampling	_	_
approach	_	_
used	_	_
in	_	_
[	_	_
13	_	_
]	_	_
.	_	_

#256
Gridwise	_	_
sampling	_	_
reduces	_	_
the	_	_
number	_	_
of	_	_
training	_	_
patches	_	_
since	_	_
the	_	_
reference	_	_
images	_	_
is	_	_
sparsely	_	_
labeled	_	_
,	_	_
only	_	_
around	_	_
five	_	_
percent	_	_
of	_	_
the	_	_
pixels	_	_
are	_	_
labeled	_	_
.	_	_

#257
The	_	_
total	_	_
loss	_	_
value	_	_
computed	_	_
over	_	_
a	_	_
mini-batch	_	_
is	_	_
the	_	_
total	_	_
loss	_	_
of	_	_
all	_	_
pixels	_	_
divided	_	_
by	_	_
the	_	_
number	_	_
of	_	_
labeled	_	_
pixels	_	_
within	_	_
the	_	_
mini-batch	_	_
.	_	_

#258
The	_	_
FuseNets	_	_
are	_	_
trained	_	_
using	_	_
backpropagation	_	_
with	_	_
stochastic	_	_
gradient	_	_
descent	_	_
setting	_	_
the	_	_
initial	_	_
learning	_	_
rate	_	_
η	_	_
=	_	_
0.01	_	_
,	_	_
momentum	_	_
α	_	_
=	_	_
0.9	_	_
,	_	_
mini-batch	_	_
size	_	_
N	_	_
=	_	_
32	_	_
,	_	_
and	_	_
maximum	_	_
number	_	_
of	_	_
epochs	_	_
T	_	_
=	_	_
240	_	_
.	_	_

#259
We	_	_
decrease	_	_
the	_	_
learning	_	_
rate	_	_
in	_	_
a	_	_
stepwise	_	_
manner	_	_
as	_	_
done	_	_
in	_	_
[	_	_
39	_	_
]	_	_
—	_	_
multiplying	_	_
it	_	_
by	_	_
a	_	_
factor	_	_
of	_	_
0.1	_	_
after	_	_
60	_	_
and	_	_
180	_	_
epochs	_	_
.	_	_

#260
The	_	_
weights	_	_
were	_	_
initialized	_	_
as	_	_
in	_	_
[	_	_
40	_	_
]	_	_
.	_	_

#261
We	_	_
did	_	_
not	_	_
find	_	_
dropout	_	_
to	_	_
be	_	_
helpful	_	_
;	_	_
hence	_	_
,	_	_
we	_	_
only	_	_
used	_	_
an	_	_
l2	_	_
-weight	_	_
decay	_	_
penalty—setting	_	_
λ	_	_
=	_	_
0.001—and	_	_
a	_	_
variant	_	_
of	_	_
early-stopping	_	_
to	_	_
regularize	_	_
FuseNet	_	_
.	_	_

#262
For	_	_
early	_	_
stopping	_	_
,	_	_
the	_	_
classification	_	_
accuracy	_	_
on	_	_
the	_	_
validation	_	_
set	_	_
is	_	_
calculated	_	_
every	_	_
epoch	_	_
and	_	_
the	_	_
last	_	_
model	_	_
with	_	_
the	_	_
best	_	_
validation	_	_
accuracy	_	_
is	_	_
fixed	_	_
to	_	_
be	_	_
the	_	_
final	_	_
instance	_	_
of	_	_
the	_	_
model	_	_
.	_	_

#263
The	_	_
FuseNet	_	_
instances	_	_
within	_	_
a	_	_
ReuseNet	_	_
are	_	_
identical	_	_
,	_	_
sharing	_	_
the	_	_
same	_	_
network	_	_
configuration	_	_
and	_	_
parameters	_	_
.	_	_

#264
Each	_	_
instance	_	_
also	_	_
couples	_	_
a	_	_
cross-entropy	_	_
loss	_	_
function	_	_
with	_	_
each	_	_
of	_	_
their	_	_
score	_	_
map	_	_
.	_	_

#265
The	_	_
total	_	_
objective	_	_
loss	_	_
of	_	_
a	_	_
ReuseNet	_	_
is	_	_
the	_	_
average	_	_
of	_	_
the	_	_
cross-entropy	_	_
loss	_	_
values	_	_
from	_	_
all	_	_
the	_	_
FuseNet	_	_
instances	_	_
.	_	_

#266
We	_	_
also	_	_
used	_	_
the	_	_
same	_	_
backpropagation	_	_
with	_	_
stochastic	_	_
gradient	_	_
descent	_	_
setting	_	_
as	_	_
training	_	_
a	_	_
FuseNet	_	_
with	_	_
the	_	_
initial	_	_
learning	_	_
rate	_	_
η	_	_
=	_	_
0.01	_	_
,	_	_
momentum	_	_
α	_	_
=	_	_
0.9	_	_
,	_	_
mini-batch	_	_
size	_	_
N	_	_
=	_	_
32	_	_
,	_	_
and	_	_
maximum	_	_
number	_	_
of	_	_
epochs	_	_
T	_	_
=	_	_
240	_	_
.	_	_

#267
Likewise	_	_
,	_	_
we	_	_
decreased	_	_
the	_	_
learning	_	_
rate	_	_
in	_	_
a	_	_
stepwise	_	_
manner—multiplying	_	_
it	_	_
by	_	_
a	_	_
factor	_	_
of	_	_
0.1	_	_
after	_	_
60	_	_
and	_	_
180	_	_
epochs	_	_
.	_	_

#268
For	_	_
regularization	_	_
,	_	_
we	_	_
only	_	_
used	_	_
an	_	_
l2	_	_
-weight	_	_
decay	_	_
penalty—setting	_	_
λ	_	_
=	_	_
0.001	_	_
.	_	_

#269
We	_	_
can	_	_
infer	_	_
classification	_	_
map	_	_
from	_	_
a	_	_
ReuseNet	_	_
in	_	_
the	_	_
same	_	_
manner	_	_
of	_	_
inference	_	_
as	_	_
a	_	_
FuseNet	_	_
,	_	_
with	_	_
one	_	_
additional	_	_
option	_	_
:	_	_
to	_	_
extract	_	_
different	_	_
predictions	_	_
from	_	_
each	_	_
FuseNet	_	_
instance	_	_
.	_	_

#270
For	_	_
applying	_	_
ReuseNet	_	_
on	_	_
the	_	_
ISPRS	_	_
Vaihingen	_	_
dataset	_	_
,	_	_
we	_	_
employed	_	_
a	_	_
feedforward	_	_
network	_	_
similar	_	_
to	_	_
the	_	_
No-downsampling	_	_
FCN	_	_
proposed	_	_
by	_	_
[	_	_
13	_	_
]	_	_
truncating	_	_
the	_	_
last	_	_
two	_	_
layers	_	_
(	_	_
fc5	_	_
and	_	_
fc6	_	_
)	_	_
before	_	_
softmax	_	_
activation	_	_
and	_	_
entirely	_	_
removing	_	_
all	_	_
maximum	_	_
pooling	_	_
without	_	_
downsampling	_	_
operations	_	_
.	_	_

#271
With	_	_
only	_	_
convolutional	_	_
layers	_	_
(	_	_
without	_	_
pooling	_	_
)	_	_
,	_	_
we	_	_
call	_	_
this	_	_
network	_	_
AllConvNet	_	_
.	_	_

#272
The	_	_
network	_	_
was	_	_
trained	_	_
on	_	_
12717	_	_
training	_	_
patches	_	_
as	_	_
opposed	_	_
to	_	_
the	_	_
123330	_	_
trainIEEE	_	_
TRANSACTIONS	_	_
ON	_	_
GEOSCIENCE	_	_
AND	_	_
REMOTE	_	_
SENSING	_	_
,	_	_
VOL	_	_
.	_	_

#273
X	_	_
,	_	_
NO	_	_
.	_	_

#274
X	_	_
,	_	_
MONTH	_	_
2017	_	_
9	_	_
ing	_	_
patches	_	_
in	_	_
[	_	_
13	_	_
]	_	_
.	_	_

#275
Although	_	_
having	_	_
less	_	_
parameters	_	_
and	_	_
having	_	_
trained	_	_
with	_	_
a	_	_
smaller	_	_
number	_	_
of	_	_
training	_	_
samples	_	_
,	_	_
AllConvNet	_	_
provided	_	_
comparable	_	_
results	_	_
with	_	_
the	_	_
original	_	_
No-downsampling	_	_
FCN	_	_
while	_	_
requiring	_	_
less	_	_
operations	_	_
.	_	_

#276
We	_	_
trained	_	_
AllConvNet	_	_
for	_	_
150000	_	_
iterations	_	_
as	_	_
reported	_	_
in	_	_
[	_	_
13	_	_
]	_	_
.	_	_

#277
ReuseNet	_	_
versions	_	_
of	_	_
AllConvNet	_	_
were	_	_
applied	_	_
to	_	_
the	_	_
ISPRS	_	_
Vaihingen	_	_
dataset	_	_
and	_	_
were	_	_
compared	_	_
to	_	_
the	_	_
best	_	_
results	_	_
of	_	_
both	_	_
[	_	_
13	_	_
]	_	_
and	_	_
[	_	_
16	_	_
]	_	_
.	_	_

#278
All	_	_
the	_	_
networks	_	_
in	_	_
this	_	_
additional	_	_
set	_	_
of	_	_
experiments	_	_
were	_	_
trained	_	_
using	_	_
a	_	_
variant	_	_
of	_	_
SGD	_	_
proposed	_	_
in	_	_
[	_	_
41	_	_
]	_	_
.	_	_

#279
C.	_	_
Accuracy	_	_
Assessment	_	_
We	_	_
compared	_	_
the	_	_
results	_	_
of	_	_
the	_	_
different	_	_
approaches	_	_
using	_	_
global	_	_
measures	_	_
:	_	_
1	_	_
)	_	_
overall	_	_
classification	_	_
accuracy	_	_
(	_	_
OA	_	_
)	_	_
,	_	_
2	_	_
)	_	_
the	_	_
Kappa	_	_
coefficient	_	_
(	_	_
κ	_	_
)	_	_
,	_	_
3	_	_
)	_	_
average	_	_
class	_	_
accuracy	_	_
(	_	_
AA	_	_
)	_	_
,	_	_
4	_	_
)	_	_
and	_	_
average	_	_
class-F1	_	_
scores	_	_
(	_	_
F1	_	_
)	_	_
.	_	_

#280
OA	_	_
is	_	_
given	_	_
by	_	_
:	_	_
OA	_	_
=	_	_
C∑	_	_
i=1	_	_
nii	_	_
n	_	_
(	_	_
11	_	_
)	_	_
where	_	_
nii	_	_
is	_	_
the	_	_
number	_	_
of	_	_
samples	_	_
classified	_	_
as	_	_
class	_	_
i	_	_
in	_	_
both	_	_
the	_	_
the	_	_
predictions	_	_
and	_	_
reference	_	_
images	_	_
,	_	_
n	_	_
is	_	_
the	_	_
total	_	_
number	_	_
of	_	_
labeled	_	_
samples	_	_
in	_	_
the	_	_
reference	_	_
images	_	_
,	_	_
and	_	_
C	_	_
is	_	_
the	_	_
number	_	_
of	_	_
classes	_	_
,	_	_
whereas	_	_
κ	_	_
is	_	_
given	_	_
by	_	_
:	_	_
κ	_	_
=	_	_
n	_	_
C∑	_	_
i=1	_	_
nii	_	_
−	_	_
C∑	_	_
i=1	_	_
ni+n+i	_	_
n2	_	_
−	_	_
C∑	_	_
i=1	_	_
ni+n+i	_	_
(	_	_
12	_	_
)	_	_
where	_	_
ni+	_	_
and	_	_
n+i	_	_
are	_	_
the	_	_
number	_	_
of	_	_
samples	_	_
classified	_	_
as	_	_
class	_	_
i	_	_
in	_	_
the	_	_
predictions	_	_
and	_	_
reference	_	_
images	_	_
respectively	_	_
.	_	_

#281
Both	_	_
OA	_	_
and	_	_
κ	_	_
provides	_	_
the	_	_
rate	_	_
of	_	_
correctly	_	_
classified	_	_
pixels	_	_
with	_	_
the	_	_
latter	_	_
compensating	_	_
for	_	_
random	_	_
agreement	_	_
in	_	_
classification	_	_
.	_	_

#282
These	_	_
global	_	_
measures	_	_
,	_	_
however	_	_
,	_	_
are	_	_
biased	_	_
toward	_	_
frequently	_	_
occurring	_	_
classes—meaning	_	_
,	_	_
classes	_	_
with	_	_
less	_	_
frequencies	_	_
have	_	_
relatively	_	_
little	_	_
impact	_	_
to	_	_
the	_	_
two	_	_
measures	_	_
.	_	_

#283
Unlike	_	_
OA	_	_
and	_	_
κ	_	_
,	_	_
AA	_	_
and	_	_
F1	_	_
provides	_	_
average	_	_
of	_	_
measures	_	_
independent	_	_
of	_	_
class	_	_
distribution	_	_
.	_	_

#284
AA	_	_
is	_	_
given	_	_
by	_	_
:	_	_
AA	_	_
=	_	_
C	_	_
C∑	_	_
i=1	_	_
nii	_	_
ni+	_	_
(	_	_
13	_	_
)	_	_
while	_	_
F1	_	_
is	_	_
given	_	_
by	_	_
:	_	_
F1	_	_
=	_	_
C	_	_
C∑	_	_
i=1	_	_
2	_	_
nii	_	_
ni+	_	_
nii	_	_
n+i	_	_
nii	_	_
ni+	_	_
+	_	_
nii	_	_
n+i	_	_
(	_	_
14	_	_
)	_	_
AA	_	_
computes	_	_
the	_	_
average	_	_
within-class	_	_
rate	_	_
of	_	_
correctly	_	_
classified	_	_
pixels	_	_
,	_	_
while	_	_
F1	_	_
calculates	_	_
the	_	_
harmonic	_	_
mean	_	_
of	_	_
the	_	_
precision	_	_
(	_	_
user’s	_	_
accuracy	_	_
)	_	_
and	_	_
recall	_	_
(	_	_
producer’s	_	_
accuracy	_	_
)	_	_
.	_	_

#285
We	_	_
also	_	_
observe	_	_
and	_	_
comment	_	_
on	_	_
the	_	_
quality	_	_
of	_	_
the	_	_
resulting	_	_
classified	_	_
maps	_	_
.	_	_

#286
V.	_	_
RESULTS	_	_
AND	_	_
DISCUSSION	_	_
A.	_	_
FuseNet	_	_
Table	_	_
IV	_	_
shows	_	_
the	_	_
results	_	_
of	_	_
accuracies	_	_
comparing	_	_
different	_	_
fusion	_	_
approaches	_	_
.	_	_

#287
The	_	_
numerical	_	_
results	_	_
are	_	_
evaluated	_	_
using	_	_
all	_	_
the	_	_
labeled	_	_
pixels	_	_
in	_	_
the	_	_
two	_	_
test	_	_
tiles	_	_
(	_	_
see	_	_
Table	_	_
III	_	_
for	_	_
the	_	_
TABLE	_	_
IV	_	_
COMPARISON	_	_
OF	_	_
FUSION	_	_
APPROACHES	_	_
Network	_	_
OA	_	_
(	_	_
%	_	_
)	_	_
κ	_	_
(	_	_
%	_	_
)	_	_
AA	_	_
(	_	_
%	_	_
)	_	_
F1	_	_
(	_	_
%	_	_
)	_	_
Netbilinear	_	_
84.76	_	_
78.70	_	_
81.99	_	_
77.48	_	_
Netpansharp	_	_
86.87	_	_
81.53	_	_
82.76	_	_
77.86	_	_
SegNet	_	_
[	_	_
26	_	_
]	_	_
88.11	_	_
83.17	_	_
83.96	_	_
77.01	_	_
FuseNethigh	_	_
88.03	_	_
83.18	_	_
89.79	_	_
79.06	_	_
FuseNetlow	_	_
91.63	_	_
88.03	_	_
92.91	_	_
82.90	_	_
FuseNetskip	_	_
91.90	_	_
88.43	_	_
93.46	_	_
81.74	_	_
Fig.	_	_
5	_	_
.	_	_

#288
PAN	_	_
,	_	_
MS	_	_
,	_	_
and	_	_
reference	_	_
images	_	_
in	_	_
the	_	_
tiles	_	_
used	_	_
for	_	_
testing	_	_
.	_	_

#289
Corresponding	_	_
legend	_	_
is	_	_
shown	_	_
.	_	_

#290
total	_	_
number	_	_
test	_	_
samples	_	_
)	_	_
.	_	_

#291
FuseNetskip	_	_
scores	_	_
the	_	_
highest	_	_
in	_	_
all	_	_
the	_	_
four	_	_
numerical	_	_
metrics	_	_
,	_	_
except	_	_
for	_	_
F1	_	_
where	_	_
FuseNetlow	_	_
scores	_	_
the	_	_
highest	_	_
.	_	_

#292
FuseNetlow	_	_
outperforms	_	_
both	_	_
the	_	_
variants	_	_
using	_	_
fixed	_	_
upsampling	_	_
(	_	_
Netpansharp	_	_
,	_	_
SegNet	_	_
,	_	_
and	_	_
Netbilinear	_	_
)	_	_
and	_	_
the	_	_
variants	_	_
learning	_	_
the	_	_
upsampling	_	_
but	_	_
fusing	_	_
at	_	_
the	_	_
scale	_	_
of	_	_
the	_	_
image	_	_
with	_	_
higher	_	_
resolution	_	_
(	_	_
FuseNethigh	_	_
)	_	_
.	_	_

#293
Observing	_	_
each	_	_
metric	_	_
:	_	_
FuseNetlow	_	_
gains	_	_
about	_	_
3–6	_	_
%	_	_
in	_	_
OA	_	_
,	_	_
4–9	_	_
%	_	_
in	_	_
κ	_	_
,	_	_
3–10	_	_
%	_	_
in	_	_
AA	_	_
,	_	_
and	_	_
1–5	_	_
%	_	_
in	_	_
F1	_	_
against	_	_
the	_	_
other	_	_
baselines	_	_
(	_	_
with	_	_
the	_	_
exemption	_	_
of	_	_
FuseNetskip	_	_
)	_	_
.	_	_

#294
FuseNetskip	_	_
further	_	_
increases	_	_
the	_	_
numerical	_	_
results	_	_
of	_	_
FuseNetlow	_	_
in	_	_
the	_	_
first	_	_
three	_	_
metrics	_	_
by	_	_
about	_	_
0.2–0.5	_	_
%	_	_
but	_	_
degrades	_	_
the	_	_
F1	_	_
by	_	_
about	_	_
1.2	_	_
%	_	_
.	_	_

#295
We	_	_
have	_	_
two	_	_
relevant	_	_
observations	_	_
:	_	_
1	_	_
)	_	_
learning	_	_
the	_	_
fusion	_	_
can	_	_
improve	_	_
the	_	_
classification	_	_
of	_	_
PAN	_	_
and	_	_
MS	_	_
VHR	_	_
images	_	_
with	_	_
different	_	_
resolutions	_	_
;	_	_
2	_	_
)	_	_
fusing	_	_
at	_	_
the	_	_
scale	_	_
of	_	_
the	_	_
image	_	_
with	_	_
lower	_	_
resolution	_	_
results	_	_
in	_	_
better	_	_
classification	_	_
than	_	_
performing	_	_
the	_	_
fusion	_	_
at	_	_
the	_	_
scale	_	_
of	_	_
the	_	_
image	_	_
with	_	_
higher	_	_
resolution	_	_
.	_	_

#296
The	_	_
first	_	_
point	_	_
demonstrates	_	_
our	_	_
expected	_	_
effectiveness	_	_
of	_	_
coupling	_	_
and	_	_
learning	_	_
the	_	_
fusion	_	_
operation	_	_
within	_	_
a	_	_
supervised	_	_
classifier	_	_
.	_	_

#297
One	_	_
explanation	_	_
for	_	_
the	_	_
second	_	_
point	_	_
could	_	_
be	_	_
the	_	_
placement	_	_
of	_	_
upsampling	_	_
layers	_	_
.	_	_

#298
Introducing	_	_
upsampling	_	_
layers	_	_
early	_	_
in	_	_
the	_	_
network—as	_	_
done	_	_
in	_	_
FuseNethigh—may	_	_
produce	_	_
artifacts	_	_
that	_	_
can	_	_
degrade	_	_
its	_	_
performance	_	_
.	_	_

#299
IEEE	_	_
TRANSACTIONS	_	_
ON	_	_
GEOSCIENCE	_	_
AND	_	_
REMOTE	_	_
SENSING	_	_
,	_	_
VOL	_	_
.	_	_

#300
X	_	_
,	_	_
NO	_	_
.	_	_

#301
X	_	_
,	_	_
MONTH	_	_
2017	_	_
10	_	_
Fig.	_	_
6	_	_
.	_	_

#302
Two	_	_
subsets	_	_
from	_	_
the	_	_
test	_	_
tiles	_	_
showing	_	_
,	_	_
from	_	_
right	_	_
to	_	_
left	_	_
,	_	_
the	_	_
satellite	_	_
image	_	_
(	_	_
natural	_	_
color	_	_
)	_	_
,	_	_
reference	_	_
image	_	_
,	_	_
and	_	_
classification	_	_
maps	_	_
from	_	_
selected	_	_
two	_	_
FuseNet	_	_
variants	_	_
(	_	_
FuseNethigh	_	_
and	_	_
FuseNetskip	_	_
)	_	_
and	_	_
one	_	_
baseline	_	_
method	_	_
(	_	_
Netpansharp	_	_
)	_	_
.	_	_

#303
Figure	_	_
5	_	_
shows	_	_
the	_	_
PAN	_	_
,	_	_
MS	_	_
,	_	_
and	_	_
reference	_	_
images	_	_
of	_	_
the	_	_
tiles	_	_
used	_	_
for	_	_
testing	_	_
.	_	_

#304
Figure	_	_
6	_	_
shows	_	_
the	_	_
classification	_	_
results	_	_
of	_	_
two	_	_
FuseNet	_	_
variants	_	_
(	_	_
FuseNethigh	_	_
and	_	_
FuseNetskip	_	_
)	_	_
and	_	_
one	_	_
baseline	_	_
method	_	_
(	_	_
Netpansharp	_	_
)	_	_
on	_	_
two	_	_
selected	_	_
areas	_	_
of	_	_
the	_	_
test	_	_
tiles	_	_
.	_	_

#305
The	_	_
most	_	_
noticeable	_	_
misclassifications	_	_
are	_	_
found	_	_
in	_	_
large	_	_
and	_	_
high-rise	_	_
buildings	_	_
,	_	_
in	_	_
both	_	_
test	_	_
tiles	_	_
,	_	_
and	_	_
an	_	_
overpassing	_	_
road	_	_
in	_	_
tile	_	_
78	_	_
.	_	_

#306
The	_	_
facades	_	_
and	_	_
rooftops	_	_
of	_	_
the	_	_
buildings	_	_
are	_	_
often	_	_
mistaken	_	_
to	_	_
be	_	_
impervious	_	_
surfaces	_	_
by	_	_
the	_	_
classifiers	_	_
;	_	_
while	_	_
the	_	_
overpassing	_	_
road	_	_
is	_	_
mistaken	_	_
to	_	_
be	_	_
a	_	_
building	_	_
.	_	_

#307
These	_	_
regions	_	_
can	_	_
appear	_	_
to	_	_
have	_	_
similar	_	_
spectral	_	_
characteristics	_	_
and	_	_
can	_	_
only	_	_
be	_	_
distinguished	_	_
by	_	_
presence	_	_
of	_	_
other	_	_
cues	_	_
such	_	_
as	_	_
appearing	_	_
to	_	_
be	_	_
elevated	_	_
.	_	_

#308
However	_	_
,	_	_
with	_	_
the	_	_
absence	_	_
of	_	_
elevation	_	_
information	_	_
,	_	_
such	_	_
cues	_	_
are	_	_
not	_	_
directly	_	_
incorporated	_	_
in	_	_
the	_	_
input	_	_
data	_	_
.	_	_

#309
Manually	_	_
distinguishing	_	_
arguably	_	_
vaguely-defined	_	_
classes	_	_
such	_	_
as	_	_
low-vegetation	_	_
and	_	_
impervious	_	_
surface	_	_
can	_	_
also	_	_
be	_	_
problematic	_	_
,	_	_
especially	_	_
in	_	_
the	_	_
PAN	_	_
image	_	_
,	_	_
with	_	_
the	_	_
lack	_	_
of	_	_
ancillary	_	_
information	_	_
such	_	_
as	_	_
elevation	_	_
.	_	_

#310
Adding	_	_
a	_	_
digital	_	_
elevation	_	_
model	_	_
or	_	_
a	_	_
digital	_	_
surface	_	_
model	_	_
can	_	_
help	_	_
address	_	_
the	_	_
misclassification	_	_
of	_	_
these	_	_
regions	_	_
.	_	_

#311
The	_	_
cars	_	_
are	_	_
also	_	_
generally	_	_
misclassified	_	_
by	_	_
all	_	_
the	_	_
classifiers	_	_
which	_	_
is	_	_
,	_	_
aside	_	_
from	_	_
being	_	_
underrepresented	_	_
in	_	_
terms	_	_
of	_	_
the	_	_
number	_	_
of	_	_
labeled	_	_
pixels	_	_
,	_	_
due	_	_
to	_	_
the	_	_
lack	_	_
of	_	_
spatial	_	_
resolution	_	_
of	_	_
the	_	_
MS	_	_
bands	_	_
and	_	_
the	_	_
cars’	_	_
spectral	_	_
similarity	_	_
with	_	_
other	_	_
classes	_	_
(	_	_
such	_	_
as	_	_
impervious	_	_
surface	_	_
and	_	_
buildings	_	_
)	_	_
in	_	_
the	_	_
PAN	_	_
band	_	_
.	_	_

#312
Overall	_	_
,	_	_
FuseNetskip	_	_
generally	_	_
has	_	_
less	_	_
errors	_	_
in	_	_
the	_	_
facade	_	_
of	_	_
large	_	_
buildings	_	_
,	_	_
lessen	_	_
the	_	_
artifacts	_	_
noticeably	_	_
present	_	_
in	_	_
the	_	_
other	_	_
techniques	_	_
,	_	_
and	_	_
has	_	_
better	_	_
delineation	_	_
of	_	_
classes	_	_
with	_	_
irregular	_	_
boundaries	_	_
such	_	_
as	_	_
trees	_	_
and	_	_
lowvegetation—providing	_	_
the	_	_
best	_	_
classification	_	_
results	_	_
among	_	_
all	_	_
the	_	_
FuseNet	_	_
variants	_	_
.	_	_

#313
We	_	_
,	_	_
therefore	_	_
,	_	_
apply	_	_
recurrence	_	_
to	_	_
FuseNetskip	_	_
architecure	_	_
to	_	_
build	_	_
the	_	_
ReuseNet	_	_
instances	_	_
.	_	_

#314
B.	_	_
ReuseNet	_	_
1	_	_
)	_	_
Worldview-03	_	_
Quezon	_	_
City	_	_
dataset	_	_
:	_	_
Table	_	_
V	_	_
shows	_	_
the	_	_
accuracies	_	_
obtained	_	_
by	_	_
comparing	_	_
different	_	_
classification	_	_
techniques	_	_
on	_	_
the	_	_
Worldview-03	_	_
Quezon	_	_
City	_	_
dataset	_	_
.	_	_

#315
We	_	_
found	_	_
that	_	_
both	_	_
the	_	_
ReuseNet	_	_
instances	_	_
and	_	_
the	_	_
baseline	_	_
method	_	_
FuseNet+CRF	_	_
improves	_	_
the	_	_
numerical	_	_
results	_	_
of	_	_
the	_	_
plain	_	_
TABLE	_	_
V	_	_
COMPARISON	_	_
OF	_	_
MAP	_	_
REGULARIZATION	_	_
APPROACHES	_	_
ON	_	_
WORLDVIEW-03	_	_
QUEZON	_	_
CITY	_	_
DATASET	_	_
Network	_	_
OA	_	_
(	_	_
%	_	_
)	_	_
κ	_	_
(	_	_
%	_	_
)	_	_
AA	_	_
(	_	_
%	_	_
)	_	_
F1	_	_
(	_	_
%	_	_
)	_	_
FuseNet	_	_
91.90	_	_
88.43	_	_
93.46	_	_
81.74	_	_
FuseNet+CRF	_	_
93.07	_	_
90.08	_	_
94.71	_	_
81.72	_	_
ReuseNet-2	_	_
92.82	_	_
89.69	_	_
94.09	_	_
82.64	_	_
ReuseNet-3	_	_
92.98	_	_
89.88	_	_
94.54	_	_
85.42	_	_
ReuseNet-4	_	_
93.49	_	_
90.58	_	_
94.53	_	_
86.67	_	_
ReuseNet-5	_	_
92.74	_	_
89.53	_	_
92.78	_	_
87.29	_	_
FuseNetskip	_	_
gaining	_	_
around	_	_
:	_	_
0.9–1.5	_	_
%	_	_
in	_	_
OA	_	_
,	_	_
1.2–2.1	_	_
%	_	_
in	_	_
κ	_	_
,	_	_
and	_	_
0.6–1.2	_	_
%	_	_
in	_	_
AA	_	_
.	_	_

#316
For	_	_
the	_	_
F1	_	_
,	_	_
however	_	_
,	_	_
FuseNet+CRF	_	_
method	_	_
performs	_	_
worse	_	_
than	_	_
the	_	_
plain	_	_
FuseNet	_	_
losing	_	_
0.02	_	_
%	_	_
;	_	_
while	_	_
all	_	_
the	_	_
other	_	_
ReuseNet	_	_
instances	_	_
improves	_	_
the	_	_
F1	_	_
by	_	_
around	_	_
0.9–5.5	_	_
%	_	_
.	_	_

#317
ReuseNet-4	_	_
outperforms	_	_
all	_	_
the	_	_
other	_	_
classifiers	_	_
in	_	_
all	_	_
the	_	_
metrics	_	_
except	_	_
for	_	_
AA	_	_
and	_	_
F1—where	_	_
both	_	_
ReuseNet-3	_	_
and	_	_
FuseNet+CRF	_	_
outperform	_	_
it	_	_
by	_	_
some	_	_
margin	_	_
in	_	_
AA	_	_
(	_	_
0.01	_	_
%	_	_
and	_	_
0.18	_	_
%	_	_
respectively	_	_
)	_	_
and	_	_
ReuseNet-5	_	_
considerably	_	_
outperforms	_	_
it	_	_
in	_	_
F1	_	_
by	_	_
0.62	_	_
%	_	_
.	_	_

#318
In	_	_
particular	_	_
,	_	_
all	_	_
the	_	_
ReuseNets	_	_
consistently	_	_
show	_	_
better	_	_
F1	_	_
compared	_	_
to	_	_
both	_	_
FuseNet	_	_
and	_	_
FuseNet+CRF—gaining	_	_
almost	_	_
6	_	_
%	_	_
.	_	_

#319
These	_	_
expected	_	_
relatively	_	_
smaller	_	_
gains	_	_
in	_	_
numerical	_	_
accuracy	_	_
is	_	_
consistent	_	_
with	_	_
what	_	_
the	_	_
author	_	_
in	_	_
[	_	_
13	_	_
]	_	_
found—applying	_	_
a	_	_
post-classification	_	_
CRF	_	_
to	_	_
an	_	_
FCN	_	_
to	_	_
classify	_	_
extremely	_	_
high	_	_
resolution	_	_
aerial	_	_
imagery	_	_
increases	_	_
the	_	_
overall	_	_
classification	_	_
accuracy	_	_
by	_	_
around	_	_
0.1–1.0	_	_
%	_	_
.	_	_

#320
More	_	_
noticeable	_	_
changes	_	_
are	_	_
expected	_	_
in	_	_
the	_	_
resulting	_	_
improved	_	_
regularity	_	_
of	_	_
the	_	_
classified	_	_
maps	_	_
.	_	_

#321
The	_	_
numerical	_	_
results	_	_
above	_	_
supports	_	_
our	_	_
assertion	_	_
that	_	_
introducing	_	_
contextual	_	_
label	_	_
information	_	_
through	_	_
recurrence	_	_
in	_	_
an	_	_
FCN	_	_
applying	_	_
a	_	_
full-patch	_	_
labeling	_	_
approach	_	_
can	_	_
improve	_	_
the	_	_
classification	_	_
of	_	_
a	_	_
VHR	_	_
image	_	_
.	_	_

#322
Such	_	_
incorporation	_	_
of	_	_
label	_	_
information	_	_
allows	_	_
our	_	_
classifier	_	_
to	_	_
learn	_	_
both	_	_
pixel-to-label	_	_
and	_	_
label-to-label	_	_
contextual	_	_
dependencies	_	_
.	_	_

#323
We	_	_
can	_	_
develop	_	_
an	_	_
intuition	_	_
of	_	_
these	_	_
two	_	_
dependencies	_	_
by	_	_
using	_	_
an	_	_
analogy	_	_
to	_	_
photointerpretation	_	_
.	_	_

#324
We	_	_
can	_	_
easily	_	_
imagine	_	_
that	_	_
it	_	_
is	_	_
easier	_	_
to	_	_
label	_	_
a	_	_
pixel	_	_
when	_	_
viewed	_	_
with	_	_
its	_	_
neighboring	_	_
pixels	_	_
.	_	_

#325
This	_	_
IEEE	_	_
TRANSACTIONS	_	_
ON	_	_
GEOSCIENCE	_	_
AND	_	_
REMOTE	_	_
SENSING	_	_
,	_	_
VOL	_	_
.	_	_

#326
X	_	_
,	_	_
NO	_	_
.	_	_

#327
X	_	_
,	_	_
MONTH	_	_
2017	_	_
11	_	_
Fig.	_	_
7	_	_
.	_	_

#328
Two	_	_
subsets	_	_
from	_	_
the	_	_
test	_	_
tiles	_	_
showing	_	_
,	_	_
from	_	_
right	_	_
to	_	_
left	_	_
,	_	_
the	_	_
satellite	_	_
image	_	_
(	_	_
natural	_	_
color	_	_
)	_	_
,	_	_
reference	_	_
image	_	_
,	_	_
and	_	_
classification	_	_
maps	_	_
from	_	_
FuseNetskip	_	_
,	_	_
FuseNetskip+CRF	_	_
,	_	_
and	_	_
ReuseNet-4	_	_
.	_	_

#329
All	_	_
ReuseNets	_	_
reported	_	_
are	_	_
“plain”	_	_
meaning	_	_
initial	_	_
score	_	_
maps	_	_
are	_	_
filled	_	_
with	_	_
zeros	_	_
.	_	_

#330
Reusenet-R	_	_
denotes	_	_
a	_	_
ReuseNet	_	_
composed	_	_
of	_	_
R	_	_
number	_	_
of	_	_
FuseNet	_	_
instances	_	_
.	_	_

#331
setup	_	_
is	_	_
analogous	_	_
to	_	_
the	_	_
improvements	_	_
a	_	_
spatial-contextual	_	_
classifier	_	_
,	_	_
like	_	_
a	_	_
CNN	_	_
applying	_	_
a	_	_
patch	_	_
classification	_	_
,	_	_
approach	_	_
bring	_	_
over	_	_
a	_	_
simple	_	_
pixel-based	_	_
classifier	_	_
.	_	_

#332
But	_	_
we	_	_
can	_	_
also	_	_
see	_	_
that	_	_
it	_	_
is	_	_
easier	_	_
to	_	_
label	_	_
a	_	_
pixel	_	_
when	_	_
,	_	_
aside	_	_
from	_	_
viewing	_	_
its	_	_
neighboring	_	_
pixels	_	_
,	_	_
its	_	_
surrounding	_	_
pixels’	_	_
labels	_	_
are	_	_
given	_	_
.	_	_

#333
With	_	_
contextual	_	_
label	_	_
information	_	_
,	_	_
the	_	_
classifier	_	_
can	_	_
learn	_	_
and	_	_
leverage	_	_
class	_	_
spatial	_	_
co-occurrences	_	_
.	_	_

#334
Additionally	_	_
,	_	_
we	_	_
observe	_	_
that	_	_
adding	_	_
more	_	_
FuseNet	_	_
instances	_	_
to	_	_
the	_	_
ReuseNet	_	_
until	_	_
R	_	_
=	_	_
4	_	_
increases	_	_
the	_	_
score	_	_
of	_	_
all	_	_
metrics	_	_
,	_	_
except	_	_
for	_	_
the	_	_
average	_	_
class	_	_
accuracy	_	_
where	_	_
ReuseNet-3	_	_
marginally	_	_
outperforms	_	_
ReuseNet-4	_	_
.	_	_

#335
Adding	_	_
one	_	_
more	_	_
instance	_	_
only	_	_
improves	_	_
the	_	_
F1	_	_
score	_	_
and	_	_
degrades	_	_
the	_	_
other	_	_
three	_	_
metrics	_	_
.	_	_

#336
We	_	_
can	_	_
interpret	_	_
this	_	_
addition	_	_
of	_	_
FuseNet	_	_
instances	_	_
as	_	_
a	_	_
way	_	_
to	_	_
increase	_	_
ReuseNet’s	_	_
capacity	_	_
to	_	_
refine	_	_
contextual	_	_
label	_	_
information	_	_
fed	_	_
to	_	_
it	_	_
as	_	_
latter	_	_
FuseNet	_	_
instances	_	_
receive	_	_
more	_	_
refined	_	_
labels	_	_
.	_	_

#337
Figure	_	_
7	_	_
shows	_	_
classification	_	_
results	_	_
of	_	_
the	_	_
best	_	_
performing	_	_
ReuseNet	_	_
,	_	_
the	_	_
baseline	_	_
method	_	_
FuseNet+CRF	_	_
,	_	_
and	_	_
the	_	_
plain	_	_
FuseNet	_	_
.	_	_

#338
Both	_	_
FuseNet+CRF	_	_
and	_	_
ReuseNet	_	_
instances	_	_
improves	_	_
the	_	_
quality	_	_
of	_	_
the	_	_
resulting	_	_
classified	_	_
map	_	_
by	_	_
producing	_	_
more	_	_
regularized	_	_
classification	_	_
.	_	_

#339
We	_	_
also	_	_
observe	_	_
that	_	_
locations	_	_
of	_	_
the	_	_
errors	_	_
are	_	_
carried	_	_
over	_	_
from	_	_
the	_	_
results	_	_
of	_	_
the	_	_
FuseNet	_	_
classifier	_	_
from	_	_
which	_	_
both	_	_
FuseNet+CRF	_	_
and	_	_
ReuseNet	_	_
are	_	_
based	_	_
from	_	_
.	_	_

#340
However	_	_
,	_	_
the	_	_
occurrences	_	_
of	_	_
the	_	_
errors	_	_
are	_	_
diminished	_	_
especially	_	_
on	_	_
the	_	_
facades	_	_
of	_	_
the	_	_
large	_	_
buildings	_	_
.	_	_

#341
Detection	_	_
of	_	_
isolated	_	_
cars	_	_
in	_	_
roads	_	_
were	_	_
also	_	_
improved	_	_
.	_	_

#342
Overall	_	_
,	_	_
results	_	_
of	_	_
ReuseNet-4	_	_
show	_	_
better-quality	_	_
classified	_	_
maps	_	_
by	_	_
reducing	_	_
noise	_	_
in	_	_
the	_	_
classification	_	_
(	_	_
such	_	_
as	_	_
island	_	_
of	_	_
impossibly	_	_
small	_	_
buildings	_	_
)	_	_
,	_	_
further	_	_
improving	_	_
delineation	_	_
of	_	_
classes	_	_
with	_	_
irregular	_	_
boundaries	_	_
,	_	_
and	_	_
reducing	_	_
misclassification	_	_
in	_	_
regions	_	_
with	_	_
ambiguous	_	_
spectral	_	_
characteristics	_	_
such	_	_
as	_	_
facades	_	_
and	_	_
rooftops	_	_
of	_	_
high	_	_
rise	_	_
buildings	_	_
.	_	_

#343
2	_	_
)	_	_
ISPRS	_	_
Vaihingen	_	_
dataset	_	_
:	_	_
Table	_	_
VI	_	_
shows	_	_
the	_	_
accuracies	_	_
obtained	_	_
by	_	_
comparing	_	_
different	_	_
classification	_	_
techniques	_	_
on	_	_
the	_	_
ISPRS	_	_
dataset	_	_
.	_	_

#344
These	_	_
results	_	_
are	_	_
in	_	_
agreement	_	_
with	_	_
the	_	_
results	_	_
from	_	_
the	_	_
previous	_	_
dataset	_	_
.	_	_

#345
All	_	_
the	_	_
ReuseNet	_	_
versions	_	_
of	_	_
AllConvNet	_	_
improve	_	_
the	_	_
resuslts	_	_
on	_	_
all	_	_
the	_	_
four	_	_
metrics	_	_
except	_	_
for	_	_
AA	_	_
and	_	_
F1	_	_
of	_	_
ReuseNet-2	_	_
(	_	_
2.08	_	_
%	_	_
in	_	_
AA	_	_
and	_	_
TABLE	_	_
VI	_	_
COMPARISON	_	_
OF	_	_
MAP	_	_
REGULARIZATION	_	_
APPROACHES	_	_
ON	_	_
ISPRS	_	_
VAIHINGEN	_	_
DATASET	_	_
Network	_	_
OA	_	_
(	_	_
%	_	_
)	_	_
κ	_	_
(	_	_
%	_	_
)	_	_
AA	_	_
(	_	_
%	_	_
)	_	_
F1	_	_
(	_	_
%	_	_
)	_	_
No-downsampling	_	_
FCN	_	_
[	_	_
13	_	_
]	_	_
87.17	_	_
–.–	_	_
–.–	_	_
–.–	_	_
CNN-FPL	_	_
[	_	_
16	_	_
]	_	_
87.83	_	_
83.83	_	_
81.35	_	_
83.58	_	_
AllConvNet	_	_
86.98	_	_
82.71	_	_
87.17	_	_
85.46	_	_
FCN	_	_
in	_	_
[	_	_
13	_	_
]	_	_
with	_	_
CRF	_	_
87.90	_	_
–.–	_	_
–.–	_	_
–.–	_	_
ReuseNet-2	_	_
87.11	_	_
82.89	_	_
85.09	_	_
85.38	_	_
ReuseNet-3	_	_
88.08	_	_
84.18	_	_
87.29	_	_
87.24	_	_
ReuseNet-4	_	_
87.64	_	_
83.59	_	_
87.18	_	_
86.81	_	_
Unreported	_	_
values	_	_
in	_	_
the	_	_
reference	_	_
are	_	_
denoted	_	_
by	_	_
”–.–”	_	_
0.06	_	_
%	_	_
in	_	_
F1	_	_
respectively	_	_
)	_	_
.	_	_

#346
ReuseNet-3	_	_
,	_	_
the	_	_
best	_	_
performing	_	_
network	_	_
,	_	_
considerably	_	_
improves	_	_
all	_	_
the	_	_
numerical	_	_
results	_	_
of	_	_
the	_	_
plain	_	_
AllConvNet	_	_
by	_	_
1.1	_	_
%	_	_
in	_	_
OA	_	_
and	_	_
is	_	_
comparable	_	_
and	_	_
even	_	_
greater	_	_
than	_	_
the	_	_
0.73	_	_
%	_	_
gain	_	_
after	_	_
a	_	_
post-classification	_	_
CRF	_	_
in	_	_
[	_	_
13	_	_
]	_	_
,	_	_
1.47	_	_
%	_	_
in	_	_
κ	_	_
,	_	_
0.12	_	_
%	_	_
in	_	_
AA	_	_
,	_	_
and	_	_
1.78	_	_
%	_	_
in	_	_
F1	_	_
.	_	_

#347
ReuseNet-3	_	_
also	_	_
outperforms	_	_
best	_	_
results	_	_
reported	_	_
in	_	_
both	_	_
[	_	_
13	_	_
]	_	_
and	_	_
[	_	_
16	_	_
]	_	_
.	_	_

#348
These	_	_
results	_	_
reconfirm	_	_
that	_	_
introducing	_	_
contextual	_	_
label	_	_
information	_	_
through	_	_
recurrence	_	_
in	_	_
an	_	_
FCN	_	_
applying	_	_
a	_	_
full-patch	_	_
labeling	_	_
approach	_	_
can	_	_
improve	_	_
the	_	_
classification	_	_
of	_	_
a	_	_
VHR	_	_
image	_	_
.	_	_

#349
Similarly	_	_
,	_	_
qualitative	_	_
improvements—such	_	_
as	_	_
holes	_	_
in	_	_
building	_	_
being	_	_
filled	_	_
,	_	_
better	_	_
delineation	_	_
of	_	_
all	_	_
classes	_	_
in	_	_
general	_	_
,	_	_
lesser	_	_
artifacts—in	_	_
the	_	_
resulting	_	_
classified	_	_
maps	_	_
are	_	_
observed	_	_
when	_	_
ReuseNet	_	_
is	_	_
applied	_	_
as	_	_
shown	_	_
in	_	_
Figure	_	_
8	_	_
.	_	_

#350
3	_	_
)	_	_
Different	_	_
initializations	_	_
:	_	_
Figure	_	_
9	_	_
shows	_	_
results	_	_
of	_	_
quantitive	_	_
metrics	_	_
on	_	_
the	_	_
three	_	_
different	_	_
ReuseNet	_	_
initializations	_	_
.	_	_

#351
There	_	_
is	_	_
low	_	_
variation	_	_
in	_	_
the	_	_
OA	_	_
and	_	_
κ	_	_
.	_	_

#352
The	_	_
trend	_	_
of	_	_
the	_	_
two	_	_
global	_	_
scores	_	_
is	_	_
also	_	_
inconsistent	_	_
across	_	_
the	_	_
ReuseNet	_	_
instances	_	_
.	_	_

#353
For	_	_
ReuseNet-2	_	_
and	_	_
ReuseNet-3	_	_
,	_	_
the	_	_
scores	_	_
increases	_	_
marginally	_	_
(	_	_
around	_	_
0.5	_	_
%	_	_
for	_	_
OA	_	_
and	_	_
0.8	_	_
%	_	_
for	_	_
κ	_	_
)	_	_
when	_	_
initialized	_	_
with	_	_
both	_	_
the	_	_
scores	_	_
and	_	_
weights	_	_
from	_	_
a	_	_
previously-trained	_	_
FuseNet	_	_
.	_	_

#354
But	_	_
for	_	_
ReuseNet-4	_	_
,	_	_
there	_	_
is	_	_
a	_	_
minor	_	_
drop	_	_
in	_	_
both	_	_
the	_	_
scores	_	_
(	_	_
around	_	_
0.2	_	_
%	_	_
for	_	_
both	_	_
scores	_	_
)	_	_
when	_	_
the	_	_
two	_	_
intialization	_	_
methods	_	_
are	_	_
introduced	_	_
.	_	_

#355
This	_	_
could	_	_
mean	_	_
that	_	_
increasing	_	_
the	_	_
FuseNet	_	_
instances	_	_
to	_	_
a	_	_
certain	_	_
amount	_	_
already	_	_
provides	_	_
enough	_	_
room	_	_
to	_	_
a	_	_
ReuseNet	_	_
for	_	_
“label	_	_
refinement”	_	_
IEEE	_	_
TRANSACTIONS	_	_
ON	_	_
GEOSCIENCE	_	_
AND	_	_
REMOTE	_	_
SENSING	_	_
,	_	_
VOL	_	_
.	_	_

#356
X	_	_
,	_	_
NO	_	_
.	_	_

#357
X	_	_
,	_	_
MONTH	_	_
2017	_	_
12	_	_
Fig.	_	_
8	_	_
.	_	_

#358
Two	_	_
subsets	_	_
from	_	_
the	_	_
validation	_	_
tiles	_	_
of	_	_
ISPRS	_	_
Vaihingen	_	_
dataset	_	_
showing	_	_
,	_	_
from	_	_
right	_	_
to	_	_
left	_	_
,	_	_
the	_	_
true	_	_
orthophoto	_	_
,	_	_
normalized	_	_
dsm	_	_
,	_	_
reference	_	_
image	_	_
,	_	_
and	_	_
classification	_	_
maps	_	_
from	_	_
AllConvNet	_	_
and	_	_
ReuseNet-3	_	_
(	_	_
best	_	_
performing	_	_
ReuseNet	_	_
in	_	_
this	_	_
dataset	_	_
)	_	_
.	_	_

#359
All	_	_
ReuseNets	_	_
reported	_	_
are	_	_
“plain”	_	_
meaning	_	_
initial	_	_
score	_	_
maps	_	_
are	_	_
filled	_	_
with	_	_
zeros	_	_
.	_	_

#360
Reusenet-R	_	_
denotes	_	_
a	_	_
ReuseNet	_	_
composed	_	_
of	_	_
R	_	_
number	_	_
of	_	_
FuseNet	_	_
instances	_	_
.	_	_

#361
Fig.	_	_
9	_	_
.	_	_

#362
Plots	_	_
showing	_	_
results	_	_
of	_	_
quantitive	_	_
metrics	_	_
comparing	_	_
different	_	_
ReuseNet	_	_
initializations	_	_
;	_	_
plain	_	_
,	_	_
map-init	_	_
,	_	_
and	_	_
map-weights-init	_	_
correspond	_	_
to	_	_
intializing	_	_
the	_	_
ReuseNet	_	_
with	_	_
zero-score	_	_
maps	_	_
,	_	_
scores	_	_
from	_	_
a	_	_
previously-trained	_	_
FuseNet	_	_
,	_	_
and	_	_
scores	_	_
and	_	_
weights	_	_
from	_	_
a	_	_
previously-trained	_	_
FuseNet	_	_
respectively	_	_
.	_	_

#363
such	_	_
that	_	_
gains	_	_
from	_	_
the	_	_
initialization	_	_
methods	_	_
are	_	_
compensated	_	_
.	_	_

#364
Introducing	_	_
both	_	_
initialization	_	_
methods	_	_
to	_	_
a	_	_
ReuseNet	_	_
degrades	_	_
the	_	_
AA	_	_
by	_	_
around	_	_
0.9–5.2	_	_
%	_	_
.	_	_

#365
Applying	_	_
only	_	_
the	_	_
initialization	_	_
using	_	_
scores	_	_
from	_	_
a	_	_
FuseNet	_	_
instance	_	_
(	_	_
map-init	_	_
)	_	_
degrades	_	_
the	_	_
F1	_	_
by	_	_
around	_	_
0.9–12.2	_	_
%	_	_
.	_	_

#366
Interestingly	_	_
,	_	_
the	_	_
F1	_	_
improve	_	_
by	_	_
around	_	_
0.8–6.1	_	_
%	_	_
when	_	_
both	_	_
initialization	_	_
methods	_	_
are	_	_
introduced	_	_
(	_	_
map-weights-init	_	_
)	_	_
.	_	_

#367
Decrease	_	_
in	_	_
AA	_	_
can	_	_
only	_	_
imply	_	_
an	_	_
increase	_	_
in	_	_
false	_	_
positive	_	_
predictions	_	_
in	_	_
most	_	_
of	_	_
the	_	_
classes	_	_
;	_	_
while	_	_
increase	_	_
in	_	_
F1	_	_
could	_	_
either	_	_
mean	_	_
decrease	_	_
in	_	_
false	_	_
positive	_	_
predictions	_	_
or	_	_
decrease	_	_
in	_	_
false	_	_
negative	_	_
predictions	_	_
or	_	_
both	_	_
in	_	_
most	_	_
of	_	_
the	_	_
classes	_	_
.	_	_

#368
The	_	_
results	_	_
therefore	_	_
Fig.	_	_
10	_	_
.	_	_

#369
Plots	_	_
showing	_	_
the	_	_
results	_	_
of	_	_
sensitivity	_	_
analysis	_	_
.	_	_

#370
Patch	_	_
sizes	_	_
are	_	_
written	_	_
as	_	_
“〈	_	_
(	_	_
4M	_	_
,	_	_
M	_	_
)	_	_
〉”	_	_
.	_	_

#371
N-neighbor	_	_
denotes	_	_
nearest	_	_
neighbor	_	_
interpolation	_	_
.	_	_

#372
show	_	_
that	_	_
the	_	_
initialization	_	_
methods	_	_
promote	_	_
higher	_	_
recall	_	_
rate	_	_
(	_	_
decrease	_	_
in	_	_
false	_	_
negatives	_	_
)	_	_
in	_	_
underrepresented	_	_
classes	_	_
such	_	_
as	_	_
cars	_	_
.	_	_

#373
C.	_	_
Sensitivity	_	_
Analysis	_	_
Fig.	_	_
10	_	_
shows	_	_
the	_	_
results	_	_
of	_	_
the	_	_
sensitivity	_	_
analysis	_	_
performed	_	_
on	_	_
four	_	_
chosen	_	_
hyperparameters	_	_
of	_	_
FuseNet	_	_
:	_	_
1	_	_
)	_	_
bottleneck	_	_
feature	_	_
map	_	_
dimensions	_	_
,	_	_
2	_	_
)	_	_
number	_	_
of	_	_
convolutional	_	_
layers	_	_
(	_	_
in	_	_
the	_	_
downsampling	_	_
part	_	_
of	_	_
the	_	_
network	_	_
)	_	_
,	_	_
3	_	_
)	_	_
input	_	_
patch	_	_
sizes	_	_
,	_	_
and	_	_
4	_	_
)	_	_
upsampling	_	_
methods	_	_
.	_	_

#374
We	_	_
got	_	_
the	_	_
highest	_	_
validation	_	_
accuracy	_	_
of	_	_
90.35	_	_
%	_	_
using	_	_
a	_	_
bottleneck	_	_
feature	_	_
map	_	_
dimension	_	_
of	_	_
4×4	_	_
pixels	_	_
.	_	_

#375
Decreasing	_	_
the	_	_
dimension	_	_
more	_	_
than	_	_
the	_	_
optimal	_	_
we	_	_
found	_	_
severely	_	_
degrades	_	_
the	_	_
classification	_	_
resulting	_	_
to	_	_
large	_	_
uniform	_	_
areas	_	_
producing	_	_
stamplike	_	_
patterns	_	_
(	_	_
especially	_	_
for	_	_
1×1	_	_
)	_	_
.	_	_

#376
Increasing	_	_
the	_	_
dimensions	_	_
produces	_	_
much	_	_
noisier	_	_
classification	_	_
.	_	_

#377
Fixing	_	_
the	_	_
bottleneck	_	_
IEEE	_	_
TRANSACTIONS	_	_
ON	_	_
GEOSCIENCE	_	_
AND	_	_
REMOTE	_	_
SENSING	_	_
,	_	_
VOL	_	_
.	_	_

#378
X	_	_
,	_	_
NO	_	_
.	_	_

#379
X	_	_
,	_	_
MONTH	_	_
2017	_	_
13	_	_
size	_	_
dimension	_	_
to	_	_
4×4	_	_
and	_	_
further	_	_
increasing	_	_
the	_	_
number	_	_
of	_	_
convolutional	_	_
layers	_	_
(	_	_
without	_	_
downsampling	_	_
)	_	_
did	_	_
not	_	_
produce	_	_
any	_	_
improvements	_	_
in	_	_
the	_	_
validation	_	_
accuracy	_	_
.	_	_

#380
Increasing	_	_
the	_	_
number	_	_
of	_	_
these	_	_
convolutional	_	_
layers	_	_
within	_	_
the	_	_
bottleneck	_	_
feature	_	_
maps	_	_
effectively	_	_
increases	_	_
the	_	_
receptive	_	_
field	_	_
(	_	_
footprint	_	_
size	_	_
in	_	_
the	_	_
input	_	_
layer	_	_
containing	_	_
the	_	_
PAN	_	_
image	_	_
patch	_	_
)	_	_
of	_	_
the	_	_
succeeding	_	_
units	_	_
by	_	_
at	_	_
least	_	_
half	_	_
of	_	_
the	_	_
size	_	_
of	_	_
kernels	_	_
used	_	_
in	_	_
the	_	_
convolutional	_	_
layers	_	_
.	_	_

#381
Hence	_	_
,	_	_
the	_	_
results	_	_
show	_	_
that	_	_
:	_	_
with	_	_
only	_	_
eight	_	_
convolutional	_	_
layers	_	_
(	_	_
with	_	_
downsampling	_	_
)	_	_
,	_	_
we	_	_
can	_	_
learn	_	_
enough	_	_
contextual	_	_
information	_	_
for	_	_
accurate	_	_
classification	_	_
.	_	_

#382
We	_	_
found	_	_
the	_	_
optimal	_	_
patch	_	_
sizes	_	_
of	_	_
64×64	_	_
for	_	_
the	_	_
xPAN	_	_
and	_	_
16×16	_	_
for	_	_
xMS	_	_
.	_	_

#383
Further	_	_
increasing	_	_
the	_	_
patch	_	_
sizes	_	_
results	_	_
in	_	_
overclassification	_	_
of	_	_
a	_	_
single	_	_
class	_	_
(	_	_
impervious	_	_
surface	_	_
)	_	_
.	_	_

#384
Increasing	_	_
the	_	_
patch	_	_
size	_	_
also	_	_
increases	_	_
the	_	_
proportion	_	_
of	_	_
frequently	_	_
occurring	_	_
classes	_	_
in	_	_
the	_	_
training	_	_
sample	_	_
,	_	_
possibly	_	_
resulting	_	_
into	_	_
overclassification	_	_
.	_	_

#385
Whereas	_	_
,	_	_
decreasing	_	_
the	_	_
patch	_	_
size	_	_
limits	_	_
the	_	_
contextual	_	_
information	_	_
incorporated	_	_
in	_	_
the	_	_
input	_	_
,	_	_
and	_	_
,	_	_
hence	_	_
,	_	_
can	_	_
degrade	_	_
the	_	_
classification	_	_
results	_	_
.	_	_

#386
Lastly	_	_
,	_	_
we	_	_
find	_	_
using	_	_
transposed	_	_
convolution	_	_
for	_	_
learned	_	_
upsampling	_	_
to	_	_
perform	_	_
better	_	_
than	_	_
using	_	_
interpolation	_	_
for	_	_
fixed	_	_
upsampling	_	_
(	_	_
bilinear	_	_
and	_	_
nearest	_	_
neighbor	_	_
)	_	_
.	_	_

#387
This	_	_
result	_	_
supports	_	_
the	_	_
expected	_	_
flexibility	_	_
of	_	_
empirically	_	_
learning	_	_
the	_	_
upsampling	_	_
operation	_	_
directly	_	_
from	_	_
data	_	_
.	_	_

#388
VI	_	_
.	_	_

#389
CONCLUSION	_	_
AND	_	_
FUTURE	_	_
WORKS	_	_
In	_	_
this	_	_
paper	_	_
,	_	_
we	_	_
presented	_	_
a	_	_
recurrent	_	_
multiresolution	_	_
convolutional	_	_
network	_	_
named	_	_
ReuseNet	_	_
to	_	_
classfiy	_	_
VHR	_	_
satellite	_	_
images	_	_
.	_	_

#390
The	_	_
operations	_	_
for	_	_
fusing	_	_
the	_	_
bands	_	_
with	_	_
different	_	_
resolutions	_	_
are	_	_
learned	_	_
within	_	_
convolutional	_	_
layers	_	_
with	_	_
corresponding	_	_
downsampling	_	_
and	_	_
upsampling	_	_
operations	_	_
to	_	_
match	_	_
the	_	_
resolution	_	_
of	_	_
the	_	_
images	_	_
.	_	_

#391
Regularization	_	_
of	_	_
the	_	_
resulting	_	_
classified	_	_
maps	_	_
is	_	_
achieved	_	_
by	_	_
incorporating	_	_
contextual	_	_
label	_	_
information	_	_
through	_	_
the	_	_
recurrent	_	_
architecture	_	_
of	_	_
ReuseNet	_	_
.	_	_

#392
Additionally	_	_
,	_	_
we	_	_
investigated	_	_
various	_	_
ways	_	_
to	_	_
initialize	_	_
ReuseNet	_	_
.	_	_

#393
The	_	_
effect	_	_
of	_	_
varying	_	_
a	_	_
set	_	_
of	_	_
chosen	_	_
network	_	_
hyperparameters	_	_
to	_	_
the	_	_
classification	_	_
accuracy	_	_
of	_	_
the	_	_
network	_	_
was	_	_
explored	_	_
.	_	_

#394
Both	_	_
numerical	_	_
and	_	_
qualitative	_	_
results	_	_
show	_	_
the	_	_
advantages	_	_
of	_	_
incorporating	_	_
image	_	_
resolution	_	_
matching	_	_
and	_	_
contextual	_	_
label	_	_
learning	_	_
within	_	_
the	_	_
training	_	_
of	_	_
the	_	_
classifier	_	_
.	_	_

#395
To	_	_
this	_	_
end	_	_
,	_	_
we	_	_
provided	_	_
a	_	_
single-stage	_	_
classification	_	_
pipeline	_	_
incorporating	_	_
image	_	_
fusion	_	_
,	_	_
feature	_	_
extraction	_	_
,	_	_
and	_	_
map	_	_
regularization	_	_
,	_	_
all	_	_
combined	_	_
in	_	_
a	_	_
convolutional	_	_
network	_	_
trained	_	_
in	_	_
an	_	_
end-to-end	_	_
manner	_	_
.	_	_

#396
We	_	_
designed	_	_
the	_	_
presented	_	_
network	_	_
architecture	_	_
such	_	_
that	_	_
it	_	_
can	_	_
easily	_	_
be	_	_
adapted	_	_
to	_	_
other	_	_
multiresolution	_	_
image	_	_
datasets	_	_
.	_	_

#397
Inclusion	_	_
and	_	_
leverage	_	_
of	_	_
contextual	_	_
label	_	_
information	_	_
is	_	_
also	_	_
separate	_	_
from	_	_
the	_	_
design	_	_
of	_	_
the	_	_
fusion	_	_
network	_	_
in	_	_
the	_	_
sense	_	_
that	_	_
it	_	_
can	_	_
be	_	_
implemented	_	_
on	_	_
network	_	_
classifying	_	_
singleresolution	_	_
images	_	_
.	_	_

#398
For	_	_
future	_	_
work	_	_
,	_	_
we	_	_
plan	_	_
to	_	_
fuse	_	_
images	_	_
from	_	_
different	_	_
sensors	_	_
(	_	_
e.g.	_	_
Sentinel-2	_	_
)	_	_
and	_	_
classify	_	_
classes	_	_
of	_	_
higher	_	_
abstraction	_	_
such	_	_
as	_	_
land	_	_
use	_	_
instead	_	_
of	_	_
land	_	_
cover	_	_
.	_	_