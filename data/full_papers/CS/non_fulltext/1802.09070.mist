#0
Attention-Aware	_	_
Generative	_	_
Adversarial	_	_
Networks	_	_
(	_	_
ATA-GANs	_	_
)	_	_
Dimitris	_	_
Kastaniotis	_	_
,	_	_
Ioanna	_	_
Ntinou	_	_
,	_	_
Dimitrios	_	_
Tsourounis	_	_
,	_	_
George	_	_
Economou	_	_
and	_	_
Spiros	_	_
Fotopoulos	_	_
,	_	_
Department	_	_
of	_	_
Physics	_	_
University	_	_
of	_	_
Patras	_	_
Patras	_	_
26504	_	_
,	_	_
Greece	_	_
dkastaniotis	_	_
@	_	_
upatras.gr	_	_
Abstract—	_	_
In	_	_
this	_	_
work	_	_
,	_	_
we	_	_
present	_	_
a	_	_
novel	_	_
approach	_	_
for	_	_
training	_	_
Generative	_	_
Adversarial	_	_
Networks	_	_
(	_	_
GANs	_	_
)	_	_
.	_	_

#1
Using	_	_
the	_	_
attention	_	_
maps	_	_
produced	_	_
by	_	_
a	_	_
Teacher-	_	_
Network	_	_
we	_	_
are	_	_
able	_	_
to	_	_
improve	_	_
the	_	_
quality	_	_
of	_	_
the	_	_
generated	_	_
images	_	_
as	_	_
well	_	_
as	_	_
perform	_	_
weakly	_	_
object	_	_
localization	_	_
on	_	_
the	_	_
generated	_	_
images	_	_
.	_	_

#2
To	_	_
this	_	_
end	_	_
,	_	_
we	_	_
generate	_	_
images	_	_
of	_	_
HEp-2	_	_
cells	_	_
captured	_	_
with	_	_
Indirect	_	_
Imunofluoresence	_	_
(	_	_
IIF	_	_
)	_	_
and	_	_
study	_	_
the	_	_
ability	_	_
of	_	_
our	_	_
network	_	_
to	_	_
perform	_	_
a	_	_
weakly	_	_
localization	_	_
of	_	_
the	_	_
cell	_	_
.	_	_

#3
Firstly	_	_
,	_	_
we	_	_
demonstrate	_	_
that	_	_
whilst	_	_
GANs	_	_
can	_	_
learn	_	_
the	_	_
mapping	_	_
between	_	_
the	_	_
input	_	_
domain	_	_
and	_	_
the	_	_
target	_	_
distribution	_	_
efficiently	_	_
,	_	_
the	_	_
discriminator	_	_
network	_	_
is	_	_
not	_	_
able	_	_
to	_	_
detect	_	_
the	_	_
regions	_	_
of	_	_
interest	_	_
.	_	_

#4
Secondly	_	_
,	_	_
we	_	_
present	_	_
a	_	_
novel	_	_
attention	_	_
transfer	_	_
mechanism	_	_
which	_	_
allows	_	_
us	_	_
to	_	_
enforce	_	_
the	_	_
discriminator	_	_
to	_	_
put	_	_
emphasis	_	_
on	_	_
the	_	_
regions	_	_
of	_	_
interest	_	_
via	_	_
transfer	_	_
learning	_	_
.	_	_

#5
Thirdly	_	_
,	_	_
we	_	_
show	_	_
that	_	_
this	_	_
leads	_	_
to	_	_
more	_	_
realistic	_	_
images	_	_
,	_	_
as	_	_
the	_	_
discriminator	_	_
learns	_	_
to	_	_
put	_	_
emphasis	_	_
on	_	_
the	_	_
area	_	_
of	_	_
interest	_	_
.	_	_

#6
Fourthly	_	_
,	_	_
the	_	_
proposed	_	_
method	_	_
allows	_	_
one	_	_
to	_	_
generate	_	_
both	_	_
images	_	_
as	_	_
well	_	_
as	_	_
attention	_	_
maps	_	_
which	_	_
can	_	_
be	_	_
useful	_	_
for	_	_
data	_	_
annotation	_	_
e.g	_	_
in	_	_
object	_	_
detection	_	_
.	_	_

#7
Keywords	_	_
:	_	_
Generative	_	_
Adversarial	_	_
Networks	_	_
,	_	_
Attention	_	_
Maps	_	_
,	_	_
HEp-2	_	_
cells	_	_
I	_	_
.	_	_

#8
INTRODUCTION	_	_
Over	_	_
the	_	_
recent	_	_
years	_	_
there	_	_
is	_	_
a	_	_
great	_	_
progress	_	_
in	_	_
the	_	_
area	_	_
of	_	_
generative	_	_
models	_	_
.	_	_

#9
In	_	_
particular	_	_
,	_	_
Generative	_	_
Adversarial	_	_
Networks	_	_
(	_	_
GANs	_	_
)	_	_
[	_	_
1	_	_
]	_	_
,	_	_
proposed	_	_
a	_	_
radically	_	_
new	_	_
approach	_	_
for	_	_
training	_	_
a	_	_
generative	_	_
model	_	_
.	_	_

#10
This	_	_
formulation	_	_
allows	_	_
one	_	_
to	_	_
capture	_	_
high	_	_
dimensional	_	_
and	_	_
complex	_	_
distributions	_	_
efficiently	_	_
using	_	_
a	_	_
minmax	_	_
game	_	_
between	_	_
two	_	_
Neural	_	_
Networks	_	_
-	_	_
one	_	_
that	_	_
generates	_	_
samples	_	_
and	_	_
one	_	_
that	_	_
evaluates	_	_
them	_	_
as	_	_
real	_	_
or	_	_
fake	_	_
.	_	_

#11
In	_	_
this	_	_
game	_	_
and	_	_
for	_	_
image	_	_
data	_	_
,	_	_
the	_	_
generator	_	_
learns	_	_
the	_	_
mapping	_	_
from	_	_
a	_	_
low	_	_
dimensional	_	_
space	_	_
to	_	_
the	_	_
space	_	_
of	_	_
images	_	_
,	_	_
allowing	_	_
one	_	_
to	_	_
sample	_	_
images	_	_
from	_	_
the	_	_
high-dimensional	_	_
distribution	_	_
by	_	_
sampling	_	_
from	_	_
a	_	_
lower-dimensional	_	_
distribution	_	_
.	_	_

#12
These	_	_
models	_	_
have	_	_
been	_	_
applied	_	_
in	_	_
many	_	_
computer	_	_
vision	_	_
tasks	_	_
like	_	_
human	_	_
brain	_	_
decoding	_	_
[	_	_
2	_	_
]	_	_
or	_	_
realistic	_	_
images	_	_
synthesis	_	_
[	_	_
3	_	_
]	_	_
.	_	_

#13
Furthermore	_	_
,	_	_
in	_	_
tasks	_	_
where	_	_
data	_	_
are	_	_
limited	_	_
(	_	_
e.g.	_	_
biomedical	_	_
datasets	_	_
)	_	_
it	_	_
can	_	_
be	_	_
used	_	_
for	_	_
data	_	_
augmentation	_	_
.	_	_

#14
One	_	_
major	_	_
limitation	_	_
of	_	_
current	_	_
deep	_	_
neural	_	_
network	_	_
models	_	_
is	_	_
the	_	_
lack	_	_
of	_	_
a	_	_
mechanism	_	_
for	_	_
knowledge	_	_
transfer	_	_
between	_	_
tasks	_	_
.	_	_

#15
Transfer	_	_
learning	_	_
aims	_	_
to	_	_
address	_	_
this	_	_
limitation	_	_
by	_	_
suggesting	_	_
novel	_	_
ways	_	_
for	_	_
transferring	_	_
the	_	_
experience	_	_
between	_	_
different	_	_
tasks	_	_
[	_	_
4	_	_
]	_	_
or	_	_
even	_	_
models	_	_
[	_	_
5	_	_
]	_	_
.	_	_

#16
However	_	_
,	_	_
these	_	_
works	_	_
focus	_	_
on	_	_
transferring	_	_
the	_	_
knowledge	_	_
of	_	_
a	_	_
network	_	_
with	_	_
respect	_	_
to	_	_
the	_	_
ability	_	_
of	_	_
mapping	_	_
images	_	_
to	_	_
a	_	_
number	_	_
of	_	_
categories	_	_
.	_	_

#17
Recently	_	_
,	_	_
authors	_	_
in	_	_
[	_	_
6	_	_
]	_	_
,	_	_
following	_	_
a	_	_
Teacher-Student	_	_
approach	_	_
,	_	_
attempted	_	_
to	_	_
transfer	_	_
the	_	_
attention	_	_
of	_	_
a	_	_
large	_	_
network	_	_
to	_	_
one	_	_
with	_	_
fewer	_	_
parameters	_	_
by	_	_
incorporating	_	_
loss	_	_
functions	_	_
between	_	_
the	_	_
Teacher	_	_
and	_	_
the	_	_
Student	_	_
intermediate	_	_
layers	_	_
.	_	_

#18
It	_	_
has	_	_
also	_	_
been	_	_
observed	_	_
,	_	_
that	_	_
intermediate	_	_
layers	_	_
of	_	_
CNNs	_	_
act	_	_
as	_	_
weak	_	_
object	_	_
detectors	_	_
[	_	_
7	_	_
]	_	_
,	_	_
[	_	_
8	_	_
]	_	_
,	_	_
[	_	_
9	_	_
]	_	_
.	_	_

#19
This	_	_
occurs	_	_
naturally	_	_
as	_	_
the	_	_
filters	_	_
,	_	_
especially	_	_
in	_	_
higher	_	_
layers	_	_
,	_	_
tend	_	_
to	_	_
synthesize	_	_
objects	_	_
.	_	_

#20
Authors	_	_
in	_	_
[	_	_
10	_	_
]	_	_
inspired	_	_
by	_	_
this	_	_
observation	_	_
,	_	_
have	_	_
shown	_	_
that	_	_
global	_	_
average	_	_
pooling	_	_
layers	_	_
can	_	_
be	_	_
used	_	_
in	_	_
order	_	_
to	_	_
create	_	_
Class	_	_
Activation	_	_
Maps	_	_
(	_	_
CAMs	_	_
)	_	_
.	_	_

#21
In	_	_
this	_	_
work	_	_
,	_	_
we	_	_
focus	_	_
on	_	_
GAN	_	_
discriminators	_	_
inability	_	_
to	_	_
locate	_	_
the	_	_
regions	_	_
of	_	_
interest	_	_
when	_	_
trying	_	_
to	_	_
learn	_	_
how	_	_
to	_	_
discriminate	_	_
real	_	_
versus	_	_
fake	_	_
images	_	_
.	_	_

#22
Specifically	_	_
,	_	_
we	_	_
investigate	_	_
if	_	_
a	_	_
discriminator	_	_
uses	_	_
patterns	_	_
within	_	_
areas	_	_
of	_	_
interest	_	_
of	_	_
an	_	_
image	_	_
.	_	_

#23
Our	_	_
findings	_	_
indicate	_	_
that	_	_
discriminators	_	_
in	_	_
a	_	_
regular	_	_
GAN	_	_
fail	_	_
to	_	_
locate	_	_
the	_	_
object	_	_
efficiently-	_	_
thus	_	_
evaluating	_	_
regions	_	_
that	_	_
are	_	_
not	_	_
always	_	_
of	_	_
much	_	_
interest	_	_
.	_	_

#24
In	_	_
this	_	_
context	_	_
,	_	_
we	_	_
propose	_	_
a	_	_
novel	_	_
formulation	_	_
for	_	_
training	_	_
GANs	_	_
,	_	_
using	_	_
a	_	_
Teacher	_	_
network	_	_
in	_	_
order	_	_
to	_	_
help	_	_
the	_	_
discriminator	_	_
learn	_	_
where	_	_
to	_	_
pay	_	_
attention	_	_
to	_	_
.	_	_

#25
Results	_	_
indicate	_	_
that	_	_
our	_	_
method	_	_
both	_	_
improves	_	_
the	_	_
quality	_	_
of	_	_
the	_	_
generated	_	_
image	_	_
as	_	_
well	_	_
as	_	_
it	_	_
provides	_	_
a	_	_
weakly	_	_
localization	_	_
of	_	_
the	_	_
objects	_	_
on	_	_
the	_	_
generated	_	_
images	_	_
.	_	_

#26
II	_	_
.	_	_

#27
PROPOSED	_	_
METHOD	_	_
A.	_	_
Overview	_	_
Our	_	_
method	_	_
is	_	_
mainly	_	_
inspired	_	_
by	_	_
two	_	_
recent	_	_
advances	_	_
in	_	_
computer	_	_
vision	_	_
.	_	_

#28
Firstly	_	_
,	_	_
authors	_	_
in	_	_
[	_	_
6	_	_
]	_	_
,	_	_
showed	_	_
that	_	_
small	_	_
CNNs	_	_
achieve	_	_
better	_	_
performance	_	_
,	_	_
if	_	_
they	_	_
learn	_	_
to	_	_
mimic	_	_
behavior	_	_
of	_	_
attention	_	_
maps	_	_
in	_	_
intermediate	_	_
layers	_	_
of	_	_
bigger	_	_
networks	_	_
.	_	_

#29
To	_	_
this	_	_
end	_	_
,	_	_
the	_	_
attention	_	_
maps	_	_
of	_	_
intermediate	_	_
layers	_	_
of	_	_
a	_	_
larger	_	_
network	_	_
are	_	_
transferred	_	_
to	_	_
the	_	_
small	_	_
network	_	_
by	_	_
attaching	_	_
several	_	_
loss	_	_
functions	_	_
in	_	_
intermediate	_	_
feature	_	_
maps	_	_
.	_	_

#30
Additionally	_	_
authors	_	_
in	_	_
[	_	_
10	_	_
]	_	_
,	_	_
showed	_	_
that	_	_
CNNs	_	_
which	_	_
use	_	_
average	_	_
pooling	_	_
at	_	_
the	_	_
last	_	_
layer	_	_
can	_	_
naturally	_	_
deliver	_	_
a	_	_
specific	_	_
type	_	_
of	_	_
attention	_	_
maps	_	_
,	_	_
called	_	_
Class	_	_
Activation	_	_
Maps	_	_
(	_	_
CAMs	_	_
)	_	_
.	_	_

#31
These	_	_
attention	_	_
maps	_	_
can	_	_
be	_	_
used	_	_
to	_	_
ar	_	_
X	_	_
iv	_	_
:1	_	_
2	_	_
.	_	_

#32
0v	_	_
1	_	_
[	_	_
cs	_	_
.C	_	_
V	_	_
]	_	_
2	_	_
5	_	_
Fe	_	_
b	_	_
Fig.	_	_
1	_	_
.	_	_

#33
Overview	_	_
of	_	_
the	_	_
proposed	_	_
method	_	_
perform	_	_
weakly	_	_
object	_	_
detection	_	_
[	_	_
8	_	_
]	_	_
.	_	_

#34
As	_	_
it	_	_
is	_	_
shown	_	_
in	_	_
Figure	_	_
2	_	_
,	_	_
a	_	_
modified	_	_
version	_	_
of	_	_
Class	_	_
Activation	_	_
Maps	_	_
(	_	_
CAMs	_	_
)	_	_
can	_	_
be	_	_
used	_	_
to	_	_
help	_	_
the	_	_
discriminator	_	_
pay	_	_
more	_	_
attention	_	_
in	_	_
regions	_	_
of	_	_
interest	_	_
.	_	_

#35
The	_	_
second	_	_
one	_	_
is	_	_
the	_	_
ability	_	_
of	_	_
GANs	_	_
to	_	_
generate	_	_
realistic	_	_
images	_	_
by	_	_
training	_	_
a	_	_
neural	_	_
network	_	_
to	_	_
generate	_	_
samples	_	_
while	_	_
a	_	_
second	_	_
one	_	_
evaluates	_	_
them	_	_
as	_	_
real	_	_
or	_	_
fake	_	_
.	_	_

#36
In	_	_
this	_	_
context	_	_
,	_	_
here	_	_
we	_	_
present	_	_
a	_	_
novel	_	_
method	_	_
that	_	_
allows	_	_
us	_	_
to	_	_
transfer	_	_
the	_	_
knowledge	_	_
of	_	_
a	_	_
large	_	_
network	_	_
,	_	_
originally	_	_
trained	_	_
to	_	_
discriminate	_	_
between	_	_
different	_	_
categories	_	_
of	_	_
HEp-2	_	_
cell	_	_
images	_	_
,	_	_
into	_	_
the	_	_
discriminator	_	_
of	_	_
a	_	_
GAN	_	_
.	_	_

#37
To	_	_
achieve	_	_
this	_	_
,	_	_
we	_	_
reformulate	_	_
the	_	_
method	_	_
of	_	_
CAMs	_	_
[	_	_
10	_	_
]	_	_
in	_	_
a	_	_
way	_	_
that	_	_
allows	_	_
us	_	_
to	_	_
incorporate	_	_
the	_	_
soft	_	_
responses	_	_
of	_	_
all	_	_
classes	_	_
in	_	_
the	_	_
estimation	_	_
of	_	_
the	_	_
CAM	_	_
image	_	_
.	_	_

#38
Our	_	_
intuition	_	_
is	_	_
that	_	_
there	_	_
are	_	_
some	_	_
common	_	_
features	_	_
shared	_	_
across	_	_
HEp-2	_	_
cell	_	_
image	_	_
categories	_	_
located	_	_
in	_	_
the	_	_
same	_	_
area	_	_
,	_	_
and	_	_
hence	_	_
,	_	_
incorporating	_	_
them	_	_
according	_	_
to	_	_
a	_	_
Soft-Max	_	_
response	_	_
allows	_	_
us	_	_
to	_	_
proportionally	_	_
consider	_	_
patterns	_	_
from	_	_
all	_	_
categories	_	_
.	_	_

#39
The	_	_
proposed	_	_
method	_	_
is	_	_
named	_	_
as	_	_
Soft-CAMS	_	_
(	_	_
SCAMS	_	_
)	_	_
.	_	_

#40
The	_	_
Soft-CAMs	_	_
,	_	_
which	_	_
are	_	_
presented	_	_
in	_	_
the	_	_
following	_	_
section	_	_
,	_	_
will	_	_
be	_	_
used	_	_
to	_	_
guide	_	_
the	_	_
attention	_	_
of	_	_
a	_	_
discriminator	_	_
to	_	_
better	_	_
localize	_	_
the	_	_
cell	_	_
.	_	_

#41
Therefore	_	_
,	_	_
we	_	_
introduce	_	_
an	_	_
additional	_	_
cost	_	_
in	_	_
the	_	_
original	_	_
GAN-minmax	_	_
optimization	_	_
problem	_	_
.	_	_

#42
This	_	_
cost	_	_
is	_	_
applied	_	_
on	_	_
the	_	_
discriminator	_	_
and	_	_
enforces	_	_
it	_	_
to	_	_
pay	_	_
more	_	_
attention	_	_
into	_	_
areas	_	_
of	_	_
interest	_	_
(	_	_
as	_	_
they	_	_
are	_	_
defined	_	_
by	_	_
the	_	_
Teacher	_	_
network	_	_
)	_	_
.	_	_

#43
The	_	_
proposed	_	_
method	_	_
is	_	_
summarized	_	_
in	_	_
Figure	_	_
1	_	_
.	_	_

#44
B.	_	_
Soft-Class	_	_
Activation	_	_
Maps	_	_
The	_	_
ability	_	_
of	_	_
Deep	_	_
Convolutional	_	_
Neural	_	_
Networks	_	_
to	_	_
perform	_	_
weak	_	_
object	_	_
detection	_	_
in	_	_
intermediate	_	_
layers	_	_
has	_	_
been	_	_
observed	_	_
in	_	_
a	_	_
number	_	_
of	_	_
works	_	_
[	_	_
7	_	_
]	_	_
,	_	_
[	_	_
8	_	_
]	_	_
,	_	_
[	_	_
9	_	_
]	_	_
.	_	_

#45
Authors	_	_
in	_	_
[	_	_
10	_	_
]	_	_
applied	_	_
global	_	_
average	_	_
pooling	_	_
(	_	_
which	_	_
is	_	_
used	_	_
in	_	_
many	_	_
state-of-the-art	_	_
deep	_	_
neural	_	_
network	_	_
architectures	_	_
)	_	_
[	_	_
11	_	_
]	_	_
,	_	_
[	_	_
12	_	_
]	_	_
to	_	_
perform	_	_
weakly	_	_
localization	_	_
of	_	_
objects	_	_
in	_	_
an	_	_
image	_	_
.	_	_

#46
Moreover	_	_
,	_	_
they	_	_
presented	_	_
a	_	_
scheme	_	_
,	_	_
which	_	_
allows	_	_
one	_	_
to	_	_
determine	_	_
the	_	_
attention	_	_
of	_	_
a	_	_
CNN	_	_
on	_	_
input	_	_
image	_	_
implicitly	_	_
.	_	_

#47
In	_	_
this	_	_
work	_	_
,	_	_
we	_	_
take	_	_
advantage	_	_
of	_	_
their	_	_
findings	_	_
to	_	_
extract	_	_
the	_	_
attention	_	_
map	_	_
from	_	_
a	_	_
large	_	_
CNN	_	_
and	_	_
then	_	_
use	_	_
this	_	_
to	_	_
train	_	_
the	_	_
discriminator	_	_
of	_	_
the	_	_
GAN	_	_
.	_	_

#48
Furthermore	_	_
,	_	_
we	_	_
present	_	_
a	_	_
modified	_	_
version	_	_
of	_	_
the	_	_
CAM	_	_
which	_	_
we	_	_
call	_	_
Soft-CAM	_	_
(	_	_
SC	_	_
)	_	_
that	_	_
can	_	_
be	_	_
expressed	_	_
as	_	_
follows	_	_
:	_	_
Fig.	_	_
2	_	_
.	_	_

#49
Soft-Max	_	_
Activation	_	_
Map	_	_
SC	_	_
=	_	_
∑	_	_
j=1	_	_
,	_	_
C	_	_
(	_	_
SM	_	_
(	_	_
j	_	_
)	_	_
·	_	_
∑	_	_
i=1	_	_
,	_	_
K	_	_
FMi	_	_
·Wi	_	_
,	_	_
j	_	_
)	_	_
(	_	_
1	_	_
)	_	_
In	_	_
the	_	_
previous	_	_
equation	_	_
SM	_	_
∈	_	_
RC	_	_
is	_	_
a	_	_
vector	_	_
containing	_	_
Soft-Max	_	_
responses	_	_
of	_	_
the	_	_
classifier	_	_
,	_	_
K	_	_
is	_	_
a	_	_
scalar	_	_
equal	_	_
to	_	_
the	_	_
number	_	_
of	_	_
channels	_	_
before	_	_
global	_	_
average	_	_
pooling	_	_
and	_	_
C	_	_
is	_	_
a	_	_
scalar	_	_
equals	_	_
the	_	_
number	_	_
of	_	_
categories	_	_
.	_	_

#50
This	_	_
vector	_	_
allows	_	_
us	_	_
to	_	_
weight	_	_
the	_	_
contribution	_	_
of	_	_
each	_	_
feature	_	_
map	_	_
in	_	_
the	_	_
Soft-CAM	_	_
computation	_	_
for	_	_
each	_	_
category	_	_
proportionally	_	_
to	_	_
the	_	_
classification	_	_
probability	_	_
.	_	_

#51
Index	_	_
j	_	_
iterates	_	_
over	_	_
the	_	_
number	_	_
of	_	_
categories	_	_
and	_	_
index	_	_
i	_	_
iterates	_	_
over	_	_
the	_	_
number	_	_
of	_	_
available	_	_
feature	_	_
maps	_	_
.	_	_

#52
In	_	_
total	_	_
,	_	_
there	_	_
are	_	_
K	_	_
feature	_	_
maps	_	_
and	_	_
C	_	_
categories	_	_
.	_	_

#53
Each	_	_
feature	_	_
map	_	_
is	_	_
a	_	_
two	_	_
dimensional	_	_
image	_	_
.	_	_

#54
Matrix	_	_
W	_	_
∈	_	_
RKC	_	_
allows	_	_
us	_	_
to	_	_
scale	_	_
each	_	_
i-th	_	_
feature	_	_
map	_	_
with	_	_
a	_	_
weight	_	_
associated	_	_
with	_	_
the	_	_
j-th	_	_
category	_	_
.	_	_

#55
The	_	_
Soft-CAM	_	_
is	_	_
a	_	_
(	_	_
single	_	_
channel	_	_
)	_	_
two-dimensional	_	_
image	_	_
with	_	_
the	_	_
same	_	_
dimensions	_	_
as	_	_
the	_	_
feature	_	_
maps	_	_
.	_	_

#56
This	_	_
image	_	_
sums	_	_
proportionally	_	_
the	_	_
contribution	_	_
of	_	_
each	_	_
class	_	_
to	_	_
the	_	_
computation	_	_
of	_	_
CAM	_	_
.	_	_

#57
It	_	_
is	_	_
important	_	_
to	_	_
notice	_	_
that	_	_
for	_	_
the	_	_
discriminator	_	_
network	_	_
,	_	_
we	_	_
have	_	_
a	_	_
single	_	_
class	_	_
while	_	_
for	_	_
the	_	_
Teacher-Network	_	_
we	_	_
have	_	_
more	_	_
than	_	_
one	_	_
classes	_	_
.	_	_

#58
One	_	_
major	_	_
advantage	_	_
of	_	_
the	_	_
proposed	_	_
scheme	_	_
is	_	_
that	_	_
it	_	_
allows	_	_
one	_	_
to	_	_
naturally	_	_
incorporate	_	_
class	_	_
information	_	_
in	_	_
the	_	_
discriminator	_	_
,	_	_
without	_	_
modifying	_	_
the	_	_
formulation	_	_
.	_	_

#59
Figure	_	_
2	_	_
,	_	_
displays	_	_
a	_	_
graphical	_	_
illustration	_	_
of	_	_
the	_	_
computation	_	_
of	_	_
Soft-CAM	_	_
presented	_	_
in	_	_
Eqn	_	_
.	_	_

#60
1	_	_
as	_	_
well	_	_
as	_	_
a	_	_
comparison	_	_
with	_	_
the	_	_
regular	_	_
CAM	_	_
computation	_	_
.	_	_

#61
Fig.	_	_
3	_	_
.	_	_

#62
Left	_	_
:	_	_
The	_	_
cell	_	_
image	_	_
.	_	_

#63
Middle	_	_
:	_	_
The	_	_
attention	_	_
map	_	_
of	_	_
a	_	_
SqueezeNet	_	_
drawn	_	_
on	_	_
top	_	_
of	_	_
a	_	_
cell	_	_
image	_	_
.	_	_

#64
Red	_	_
color	_	_
indicates	_	_
more	_	_
contribution	_	_
in	_	_
the	_	_
classification	_	_
result	_	_
.	_	_

#65
Right	_	_
:	_	_
The	_	_
attention	_	_
map	_	_
of	_	_
a	_	_
ResNet	_	_
.	_	_

#66
C.	_	_
Attention	_	_
transfer	_	_
from	_	_
an	_	_
Expert	_	_
Network	_	_
As	_	_
we	_	_
have	_	_
already	_	_
claimed	_	_
,	_	_
the	_	_
discriminator	_	_
of	_	_
a	_	_
regular	_	_
GAN	_	_
,	_	_
is	_	_
unable	_	_
to	_	_
efficiently	_	_
locate	_	_
the	_	_
region	_	_
of	_	_
interest	_	_
(	_	_
location	_	_
of	_	_
cell	_	_
)	_	_
.	_	_

#67
This	_	_
is	_	_
also	_	_
demonstrated	_	_
in	_	_
Figure	_	_
4	_	_
.	_	_

#68
In	_	_
order	_	_
to	_	_
help	_	_
the	_	_
discriminator	_	_
better	_	_
localize	_	_
the	_	_
cell	_	_
,	_	_
here	_	_
we	_	_
are	_	_
incorporating	_	_
a	_	_
large	_	_
network	_	_
(	_	_
ResNet-18	_	_
)	_	_
[	_	_
12	_	_
]	_	_
,	_	_
trained	_	_
on	_	_
a	_	_
large	_	_
corpus	_	_
of	_	_
HEp-2	_	_
cell	_	_
images	_	_
[	_	_
13	_	_
]	_	_
which	_	_
was	_	_
able	_	_
to	_	_
perform	_	_
a	_	_
state-of-the-art	_	_
weak	_	_
localization	_	_
of	_	_
the	_	_
cell	_	_
inside	_	_
image	_	_
as	_	_
shown	_	_
in	_	_
Figure	_	_
5	_	_
.	_	_

#69
We	_	_
also	_	_
claim	_	_
that	_	_
this	_	_
network	_	_
should	inference	_
have	_	_
enough	_	_
capacity	_	_
to	_	_
learn	_	_
the	_	_
mapping	_	_
between	_	_
the	_	_
images	_	_
and	_	_
the	_	_
class	_	_
categories	_	_
.	_	_

#70
One	_	_
way	_	_
to	_	_
ensure	_	_
this	_	_
,	_	_
is	_	_
to	_	_
require	_	_
that	_	_
the	_	_
network	_	_
will	_	_
achieve	_	_
a	_	_
human-level	_	_
classification	_	_
score	_	_
.	_	_

#71
As	_	_
we	_	_
show	_	_
in	_	_
the	_	_
experimental	_	_
results	_	_
,	_	_
the	_	_
proposed	_	_
Teacher-Network	_	_
is	_	_
able	_	_
to	_	_
surpass	_	_
human-level	_	_
error	_	_
.	_	_

#72
On	_	_
the	_	_
contrary	_	_
,	_	_
as	_	_
we	_	_
show	_	_
in	_	_
Figure	_	_
3	_	_
,	_	_
a	_	_
SqueezeNet	_	_
[	_	_
11	_	_
]	_	_
network	_	_
(	_	_
image	_	_
in	_	_
the	_	_
middle	_	_
)	_	_
is	_	_
not	_	_
able	_	_
to	_	_
perform	_	_
a	_	_
robust	_	_
weak	_	_
localization	_	_
.	_	_

#73
Also	_	_
,	_	_
in	_	_
experiments	_	_
we	_	_
performed	_	_
we	_	_
noticed	_	_
that	_	_
SqueezeNet	_	_
[	_	_
11	_	_
]	_	_
was	_	_
not	_	_
able	_	_
to	_	_
surpass	_	_
human	_	_
level	_	_
error	_	_
.	_	_

#74
D.	_	_
Train	_	_
GANS	_	_
with	_	_
Attention	_	_
(	_	_
ATA-GANS	_	_
)	_	_
In	_	_
this	_	_
section	_	_
we	_	_
first	_	_
show	_	_
that	_	_
a	_	_
discriminator	_	_
in	_	_
a	_	_
GAN	_	_
whilst	_	_
being	_	_
able	_	_
to	_	_
separate	_	_
real	_	_
from	_	_
fake	_	_
images	_	_
,	_	_
is	_	_
not	_	_
able	_	_
to	_	_
localize	_	_
the	_	_
region	_	_
of	_	_
interest	_	_
of	_	_
the	_	_
cell	_	_
.	_	_

#75
Then	_	_
we	_	_
present	_	_
the	_	_
original	_	_
GAN	_	_
minmax	_	_
problem	_	_
and	_	_
our	_	_
modified	_	_
version	_	_
that	_	_
incorporates	_	_
an	_	_
attention	_	_
cost	_	_
which	_	_
helps	_	_
the	_	_
discriminator	_	_
to	_	_
better	_	_
localize	_	_
the	_	_
areas	_	_
of	_	_
interest	_	_
.	_	_

#76
The	_	_
ability	_	_
of	_	_
the	_	_
discriminator	_	_
to	_	_
locate	_	_
the	_	_
object	_	_
of	_	_
interest	_	_
appropriately	_	_
(	_	_
here	_	_
the	_	_
cell	_	_
)	_	_
is	_	_
very	_	_
important	_	_
.	_	_

#77
More	_	_
specifically	_	_
the	_	_
discriminator	_	_
might	speculation	_
learn	_	_
to	_	_
classify	_	_
images	_	_
as	_	_
fake	_	_
by	_	_
focusing	_	_
on	_	_
particular	_	_
patterns	_	_
in	_	_
the	_	_
boundaries	_	_
of	_	_
the	_	_
image	_	_
or	_	_
even	_	_
might	speculation	_
focus	_	_
on	_	_
patterns	_	_
that	_	_
are	_	_
not	_	_
related	_	_
to	_	_
the	_	_
information	_	_
that	_	_
is	_	_
valuable	_	_
for	_	_
classification	_	_
.	_	_

#78
In	_	_
the	_	_
following	_	_
Figure	_	_
4	_	_
,	_	_
we	_	_
show	_	_
the	_	_
Soft-Class	_	_
Activation	_	_
Maps	_	_
(	_	_
SCAMs	_	_
)	_	_
of	_	_
two	_	_
images-	_	_
one	_	_
real	_	_
and	_	_
one	_	_
fake	_	_
.	_	_

#79
It	_	_
is	_	_
obvious	_	_
that	_	_
the	_	_
attention	_	_
of	_	_
the	_	_
discriminator	_	_
spreads	_	_
across	_	_
the	_	_
whole	_	_
image	_	_
and	_	_
does	_	_
not	_	_
focus	_	_
on	_	_
the	_	_
area	_	_
of	_	_
interest-	_	_
which	_	_
in	_	_
this	_	_
case	_	_
is	_	_
the	_	_
area	_	_
where	_	_
the	_	_
cell	_	_
is	_	_
located	_	_
.	_	_

#80
As	_	_
we	_	_
have	_	_
shown	_	_
previously	_	_
and	_	_
depicted	_	_
in	_	_
Figure	_	_
4	_	_
the	_	_
discriminator	_	_
of	_	_
a	_	_
GAN	_	_
,	_	_
is	_	_
unable	_	_
to	_	_
efficiently	_	_
locate	_	_
the	_	_
region	_	_
of	_	_
interest	_	_
(	_	_
location	_	_
of	_	_
cell	_	_
)	_	_
.	_	_

#81
In	_	_
order	_	_
Fig.	_	_
4	_	_
.	_	_

#82
Soft-CAM	_	_
of	_	_
the	_	_
discriminator	_	_
of	_	_
a	_	_
regular	_	_
GAN	_	_
.	_	_

#83
TopLeft	_	_
:	_	_
A	_	_
real	_	_
image	_	_
,	_	_
Top-Right	_	_
:	_	_
A	_	_
generated	_	_
image	_	_
.	_	_

#84
Bottom-Left	_	_
:	_	_
The	_	_
attention	_	_
map	_	_
of	_	_
the	_	_
real	_	_
image	_	_
.	_	_

#85
Bottom-Right	_	_
:	_	_
The	_	_
attention	_	_
map	_	_
of	_	_
the	_	_
generated	_	_
image	_	_
.	_	_

#86
Fig.	_	_
5	_	_
.	_	_

#87
Teacher	_	_
Network	_	_
:	_	_
Soft-Class	_	_
Activation	_	_
Maps	_	_
from	_	_
ResNet18	_	_
,	_	_
trained	_	_
on	_	_
HEp-2	_	_
cell	_	_
images	_	_
.	_	_

#88
Top	_	_
Row	_	_
:	_	_
Cell	_	_
Images	_	_
.	_	_

#89
Bottom	_	_
Row	_	_
:	_	_
Soft-Class	_	_
Activation	_	_
Maps	_	_
.	_	_

#90
to	_	_
help	_	_
the	_	_
discriminator	_	_
better	_	_
localize	_	_
the	_	_
cell	_	_
,	_	_
we	_	_
are	_	_
incorporating	_	_
a	_	_
large	_	_
network	_	_
(	_	_
ResNet-18	_	_
)	_	_
[	_	_
12	_	_
]	_	_
,	_	_
trained	_	_
on	_	_
a	_	_
large	_	_
corpus	_	_
of	_	_
HEp-2	_	_
cell	_	_
images	_	_
[	_	_
13	_	_
]	_	_
which	_	_
is	_	_
able	_	_
to	_	_
perform	_	_
state-of-the-art	_	_
weak	_	_
localization	_	_
of	_	_
the	_	_
cell	_	_
inside	_	_
the	_	_
image	_	_
as	_	_
depicted	_	_
in	_	_
Figure	_	_
5	_	_
.	_	_

#91
At	_	_
the	_	_
bottom	_	_
we	_	_
have	_	_
the	_	_
input	_	_
images	_	_
and	_	_
at	_	_
the	_	_
top	_	_
we	_	_
have	_	_
the	_	_
Soft-Class	_	_
Activation	_	_
Maps	_	_
.	_	_

#92
During	_	_
the	_	_
training	_	_
process	_	_
,	_	_
input	_	_
images	_	_
(	_	_
both	_	_
real	_	_
and	_	_
fake	_	_
ones	_	_
)	_	_
are	_	_
passed	_	_
to	_	_
the	_	_
Teacher-Network	_	_
as	_	_
well	_	_
as	_	_
to	_	_
the	_	_
discriminator	_	_
(	_	_
see	_	_
Figure	_	_
1	_	_
)	_	_
.	_	_

#93
It	_	_
is	_	_
obvious	_	_
,	_	_
that	_	_
the	_	_
discriminator	_	_
has	_	_
to	_	_
be	_	_
implemented	_	_
in	_	_
a	_	_
way	_	_
that	_	_
will	_	_
produce	_	_
these	_	_
Soft-CAMs	_	_
.	_	_

#94
In	_	_
this	_	_
context	_	_
in	_	_
Figure	_	_
6	_	_
,	_	_
we	_	_
present	_	_
a	_	_
version	_	_
of	_	_
the	_	_
discriminator	_	_
that	_	_
produces	_	_
two	_	_
outputs	_	_
.	_	_

#95
Firstly	_	_
,	_	_
it	_	_
provides	_	_
the	_	_
binary	_	_
decision	_	_
of	_	_
whether	_	_
the	_	_
input	_	_
image	_	_
is	_	_
real	_	_
or	_	_
fake	_	_
,	_	_
and	_	_
secondly	_	_
,	_	_
it	_	_
produces	_	_
the	_	_
Soft-CAM	_	_
image	_	_
.	_	_

#96
The	_	_
output	_	_
of	_	_
the	_	_
teacher	_	_
network	_	_
together	_	_
with	_	_
the	_	_
Soft-CAM	_	_
output	_	_
of	_	_
the	_	_
discriminator	_	_
is	_	_
then	_	_
used	_	_
in	_	_
order	_	_
to	_	_
compute	_	_
the	_	_
following	_	_
Mean-Square-Error	_	_
Fig.	_	_
6	_	_
.	_	_

#97
The	_	_
architecture	_	_
of	_	_
discriminator	_	_
.	_	_

#98
The	_	_
network	_	_
produces	_	_
a	_	_
binary	_	_
decision	_	_
characterizing	_	_
the	_	_
input	_	_
images	_	_
as	_	_
genuine	_	_
or	_	_
not	_	_
,	_	_
as	_	_
well	_	_
as	_	_
a	_	_
second	_	_
output	_	_
the	_	_
S-CAM	_	_
(	_	_
MSE	_	_
)	_	_
loss	_	_
:	_	_
LSCAM	_	_
=	_	_
(	_	_
TSCAM	_	_
−	_	_
DSCAM	_	_
)	_	_
2	_	_
(	_	_
2	_	_
)	_	_
In	_	_
the	_	_
previous	_	_
equation	_	_
TSCAM	_	_
is	_	_
the	_	_
attention	_	_
map	_	_
produced	_	_
by	_	_
the	_	_
Teacher	_	_
network	_	_
presented	_	_
at	_	_
the	_	_
top	_	_
of	_	_
Figure	_	_
1	_	_
and	_	_
DSCAM	_	_
is	_	_
the	_	_
attention	_	_
map	_	_
produced	_	_
by	_	_
the	_	_
discriminator	_	_
and	_	_
presented	_	_
at	_	_
the	_	_
bottom	_	_
of	_	_
Figure	_	_
1	_	_
.	_	_

#99
However	_	_
,	_	_
this	_	_
loss	_	_
function	_	_
is	_	_
computed	_	_
twice	_	_
for	_	_
the	_	_
training	_	_
of	_	_
the	_	_
discriminator	_	_
,	_	_
one	_	_
for	_	_
the	_	_
real	_	_
image	_	_
and	_	_
one	_	_
for	_	_
the	_	_
generated	_	_
image	_	_
.	_	_

#100
Consequently	_	_
,	_	_
the	_	_
same	_	_
procedure	_	_
is	_	_
repeated	_	_
for	_	_
the	_	_
generated	_	_
image	_	_
and	_	_
the	_	_
total	_	_
loss	_	_
is	_	_
computed	_	_
as	_	_
LSCAMtotal	_	_
=	_	_
LSCAMreal	_	_
+	_	_
LSCAM	_	_
f	_	_
ake	_	_
(	_	_
3	_	_
)	_	_
This	_	_
loss	_	_
is	_	_
being	_	_
added	_	_
to	_	_
the	_	_
Discriminator	_	_
loss	_	_
function	_	_
only	_	_
when	_	_
training	_	_
the	_	_
discriminator	_	_
.	_	_

#101
For	_	_
the	_	_
training	_	_
of	_	_
the	_	_
Generator	_	_
network	_	_
we	_	_
didnt	_	_
incorporate	_	_
and	_	_
attention	_	_
loss	_	_
as	_	_
our	_	_
main	_	_
intuition	_	_
is	_	_
that	_	_
we	_	_
can	_	_
improve	_	_
the	_	_
generator	_	_
by	_	_
allowing	_	_
an	_	_
expert	_	_
network	_	_
teach	_	_
the	_	_
discriminator	_	_
to	_	_
pay	_	_
attention	_	_
.	_	_

#102
The	_	_
optimization	_	_
problem	_	_
is	_	_
therefore	_	_
formulated	_	_
as	_	_
follows	_	_
:	_	_
minGmaxDV	_	_
(	_	_
D	_	_
,	_	_
G	_	_
)	_	_
=	_	_
Ex∼pdata	_	_
[	_	_
log	_	_
(	_	_
D	_	_
(	_	_
x	_	_
)	_	_
)	_	_
]	_	_
+	_	_
Ez∼pz	_	_
[	_	_
log	_	_
(	_	_
1−	_	_
D	_	_
(	_	_
G	_	_
(	_	_
x	_	_
)	_	_
)	_	_
)	_	_
]	_	_
(	_	_
4	_	_
)	_	_
While	_	_
we	_	_
also	_	_
add	_	_
the	_	_
minimization	_	_
of	_	_
the	_	_
MSE	_	_
criterion	_	_
of	_	_
Equation	_	_
3	_	_
on	_	_
the	_	_
discriminator	_	_
update	_	_
step	_	_
.	_	_

#103
III	_	_
.	_	_

#104
EXPERIMENTAL	_	_
RESULTS	_	_
Here	_	_
we	_	_
present	_	_
some	_	_
experimental	_	_
results	_	_
demonstrating	_	_
the	_	_
quality	_	_
of	_	_
generated	_	_
images	_	_
as	_	_
well	_	_
as	_	_
the	_	_
ability	_	_
of	_	_
the	_	_
proposed	_	_
scheme	_	_
to	_	_
provide	_	_
both	_	_
realistic	_	_
new	_	_
samples	_	_
as	_	_
well	_	_
as	_	_
weakly	_	_
annotations	_	_
.	_	_

#105
For	_	_
this	_	_
,	_	_
in	_	_
order	_	_
to	_	_
construct	_	_
the	_	_
Teacher	_	_
network	_	_
,	_	_
we	_	_
used	_	_
ResNet-18	_	_
[	_	_
12	_	_
]	_	_
,	_	_
which	_	_
we	_	_
trained	_	_
a	_	_
on	_	_
the	_	_
task	_	_
of	_	_
HEp-2	_	_
cell	_	_
image	_	_
classification	_	_
using	_	_
the	_	_
dataset	_	_
presented	_	_
in	_	_
[	_	_
13	_	_
]	_	_
.	_	_

#106
This	_	_
network	_	_
achieved	_	_
a	_	_
remarkable	_	_
performance	_	_
on	_	_
the	_	_
dataset	_	_
of	_	_
HEp-2	_	_
cell	_	_
images	_	_
[	_	_
15	_	_
]	_	_
(	_	_
76.28	_	_
%	_	_
accuracy	_	_
)	_	_
surpassing	_	_
human	_	_
level	_	_
performance	_	_
(	_	_
73.3	_	_
%	_	_
)	_	_
and	_	_
approaching	_	_
the	_	_
top	_	_
performance	_	_
(	_	_
78.1	_	_
%	_	_
)	_	_
achieved	_	_
in	_	_
[	_	_
14	_	_
]	_	_
.	_	_

#107
Also	_	_
,	_	_
this	_	_
network	_	_
was	_	_
able	_	_
to	_	_
efficiently	_	_
locate	_	_
the	_	_
object	_	_
of	_	_
interest	_	_
on	_	_
images	_	_
as	_	_
shown	_	_
in	_	_
Figure	_	_
5	_	_
.	_	_

#108
Then	_	_
we	_	_
used	_	_
this	_	_
Teacher-network	_	_
in	_	_
order	_	_
to	_	_
train	_	_
our	_	_
discriminator	_	_
by	_	_
introducing	_	_
one	_	_
extra	_	_
cost	_	_
in	_	_
the	_	_
discriminator	_	_
as	_	_
shown	_	_
in	_	_
Equation	_	_
4	_	_
during	_	_
the	_	_
min-max	_	_
game	_	_
between	_	_
the	_	_
generator	_	_
and	_	_
the	_	_
discriminator	_	_
.	_	_

#109
In	_	_
Figure	_	_
7	_	_
we	_	_
provide	_	_
some	_	_
results	_	_
of	_	_
the	_	_
generated	_	_
images	_	_
one	_	_
the	_	_
left	_	_
side	_	_
,	_	_
and	_	_
some	_	_
real	_	_
images	_	_
on	_	_
the	_	_
right	_	_
side	_	_
.	_	_

#110
Our	_	_
approach	_	_
clearly	_	_
generated	_	_
very	_	_
realistic	_	_
images	_	_
and	_	_
most	_	_
importantly	_	_
,	_	_
we	_	_
verified	_	_
that	_	_
incorporating	_	_
an	_	_
attention	_	_
loss	_	_
does	_	_
not	_	_
affect	_	_
not	_	_
affect	_	_
negatively	_	_
the	_	_
quality	_	_
of	_	_
the	_	_
generators	_	_
images	_	_
.	_	_

#111
Fig.	_	_
7	_	_
.	_	_

#112
Left	_	_
:	_	_
Generated	_	_
Images	_	_
,	_	_
Right	_	_
:	_	_
Real	_	_
Images	_	_
Fig.	_	_
8	_	_
.	_	_

#113
Discriminator	_	_
attention	_	_
maps	_	_
for	_	_
input	_	_
output	_	_
pairs	_	_
after	_	_
training	_	_
with	_	_
our	_	_
method	_	_
.	_	_

#114
These	_	_
images	_	_
provide	_	_
a	_	_
weak	_	_
localization	_	_
of	_	_
the	_	_
cell	_	_
area	_	_
.	_	_

#115
On	_	_
the	_	_
left	_	_
,	_	_
we	_	_
have	_	_
two	_	_
generated	_	_
images	_	_
(	_	_
bottom	_	_
row	_	_
)	_	_
and	_	_
their	_	_
Soft-CAMs	_	_
(	_	_
top	_	_
row	_	_
)	_	_
.On	_	_
the	_	_
right	_	_
,	_	_
we	_	_
have	_	_
two	_	_
real	_	_
images	_	_
(	_	_
bottom	_	_
row	_	_
)	_	_
and	_	_
their	_	_
Soft-CAMs	_	_
(	_	_
top	_	_
row	_	_
)	_	_
.	_	_

#116
Regarding	_	_
the	_	_
ability	_	_
of	_	_
the	_	_
proposed	_	_
scheme	_	_
to	_	_
perform	_	_
a	_	_
weakly	_	_
localization	_	_
,	_	_
in	_	_
Figure	_	_
8	_	_
we	_	_
provide	_	_
some	_	_
Soft-CAMs	_	_
from	_	_
both	_	_
generated	_	_
as	_	_
well	_	_
as	_	_
real	_	_
images	_	_
.	_	_

#117
As	_	_
compared	_	_
to	_	_
Figure	_	_
4	_	_
,	_	_
our	_	_
modified	_	_
minmax	_	_
game	_	_
was	_	_
able	_	_
to	_	_
improve	_	_
the	_	_
attention	_	_
of	_	_
the	_	_
discriminator	_	_
significantly	_	_
.	_	_

#118
Moreover	_	_
,	_	_
as	_	_
we	_	_
are	_	_
interested	_	_
in	_	_
the	_	_
ability	_	_
of	_	_
the	_	_
network	_	_
(	_	_
generator	_	_
)	_	_
to	_	_
generate	_	_
realistic	_	_
image	_	_
and	_	_
the	_	_
discriminator	_	_
to	_	_
perform	_	_
weak	_	_
object	_	_
localization	_	_
,	_	_
we	_	_
provide	_	_
some	_	_
input-output	_	_
pairs	_	_
from	_	_
both	_	_
read	_	_
as	_	_
well	_	_
as	_	_
generated	_	_
images	_	_
.	_	_

#119
Results	_	_
in	_	_
the	_	_
Figure	_	_
8	_	_
verify	_	_
that	_	_
the	_	_
proposed	_	_
scheme	_	_
can	_	_
be	_	_
used	_	_
to	_	_
both	_	_
generate	_	_
images	_	_
as	_	_
well	_	_
as	_	_
to	_	_
provide	_	_
weakly	_	_
annotations	_	_
.	_	_

#120
IV	_	_
.	_	_

#121
CONCLUSIONS	_	_
In	_	_
this	_	_
work	_	_
we	_	_
proposed	_	_
a	_	_
method	_	_
which	_	_
allows	_	_
the	_	_
discriminator	_	_
network	_	_
of	_	_
a	_	_
GAN	_	_
to	_	_
perform	_	_
weakly	_	_
localization	_	_
of	_	_
the	_	_
objects	_	_
of	_	_
interest	_	_
.	_	_

#122
In	_	_
order	_	_
to	_	_
achieve	_	_
this	_	_
we	_	_
proposed	_	_
a	_	_
Teacher-Student	_	_
learning	_	_
scheme	_	_
as	_	_
well	_	_
as	_	_
a	_	_
novel	_	_
type	_	_
of	_	_
Soft-Class	_	_
Activation	_	_
maps	_	_
.	_	_

#123
This	_	_
scheme	_	_
allows	_	_
the	_	_
discriminator	_	_
to	_	_
generate	_	_
weak	_	_
annotation	_	_
of	_	_
the	_	_
generated	_	_
images	_	_
which	_	_
can	_	_
be	_	_
used	_	_
for	_	_
automatic	_	_
annotation	_	_
of	_	_
generated	_	_
images	_	_
.	_	_

#124
In	_	_
the	_	_
future	_	_
we	_	_
plan	_	_
to	_	_
apply	_	_
this	_	_
scheme	_	_
on	_	_
datasets	_	_
designed	_	_
for	_	_
object	_	_
detection	_	_
in	_	_
order	_	_
to	_	_
generate	_	_
both	_	_
images	_	_
as	_	_
well	_	_
as	_	_
weak	_	_
annotations	_	_
.	_	_

#125
We	_	_
plan	_	_
to	_	_
make	_	_
the	_	_
code	_	_
publicly	_	_
available	_	_
after	_	_
the	_	_
publication	_	_
of	_	_
this	_	_
work	_	_
.	_	_