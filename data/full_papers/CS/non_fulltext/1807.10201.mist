#0
A	_	_
Style-Aware	_	_
Content	_	_
Loss	_	_
for	_	_
Real-time	_	_
HD	_	_
Style	_	_
Transfer	_	_
Artsiom	_	_
Sanakoyeu	_	_
?	_	_
,	_	_
Dmytro	_	_
Kotovenko	_	_
?	_	_
,	_	_
Sabine	_	_
Lang	_	_
,	_	_
and	_	_
Björn	_	_
Ommer	_	_
Heidelberg	_	_
Collaboratory	_	_
for	_	_
Image	_	_
Processing	_	_
,	_	_
IWR	_	_
,	_	_
Heidelberg	_	_
University	_	_
,	_	_
Germany	_	_
firstname.lastname	_	_
@	_	_
iwr.uni-heidelberg.de	_	_
Abstract	_	_
.	_	_

#1
Recently	_	_
,	_	_
style	_	_
transfer	_	_
has	_	_
received	_	_
a	_	_
lot	_	_
of	_	_
attention	_	_
.	_	_

#2
While	_	_
much	_	_
of	_	_
this	_	_
research	_	_
has	_	_
aimed	_	_
at	_	_
speeding	_	_
up	_	_
processing	_	_
,	_	_
the	_	_
approaches	_	_
are	_	_
still	_	_
lacking	_	_
from	_	_
a	_	_
principled	_	_
,	_	_
art	_	_
historical	_	_
standpoint	_	_
:	_	_
a	_	_
style	_	_
is	_	_
more	_	_
than	_	_
just	_	_
a	_	_
single	_	_
image	_	_
or	_	_
an	_	_
artist	_	_
,	_	_
but	_	_
previous	_	_
work	_	_
is	_	_
limited	_	_
to	_	_
only	_	_
a	_	_
single	_	_
instance	_	_
of	_	_
a	_	_
style	_	_
or	_	_
shows	_	_
no	_	_
benefit	_	_
from	_	_
more	_	_
images	_	_
.	_	_

#3
Moreover	_	_
,	_	_
previous	_	_
work	_	_
has	_	_
relied	_	_
on	_	_
a	_	_
direct	_	_
comparison	_	_
of	_	_
art	_	_
in	_	_
the	_	_
domain	_	_
of	_	_
RGB	_	_
images	_	_
or	_	_
on	_	_
CNNs	_	_
pre-trained	_	_
on	_	_
ImageNet	_	_
,	_	_
which	_	_
requires	_	_
millions	_	_
of	_	_
labeled	_	_
object	_	_
bounding	_	_
boxes	_	_
and	_	_
can	_	_
introduce	_	_
an	_	_
extra	_	_
bias	_	_
,	_	_
since	_	_
it	_	_
has	_	_
been	_	_
assembled	_	_
without	_	_
artistic	_	_
consideration	_	_
.	_	_

#4
To	_	_
circumvent	_	_
these	_	_
issues	_	_
,	_	_
we	_	_
propose	_	_
a	_	_
style-aware	_	_
content	_	_
loss	_	_
,	_	_
which	_	_
is	_	_
trained	_	_
jointly	_	_
with	_	_
a	_	_
deep	_	_
encoder-decoder	_	_
network	_	_
for	_	_
real-time	_	_
,	_	_
high-resolution	_	_
stylization	_	_
of	_	_
images	_	_
and	_	_
videos	_	_
.	_	_

#5
We	_	_
propose	_	_
a	_	_
quantitative	_	_
measure	_	_
for	_	_
evaluating	_	_
the	_	_
quality	_	_
of	_	_
a	_	_
stylized	_	_
image	_	_
and	_	_
also	_	_
have	_	_
art	_	_
historians	_	_
rank	_	_
patches	_	_
from	_	_
our	_	_
approach	_	_
against	_	_
those	_	_
from	_	_
previous	_	_
work	_	_
.	_	_

#6
These	_	_
and	_	_
our	_	_
qualitative	_	_
results	_	_
ranging	_	_
from	_	_
small	_	_
image	_	_
patches	_	_
to	_	_
megapixel	_	_
stylistic	_	_
images	_	_
and	_	_
videos	_	_
show	_	_
that	_	_
our	_	_
approach	_	_
better	_	_
captures	_	_
the	_	_
subtle	_	_
nature	_	_
in	_	_
which	_	_
a	_	_
style	_	_
affects	_	_
content.1	_	_
Keywords	_	_
:	_	_
Style	_	_
transfer	_	_
,	_	_
generative	_	_
network	_	_
,	_	_
deep	_	_
learning	_	_

#7
1	_	_
Introduction	_	_

#8
A	_	_
picture	_	_
may	_	_
be	_	_
worth	_	_
a	_	_
thousand	_	_
words	_	_
,	_	_
but	_	_
at	_	_
least	_	_
it	_	_
contains	_	_
a	_	_
lot	_	_
of	_	_
very	_	_
diverse	_	_
information	_	_
.	_	_

#9
This	_	_
not	_	_
only	_	_
comprises	_	_
what	_	_
is	_	_
portrayed	_	_
,	_	_
e.g.	_	_
,	_	_
composition	_	_
?	_	_

#10
Both	_	_
authors	_	_
contributed	_	_
equally	_	_
to	_	_
this	_	_
work	_	_
.	_	_

#11
1	_	_
Project	_	_
page	_	_
:	_	_
https	_	_
:	_	_
//compvis.github.io/adaptive-style-transfer	_	_
.	_	_

#12
Fig.	_	_
1	_	_
.	_	_

#13
Evaluating	_	_
the	_	_
fine	_	_
details	_	_
preserved	_	_
by	_	_
our	_	_
approach	_	_
.	_	_

#14
Can	_	_
you	_	_
guess	_	_
which	_	_
of	_	_
the	_	_
cut-outs	_	_
are	_	_
from	_	_
Monet’s	_	_
artworks	_	_
and	_	_
which	_	_
are	_	_
generated	_	_
?	_	_

#15
Solution	_	_
is	_	_
on	_	_
p.	_	_
15.	_	_
ar	_	_
X	_	_
iv	_	_
:1	_	_
7	_	_
.	_	_

#16
1v	_	_
2	_	_
[	_	_
cs	_	_
.C	_	_
V	_	_
]	_	_
2	_	_
8	_	_
Ju	_	_
l	_	_
2	_	_
2	_	_
A.	_	_
Sanakoyeu	_	_
,	_	_
D.	_	_
Kotovenko	_	_
,	_	_
S.	_	_
Lang	_	_
,	_	_
and	_	_
B.	_	_
Ommer	_	_
[	_	_
13	_	_
]	_	_
[	_	_
13	_	_
]	_	_
[	_	_
13	_	_
]	_	_
on	_	_
collection	_	_
[	_	_
24	_	_
]	_	_
on	_	_
collection	_	_
Ours	_	_
on	_	_
collection	_	_
Content	_	_
(	_	_
a	_	_
)	_	_
(	_	_
b	_	_
)	_	_
(	_	_
c	_	_
)	_	_
(	_	_
d	_	_
)	_	_
(	_	_
e	_	_
)	_	_
Fig.	_	_
2	_	_
.	_	_

#17
Style	_	_
transfer	_	_
using	_	_
different	_	_
approaches	_	_
on	_	_
1	_	_
and	_	_
a	_	_
collection	_	_
of	_	_
reference	_	_
style	_	_
images	_	_
.	_	_

#18
(	_	_
a	_	_
)	_	_
[	_	_
13	_	_
]	_	_
using	_	_
van	_	_
Gogh’s	_	_
”Road	_	_
with	_	_
Cypress	_	_
and	_	_
Star”	_	_
as	_	_
reference	_	_
style	_	_
image	_	_
;	_	_
(	_	_
b	_	_
)	_	_
[	_	_
13	_	_
]	_	_
using	_	_
van	_	_
Gogh’s	_	_
”Starry	_	_
night”	_	_
;	_	_
(	_	_
c	_	_
)	_	_
[	_	_
13	_	_
]	_	_
using	_	_
the	_	_
average	_	_
Gram	_	_
matrix	_	_
computed	_	_
across	_	_
the	_	_
collection	_	_
of	_	_
Vincent	_	_
van	_	_
Gogh’s	_	_
artworks	_	_
;	_	_
(	_	_
d	_	_
)	_	_
[	_	_
24	_	_
]	_	_
trained	_	_
on	_	_
the	_	_
collection	_	_
of	_	_
van	_	_
Gogh’s	_	_
artworks	_	_
alternating	_	_
target	_	_
style	_	_
images	_	_
every	_	_
SGD	_	_
mini-batch	_	_
;	_	_
(	_	_
e	_	_
)	_	_
our	_	_
approach	_	_
trained	_	_
on	_	_
the	_	_
same	_	_
collection	_	_
of	_	_
van	_	_
Gogh’s	_	_
artworks	_	_
.	_	_

#19
Stylizations	_	_
(	_	_
a	_	_
)	_	_
and	_	_
(	_	_
b	_	_
)	_	_
depend	_	_
significantly	_	_
on	_	_
the	_	_
particular	_	_
style	_	_
image	_	_
,	_	_
but	_	_
using	_	_
a	_	_
collection	_	_
of	_	_
the	_	_
style	_	_
images	_	_
(	_	_
c	_	_
)	_	_
,	_	_
(	_	_
d	_	_
)	_	_
does	_	_
not	_	_
produce	_	_
visually	_	_
plausible	_	_
results	_	_
,	_	_
due	_	_
to	_	_
oversmoothing	_	_
over	_	_
the	_	_
numerous	_	_
Gram	_	_
matrices	_	_
.	_	_

#20
In	_	_
contrast	_	_
,	_	_
our	_	_
approach	_	_
(	_	_
e	_	_
)	_	_
has	_	_
learned	_	_
how	_	_
van	_	_
Gogh	_	_
is	_	_
altering	_	_
particular	_	_
content	_	_
in	_	_
a	_	_
specific	_	_
manner	_	_
(	_	_
edges	_	_
around	_	_
objects	_	_
also	_	_
stylized	_	_
,	_	_
cf	_	_
.	_	_
bell	_	_
tower	_	_
)	_	_
of	_	_
a	_	_
scene	_	_
and	_	_
individual	_	_
objects	_	_
,	_	_
but	_	_
also	_	_
how	_	_
it	_	_
is	_	_
depicted	_	_
,	_	_
referring	_	_
to	_	_
the	_	_
artistic	_	_
style	_	_
of	_	_
a	_	_
painting	_	_
or	_	_
filters	_	_
applied	_	_
to	_	_
a	_	_
photo	_	_
.	_	_

#21
Especially	_	_
when	_	_
considering	_	_
artistic	_	_
images	_	_
,	_	_
it	_	_
becomes	_	_
evident	_	_
that	_	_
not	_	_
only	_	_
content	_	_
but	_	_
also	_	_
style	_	_
is	_	_
a	_	_
crucial	_	_
part	_	_
of	_	_
the	_	_
message	_	_
an	_	_
image	_	_
communicates	_	_
(	_	_
just	_	_
imagine	_	_
van	_	_
Gogh’s	_	_
Starry	_	_
Night	_	_
in	_	_
the	_	_
style	_	_
of	_	_
Pop	_	_
Art	_	_
)	_	_
.	_	_

#22
Here	_	_
,	_	_
we	_	_
follow	_	_
the	_	_
common	_	_
wording	_	_
of	_	_
our	_	_
community	_	_
and	_	_
refer	_	_
to	_	_
’content’	_	_
as	_	_
a	_	_
synonym	_	_
for	_	_
’subject	_	_
matter’	_	_
or	_	_
’sujet’	_	_
,	_	_
preferably	_	_
used	_	_
in	_	_
art	_	_
history	_	_
.	_	_

#23
A	_	_
vision	_	_
system	_	_
then	_	_
faces	_	_
the	_	_
challenge	_	_
to	_	_
decompose	_	_
and	_	_
separately	_	_
represent	_	_
the	_	_
content	_	_
and	_	_
style	_	_
of	_	_
an	_	_
image	_	_
to	_	_
enable	_	_
a	_	_
direct	_	_
analysis	_	_
based	_	_
on	_	_
each	_	_
individually	_	_
.	_	_

#24
The	_	_
ultimate	_	_
test	_	_
for	_	_
this	_	_
ability	_	_
is	_	_
style	_	_
transfer	_	_
[	_	_
13	_	_
]	_	_
–	_	_
exchanging	_	_
the	_	_
style	_	_
of	_	_
an	_	_
image	_	_
while	_	_
retaining	_	_
its	_	_
content	_	_
.	_	_

#25
In	_	_
contrast	_	_
to	_	_
the	_	_
seminal	_	_
work	_	_
of	_	_
Gatys	_	_
et	_	_
al.	_	_
[	_	_
13	_	_
]	_	_
,	_	_
who	_	_
have	_	_
relied	_	_
on	_	_
powerful	_	_
but	_	_
slow	_	_
iterative	_	_
optimization	_	_
,	_	_
there	_	_
has	_	_
recently	_	_
been	_	_
a	_	_
focus	_	_
on	_	_
feed-forward	_	_
generator	_	_
networks	_	_
[	_	_
24,47,42,44,29,7,21	_	_
]	_	_
.	_	_

#26
The	_	_
crucial	_	_
representation	_	_
in	_	_
all	_	_
these	_	_
approaches	_	_
has	_	_
been	_	_
based	_	_
on	_	_
a	_	_
VGG16	_	_
or	_	_
VGG19	_	_
network	_	_
[	_	_
41	_	_
]	_	_
,	_	_
pre-trained	_	_
on	_	_
ImageNet	_	_
[	_	_
36	_	_
]	_	_
.	_	_

#27
However	_	_
,	_	_
a	_	_
recent	_	_
trend	_	_
in	_	_
deep	_	_
learning	_	_
has	_	_
been	_	_
to	_	_
avoid	_	_
supervised	_	_
pre-training	_	_
on	_	_
a	_	_
million	_	_
images	_	_
with	_	_
tediously	_	_
labeled	_	_
object	_	_
bounding	_	_
boxes	_	_
[	_	_
46	_	_
]	_	_
.	_	_

#28
In	_	_
the	_	_
setting	_	_
of	_	_
style	_	_
transfer	_	_
this	_	_
has	_	_
the	_	_
particular	_	_
benefit	_	_
of	_	_
avoiding	_	_
from	_	_
the	_	_
outset	_	_
any	_	_
bias	_	_
introduced	_	_
by	_	_
ImageNet	_	_
,	_	_
which	_	_
has	_	_
been	_	_
assembled	_	_
without	_	_
artistic	_	_
consideration	_	_
.	_	_

#29
Rather	_	_
than	_	_
utilizing	_	_
a	_	_
separate	_	_
pre-trained	_	_
VGG	_	_
network	_	_
to	_	_
measure	_	_
and	_	_
optimize	_	_
the	_	_
quality	_	_
of	_	_
the	_	_
stylistic	_	_
output	_	_
[	_	_
13,24,47,42,44,29,7	_	_
]	_	_
,	_	_
we	_	_
employ	_	_
an	_	_
encoder-decoder	_	_
architecture	_	_
with	_	_
A	_	_
Style-Aware	_	_
Content	_	_
Loss	_	_
for	_	_
Real-time	_	_
HD	_	_
Style	_	_
Transfer	_	_
3	_	_
adversarial	_	_
discriminator	_	_
,	_	_
Fig.	_	_
3	_	_
,	_	_
to	_	_
stylize	_	_
the	_	_
input	_	_
content	_	_
image	_	_
and	_	_
also	_	_
use	_	_
the	_	_
encoder	_	_
to	_	_
measure	_	_
the	_	_
reconstruction	_	_
loss	_	_
.	_	_

#30
In	_	_
essence	_	_
the	_	_
stylized	_	_
output	_	_
image	_	_
is	_	_
again	_	_
run	_	_
through	_	_
the	_	_
encoder	_	_
and	_	_
compared	_	_
with	_	_
the	_	_
encoded	_	_
input	_	_
content	_	_
image	_	_
.	_	_

#31
Thus	_	_
,	_	_
we	_	_
learn	_	_
a	_	_
style-specific	_	_
content	_	_
loss	_	_
from	_	_
scratch	_	_
,	_	_
which	_	_
adapts	_	_
to	_	_
the	_	_
specific	_	_
way	_	_
in	_	_
which	_	_
a	_	_
particular	_	_
style	_	_
retains	_	_
content	_	_
and	_	_
is	_	_
more	_	_
adaptive	_	_
than	_	_
a	_	_
comparison	_	_
in	_	_
the	_	_
domain	_	_
of	_	_
RGB	_	_
images	_	_
[	_	_
52	_	_
]	_	_
.	_	_

#32
Most	_	_
importantly	_	_
,	_	_
however	_	_
,	_	_
previous	_	_
work	_	_
has	_	_
only	_	_
been	_	_
based	_	_
on	_	_
a	_	_
single	_	_
style	_	_
image	_	_
.	_	_

#33
This	_	_
stands	_	_
in	_	_
stark	_	_
contrast	_	_
to	_	_
art	_	_
history	_	_
which	_	_
understands	_	_
”style	_	_
as	_	_
an	_	_
expression	_	_
of	_	_
a	_	_
collective	_	_
spirit”	_	_
resulting	_	_
in	_	_
a	_	_
”distinctive	_	_
manner	_	_
which	_	_
permits	_	_
the	_	_
grouping	_	_
of	_	_
works	_	_
into	_	_
related	_	_
categories”	_	_
[	_	_
10	_	_
]	_	_
.	_	_

#34
As	_	_
a	_	_
result	_	_
,	_	_
art	_	_
history	_	_
developed	_	_
a	_	_
scheme	_	_
,	_	_
which	_	_
allows	_	_
to	_	_
identify	_	_
groups	_	_
of	_	_
artworks	_	_
based	_	_
on	_	_
shared	_	_
qualities	_	_
.	_	_

#35
Artistic	_	_
style	_	_
consists	_	_
of	_	_
a	_	_
diverse	_	_
range	_	_
of	_	_
elements	_	_
,	_	_
such	_	_
as	_	_
form	_	_
,	_	_
color	_	_
,	_	_
brushstroke	_	_
,	_	_
or	_	_
use	_	_
of	_	_
light	_	_
.	_	_

#36
Therefore	_	_
,	_	_
it	_	_
is	_	_
insufficient	_	_
to	_	_
only	_	_
use	_	_
a	_	_
single	_	_
artwork	_	_
,	_	_
because	_	_
it	_	_
might	speculation	_
not	_	_
represent	_	_
the	_	_
full	_	_
scope	_	_
of	_	_
an	_	_
artistic	_	_
style	_	_
.	_	_

#37
Today	_	_
,	_	_
freely	_	_
available	_	_
art	_	_
datasets	_	_
such	_	_
as	_	_
Wikiart	_	_
[	_	_
25	_	_
]	_	_
easily	_	_
contain	_	_
more	_	_
than	_	_
100K	_	_
images	_	_
,	_	_
thus	_	_
providing	_	_
numerous	_	_
examples	_	_
for	_	_
various	_	_
styles	_	_
.	_	_

#38
Previous	_	_
work	_	_
[	_	_
13,24,47,42,44,29,7	_	_
]	_	_
has	_	_
represented	_	_
style	_	_
based	_	_
on	_	_
the	_	_
Gram	_	_
matrix	_	_
,	_	_
which	_	_
captures	_	_
highly	_	_
image-specific	_	_
style	_	_
statistics	_	_
,	_	_
cf.	_	_
Fig.	_	_
2	_	_
.	_	_

#39
To	_	_
combine	_	_
several	_	_
style	_	_
images	_	_
in	_	_
[	_	_
13,24,47,42,44,29,7	_	_
]	_	_
one	_	_
needs	_	_
to	_	_
aggregate	_	_
their	_	_
Gram	_	_
matrices	_	_
.	_	_

#40
We	_	_
have	_	_
evaluated	_	_
several	_	_
aggregation	_	_
strategies	_	_
and	_	_
averaging	_	_
worked	_	_
the	_	_
best	_	_
,	_	_
Fig.	_	_
2	_	_
(	_	_
c	_	_
)	_	_
.	_	_

#41
But	_	_
,	_	_
obviously	_	_
,	_	_
neither	_	_
art	_	_
history	_	_
,	_	_
nor	_	_
statistics	_	_
suggests	_	_
aggregating	_	_
Gram	_	_
matrices	_	_
.	_	_

#42
Additionally	_	_
,	_	_
we	_	_
investigated	_	_
alternating	_	_
the	_	_
target	_	_
style	_	_
images	_	_
in	_	_
every	_	_
mini-batch	_	_
while	_	_
training	_	_
[	_	_
24	_	_
]	_	_
,	_	_
Fig.	_	_
2	_	_
(	_	_
d	_	_
)	_	_
.	_	_

#43
However	_	_
,	_	_
all	_	_
these	_	_
methods	_	_
can	_	_
not	_	_
make	_	_
proper	_	_
use	_	_
of	_	_
several	_	_
style	_	_
images	_	_
,	_	_
because	_	_
combining	_	_
the	_	_
Gram	_	_
matrices	_	_
of	_	_
several	_	_
images	_	_
forfeits	_	_
the	_	_
details	_	_
of	_	_
style	_	_
,	_	_
cf	_	_
.	_	_
the	_	_
analysis	_	_
in	_	_
Fig.	_	_
2	_	_
.	_	_

#44
In	_	_
contrast	_	_
,	_	_
our	_	_
proposed	_	_
approach	_	_
allows	_	_
to	_	_
combine	_	_
an	_	_
arbitrary	_	_
number	_	_
of	_	_
instances	_	_
of	_	_
a	_	_
style	_	_
during	_	_
training	_	_
.	_	_

#45
We	_	_
conduct	_	_
extensive	_	_
evaluations	_	_
of	_	_
the	_	_
proposed	_	_
style	_	_
transfer	_	_
approach	_	_
;	_	_
we	_	_
quantitatively	_	_
and	_	_
qualitatively	_	_
compare	_	_
it	_	_
against	_	_
numerous	_	_
baselines	_	_
.	_	_

#46
Being	_	_
able	_	_
to	_	_
generate	_	_
high	_	_
quality	_	_
artistic	_	_
works	_	_
in	_	_
high-resolution	_	_
,	_	_
our	_	_
approach	_	_
produces	_	_
visually	_	_
more	_	_
detailed	_	_
stylizations	_	_
than	_	_
the	_	_
current	_	_
state	_	_
of	_	_
the	_	_
art	_	_
style	_	_
transfer	_	_
approaches	_	_
and	_	_
yet	_	_
shows	_	_
real-time	_	_
inference	_	_
speed	_	_
.	_	_

#47
The	_	_
results	_	_
are	_	_
quantitatively	_	_
validated	_	_
by	_	_
experts	_	_
from	_	_
art	_	_
history	_	_
and	_	_
by	_	_
adopting	_	_
in	_	_
this	_	_
paper	_	_
a	_	_
deception	_	_
rate	_	_
metric	_	_
based	_	_
on	_	_
a	_	_
deep	_	_
neural	_	_
network	_	_
for	_	_
artist	_	_
classification	_	_
.	_	_

#48
1.1	_	_
Related	_	_
Work	_	_

#49
In	_	_
recent	_	_
years	_	_
,	_	_
a	_	_
lot	_	_
of	_	_
research	_	_
efforts	_	_
have	_	_
been	_	_
devoted	_	_
to	_	_
texture	_	_
synthesis	_	_
and	_	_
style	_	_
transfer	_	_
problems	_	_
.	_	_

#50
Earlier	_	_
methods	_	_
[	_	_
18	_	_
]	_	_
are	_	_
usually	_	_
non-parametric	_	_
and	_	_
are	_	_
build	_	_
upon	_	_
low-level	_	_
image	_	_
features	_	_
.	_	_

#51
Inspired	_	_
by	_	_
Image	_	_
Analogies	_	_
[	_	_
18	_	_
]	_	_
,	_	_
approaches	_	_
[	_	_
11,30,39,40	_	_
]	_	_
are	_	_
based	_	_
on	_	_
finding	_	_
dense	_	_
correspondence	_	_
between	_	_
content	_	_
and	_	_
style	_	_
image	_	_
and	_	_
often	_	_
require	_	_
image	_	_
pairs	_	_
to	_	_
depict	_	_
similar	_	_
content	_	_
.	_	_

#52
Therefore	_	_
,	_	_
these	_	_
methods	_	_
do	_	_
not	_	_
scale	_	_
to	_	_
the	_	_
setting	_	_
of	_	_
arbitrary	_	_
content	_	_
images	_	_
.	_	_

#53
In	_	_
contrast	_	_
,	_	_
Gatys	_	_
et	_	_
al.	_	_
[	_	_
13,12	_	_
]	_	_
proposed	_	_
a	_	_
more	_	_
flexible	_	_
iterative	_	_
optimization	_	_
approach	_	_
based	_	_
on	_	_
a	_	_
pre-trained	_	_
VGG19	_	_
network	_	_
[	_	_
41	_	_
]	_	_
.	_	_

#54
This	_	_
method	_	_
pro4	_	_
A.	_	_
Sanakoyeu	_	_
,	_	_
D.	_	_
Kotovenko	_	_
,	_	_
S.	_	_
Lang	_	_
,	_	_
and	_	_
B.	_	_
Ommer	_	_
Fig.	_	_
3	_	_
.	_	_

#55
Encoder-decoder	_	_
network	_	_
for	_	_
style	_	_
transfer	_	_
based	_	_
on	_	_
style-aware	_	_
content	_	_
loss	_	_
.	_	_

#56
duces	_	_
high	_	_
quality	_	_
results	_	_
and	_	_
works	_	_
on	_	_
arbitrary	_	_
inputs	_	_
,	_	_
but	_	_
is	_	_
costly	_	_
,	_	_
since	_	_
each	_	_
optimization	_	_
step	_	_
requires	_	_
a	_	_
forward	_	_
and	_	_
backward	_	_
pass	_	_
through	_	_
the	_	_
VGG19	_	_
network	_	_
.	_	_

#57
Subsequent	_	_
methods	_	_
[	_	_
24,42,27	_	_
]	_	_
aimed	_	_
to	_	_
accelerate	_	_
the	_	_
optimization	_	_
procedure	_	_
[	_	_
13	_	_
]	_	_
by	_	_
approximating	_	_
it	_	_
with	_	_
feed-forward	_	_
convolutional	_	_
neural	_	_
networks	_	_
.	_	_

#58
This	_	_
way	_	_
,	_	_
only	_	_
one	_	_
forward	_	_
pass	_	_
through	_	_
the	_	_
network	_	_
is	_	_
required	_	_
to	_	_
generate	_	_
a	_	_
stylized	_	_
image	_	_
.	_	_

#59
Beyond	_	_
that	_	_
,	_	_
a	_	_
number	_	_
of	_	_
methods	_	_
have	_	_
been	_	_
proposed	_	_
to	_	_
address	_	_
different	_	_
aspects	_	_
of	_	_
style	_	_
transfer	_	_
,	_	_
including	_	_
quality	_	_
[	_	_
14,49,4,47,23	_	_
]	_	_
,	_	_
diversity	_	_
[	_	_
28,44	_	_
]	_	_
,	_	_
photorealism	_	_
[	_	_
32	_	_
]	_	_
,	_	_
combining	_	_
several	_	_
styles	_	_
in	_	_
a	_	_
single	_	_
model	_	_
[	_	_
45,7,3	_	_
]	_	_
and	_	_
generalizing	_	_
to	_	_
previously	_	_
unseen	_	_
styles	_	_
[	_	_
21,29,15,38	_	_
]	_	_
.	_	_

#60
However	_	_
,	_	_
all	_	_
these	_	_
methods	_	_
rely	_	_
on	_	_
the	_	_
fixed	_	_
style	_	_
representation	_	_
which	_	_
is	_	_
captured	_	_
by	_	_
the	_	_
features	_	_
of	_	_
a	_	_
VGG	_	_
[	_	_
41	_	_
]	_	_
network	_	_
pre-trained	_	_
on	_	_
ImageNet	_	_
.	_	_

#61
Therefore	_	_
they	_	_
require	_	_
a	_	_
supervised	_	_
pre-training	_	_
on	_	_
millions	_	_
of	_	_
labeled	_	_
object	_	_
bounding	_	_
boxes	_	_
and	_	_
have	_	_
a	_	_
bias	_	_
introduced	_	_
by	_	_
ImageNet	_	_
,	_	_
because	_	_
it	_	_
has	_	_
been	_	_
assembled	_	_
without	_	_
artistic	_	_
consideration	_	_
.	_	_

#62
Moreover	_	_
,	_	_
the	_	_
image	_	_
quality	_	_
achieved	_	_
by	_	_
the	_	_
costly	_	_
optimization	_	_
in	_	_
[	_	_
13	_	_
]	_	_
still	_	_
remains	_	_
an	_	_
upper	_	_
bound	_	_
for	_	_
the	_	_
performance	_	_
of	_	_
recent	_	_
methods	_	_
.	_	_

#63
Other	_	_
works	_	_
like	_	_
[	_	_
48,5,34,9,1	_	_
]	_	_
learn	_	_
how	_	_
to	_	_
discriminate	_	_
different	_	_
techniques	_	_
,	_	_
styles	_	_
and	_	_
contents	_	_
in	_	_
the	_	_
latent	_	_
space	_	_
.	_	_

#64
Zhu	_	_
et	_	_
al.	_	_
[	_	_
52	_	_
]	_	_
learn	_	_
a	_	_
bidirectional	_	_
mapping	_	_
between	_	_
a	_	_
domain	_	_
of	_	_
content	_	_
images	_	_
and	_	_
paintings	_	_
using	_	_
generative	_	_
adversarial	_	_
networks	_	_
.	_	_

#65
Employing	_	_
cycle	_	_
consistency	_	_
loss	_	_
,	_	_
they	_	_
directly	_	_
measure	_	_
the	_	_
distance	_	_
between	_	_
a	_	_
backprojection	_	_
of	_	_
the	_	_
stylized	_	_
output	_	_
and	_	_
the	_	_
content	_	_
image	_	_
in	_	_
the	_	_
RGB	_	_
pixel	_	_
space	_	_
.	_	_

#66
Measuring	_	_
distances	_	_
in	_	_
the	_	_
RGB	_	_
image	_	_
domain	_	_
is	_	_
not	_	_
just	_	_
generally	_	_
prone	_	_
to	_	_
be	_	_
coarse	_	_
,	_	_
but	_	_
,	_	_
especially	_	_
for	_	_
abstract	_	_
styles	_	_
,	_	_
a	_	_
pixel-wise	_	_
comparison	_	_
of	_	_
backwards	_	_
mapped	_	_
stylized	_	_
images	_	_
is	_	_
not	_	_
suited	_	_
.	_	_

#67
Then	_	_
,	_	_
either	_	_
content	_	_
is	_	_
preserved	_	_
and	_	_
the	_	_
stylized	_	_
image	_	_
is	_	_
not	_	_
sufficiently	_	_
abstract	_	_
,	_	_
e.g.	_	_
,	_	_
not	_	_
altering	_	_
object	_	_
boundaries	_	_
,	_	_
or	_	_
the	_	_
stylized	_	_
image	_	_
has	_	_
a	_	_
suitable	_	_
degree	_	_
of	_	_
abstractness	_	_
and	_	_
so	_	_
a	_	_
pixel-based	_	_
comparison	_	_
with	_	_
the	_	_
content	_	_
image	_	_
must	inference	_
fail	_	_
.	_	_

#68
Moreover	_	_
,	_	_
the	_	_
more	_	_
abstract	_	_
the	_	_
style	_	_
is	_	_
,	_	_
the	_	_
more	_	_
potential	_	_
backprojections	_	_
into	_	_
the	_	_
content	_	_
domain	_	_
exist	_	_
,	_	_
because	_	_
this	_	_
mapping	_	_
is	_	_
underdetermined	_	_
(	_	_
think	_	_
of	_	_
the	_	_
many	_	_
possible	_	_
content	_	_
images	_	_
for	_	_
a	_	_
single	_	_
cubistic	_	_
painting	_	_
)	_	_
.	_	_

#69
In	_	_
contrast	_	_
,	_	_
we	_	_
spare	_	_
the	_	_
ill-posed	_	_
backward	_	_
mapping	_	_
of	_	_
styles	_	_
and	_	_
compare	_	_
stylized	_	_
and	_	_
content	_	_
images	_	_
in	_	_
the	_	_
latent	_	_
space	_	_
which	_	_
is	_	_
trained	_	_
jointly	_	_
with	_	_
the	_	_
style	_	_
transfer	_	_
network	_	_
.	_	_

#70
Since	_	_
both	_	_
content	_	_
and	_	_
stylized	_	_
images	_	_
are	_	_
run	_	_
through	_	_
our	_	_
encoder	_	_
,	_	_
A	_	_
Style-Aware	_	_
Content	_	_
Loss	_	_
for	_	_
Real-time	_	_
HD	_	_
Style	_	_
Transfer	_	_
5	_	_
Content	_	_
(	_	_
a	_	_
)	_	_
Pollock	_	_
(	_	_
b	_	_
)	_	_
El-Greco	_	_
(	_	_
c	_	_
)	_	_
Gauguin	_	_
(	_	_
d	_	_
)	_	_
Cézanne	_	_
Fig.	_	_
4	_	_
.	_	_

#71
1st	_	_
row	_	_
-	_	_
results	_	_
of	_	_
style	_	_
transfer	_	_
for	_	_
different	_	_
styles	_	_
.	_	_

#72
2nd	_	_
row	_	_
-	_	_
sketchy	_	_
content	_	_
visualization	_	_
reconstructed	_	_
from	_	_
the	_	_
latent	_	_
space	_	_
E	_	_
(	_	_
x	_	_
)	_	_
using	_	_
method	_	_
of	_	_
[	_	_
33	_	_
]	_	_
.	_	_

#73
(	_	_
a	_	_
)	_	_
The	_	_
encoder	_	_
for	_	_
Pollock	_	_
does	_	_
not	_	_
preserve	_	_
much	_	_
content	_	_
due	_	_
to	_	_
the	_	_
abstract	_	_
style	_	_
;	_	_
(	_	_
b	_	_
)	_	_
only	_	_
rough	_	_
structure	_	_
of	_	_
the	_	_
content	_	_
is	_	_
preserved	_	_
(	_	_
coarse	_	_
patches	_	_
)	_	_
because	_	_
of	_	_
the	_	_
distinct	_	_
style	_	_
of	_	_
El	_	_
Greco	_	_
;	_	_
(	_	_
c	_	_
)	_	_
latent	_	_
space	_	_
highlights	_	_
surfaces	_	_
of	_	_
the	_	_
same	_	_
color	_	_
and	_	_
that	_	_
fine	_	_
object	_	_
details	_	_
are	_	_
ignored	_	_
,	_	_
since	_	_
Gauguin	_	_
was	_	_
less	_	_
interested	_	_
in	_	_
details	_	_
,	_	_
often	_	_
painted	_	_
plain	_	_
surfaces	_	_
and	_	_
used	_	_
vivid	_	_
colors	_	_
;	_	_
(	_	_
d	_	_
)	_	_
encodes	_	_
the	_	_
thick	_	_
,	_	_
wide	_	_
brushstrokes	_	_
Cézanne	_	_
used	_	_
,	_	_
but	_	_
preserves	_	_
a	_	_
larger	_	_
palette	_	_
of	_	_
colors	_	_
.	_	_

#74
the	_	_
latent	_	_
space	_	_
is	_	_
trained	_	_
to	_	_
only	_	_
pay	_	_
attention	_	_
to	_	_
the	_	_
commonalities	_	_
,	_	_
i.e.	_	_
,	_	_
the	_	_
content	_	_
present	_	_
in	_	_
both	_	_
.	_	_

#75
Another	_	_
consequence	_	_
of	_	_
the	_	_
cycle	_	_
consistency	_	_
loss	_	_
is	_	_
that	_	_
it	_	_
requires	_	_
content	_	_
and	_	_
style	_	_
images	_	_
used	_	_
for	_	_
training	_	_
to	_	_
represent	_	_
similar	_	_
scenes	_	_
[	_	_
52	_	_
]	_	_
,	_	_
and	_	_
thus	_	_
training	_	_
data	_	_
preparation	_	_
for	_	_
[	_	_
52	_	_
]	_	_
involves	_	_
tedious	_	_
manual	_	_
filtering	_	_
of	_	_
samples	_	_
,	_	_
while	_	_
our	_	_
approach	_	_
can	_	_
be	_	_
trained	_	_
on	_	_
arbitrary	_	_
unpaired	_	_
content	_	_
and	_	_
style	_	_
images	_	_
.	_	_

#76
2	_	_
Approach	_	_

#77
To	_	_
enable	_	_
a	_	_
fast	_	_
style	_	_
transfer	_	_
that	_	_
instantly	_	_
transfers	_	_
a	_	_
content	_	_
image	_	_
or	_	_
even	_	_
frames	_	_
of	_	_
a	_	_
video	_	_
according	_	_
to	_	_
a	_	_
particular	_	_
style	_	_
,	_	_
we	_	_
need	_	_
a	_	_
feed-forward	_	_
architecture	_	_
[	_	_
24	_	_
]	_	_
rather	_	_
than	_	_
the	_	_
slow	_	_
optimization-based	_	_
approach	_	_
of	_	_
[	_	_
13	_	_
]	_	_
.	_	_

#78
To	_	_
this	_	_
end	_	_
,	_	_
we	_	_
adopt	_	_
an	_	_
encoder-decoder	_	_
architecture	_	_
that	_	_
utilizes	_	_
an	_	_
encoder	_	_
network	_	_
E	_	_
to	_	_
map	_	_
an	_	_
input	_	_
content	_	_
image	_	_
x	_	_
onto	_	_
a	_	_
latent	_	_
representation	_	_
z	_	_
=	_	_
E	_	_
(	_	_
x	_	_
)	_	_
.	_	_

#79
A	_	_
generative	_	_
decoder	_	_
G	_	_
then	_	_
plays	_	_
the	_	_
role	_	_
of	_	_
a	_	_
painter	_	_
and	_	_
generates	_	_
the	_	_
stylized	_	_
output	_	_
image	_	_
y	_	_
=	_	_
G	_	_
(	_	_
z	_	_
)	_	_
from	_	_
the	_	_
sketchy	_	_
content	_	_
representation	_	_
z.	_	_
Stylization	_	_
then	_	_
only	_	_
requires	_	_
a	_	_
single	_	_
forward	_	_
pass	_	_
,	_	_
thus	_	_
working	_	_
in	_	_
real-time	_	_
.	_	_

#80
2.1	_	_
Training	_	_
with	_	_
a	_	_
Style-Aware	_	_
Content	_	_
Loss	_	_

#81
Previous	_	_
approaches	_	_
have	_	_
been	_	_
limited	_	_
in	_	_
that	_	_
training	_	_
worked	_	_
only	_	_
with	_	_
a	_	_
single	_	_
style	_	_
image	_	_
[	_	_
13,24,21,29,47,7,42	_	_
]	_	_
or	_	_
that	_	_
style	_	_
images	_	_
used	_	_
for	_	_
training	_	_
had	_	_
to	_	_
be	_	_
similar	_	_
in	_	_
content	_	_
to	_	_
the	_	_
content	_	_
images	_	_
[	_	_
52	_	_
]	_	_
.	_	_

#82
In	_	_
contrast	_	_
,	_	_
given	_	_
a	_	_
single	_	_
style	_	_
image	_	_
y0	_	_
we	_	_
include	_	_
a	_	_
set	_	_
Y	_	_
of	_	_
related	_	_
style	_	_
images	_	_
yj	_	_
∈	_	_
Y	_	_
,	_	_
which	_	_
are	_	_
automatically	_	_
selected	_	_
(	_	_
see	_	_
Sec	_	_
.	_	_

#83
2.2	_	_
)	_	_
from	_	_
a	_	_
large	_	_
art	_	_
dataset	_	_
(	_	_
Wikiart	_	_
)	_	_
.	_	_

#84
We	_	_
do	_	_
6	_	_
A.	_	_
Sanakoyeu	_	_
,	_	_
D.	_	_
Kotovenko	_	_
,	_	_
S.	_	_
Lang	_	_
,	_	_
and	_	_
B.	_	_
Ommer	_	_
not	_	_
require	_	_
the	_	_
yj	_	_
to	_	_
depict	_	_
similar	_	_
content	_	_
as	_	_
the	_	_
set	_	_
X	_	_
of	_	_
arbitrary	_	_
content	_	_
images	_	_
xi	_	_
∈	_	_
X	_	_
,	_	_
which	_	_
we	_	_
simply	_	_
take	_	_
from	_	_
Places365	_	_
[	_	_
51	_	_
]	_	_
.	_	_

#85
Compared	_	_
to	_	_
[	_	_
52	_	_
]	_	_
,	_	_
we	_	_
thus	_	_
can	_	_
utilize	_	_
standard	_	_
datasets	_	_
for	_	_
content	_	_
and	_	_
style	_	_
and	_	_
need	_	_
no	_	_
tedious	_	_
manual	_	_
selection	_	_
of	_	_
the	_	_
xi	_	_
and	_	_
yj	_	_
as	_	_
described	_	_
in	_	_
Sect.	_	_
5.1	_	_
and	_	_
7.1	_	_
of	_	_
[	_	_
52	_	_
]	_	_
.	_	_

#86
To	_	_
train	_	_
E	_	_
and	_	_
G	_	_
we	_	_
employ	_	_
a	_	_
standard	_	_
adversarial	_	_
discriminator	_	_
D	_	_
[	_	_
16	_	_
]	_	_
to	_	_
distinguish	_	_
the	_	_
stylized	_	_
output	_	_
G	_	_
(	_	_
E	_	_
(	_	_
xi	_	_
)	_	_
)	_	_
from	_	_
real	_	_
examples	_	_
yj	_	_
∈	_	_
Y	_	_
,	_	_
LD	_	_
(	_	_
E	_	_
,	_	_
G	_	_
,	_	_
D	_	_
)	_	_
=	_	_
E	_	_
y∼pY	_	_
(	_	_
y	_	_
)	_	_
[	_	_
logD	_	_
(	_	_
y	_	_
)	_	_
]	_	_
+	_	_
E	_	_
x∼pX	_	_
(	_	_
x	_	_
)	_	_
[	_	_
log	_	_
(	_	_
1−D	_	_
(	_	_
G	_	_
(	_	_
E	_	_
(	_	_
x	_	_
)	_	_
)	_	_
)	_	_
)	_	_
]	_	_
(	_	_
1	_	_
)	_	_
However	_	_
,	_	_
the	_	_
crucial	_	_
challenge	_	_
is	_	_
to	_	_
decide	_	_
which	_	_
details	_	_
to	_	_
retain	_	_
from	_	_
the	_	_
content	_	_
image	_	_
,	_	_
something	_	_
which	_	_
is	_	_
not	_	_
captured	_	_
by	_	_
Eq.	_	_
1	_	_
.	_	_

#87
Contrary	_	_
to	_	_
previous	_	_
work	_	_
,	_	_
we	_	_
want	_	_
to	_	_
directly	_	_
enforce	_	_
E	_	_
to	_	_
strip	_	_
the	_	_
latent	_	_
space	_	_
of	_	_
all	_	_
image	_	_
details	_	_
that	_	_
the	_	_
target	_	_
style	_	_
disregards	_	_
.	_	_

#88
Therefore	_	_
,	_	_
the	_	_
details	_	_
that	_	_
need	_	_
to	_	_
be	_	_
retained	_	_
or	_	_
ignored	_	_
in	_	_
z	_	_
depend	_	_
on	_	_
the	_	_
style	_	_
.	_	_

#89
For	_	_
instance	_	_
,	_	_
Cubism	_	_
would	_	_
disregard	_	_
texture	_	_
,	_	_
whereas	_	_
Pointillism	_	_
would	_	_
retain	_	_
low-frequency	_	_
textures	_	_
.	_	_

#90
Therefore	_	_
,	_	_
a	_	_
pre-trained	_	_
network	_	_
or	_	_
fixed	_	_
similarity	_	_
measure	_	_
[	_	_
13	_	_
]	_	_
for	_	_
measuring	_	_
the	_	_
similarity	_	_
in	_	_
content	_	_
between	_	_
xi	_	_
and	_	_
yi	_	_
is	_	_
violating	_	_
the	_	_
art	_	_
historical	_	_
premise	_	_
that	_	_
the	_	_
manner	_	_
,	_	_
in	_	_
which	_	_
content	_	_
is	_	_
preserved	_	_
,	_	_
depends	_	_
on	_	_
the	_	_
style	_	_
.	_	_

#91
Similar	_	_
issues	_	_
arise	_	_
when	_	_
measuring	_	_
the	_	_
distance	_	_
after	_	_
projecting	_	_
the	_	_
stylized	_	_
image	_	_
G	_	_
(	_	_
E	_	_
(	_	_
xi	_	_
)	_	_
)	_	_
back	_	_
into	_	_
the	_	_
domain	_	_
X	_	_
of	_	_
original	_	_
images	_	_
with	_	_
a	_	_
second	_	_
pair	_	_
of	_	_
encoder	_	_
and	_	_
decoder	_	_
G2	_	_
(	_	_
E2	_	_
(	_	_
G	_	_
(	_	_
E	_	_
(	_	_
xi	_	_
)	_	_
)	_	_
)	_	_
)	_	_
.	_	_

#92
The	_	_
resulting	_	_
loss	_	_
proposed	_	_
in	_	_
[	_	_
52	_	_
]	_	_
,	_	_
LcycleGAN	_	_
=	_	_
E	_	_
x∼pX	_	_
(	_	_
x	_	_
)	_	_
[	_	_
‖x−G2	_	_
(	_	_
E2	_	_
(	_	_
G	_	_
(	_	_
E	_	_
(	_	_
x	_	_
)	_	_
)	_	_
)	_	_
)	_	_
‖1	_	_
]	_	_
,	_	_
(	_	_
2	_	_
)	_	_
fails	_	_
where	_	_
styles	_	_
become	_	_
abstract	_	_
,	_	_
since	_	_
the	_	_
backward	_	_
projection	_	_
of	_	_
abstract	_	_
art	_	_
to	_	_
the	_	_
original	_	_
image	_	_
is	_	_
highly	_	_
underdetermined	_	_
.	_	_

#93
Therefore	_	_
,	_	_
we	_	_
propose	_	_
a	_	_
style-aware	_	_
content	_	_
loss	_	_
that	_	_
is	_	_
being	_	_
optimized	_	_
,	_	_
while	_	_
the	_	_
network	_	_
learns	_	_
to	_	_
stylize	_	_
images	_	_
.	_	_

#94
Since	_	_
encoder	_	_
training	_	_
is	_	_
coupled	_	_
with	_	_
training	_	_
of	_	_
the	_	_
decoder	_	_
,	_	_
which	_	_
produces	_	_
artistic	_	_
images	_	_
of	_	_
the	_	_
specific	_	_
style	_	_
,	_	_
the	_	_
latent	_	_
vector	_	_
z	_	_
produced	_	_
for	_	_
the	_	_
input	_	_
image	_	_
x	_	_
can	_	_
be	_	_
viewed	_	_
as	_	_
its	_	_
styledependent	_	_
sketchy	_	_
content	_	_
representation	_	_
.	_	_

#95
This	_	_
latent	_	_
space	_	_
representation	_	_
is	_	_
changing	_	_
during	_	_
training	_	_
and	_	_
hence	_	_
adapts	_	_
to	_	_
the	_	_
style	_	_
.	_	_

#96
Thus	_	_
,	_	_
when	_	_
measuring	_	_
the	_	_
similarity	_	_
in	_	_
content	_	_
between	_	_
input	_	_
image	_	_
xi	_	_
and	_	_
the	_	_
stylized	_	_
image	_	_
yi	_	_
=	_	_
G	_	_
(	_	_
E	_	_
(	_	_
xi	_	_
)	_	_
)	_	_
in	_	_
the	_	_
latent	_	_
space	_	_
,	_	_
we	_	_
focus	_	_
only	_	_
on	_	_
those	_	_
details	_	_
which	_	_
are	_	_
relevant	_	_
for	_	_
the	_	_
style	_	_
.	_	_

#97
Let	_	_
the	_	_
latent	_	_
space	_	_
have	_	_
d	_	_
dimensions	_	_
,	_	_
then	_	_
we	_	_
define	_	_
a	_	_
style-aware	_	_
content	_	_
loss	_	_
as	_	_
normalized	_	_
squared	_	_
Euclidean	_	_
distance	_	_
between	_	_
E	_	_
(	_	_
xi	_	_
)	_	_
and	_	_
E	_	_
(	_	_
yi	_	_
)	_	_
:	_	_
Lc	_	_
(	_	_
E	_	_
,	_	_
G	_	_
)	_	_
=	_	_
E	_	_
x∼pX	_	_
(	_	_
x	_	_
)	_	_
[	_	_
d	_	_
‖E	_	_
(	_	_
x	_	_
)	_	_
−	_	_
E	_	_
(	_	_
G	_	_
(	_	_
E	_	_
(	_	_
x	_	_
)	_	_
)	_	_
)	_	_
‖22	_	_
]	_	_
(	_	_
3	_	_
)	_	_
To	_	_
show	_	_
the	_	_
additional	_	_
intuition	_	_
behind	_	_
the	_	_
style-aware	_	_
content	_	_
loss	_	_
we	_	_
used	_	_
the	_	_
method	_	_
[	_	_
33	_	_
]	_	_
to	_	_
reconstruct	_	_
the	_	_
content	_	_
image	_	_
from	_	_
latent	_	_
representations	_	_
trained	_	_
on	_	_
different	_	_
styles	_	_
and	_	_
illustrated	_	_
it	_	_
in	_	_
Fig.	_	_
4	_	_
.	_	_

#98
It	_	_
can	_	_
be	_	_
seen	_	_
that	_	_
latent	_	_
space	_	_
encodes	_	_
a	_	_
sketchy	_	_
,	_	_
style-specific	_	_
visual	_	_
content	_	_
,	_	_
which	_	_
is	_	_
implicitly	_	_
used	_	_
by	_	_
the	_	_
loss	_	_
function	_	_
.	_	_

#99
For	_	_
example	_	_
,	_	_
Pollock	_	_
is	_	_
famous	_	_
for	_	_
his	_	_
abstract	_	_
paintings	_	_
,	_	_
A	_	_
Style-Aware	_	_
Content	_	_
Loss	_	_
for	_	_
Real-time	_	_
HD	_	_
Style	_	_
Transfer	_	_
7	_	_
so	_	_
reconstruction	_	_
(	_	_
a	_	_
)	_	_
shows	_	_
that	_	_
the	_	_
latent	_	_
space	_	_
ignores	_	_
most	_	_
of	_	_
the	_	_
object	_	_
structure	_	_
;	_	_
Gauguin	_	_
was	_	_
less	_	_
interested	_	_
in	_	_
details	_	_
,	_	_
painted	_	_
a	_	_
lot	_	_
of	_	_
plain	_	_
surfaces	_	_
and	_	_
used	_	_
vivid	_	_
colors	_	_
which	_	_
is	_	_
reflected	_	_
in	_	_
the	_	_
reconstruction	_	_
(	_	_
c	_	_
)	_	_
,	_	_
where	_	_
latent	_	_
space	_	_
highlights	_	_
surfaces	_	_
of	_	_
the	_	_
same	_	_
color	_	_
and	_	_
fine	_	_
object	_	_
details	_	_
are	_	_
ignored	_	_
.	_	_

#100
Since	_	_
we	_	_
train	_	_
our	_	_
model	_	_
for	_	_
altering	_	_
the	_	_
artistic	_	_
style	_	_
without	_	_
supervision	_	_
and	_	_
from	_	_
scratch	_	_
,	_	_
we	_	_
now	_	_
introduce	_	_
extra	_	_
signal	_	_
to	_	_
initialize	_	_
training	_	_
and	_	_
boost	_	_
the	_	_
learning	_	_
of	_	_
the	_	_
primary	_	_
latent	_	_
space	_	_
.	_	_

#101
The	_	_
simplest	_	_
thing	_	_
to	_	_
do	_	_
is	_	_
to	_	_
use	_	_
an	_	_
autoencoder	_	_
loss	_	_
which	_	_
computes	_	_
the	_	_
difference	_	_
between	_	_
xi	_	_
and	_	_
yi	_	_
in	_	_
the	_	_
RGB	_	_
space	_	_
.	_	_

#102
However	_	_
,	_	_
this	_	_
loss	_	_
would	_	_
impose	_	_
a	_	_
high	_	_
penalty	_	_
for	_	_
any	_	_
changes	_	_
in	_	_
image	_	_
structure	_	_
between	_	_
input	_	_
xi	_	_
and	_	_
output	_	_
yi	_	_
,	_	_
because	_	_
it	_	_
relies	_	_
only	_	_
on	_	_
low-level	_	_
pixel	_	_
information	_	_
.	_	_

#103
But	_	_
we	_	_
aim	_	_
to	_	_
learn	_	_
image	_	_
stylization	_	_
and	_	_
want	_	_
the	_	_
encoder	_	_
to	_	_
discard	_	_
certain	_	_
details	_	_
in	_	_
the	_	_
content	_	_
depending	_	_
on	_	_
style	_	_
.	_	_

#104
Hence	_	_
the	_	_
autoencoder	_	_
loss	_	_
will	_	_
contradict	_	_
with	_	_
the	_	_
purpose	_	_
of	_	_
the	_	_
style-aware	_	_
loss	_	_
,	_	_
where	_	_
the	_	_
style	_	_
determines	_	_
which	_	_
details	_	_
to	_	_
retain	_	_
and	_	_
which	_	_
to	_	_
disregard	_	_
.	_	_

#105
Therefore	_	_
,	_	_
we	_	_
propose	_	_
to	_	_
measure	_	_
the	_	_
difference	_	_
after	_	_
applying	_	_
a	_	_
weak	_	_
image	_	_
transformation	_	_
on	_	_
xi	_	_
and	_	_
yi	_	_
,	_	_
which	_	_
is	_	_
learned	_	_
while	_	_
learning	_	_
E	_	_
and	_	_
G.	_	_
We	_	_
inject	_	_
in	_	_
our	_	_
model	_	_
a	_	_
transformer	_	_
block	_	_
T	_	_
which	_	_
is	_	_
essentially	_	_
a	_	_
one-layer	_	_
fully	_	_
convolutional	_	_
neural	_	_
network	_	_
taking	_	_
an	_	_
image	_	_
as	_	_
input	_	_
and	_	_
producing	_	_
a	_	_
transformed	_	_
image	_	_
of	_	_
the	_	_
same	_	_
size	_	_
.	_	_

#106
We	_	_
apply	_	_
T	_	_
to	_	_
images	_	_
xi	_	_
and	_	_
yi	_	_
=	_	_
G	_	_
(	_	_
E	_	_
(	_	_
xi	_	_
)	_	_
)	_	_
before	_	_
measuring	_	_
the	_	_
difference	_	_
.	_	_

#107
We	_	_
refer	_	_
to	_	_
this	_	_
as	_	_
transformed	_	_
image	_	_
loss	_	_
and	_	_
define	_	_
it	_	_
as	_	_
LT	_	_
(	_	_
E	_	_
,	_	_
G	_	_
)	_	_
=	_	_
E	_	_
x∼pX	_	_
(	_	_
x	_	_
)	_	_
[	_	_
CHW	_	_
||T	_	_
(	_	_
x	_	_
)	_	_
−T	_	_
(	_	_
G	_	_
(	_	_
E	_	_
(	_	_
x	_	_
)	_	_
)	_	_
||22	_	_
]	_	_
,	_	_
(	_	_
4	_	_
)	_	_
where	_	_
C	_	_
×	_	_
H	_	_
×W	_	_
is	_	_
the	_	_
size	_	_
of	_	_
image	_	_
x	_	_
and	_	_
for	_	_
training	_	_
T	_	_
is	_	_
initialized	_	_
with	_	_
uniform	_	_
weights	_	_
.	_	_

#108
Fig.	_	_
3	_	_
illustrates	_	_
the	_	_
full	_	_
pipeline	_	_
of	_	_
our	_	_
approach	_	_
.	_	_

#109
To	_	_
summarize	_	_
,	_	_
the	_	_
full	_	_
objective	_	_
of	_	_
our	_	_
model	_	_
is	_	_
:	_	_
L	_	_
(	_	_
E	_	_
,	_	_
G	_	_
,	_	_
D	_	_
)	_	_
=	_	_
Lc	_	_
(	_	_
E	_	_
,	_	_
G	_	_
)	_	_
+	_	_
Lt	_	_
(	_	_
E	_	_
,	_	_
G	_	_
)	_	_
+	_	_
λLD	_	_
(	_	_
E	_	_
,	_	_
G	_	_
,	_	_
D	_	_
)	_	_
,	_	_
(	_	_
5	_	_
)	_	_
where	_	_
λ	_	_
controls	_	_
the	_	_
relative	_	_
importance	_	_
of	_	_
adversarial	_	_
loss	_	_
.	_	_

#110
We	_	_
solve	_	_
the	_	_
following	_	_
optimization	_	_
problem	_	_
:	_	_
E	_	_
,	_	_
G	_	_
=	_	_
arg	_	_
min	_	_
E	_	_
,	_	_
G	_	_
max	_	_
D	_	_
L	_	_
(	_	_
E	_	_
,	_	_
G	_	_
,	_	_
D	_	_
)	_	_
.	_	_

#111
(	_	_
6	_	_
)	_	_

#112
2.2	_	_
Style	_	_
Image	_	_
Grouping	_	_

#113
In	_	_
this	_	_
section	_	_
we	_	_
explain	_	_
an	_	_
automatic	_	_
approach	_	_
for	_	_
gathering	_	_
a	_	_
set	_	_
of	_	_
related	_	_
style	_	_
images	_	_
.	_	_

#114
Given	_	_
a	_	_
single	_	_
style	_	_
image	_	_
y0	_	_
we	_	_
strive	_	_
to	_	_
find	_	_
a	_	_
set	_	_
Y	_	_
of	_	_
related	_	_
style	_	_
images	_	_
yj	_	_
∈	_	_
Y	_	_
.	_	_

#115
Contrary	_	_
to	_	_
[	_	_
52	_	_
]	_	_
we	_	_
avoid	_	_
tedious	_	_
manual	_	_
selection	_	_
of	_	_
style	_	_
images	_	_
and	_	_
follow	_	_
a	_	_
fully	_	_
automatic	_	_
approach	_	_
.	_	_

#116
To	_	_
this	_	_
end	_	_
,	_	_
we	_	_
train	_	_
a	_	_
VGG16	_	_
[	_	_
41	_	_
]	_	_
network	_	_
C	_	_
from	_	_
scratch	_	_
on	_	_
the	_	_
Wikiart	_	_
[	_	_
25	_	_
]	_	_
dataset	_	_
to	_	_
predict	_	_
an	_	_
artist	_	_
given	_	_
the	_	_
artwork	_	_
.	_	_

#117
The	_	_
network	_	_
is	_	_
trained	_	_
on	_	_
the	_	_
624	_	_
largest	_	_
(	_	_
by	_	_
number	_	_
of	_	_
works	_	_
)	_	_
artists	_	_
from	_	_
the	_	_
Wikiart	_	_
dataset	_	_
.	_	_

#118
Note	_	_
that	_	_
our	_	_
ultimate	_	_
goal	_	_
is	_	_
stylization	_	_
and	_	_
numerous	_	_
artists	_	_
can	_	_
share	_	_
the	_	_
same	_	_
style	_	_
,	_	_
e.g.	_	_
,	_	_
Impressionism	_	_
,	_	_
as	_	_
well	_	_
as	_	_
a	_	_
single	_	_
artist	_	_
can	_	_
exhibit	_	_
different	_	_
styles	_	_
,	_	_
such	_	_
as	_	_
the	_	_
different	_	_
stylistic	_	_
periods	_	_
of	_	_
Picasso	_	_
.	_	_

#119
8	_	_
A.	_	_
Sanakoyeu	_	_
,	_	_
D.	_	_
Kotovenko	_	_
,	_	_
S.	_	_
Lang	_	_
,	_	_
and	_	_
B.	_	_
Ommer	_	_
However	_	_
,	_	_
we	_	_
do	_	_
not	_	_
use	_	_
any	_	_
style	_	_
labels	_	_
.	_	_

#120
Artist	_	_
classification	_	_
in	_	_
this	_	_
case	_	_
is	_	_
the	_	_
surrogate	_	_
task	_	_
for	_	_
learning	_	_
meaningful	_	_
features	_	_
in	_	_
the	_	_
artworks’	_	_
domain	_	_
,	_	_
which	_	_
allows	_	_
to	_	_
retrieve	_	_
similar	_	_
artworks	_	_
to	_	_
image	_	_
y0	_	_
.	_	_

#121
Let	_	_
φ	_	_
(	_	_
y	_	_
)	_	_
be	_	_
the	_	_
activations	_	_
of	_	_
the	_	_
fc6	_	_
layer	_	_
of	_	_
the	_	_
VGG16	_	_
network	_	_
C	_	_
for	_	_
input	_	_
image	_	_
y	_	_
.	_	_

#122
To	_	_
get	_	_
a	_	_
set	_	_
of	_	_
related	_	_
style	_	_
images	_	_
to	_	_
y0	_	_
from	_	_
the	_	_
Wikiart	_	_
dataset	_	_
Y	_	_
we	_	_
retrieve	_	_
all	_	_
nearest	_	_
neighbors	_	_
of	_	_
y0	_	_
based	_	_
on	_	_
the	_	_
cosine	_	_
distance	_	_
δ	_	_
of	_	_
the	_	_
activations	_	_
φ	_	_
(	_	_
·	_	_
)	_	_
,	_	_
i.e.	_	_
Y	_	_
=	_	_
{	_	_
y	_	_
|	_	_
y	_	_
∈	_	_
Y	_	_
,	_	_
δ	_	_
(	_	_
φ	_	_
(	_	_
y	_	_
)	_	_
,	_	_
φ	_	_
(	_	_
y0	_	_
)	_	_
)	_	_
<	_	_
t	_	_
}	_	_
,	_	_
(	_	_
7	_	_
)	_	_
where	_	_
δ	_	_
(	_	_
a	_	_
,	_	_
b	_	_
)	_	_
=	_	_
1	_	_
+	_	_
φ	_	_
(	_	_
a	_	_
)	_	_
φ	_	_
(	_	_
b	_	_
)	_	_
||a||2||b||2	_	_
and	_	_
t	_	_
is	_	_
the	_	_
10	_	_
%	_	_
quantile	_	_
of	_	_
all	_	_
pairwise	_	_
distances	_	_
in	_	_
the	_	_
dataset	_	_
Y	_	_
.	_	_

#123
3	_	_
Experiments	_	_

#124
To	_	_
compare	_	_
our	_	_
style	_	_
transfer	_	_
approach	_	_
with	_	_
the	_	_
state-of-the-art	_	_
,	_	_
we	_	_
first	_	_
perform	_	_
extensive	_	_
qualitative	_	_
analysis	_	_
,	_	_
then	_	_
we	_	_
provide	_	_
quantitative	_	_
results	_	_
based	_	_
on	_	_
the	_	_
deception	_	_
score	_	_
and	_	_
evaluations	_	_
of	_	_
experts	_	_
from	_	_
art	_	_
history	_	_
.	_	_

#125
Afterwards	_	_
in	_	_
Sect.	_	_
3.3	_	_
we	_	_
ablate	_	_
single	_	_
components	_	_
of	_	_
our	_	_
model	_	_
and	_	_
show	_	_
their	_	_
importance	_	_
.	_	_

#126
Implementation	_	_
details	_	_
:	_	_
The	_	_
basis	_	_
for	_	_
our	_	_
style	_	_
transfer	_	_
model	_	_
is	_	_
an	_	_
encoder-decoder	_	_
architecture	_	_
,	_	_
cf	_	_
.	_	_
[	_	_
24	_	_
]	_	_
.	_	_

#127
The	_	_
encoder	_	_
network	_	_
contains	_	_
5	_	_
conv	_	_
layers	_	_
:	_	_
1×conv-stride-1	_	_
and	_	_
4×conv-stride-2	_	_
.	_	_

#128
The	_	_
decoder	_	_
network	_	_
has	_	_
9	_	_
residual	_	_
blocks	_	_
[	_	_
17	_	_
]	_	_
,	_	_
4	_	_
upsampling	_	_
blocks	_	_
and	_	_
1×conv-stride-1	_	_
.	_	_

#129
For	_	_
upsampling	_	_
blocks	_	_
we	_	_
used	_	_
a	_	_
sequence	_	_
of	_	_
nearest-neighbor	_	_
upscaling	_	_
and	_	_
conv-stride-1	_	_
instead	_	_
of	_	_
fractionally	_	_
strided	_	_
convolutions	_	_
[	_	_
31	_	_
]	_	_
,	_	_
which	_	_
tend	_	_
to	_	_
produce	_	_
heavier	_	_
artifacts	_	_
[	_	_
35	_	_
]	_	_
.	_	_

#130
Discriminator	_	_
is	_	_
a	_	_
fully	_	_
convolutional	_	_
network	_	_
with	_	_
7×conv-stride-2	_	_
layers	_	_
.	_	_

#131
For	_	_
a	_	_
detailed	_	_
network	_	_
architecture	_	_
description	_	_
we	_	_
refer	_	_
to	_	_
the	_	_
supplementary	_	_
material	_	_
.	_	_

#132
We	_	_
set	_	_
λ	_	_
=	_	_
0.001	_	_
in	_	_
Eq.	_	_
5	_	_
.	_	_

#133
During	_	_
the	_	_
training	_	_
process	_	_
we	_	_
sample	_	_
768	_	_
×	_	_
768	_	_
content	_	_
image	_	_
patches	_	_
from	_	_
the	_	_
training	_	_
set	_	_
of	_	_
Places365	_	_
[	_	_
51	_	_
]	_	_
and	_	_
768×768	_	_
style	_	_
image	_	_
patches	_	_
from	_	_
the	_	_
Wikiart	_	_
[	_	_
25	_	_
]	_	_
dataset	_	_
.	_	_

#134
We	_	_
train	_	_
for	_	_
300000	_	_
iterations	_	_
with	_	_
batch	_	_
size	_	_
1	_	_
,	_	_
learning	_	_
rate	_	_
0.0002	_	_
and	_	_
Adam	_	_
[	_	_
26	_	_
]	_	_
optimizer	_	_
.	_	_

#135
The	_	_
learning	_	_
rate	_	_
is	_	_
reduced	_	_
by	_	_
a	_	_
factor	_	_
of	_	_
10	_	_
after	_	_
200000	_	_
iterations	_	_
.	_	_

#136
Baselines	_	_
:	_	_
Since	_	_
we	_	_
aim	_	_
to	_	_
generate	_	_
high-resolution	_	_
stylizations	_	_
,	_	_
for	_	_
comparison	_	_
we	_	_
run	_	_
style	_	_
transfer	_	_
on	_	_
our	_	_
method	_	_
and	_	_
all	_	_
baselines	_	_
for	_	_
input	_	_
images	_	_
of	_	_
size	_	_
768×768	_	_
,	_	_
unless	_	_
otherwise	_	_
specified	_	_
.	_	_

#137
We	_	_
did	_	_
not	_	_
not	_	_
exceed	_	_
this	_	_
resolution	_	_
when	_	_
comparing	_	_
,	_	_
because	_	_
some	_	_
other	_	_
methods	_	_
were	_	_
reaching	_	_
the	_	_
GPU	_	_
memory	_	_
limit	_	_
.	_	_

#138
We	_	_
optimize	_	_
Gatys	_	_
et	_	_
al.	_	_
[	_	_
13	_	_
]	_	_
for	_	_
500	_	_
iterations	_	_
using	_	_
L-BFGS	_	_
.	_	_

#139
For	_	_
Johnson	_	_
et	_	_
al.	_	_
[	_	_
24	_	_
]	_	_
we	_	_
used	_	_
the	_	_
implementation	_	_
of	_	_
[	_	_
8	_	_
]	_	_
and	_	_
trained	_	_
a	_	_
separate	_	_
network	_	_
for	_	_
every	_	_
reference	_	_
style	_	_
image	_	_
on	_	_
the	_	_
same	_	_
content	_	_
images	_	_
from	_	_
Places365	_	_
[	_	_
51	_	_
]	_	_
as	_	_
our	_	_
method	_	_
.	_	_

#140
For	_	_
Huang	_	_
et	_	_
al.	_	_
[	_	_
21	_	_
]	_	_
,	_	_
Chen	_	_
et	_	_
al.	_	_
[	_	_
4	_	_
]	_	_
and	_	_
Li	_	_
et	_	_
al.	_	_
[	_	_
29	_	_
]	_	_
implementations	_	_
and	_	_
pre-trained	_	_
models	_	_
provided	_	_
by	_	_
the	_	_
authors	_	_
were	_	_
used	_	_
.	_	_

#141
Zhu	_	_
et	_	_
al.	_	_
[	_	_
52	_	_
]	_	_
was	_	_
trained	_	_
on	_	_
exactly	_	_
the	_	_
same	_	_
content	_	_
and	_	_
style	_	_
images	_	_
as	_	_
our	_	_
approach	_	_
using	_	_
the	_	_
source	_	_
code	_	_
provided	_	_
by	_	_
the	_	_
authors	_	_
.	_	_

#142
Methods	_	_
[	_	_
13,24,21,4,29	_	_
]	_	_
utilized	_	_
only	_	_
one	_	_
example	_	_
per	_	_
style	_	_
,	_	_
as	_	_
they	_	_
can	_	_
not	_	_
benefit	_	_
from	_	_
more	_	_
(	_	_
cf	_	_
.	_	_
the	_	_
analysis	_	_
in	_	_
Fig.	_	_
2	_	_
)	_	_
.	_	_

#143
A	_	_
Style-Aware	_	_
Content	_	_
Loss	_	_
for	_	_
Real-time	_	_
HD	_	_
Style	_	_
Transfer	_	_
9	_	_
Style	_	_
Content	_	_
(	_	_
a	_	_
)	_	_
Ours	_	_
(	_	_
b	_	_
)	_	_
[	_	_
13	_	_
]	_	_
(	_	_
c	_	_
)	_	_
[	_	_
52	_	_
]	_	_
(	_	_
d	_	_
)	_	_
[	_	_
4	_	_
]	_	_
(	_	_
e	_	_
)	_	_
[	_	_
21	_	_
]	_	_
(	_	_
f	_	_
)	_	_
[	_	_
29	_	_
]	_	_
(	_	_
g	_	_
)	_	_
[	_	_
24	_	_
]	_	_
Fig.	_	_
5	_	_
.	_	_

#144
Results	_	_
from	_	_
different	_	_
style	_	_
transfer	_	_
methods	_	_
.	_	_

#145
We	_	_
compare	_	_
methods	_	_
on	_	_
different	_	_
styles	_	_
and	_	_
content	_	_
images	_	_
.	_	_

#146
3.1	_	_
Qualitative	_	_
Results	_	_

#147
Full	_	_
image	_	_
stylization	_	_
:	_	_
In	_	_
Fig.	_	_
5	_	_
we	_	_
demonstrate	_	_
the	_	_
effectiveness	_	_
of	_	_
our	_	_
approach	_	_
for	_	_
stylizing	_	_
different	_	_
contents	_	_
with	_	_
various	_	_
styles	_	_
.	_	_

#148
Chen	_	_
et	_	_
al.	_	_
[	_	_
4	_	_
]	_	_
work	_	_
on	_	_
the	_	_
overlapping	_	_
patches	_	_
extracted	_	_
from	_	_
the	_	_
content	_	_
image	_	_
,	_	_
swapping	_	_
the	_	_
features	_	_
of	_	_
the	_	_
original	_	_
patch	_	_
with	_	_
the	_	_
features	_	_
of	_	_
the	_	_
most	_	_
similar	_	_
patch	_	_
in	_	_
the	_	_
style	_	_
image	_	_
,	_	_
and	_	_
then	_	_
averages	_	_
the	_	_
features	_	_
in	_	_
the	_	_
overlapping	_	_
regions	_	_
,	_	_
thus	_	_
producing	_	_
an	_	_
over-smoothed	_	_
image	_	_
without	_	_
fine	_	_
details	_	_
(	_	_
Fig.	_	_
5	_	_
(	_	_
d	_	_
)	_	_
)	_	_
.	_	_

#149
[	_	_
21	_	_
]	_	_
produces	_	_
a	_	_
lot	_	_
of	_	_
repetitive	_	_
artifacts	_	_
,	_	_
especially	_	_
visible	_	_
on	_	_
flat	_	_
surfaces	_	_
,	_	_
cf	_	_
.	_	_
Fig.	_	_
5	_	_
(	_	_
e	_	_
,	_	_
rows	_	_
1	_	_
,	_	_
4–6	_	_
)	_	_
.	_	_

#150
Method	_	_
[	_	_
29	_	_
]	_	_
fails	_	_
to	_	_
understand	_	_
the	_	_
content	_	_
of	_	_
the	_	_
image	_	_
and	_	_
applies	_	_
different	_	_
colors	_	_
in	_	_
the	_	_
wrong	_	_
locations	_	_
(	_	_
Fig.	_	_
5	_	_
(	_	_
f	_	_
)	_	_
)	_	_
.	_	_

#151
Methods	_	_
[	_	_
24,52	_	_
]	_	_
often	_	_
fail	_	_
to	_	_
alter	_	_
content	_	_
image	_	_
and	_	_
their	_	_
effect	_	_
may	_	_
be	_	_
characterized	_	_
as	_	_
shifting	_	_
the	_	_
color	_	_
histogram	_	_
,	_	_
e.g.	_	_
,	_	_
Fig.	_	_
5	_	_
(	_	_
g	_	_
,	_	_
rows	_	_
3	_	_
,	_	_
7	_	_
;	_	_
c	_	_
,	_	_
rows	_	_
1	_	_
,	_	_
3–4	_	_
)	_	_
.	_	_

#152
One	_	_
reason	_	_
for	_	_
such	_	_
failure	_	_
cases	_	_
of	_	_
[	_	_
52	_	_
]	_	_
is	_	_
the	_	_
loss	_	_
in	_	_
the	_	_
RGB	_	_
pixel	_	_
space	_	_
based	_	_
on	_	_
the	_	_
difference	_	_
between	_	_
a	_	_
backward	_	_
mapping	_	_
of	_	_
the	_	_
stylized	_	_
output	_	_
and	_	_
the	_	_
content	_	_
image	_	_
.	_	_

#153
Another	_	_
reason	_	_
for	_	_
this	_	_
is	_	_
that	_	_
we	_	_
utilized	_	_
the	_	_
standard	_	_
Places365	_	_
[	_	_
51	_	_
]	_	_
dataset	_	_
and	_	_
did	_	_
not	_	_
hand-pick	_	_
training	_	_
content	_	_
images	_	_
,	_	_
as	_	_
is	_	_
advised	_	_
for	_	_
[	_	_
52	_	_
]	_	_
.	_	_

#154
Thus	_	_
,	_	_
artworks	_	_
and	_	_
content	_	_
images	_	_
used	_	_
for	_	_
training	_	_
differed	_	_
significantly	_	_
in	_	_
their	_	_
content	_	_
,	_	_
which	_	_
is	_	_
the	_	_
ultimate	_	_
test	_	_
for	_	_
a	_	_
stylization	_	_
that	_	_
truly	_	_
alters	_	_
the	_	_
input	_	_
and	_	_
goes	_	_
beyond	_	_
a	_	_
direct	_	_
mapping	_	_
between	_	_
regions	_	_
of	_	_
content	_	_
and	_	_
style	_	_
images	_	_
.	_	_

#155
The	_	_
optimization-based	_	_
method	_	_
[	_	_
13	_	_
]	_	_
often	_	_
works	_	_
better	_	_
than	_	_
other	_	_
baselines	_	_
,	_	_
but	_	_
produces	_	_
a	_	_
lot	_	_
of	_	_
prominent	_	_
ar10	_	_
A.	_	_
Sanakoyeu	_	_
,	_	_
D.	_	_
Kotovenko	_	_
,	_	_
S.	_	_
Lang	_	_
,	_	_
and	_	_
B.	_	_
Ommer	_	_
Content	_	_
(	_	_
a	_	_
)	_	_
Early	_	_
period	_	_
(	_	_
b	_	_
)	_	_
Stylized	_	_
(	_	_
c	_	_
)	_	_
Late	_	_
period	_	_
(	_	_
d	_	_
)	_	_
Stylized	_	_
Fig.	_	_
6	_	_
.	_	_

#156
Artwork	_	_
examples	_	_
of	_	_
the	_	_
early	_	_
artistic	_	_
period	_	_
of	_	_
van	_	_
Gogh	_	_
(	_	_
a	_	_
)	_	_
and	_	_
his	_	_
late	_	_
period	_	_
(	_	_
c	_	_
)	_	_
.	_	_

#157
Style	_	_
transfer	_	_
of	_	_
the	_	_
content	_	_
image	_	_
(	_	_
1st	_	_
column	_	_
)	_	_
onto	_	_
the	_	_
early	_	_
period	_	_
is	_	_
presented	_	_
in	_	_
(	_	_
b	_	_
)	_	_
and	_	_
the	_	_
late	_	_
period	_	_
in	_	_
(	_	_
d	_	_
)	_	_
.	_	_

#158
tifacts	_	_
,	_	_
leading	_	_
to	_	_
details	_	_
of	_	_
stylizations	_	_
looking	_	_
unnatural	_	_
,	_	_
cf	_	_
.	_	_
Fig.	_	_
5	_	_
(	_	_
b	_	_
,	_	_
rows	_	_
4	_	_
,	_	_
5	_	_
,	_	_
6	_	_
)	_	_
.	_	_

#159
This	_	_
is	_	_
due	_	_
to	_	_
an	_	_
explicit	_	_
minimization	_	_
of	_	_
the	_	_
loss	_	_
directly	_	_
on	_	_
the	_	_
pixel	_	_
level	_	_
.	_	_

#160
In	_	_
contrast	_	_
to	_	_
this	_	_
,	_	_
our	_	_
model	_	_
can	_	_
not	_	_
only	_	_
handle	_	_
styles	_	_
,	_	_
which	_	_
have	_	_
salient	_	_
,	_	_
simple	_	_
to	_	_
spot	_	_
characteristics	_	_
,	_	_
but	_	_
also	_	_
styles	_	_
,	_	_
such	_	_
as	_	_
El	_	_
Greco’s	_	_
Mannerism	_	_
,	_	_
with	_	_
less	_	_
graspable	_	_
stylistic	_	_
characteristics	_	_
,	_	_
where	_	_
other	_	_
methods	_	_
fail	_	_
(	_	_
Fig.	_	_
5	_	_
,	_	_
b–g	_	_
,	_	_
5th	_	_
row	_	_
)	_	_
.	_	_

#161
Fine-grained	_	_
style	_	_
details	_	_
:	_	_
In	_	_
Fig.	_	_
7	_	_
we	_	_
show	_	_
zoomed	_	_
in	_	_
cut-outs	_	_
from	_	_
the	_	_
stylized	_	_
images	_	_
.	_	_

#162
Interestingly	_	_
,	_	_
the	_	_
stylizations	_	_
of	_	_
methods	_	_
[	_	_
13,4,21,29,20	_	_
]	_	_
do	_	_
not	_	_
change	_	_
much	_	_
across	_	_
styles	_	_
(	_	_
compare	_	_
Fig.	_	_
7	_	_
(	_	_
d	_	_
,	_	_
f–i	_	_
,	_	_
rows	_	_
1–3	_	_
)	_	_
)	_	_
.	_	_

#163
Zhu	_	_
et	_	_
al.	_	_
[	_	_
52	_	_
]	_	_
produce	_	_
more	_	_
diverse	_	_
images	_	_
for	_	_
different	_	_
styles	_	_
,	_	_
but	_	_
obviously	_	_
can	_	_
not	_	_
alter	_	_
the	_	_
edges	_	_
of	_	_
the	_	_
content	_	_
(	_	_
blades	_	_
of	_	_
grass	_	_
are	_	_
clearly	_	_
visible	_	_
on	_	_
all	_	_
the	_	_
cutouts	_	_
in	_	_
Fig.	_	_
7	_	_
(	_	_
e	_	_
)	_	_
)	_	_
.	_	_

#164
Fig.	_	_
7	_	_
(	_	_
c	_	_
)	_	_
shows	_	_
the	_	_
stylized	_	_
cutouts	_	_
of	_	_
our	_	_
approach	_	_
,	_	_
which	_	_
exhibit	_	_
significant	_	_
changes	_	_
from	_	_
one	_	_
style	_	_
to	_	_
another	_	_
.	_	_

#165
Another	_	_
interesting	_	_
example	_	_
is	_	_
the	_	_
style	_	_
of	_	_
Pollock	_	_
,	_	_
Fig.	_	_
7	_	_
(	_	_
row	_	_
8	_	_
)	_	_
,	_	_
where	_	_
the	_	_
style-aware	_	_
loss	_	_
allows	_	_
our	_	_
model	_	_
to	_	_
properly	_	_
alter	_	_
content	_	_
to	_	_
the	_	_
point	_	_
of	_	_
discarding	_	_
it	_	_
–	_	_
as	_	_
would	_	_
be	_	_
expected	_	_
from	_	_
a	_	_
Pollock	_	_
action	_	_
painting	_	_
.	_	_

#166
Our	_	_
approach	_	_
is	_	_
able	_	_
to	_	_
generate	_	_
high-resolution	_	_
stylizations	_	_
with	_	_
a	_	_
lot	_	_
of	_	_
style	_	_
specific	_	_
details	_	_
and	_	_
retains	_	_
those	_	_
content	_	_
details	_	_
which	_	_
are	_	_
necessary	_	_
for	_	_
the	_	_
style	_	_
.	_	_

#167
Style	_	_
transfer	_	_
for	_	_
different	_	_
periods	_	_
of	_	_
van	_	_
Gogh	_	_
:	_	_
We	_	_
now	_	_
investigate	_	_
our	_	_
ability	_	_
to	_	_
properly	_	_
model	_	_
fine	_	_
differences	_	_
in	_	_
style	_	_
despite	_	_
using	_	_
a	_	_
group	_	_
of	_	_
style	_	_
images	_	_
.	_	_

#168
Therefore	_	_
,	_	_
we	_	_
take	_	_
two	_	_
reference	_	_
images	_	_
Fig.	_	_
6	_	_
(	_	_
a	_	_
)	_	_
and	_	_
(	_	_
c	_	_
)	_	_
from	_	_
van	_	_
Gogh’s	_	_
early	_	_
and	_	_
late	_	_
period	_	_
,	_	_
respectively	_	_
,	_	_
and	_	_
acquire	_	_
related	_	_
style	_	_
images	_	_
for	_	_
both	_	_
from	_	_
Wikiart	_	_
.	_	_

#169
It	_	_
can	_	_
be	_	_
clearly	_	_
seen	_	_
that	_	_
the	_	_
stylizations	_	_
produced	_	_
for	_	_
either	_	_
period	_	_
Fig.	_	_
6	_	_
(	_	_
b	_	_
,	_	_
d	_	_
)	_	_
are	_	_
fairly	_	_
different	_	_
and	_	_
indeed	_	_
depict	_	_
the	_	_
content	_	_
in	_	_
correspondence	_	_
with	_	_
the	_	_
style	_	_
of	_	_
early	_	_
(	_	_
b	_	_
)	_	_
and	_	_
late	_	_
(	_	_
d	_	_
)	_	_
periods	_	_
of	_	_
van	_	_
Gogh	_	_
.	_	_

#170
This	_	_
highlights	_	_
that	_	_
collections	_	_
of	_	_
style	_	_
images	_	_
are	_	_
properly	_	_
used	_	_
and	_	_
do	_	_
not	_	_
lead	_	_
to	_	_
an	_	_
averaging	_	_
effect	_	_
.	_	_

#171
High-resolution	_	_
image	_	_
generation	_	_
:	_	_
Our	_	_
approach	_	_
allows	_	_
us	_	_
to	_	_
produce	_	_
high	_	_
quality	_	_
stylized	_	_
images	_	_
in	_	_
high-resolution	_	_
.	_	_

#172
Fig.	_	_
8	_	_
illustrates	_	_
an	_	_
example	_	_
of	_	_
the	_	_
generated	_	_
piece	_	_
of	_	_
art	_	_
in	_	_
the	_	_
style	_	_
of	_	_
Berthe	_	_
Morisot	_	_
with	_	_
resolution	_	_
1280×1280	_	_
.	_	_

#173
The	_	_
result	_	_
exhibits	_	_
a	_	_
lot	_	_
of	_	_
fine	_	_
details	_	_
such	_	_
as	_	_
color	_	_
transitions	_	_
of	_	_
the	_	_
oil	_	_
paint	_	_
A	_	_
Style-Aware	_	_
Content	_	_
Loss	_	_
for	_	_
Real-time	_	_
HD	_	_
Style	_	_
Transfer	_	_
11	_	_
Style	_	_
(	_	_
a	_	_
)	_	_
(	_	_
b	_	_
)	_	_
(	_	_
c	_	_
)	_	_
(	_	_
d	_	_
)	_	_
[	_	_
13	_	_
]	_	_
(	_	_
e	_	_
)	_	_
[	_	_
52	_	_
]	_	_
(	_	_
f	_	_
)	_	_
[	_	_
4	_	_
]	_	_
(	_	_
g	_	_
)	_	_
[	_	_
21	_	_
]	_	_
(	_	_
h	_	_
)	_	_
[	_	_
29	_	_
]	_	_
(	_	_
i	_	_
)	_	_
[	_	_
24	_	_
]	_	_
Fig.	_	_
7	_	_
.	_	_

#174
Details	_	_
from	_	_
stylized	_	_
images	_	_
produced	_	_
for	_	_
different	_	_
styles	_	_
for	_	_
a	_	_
fixed	_	_
content	_	_
image	_	_
(	_	_
a	_	_
)	_	_
.	_	_

#175
(	_	_
b	_	_
)	_	_
is	_	_
our	_	_
entire	_	_
stylized	_	_
image	_	_
,	_	_
(	_	_
c	_	_
)	_	_
the	_	_
zoomed	_	_
in	_	_
cut-out	_	_
and	_	_
(	_	_
d	_	_
)	_	_
-	_	_
(	_	_
i	_	_
)	_	_
the	_	_
same	_	_
region	_	_
for	_	_
competitors	_	_
.	_	_

#176
Note	_	_
the	_	_
variation	_	_
across	_	_
different	_	_
styles	_	_
along	_	_
the	_	_
column	_	_
for	_	_
our	_	_
method	_	_
compared	_	_
to	_	_
other	_	_
approaches	_	_
.	_	_

#177
This	_	_
highlights	_	_
the	_	_
ability	_	_
to	_	_
adapt	_	_
content	_	_
(	_	_
not	_	_
just	_	_
colors	_	_
or	_	_
textures	_	_
)	_	_
where	_	_
demanded	_	_
by	_	_
a	_	_
style	_	_
.	_	_

#178
Fine	_	_
grained	_	_
artistic	_	_
details	_	_
with	_	_
sharp	_	_
boundaries	_	_
are	_	_
produced	_	_
,	_	_
while	_	_
altering	_	_
the	_	_
original	_	_
content	_	_
edges	_	_
.	_	_

#179
and	_	_
brushstrokes	_	_
of	_	_
different	_	_
sizes	_	_
.	_	_

#180
More	_	_
HD	_	_
images	_	_
are	_	_
in	_	_
the	_	_
supplementary	_	_
material	_	_
.	_	_

#181
12	_	_
A.	_	_
Sanakoyeu	_	_
,	_	_
D.	_	_
Kotovenko	_	_
,	_	_
S.	_	_
Lang	_	_
,	_	_
and	_	_
B.	_	_
Ommer	_	_
Fig.	_	_
8	_	_
.	_	_

#182
High-resolution	_	_
image	_	_
(	_	_
1280x1280	_	_
pix	_	_
)	_	_
generated	_	_
by	_	_
our	_	_
approach	_	_
.	_	_

#183
A	_	_
lot	_	_
of	_	_
fine	_	_
details	_	_
and	_	_
brushstrokes	_	_
are	_	_
visible	_	_
.	_	_

#184
A	_	_
style	_	_
example	_	_
is	_	_
in	_	_
the	_	_
bottom	_	_
left	_	_
corner	_	_
.	_	_

#185
Style	_	_
examples	_	_
Stylized	_	_
frames	_	_
Fig.	_	_
9	_	_
.	_	_

#186
Results	_	_
of	_	_
our	_	_
approach	_	_
applied	_	_
to	_	_
the	_	_
HD	_	_
video	_	_
of	_	_
Eadweard	_	_
Muybridge	_	_
”The	_	_
horse	_	_
in	_	_
motion”	_	_
(	_	_
1878	_	_
)	_	_
.	_	_

#187
Every	_	_
frame	_	_
was	_	_
independently	_	_
processed	_	_
(	_	_
no	_	_
smoothing	_	_
or	_	_
post-processing	_	_
)	_	_
by	_	_
our	_	_
model	_	_
in	_	_
the	_	_
style	_	_
of	_	_
Picasso	_	_
.	_	_

#188
Video	_	_
resolution	_	_
is	_	_
1920×	_	_
1280	_	_
pix	_	_
.	_	_

#189
The	_	_
full	_	_
video	_	_
is	_	_
available	_	_
on	_	_
YouTube	_	_
:	_	_
https	_	_
:	_	_
//youtu.be/TtHJcL8Feu0	_	_
.	_	_

#190
Real-time	_	_
HD	_	_
video	_	_
stylization	_	_
:	_	_
We	_	_
also	_	_
apply	_	_
our	_	_
method	_	_
to	_	_
several	_	_
videos	_	_
.	_	_

#191
Our	_	_
approach	_	_
can	_	_
stylize	_	_
HD	_	_
videos	_	_
(	_	_
1280×720	_	_
)	_	_
at	_	_
9	_	_
FPS	_	_
.	_	_

#192
Fig.	_	_
9	_	_
shows	_	_
stylized	_	_
frames	_	_
from	_	_
a	_	_
video	_	_
.	_	_

#193
We	_	_
did	_	_
not	_	_
use	_	_
a	_	_
temporal	_	_
regularization	_	_
to	_	_
show	_	_
that	_	_
our	_	_
method	_	_
produces	_	_
equally	_	_
good	_	_
results	_	_
for	_	_
consecutive	_	_
frames	_	_
with	_	_
varying	_	_
appearance	_	_
w/o	_	_
extra	_	_
constraints	_	_
.	_	_

#194
Stylized	_	_
videos	_	_
are	_	_
in	_	_
the	_	_
supplementary	_	_
material	_	_
.	_	_

#195
A	_	_
Style-Aware	_	_
Content	_	_
Loss	_	_
for	_	_
Real-time	_	_
HD	_	_
Style	_	_
Transfer	_	_
13	_	_

#196
3.2	_	_
Quantitative	_	_
Evaluation	_	_

#197
Style	_	_
transfer	_	_
deception	_	_
rate	_	_
:	_	_
While	_	_
several	_	_
metrics	_	_
[	_	_
37,2,19	_	_
]	_	_
have	_	_
been	_	_
proposed	_	_
to	_	_
evaluate	_	_
the	_	_
quality	_	_
of	_	_
image	_	_
generation	_	_
,	_	_
until	_	_
now	_	_
no	_	_
evaluation	_	_
metric	_	_
has	_	_
been	_	_
proposed	_	_
for	_	_
an	_	_
automatic	_	_
evaluation	_	_
of	_	_
style	_	_
transfer	_	_
results	_	_
.	_	_

#198
To	_	_
measure	_	_
the	_	_
quality	_	_
of	_	_
the	_	_
stylized	_	_
images	_	_
,	_	_
we	_	_
introduce	_	_
the	_	_
style	_	_
transfer	_	_
deception	_	_
rate	_	_
.	_	_

#199
We	_	_
use	_	_
a	_	_
VGG16	_	_
network	_	_
trained	_	_
from	_	_
scratch	_	_
to	_	_
classify	_	_
624	_	_
artists	_	_
on	_	_
Wikiart	_	_
.	_	_

#200
Style	_	_
transfer	_	_
deception	_	_
rate	_	_
is	_	_
calculated	_	_
as	_	_
the	_	_
fraction	_	_
of	_	_
generated	_	_
images	_	_
which	_	_
were	_	_
classified	_	_
by	_	_
the	_	_
network	_	_
as	_	_
the	_	_
artworks	_	_
of	_	_
an	_	_
artist	_	_
for	_	_
which	_	_
the	_	_
stylization	_	_
was	_	_
produced	_	_
.	_	_

#201
For	_	_
fair	_	_
comparison	_	_
with	_	_
other	_	_
approaches	_	_
,	_	_
which	_	_
used	_	_
only	_	_
one	_	_
style	_	_
image	_	_
y0	_	_
(	_	_
hence	_	_
only	_	_
one	_	_
artist	_	_
)	_	_
,	_	_
we	_	_
restricted	_	_
Y	_	_
to	_	_
only	_	_
contain	_	_
samples	_	_
coming	_	_
from	_	_
the	_	_
same	_	_
artist	_	_
as	_	_
the	_	_
query	_	_
example	_	_
y0	_	_
.	_	_

#202
We	_	_
selected	_	_
18	_	_
different	_	_
artists	_	_
(	_	_
i.e.	_	_
styles	_	_
)	_	_
.	_	_

#203
For	_	_
every	_	_
method	_	_
we	_	_
generated	_	_
5400	_	_
stylizations	_	_
(	_	_
18	_	_
styles	_	_
,	_	_
300	_	_
per	_	_
style	_	_
)	_	_
.	_	_

#204
In	_	_
Tab	_	_
.	_	_

#205
1	_	_
we	_	_
report	_	_
mean	_	_
deception	_	_
rate	_	_
for	_	_
18	_	_
styles	_	_
.	_	_

#206
Our	_	_
method	_	_
achieves	_	_
0.393	_	_
significantly	_	_
outperforming	_	_
the	_	_
baselines	_	_
.	_	_

#207
For	_	_
comparison	_	_
,	_	_
mean	_	_
accuracy	_	_
of	_	_
the	_	_
network	_	_
on	_	_
hold-out	_	_
real	_	_
images	_	_
of	_	_
aforementioned	_	_
18	_	_
artists	_	_
from	_	_
Wikiart	_	_
is	_	_
0.616	_	_
.	_	_

#208
Human	_	_
art	_	_
history	_	_
experts	_	_
perceptual	_	_
studies	_	_
:	_	_
Three	_	_
experts	_	_
(	_	_
with	_	_
a	_	_
PhD	_	_
in	_	_
art	_	_
history	_	_
with	_	_
focus	_	_
on	_	_
modern	_	_
and	_	_
pre-modern	_	_
paintings	_	_
)	_	_
have	_	_
compared	_	_
results	_	_
of	_	_
our	_	_
method	_	_
against	_	_
recent	_	_
work	_	_
.	_	_

#209
Each	_	_
expert	_	_
was	_	_
shown	_	_
1000	_	_
groups	_	_
of	_	_
images	_	_
.	_	_

#210
Each	_	_
group	_	_
consists	_	_
of	_	_
stylizations	_	_
which	_	_
were	_	_
generated	_	_
by	_	_
different	_	_
methods	_	_
based	_	_
on	_	_
the	_	_
same	_	_
content	_	_
and	_	_
style	_	_
images	_	_
.	_	_

#211
Experts	_	_
were	_	_
asked	_	_
to	_	_
choose	_	_
one	_	_
image	_	_
which	_	_
best	_	_
and	_	_
most	_	_
realistically	_	_
reflects	_	_
the	_	_
current	_	_
style	_	_
.	_	_

#212
The	_	_
score	_	_
is	_	_
computed	_	_
as	_	_
the	_	_
fraction	_	_
of	_	_
times	_	_
a	_	_
specific	_	_
method	_	_
was	_	_
chosen	_	_
as	_	_
the	_	_
best	_	_
in	_	_
the	_	_
group	_	_
.	_	_

#213
We	_	_
calculate	_	_
a	_	_
mean	_	_
expert	_	_
score	_	_
for	_	_
each	_	_
method	_	_
using	_	_
18	_	_
different	_	_
styles	_	_
and	_	_
report	_	_
them	_	_
in	_	_
Tab	_	_
.	_	_

#214
1	_	_
.	_	_

#215
Here	_	_
,	_	_
we	_	_
see	_	_
that	_	_
the	_	_
experts	_	_
selected	_	_
our	_	_
method	_	_
in	_	_
around	_	_
50	_	_
%	_	_
of	_	_
the	_	_
cases	_	_
.	_	_

#216
Speed	_	_
and	_	_
memory	_	_
:	_	_
Tab	_	_
.	_	_

#217
2	_	_
shows	_	_
the	_	_
time	_	_
and	_	_
memory	_	_
required	_	_
for	_	_
stylization	_	_
of	_	_
a	_	_
single	_	_
image	_	_
of	_	_
size	_	_
768	_	_
×	_	_
768	_	_
px	_	_
for	_	_
different	_	_
methods	_	_
.	_	_

#218
One	_	_
can	_	_
see	_	_
that	_	_
our	_	_
approach	_	_
and	_	_
that	_	_
of	_	_
[	_	_
24	_	_
]	_	_
and	_	_
[	_	_
52	_	_
]	_	_
have	_	_
comparable	_	_
speed	_	_
and	_	_
only	_	_
very	_	_
modest	_	_
demands	_	_
on	_	_
GPU	_	_
memory	_	_
,	_	_
compared	_	_
to	_	_
modern	_	_
graphics	_	_
cards	_	_
.	_	_

#219
Table	_	_
1	_	_
.	_	_

#220
Mean	_	_
deception	_	_
rate	_	_
and	_	_
mean	_	_
expert	_	_
score	_	_
for	_	_
different	_	_
methods	_	_
.	_	_

#221
The	_	_
higher	_	_
the	_	_
better	_	_
.	_	_

#222
Method	_	_
Deception	_	_
rate	_	_
Expert	_	_
score	_	_
Content	_	_
images	_	_
0.002	_	_
AdaIn	_	_
[	_	_
21	_	_
]	_	_
0.074	_	_
0.060	_	_
PatchBased	_	_
[	_	_
4	_	_
]	_	_
0.040	_	_
0.132	_	_
Johnson	_	_
et	_	_
al.	_	_
[	_	_
24	_	_
]	_	_
0.051	_	_
0.048	_	_
WCT	_	_
[	_	_
29	_	_
]	_	_
0.035	_	_
0.044	_	_
CycleGan	_	_
[	_	_
52	_	_
]	_	_
0.139	_	_
0.044	_	_
Gatys	_	_
et	_	_
al.	_	_
[	_	_
13	_	_
]	_	_
0.147	_	_
0.178	_	_
Ours	_	_
0.393	_	_
0.495	_	_
Table	_	_
2	_	_
.	_	_

#223
Average	_	_
inference	_	_
time	_	_
and	_	_
GPU	_	_
memory	_	_
consumption	_	_
,	_	_
measured	_	_
on	_	_
a	_	_
Titan	_	_
X	_	_
Pascal	_	_
,	_	_
for	_	_
different	_	_
methods	_	_
with	_	_
batch	_	_
size	_	_
1	_	_
and	_	_
input	_	_
image	_	_
of	_	_
768×	_	_
768	_	_
pix	_	_
.	_	_

#224
Method	_	_
Time	_	_
GPU	_	_
memory	_	_
Gatys	_	_
et	_	_
al.	_	_
[	_	_
13	_	_
]	_	_
200	_	_
sec	_	_
3887	_	_
MiB	_	_
CycleGan	_	_
[	_	_
52	_	_
]	_	_
0.07	_	_
sec	_	_
1391	_	_
MiB	_	_
AdaIn	_	_
[	_	_
21	_	_
]	_	_
0.16	_	_
sec	_	_
8872	_	_
MiB	_	_
PatchBased	_	_
[	_	_
4	_	_
]	_	_
8.70	_	_
sec	_	_
4159	_	_
MiB	_	_
WCT	_	_
[	_	_
29	_	_
]	_	_
5.22	_	_
sec	_	_
10720	_	_
MiB	_	_
Johnson	_	_
et	_	_
al.	_	_
[	_	_
24	_	_
]	_	_
0.06	_	_
sec	_	_
671	_	_
MiB	_	_
Ours	_	_
0.07	_	_
sec	_	_
1043	_	_
MiB	_	_
14	_	_
A.	_	_
Sanakoyeu	_	_
,	_	_
D.	_	_
Kotovenko	_	_
,	_	_
S.	_	_
Lang	_	_
,	_	_
and	_	_
B.	_	_
Ommer	_	_
Style	_	_
(	_	_
a	_	_
)	_	_
Content	_	_
(	_	_
b	_	_
)	_	_
Ours	_	_
(	_	_
c	_	_
)	_	_
(	_	_
d	_	_
)	_	_
(	_	_
e	_	_
)	_	_
(	_	_
f	_	_
)	_	_
Fig.	_	_
10	_	_
.	_	_

#225
Different	_	_
variations	_	_
of	_	_
our	_	_
method	_	_
for	_	_
Gauguin	_	_
stylization	_	_
.	_	_

#226
See	_	_
Sect.	_	_
3.3	_	_
for	_	_
details	_	_
.	_	_

#227
(	_	_
a	_	_
)	_	_
Content	_	_
image	_	_
;	_	_
(	_	_
b	_	_
)	_	_
full	_	_
model	_	_
(	_	_
Lc	_	_
,	_	_
Lrgb	_	_
and	_	_
LD	_	_
)	_	_
;	_	_
(	_	_
c	_	_
)	_	_
Lrgb	_	_
and	_	_
LD	_	_
;	_	_
(	_	_
d	_	_
)	_	_
without	_	_
transformer	_	_
block	_	_
;	_	_
(	_	_
e	_	_
)	_	_
only	_	_
LD	_	_
;	_	_
(	_	_
f	_	_
)	_	_
trained	_	_
with	_	_
all	_	_
of	_	_
Gauguin’s	_	_
artworks	_	_
as	_	_
style	_	_
images	_	_
.	_	_

#228
Please	_	_
zoom	_	_
in	_	_
to	_	_
compare	_	_
.	_	_

#229
Style	_	_
Content	_	_
(	_	_
a	_	_
)	_	_
(	_	_
b	_	_
)	_	_
Fig.	_	_
11	_	_
.	_	_

#230
Encoder	_	_
ablation	_	_
studies	_	_
:	_	_
(	_	_
a	_	_
)	_	_
stylization	_	_
using	_	_
our	_	_
model	_	_
;	_	_
(	_	_
b	_	_
)	_	_
stylization	_	_
using	_	_
pre-trained	_	_
VGG16	_	_
encoder	_	_
instead	_	_
of	_	_
E	_	_
.	_	_

#231
3.3	_	_
Ablation	_	_
Studies	_	_

#232
Effect	_	_
of	_	_
different	_	_
losses	_	_
:	_	_
We	_	_
study	_	_
the	_	_
effect	_	_
of	_	_
different	_	_
components	_	_
of	_	_
our	_	_
model	_	_
in	_	_
Fig.	_	_
10	_	_
.	_	_

#233
Removing	_	_
the	_	_
style-aware	_	_
content	_	_
loss	_	_
significantly	_	_
degrades	_	_
the	_	_
results	_	_
,	_	_
(	_	_
c	_	_
)	_	_
.	_	_

#234
We	_	_
observe	_	_
that	_	_
without	_	_
the	_	_
style-aware	_	_
loss	_	_
training	_	_
becomes	_	_
instable	_	_
and	_	_
often	_	_
stalls	_	_
.	_	_

#235
If	_	_
we	_	_
remove	_	_
the	_	_
transformed	_	_
image	_	_
loss	_	_
,	_	_
which	_	_
we	_	_
introduced	_	_
for	_	_
a	_	_
proper	_	_
initialization	_	_
of	_	_
our	_	_
model	_	_
that	_	_
is	_	_
trained	_	_
from	_	_
scratch	_	_
,	_	_
we	_	_
notice	_	_
mode	_	_
collapse	_	_
after	_	_
5000	_	_
iterations	_	_
.	_	_

#236
Training	_	_
directly	_	_
with	_	_
pixel-wise	_	_
L2	_	_
distance	_	_
causes	_	_
a	_	_
lot	_	_
of	_	_
artifacts	_	_
(	_	_
grey	_	_
blobs	_	_
and	_	_
flaky	_	_
structure	_	_
)	_	_
,	_	_
(	_	_
d	_	_
)	_	_
.	_	_

#237
Training	_	_
only	_	_
with	_	_
a	_	_
discriminator	_	_
neither	_	_
exhibits	_	_
the	_	_
variability	_	_
in	_	_
the	_	_
painting	_	_
nor	_	_
in	_	_
the	_	_
content	_	_
,	_	_
(	_	_
e	_	_
)	_	_
.	_	_

#238
Therefore	_	_
we	_	_
conclude	_	_
that	_	_
both	_	_
the	_	_
style-aware	_	_
content	_	_
loss	_	_
and	_	_
the	_	_
transformed	_	_
image	_	_
loss	_	_
are	_	_
critical	_	_
for	_	_
our	_	_
approach	_	_
.	_	_

#239
Single	_	_
vs	_	_
collection	_	_
of	_	_
style	_	_
images	_	_
:	_	_
Here	_	_
,	_	_
we	_	_
investigate	_	_
the	_	_
importance	_	_
of	_	_
the	_	_
style	_	_
image	_	_
grouping	_	_
.	_	_

#240
First	_	_
,	_	_
we	_	_
trained	_	_
a	_	_
model	_	_
with	_	_
only	_	_
one	_	_
style	_	_
image	_	_
of	_	_
Gauguin	_	_
,	_	_
which	_	_
led	_	_
to	_	_
mode	_	_
collapse	_	_
.	_	_

#241
Second	_	_
,	_	_
we	_	_
trained	_	_
with	_	_
all	_	_
of	_	_
Gauguin’s	_	_
artworks	_	_
as	_	_
style	_	_
images	_	_
(	_	_
without	_	_
utilizing	_	_
style	_	_
grouping	_	_
procedure	_	_
)	_	_
.	_	_

#242
It	_	_
produced	_	_
unsatisfactory	_	_
results	_	_
,	_	_
cf	_	_
.	_	_
Fig.	_	_
10	_	_
(	_	_
f	_	_
)	_	_
,	_	_
because	_	_
style	_	_
images	_	_
comprised	_	_
several	_	_
distinct	_	_
styles	_	_
.	_	_

#243
Therefore	_	_
we	_	_
conclude	_	_
that	_	_
to	_	_
learn	_	_
a	_	_
good	_	_
style	_	_
transfer	_	_
model	_	_
it	_	_
is	_	_
important	_	_
to	_	_
group	_	_
style	_	_
images	_	_
according	_	_
to	_	_
their	_	_
stylistic	_	_
similarity	_	_
.	_	_

#244
Encoder	_	_
ablation	_	_
:	_	_
To	_	_
investigate	_	_
the	_	_
effect	_	_
of	_	_
our	_	_
encoder	_	_
E	_	_
,	_	_
we	_	_
substitute	_	_
it	_	_
with	_	_
VGG16	_	_
[	_	_
41	_	_
]	_	_
encoder	_	_
(	_	_
up	_	_
to	_	_
conv5	_	_
3	_	_
)	_	_
pre-trained	_	_
on	_	_
ImageNet	_	_
.	_	_

#245
The	_	_
VGG	_	_
encoder	_	_
retains	_	_
features	_	_
that	_	_
separate	_	_
object	_	_
classes	_	_
(	_	_
since	_	_
it	_	_
was	_	_
trained	_	_
discriminatively	_	_
)	_	_
,	_	_
as	_	_
opposed	_	_
to	_	_
our	_	_
encoder	_	_
which	_	_
is	_	_
trained	_	_
to	_	_
retain	_	_
style-specific	_	_
content	_	_
details	_	_
.	_	_

#246
Hence	_	_
,	_	_
our	_	_
encoder	_	_
is	_	_
not	_	_
biased	_	_
towards	_	_
class-discriminative	_	_
feaA	_	_
Style-Aware	_	_
Content	_	_
Loss	_	_
for	_	_
Real-time	_	_
HD	_	_
Style	_	_
Transfer	_	_
15	_	_
tures	_	_
,	_	_
but	_	_
is	_	_
style	_	_
specific	_	_
and	_	_
trained	_	_
from	_	_
scratch	_	_
.	_	_

#247
Fig.	_	_
11	_	_
(	_	_
a	_	_
,	_	_
b	_	_
)	_	_
show	_	_
that	_	_
our	_	_
approach	_	_
produces	_	_
better	_	_
results	_	_
than	_	_
with	_	_
pre-trained	_	_
VGG16	_	_
encoder	_	_
.	_	_

#248
4	_	_
Conclusion	_	_

#249
This	_	_
paper	_	_
has	_	_
addressed	_	_
major	_	_
conceptual	_	_
issues	_	_
in	_	_
state-of-the-art	_	_
approaches	_	_
for	_	_
style	_	_
transfer	_	_
.	_	_

#250
We	_	_
overcome	_	_
the	_	_
limitation	_	_
of	_	_
only	_	_
a	_	_
single	_	_
style	_	_
image	_	_
or	_	_
the	_	_
need	_	_
for	_	_
style	_	_
and	_	_
content	_	_
training	_	_
images	_	_
to	_	_
show	_	_
similar	_	_
content	_	_
.	_	_

#251
Moreover	_	_
,	_	_
we	_	_
exceed	_	_
a	_	_
mere	_	_
pixel-wise	_	_
comparison	_	_
of	_	_
stylistic	_	_
images	_	_
or	_	_
models	_	_
that	_	_
are	_	_
pre-trained	_	_
on	_	_
millions	_	_
of	_	_
ImageNet	_	_
bounding	_	_
boxes	_	_
.	_	_

#252
The	_	_
proposed	_	_
style-aware	_	_
content	_	_
loss	_	_
enables	_	_
a	_	_
real-time	_	_
,	_	_
high-resolution	_	_
encoder-decoder	_	_
based	_	_
stylization	_	_
of	_	_
images	_	_
and	_	_
videos	_	_
and	_	_
significantly	_	_
improves	_	_
stylization	_	_
by	_	_
capturing	_	_
how	_	_
style	_	_
affects	_	_
content	_	_
.	_	_

#253
Solution	_	_
to	_	_
Fig.	_	_
1	_	_
:	_	_
patches	_	_
3	_	_
and	_	_
5	_	_
were	_	_
generated	_	_
by	_	_
our	_	_
approach	_	_
,	_	_
others	_	_
by	_	_
artists	_	_
.	_	_

#254
This	_	_
work	_	_
has	_	_
been	_	_
supported	_	_
in	_	_
part	_	_
by	_	_
a	_	_
DFG	_	_
grant	_	_
,	_	_
the	_	_
Heidelberg	_	_
Academy	_	_
of	_	_
Science	_	_
,	_	_
and	_	_
an	_	_
Nvidia	_	_
hardware	_	_
donation	_	_
.	_	_

#255
16	_	_
A.	_	_
Sanakoyeu	_	_
,	_	_
D.	_	_
Kotovenko	_	_
,	_	_
S.	_	_
Lang	_	_
,	_	_
and	_	_
B.	_	_
Ommer	_	_