#0
Deep	_	_
Learning	_	_
Object	_	_
Detection	_	_
Methods	_	_
for	_	_
Ecological	_	_
Camera	_	_
Trap	_	_
Data	_	_
Stefan	_	_
Schneider∗	_	_
,	_	_
Graham	_	_
W.	_	_
Taylor†	_	_
,	_	_
Stefan	_	_
C.	_	_
Kremer∗	_	_
∗School	_	_
of	_	_
Computer	_	_
Science	_	_
,	_	_
University	_	_
of	_	_
Guelph	_	_
{	_	_
sschne01	_	_
,	_	_
skremer	_	_
}	_	_
@	_	_
uoguelph.ca	_	_
†School	_	_
of	_	_
Engineering	_	_
,	_	_
University	_	_
of	_	_
Guelph	_	_
gwtaylor	_	_
@	_	_
uoguelph.ca	_	_
†Vector	_	_
Institute	_	_
for	_	_
Artificial	_	_
Intelligence	_	_
†Canadian	_	_
Institute	_	_
for	_	_
Advanced	_	_
Research	_	_
Abstract—Deep	_	_
learning	_	_
methods	_	_
for	_	_
computer	_	_
vision	_	_
tasks	_	_
show	_	_
promise	_	_
for	_	_
automating	_	_
the	_	_
data	_	_
analysis	_	_
of	_	_
camera	_	_
trap	_	_
images	_	_
.	_	_

#1
Ecological	_	_
camera	_	_
traps	_	_
are	_	_
a	_	_
common	_	_
approach	_	_
for	_	_
monitoring	_	_
an	_	_
ecosystem’s	_	_
animal	_	_
population	_	_
,	_	_
as	_	_
they	_	_
provide	_	_
continual	_	_
insight	_	_
into	_	_
an	_	_
environment	_	_
without	_	_
being	_	_
intrusive	_	_
.	_	_

#2
However	_	_
,	_	_
the	_	_
analysis	_	_
of	_	_
camera	_	_
trap	_	_
images	_	_
is	_	_
expensive	_	_
,	_	_
labour	_	_
intensive	_	_
,	_	_
and	_	_
time	_	_
consuming	_	_
.	_	_

#3
Recent	_	_
advances	_	_
in	_	_
the	_	_
field	_	_
of	_	_
deep	_	_
learning	_	_
for	_	_
object	_	_
detection	_	_
show	_	_
promise	_	_
towards	_	_
automating	_	_
the	_	_
analysis	_	_
of	_	_
camera	_	_
trap	_	_
images	_	_
.	_	_

#4
Here	_	_
,	_	_
we	_	_
demonstrate	_	_
their	_	_
capabilities	_	_
by	_	_
training	_	_
and	_	_
comparing	_	_
two	_	_
deep	_	_
learning	_	_
object	_	_
detection	_	_
classifiers	_	_
,	_	_
Faster	_	_
R-CNN	_	_
and	_	_
YOLO	_	_
v2.0	_	_
,	_	_
to	_	_
identify	_	_
,	_	_
quantify	_	_
,	_	_
and	_	_
localize	_	_
animal	_	_
species	_	_
within	_	_
camera	_	_
trap	_	_
images	_	_
using	_	_
the	_	_
Reconyx	_	_
Camera	_	_
Trap	_	_
and	_	_
the	_	_
self-labeled	_	_
Gold	_	_
Standard	_	_
Snapshot	_	_
Serengeti	_	_
data	_	_
sets	_	_
.	_	_

#5
When	_	_
trained	_	_
on	_	_
large	_	_
labeled	_	_
datasets	_	_
,	_	_
object	_	_
recognition	_	_
methods	_	_
have	_	_
shown	_	_
success	_	_
.	_	_

#6
We	_	_
demonstrate	_	_
their	_	_
use	_	_
,	_	_
in	_	_
the	_	_
context	_	_
of	_	_
realistically	_	_
sized	_	_
ecological	_	_
data	_	_
sets	_	_
,	_	_
by	_	_
testing	_	_
if	_	_
object	_	_
detection	_	_
methods	_	_
are	_	_
applicable	_	_
for	_	_
ecological	_	_
research	_	_
scenarios	_	_
when	_	_
utilizing	_	_
transfer	_	_
learning	_	_
.	_	_

#7
Faster	_	_
R-CNN	_	_
outperformed	_	_
YOLO	_	_
v2.0	_	_
with	_	_
average	_	_
accuracies	_	_
of	_	_
93.0	_	_
%	_	_
and	_	_
76.7	_	_
%	_	_
on	_	_
the	_	_
two	_	_
data	_	_
sets	_	_
,	_	_
respectively	_	_
.	_	_

#8
Our	_	_
findings	_	_
show	_	_
promising	_	_
steps	_	_
towards	_	_
the	_	_
automation	_	_
of	_	_
the	_	_
labourious	_	_
task	_	_
of	_	_
labeling	_	_
camera	_	_
trap	_	_
images	_	_
,	_	_
which	_	_
can	_	_
be	_	_
used	_	_
to	_	_
improve	_	_
our	_	_
understanding	_	_
of	_	_
the	_	_
population	_	_
dynamics	_	_
of	_	_
ecosystems	_	_
across	_	_
the	_	_
planet	_	_
.	_	_

#9
I	_	_
.	_	_

#10
INTRODUCTION	_	_
Population	_	_
ecologists	_	_
use	_	_
camera	_	_
traps	_	_
to	_	_
monitor	_	_
animal	_	_
population	_	_
sizes	_	_
and	_	_
manage	_	_
ecosystems	_	_
around	_	_
the	_	_
world	_	_
.	_	_

#11
Camera	_	_
traps	_	_
were	_	_
first	_	_
introduced	_	_
in	_	_
1956	_	_
,	_	_
and	_	_
in	_	_
1995	_	_
,	_	_
Karanth	_	_
demonstrated	_	_
their	_	_
usefulness	_	_
for	_	_
population	_	_
ecology	_	_
by	_	_
re-identifying	_	_
tigers	_	_
(	_	_
Panthera	_	_
tigris	_	_
)	_	_
in	_	_
Nagarahole	_	_
,	_	_
India	_	_
using	_	_
a	_	_
formal	_	_
mark	_	_
and	_	_
recapture	_	_
model	_	_
[	_	_
1	_	_
]	_	_
,	_	_
[	_	_
2	_	_
]	_	_
.	_	_

#12
The	_	_
popularity	_	_
of	_	_
the	_	_
camera	_	_
trap	_	_
methodology	_	_
grew	_	_
rapidly	_	_
thereafter	_	_
,	_	_
with	_	_
a	_	_
50	_	_
%	_	_
annual	_	_
growth	_	_
using	_	_
the	_	_
technique	_	_
as	_	_
a	_	_
tool	_	_
to	_	_
estimate	_	_
population	_	_
sizes	_	_
[	_	_
3	_	_
]	_	_
,	_	_
[	_	_
4	_	_
]	_	_
.	_	_

#13
Camera	_	_
traps	_	_
respond	_	_
to	_	_
motion	_	_
,	_	_
which	_	_
generally	_	_
corresponds	_	_
with	_	_
an	_	_
animal	_	_
entering	_	_
the	_	_
frame	_	_
.	_	_

#14
Camera	_	_
trap	_	_
data	_	_
analyses	_	_
involve	_	_
manually	_	_
quantifying	_	_
the	_	_
species	_	_
and	_	_
number	_	_
of	_	_
individuals	_	_
in	_	_
thousands	_	_
of	_	_
images	_	_
.	_	_

#15
Automating	_	_
this	_	_
process	_	_
has	_	_
obvious	_	_
advantages	_	_
,	_	_
including	_	_
a	_	_
reduction	_	_
in	_	_
human	_	_
labour	_	_
,	_	_
an	_	_
unbiased	_	_
estimate	_	_
across	_	_
analyses	_	_
,	_	_
and	_	_
the	_	_
availability	_	_
of	_	_
species	_	_
identification	_	_
without	_	_
domain	_	_
expertise	_	_
.	_	_

#16
In	_	_
this	_	_
work	_	_
,	_	_
we	_	_
focus	_	_
on	_	_
utilizing	_	_
deep	_	_
learning	_	_
based	_	_
approaches	_	_
for	_	_
object	_	_
detection	_	_
to	_	_
identify	_	_
,	_	_
quantify	_	_
,	_	_
and	_	_
localize	_	_
animal	_	_
species	_	_
within	_	_
camera	_	_
trap	_	_
images	_	_
.	_	_

#17
Camera	_	_
trap	_	_
data	_	_
provides	_	_
a	_	_
robust	_	_
measure	_	_
of	_	_
the	_	_
capabilities	_	_
of	_	_
deep	_	_
learning	_	_
for	_	_
species	_	_
classification	_	_
,	_	_
as	_	_
the	_	_
images	_	_
are	_	_
often	_	_
‘messy’	_	_
,	_	_
with	_	_
animals	_	_
being	_	_
partly	_	_
obstructed	_	_
,	_	_
positioned	_	_
at	_	_
varying	_	_
distances	_	_
,	_	_
cropped	_	_
out	_	_
of	_	_
the	_	_
image	_	_
,	_	_
or	_	_
extremely	_	_
close	_	_
to	_	_
the	_	_
camera	_	_
[	_	_
5	_	_
]	_	_
.	_	_

#18
These	_	_
obstacles	_	_
are	_	_
in	_	_
addition	_	_
to	_	_
the	_	_
traditional	_	_
difficulties	_	_
of	_	_
computer	_	_
vision	_	_
tasks	_	_
,	_	_
such	_	_
as	_	_
variable	_	_
lighting	_	_
,	_	_
photos	_	_
taken	_	_
at	_	_
day	_	_
and	_	_
night	_	_
,	_	_
and	_	_
species	_	_
exhibiting	_	_
a	_	_
variety	_	_
of	_	_
poses	_	_
.	_	_

#19
Deep	_	_
learning	_	_
methods	_	_
have	_	_
demonstrated	_	_
near	_	_
perfect	_	_
accuracy	_	_
for	_	_
computer	_	_
vision	_	_
tasks	_	_
when	_	_
trained	_	_
on	_	_
large	_	_
labled	_	_
datasets	_	_
;	_	_
however	_	_
,	_	_
labeled	_	_
ecological	_	_
data	_	_
is	_	_
notorious	_	_
for	_	_
being	_	_
sparse	_	_
and	_	_
intermittent	_	_
[	_	_
6	_	_
]	_	_
.	_	_

#20
We	_	_
aim	_	_
to	_	_
test	_	_
the	_	_
bounds	_	_
of	_	_
deep	_	_
learning	_	_
for	_	_
realistic	_	_
ecological	_	_
applications	_	_
,	_	_
demonstrating	_	_
the	_	_
usefulness	_	_
of	_	_
the	_	_
technique	_	_
for	_	_
researchers	_	_
to	_	_
train	_	_
their	_	_
own	_	_
classifiers	_	_
on	_	_
their	_	_
own	_	_
ecosystem	_	_
of	_	_
interest	_	_
,	_	_
instead	_	_
of	_	_
relying	_	_
on	_	_
large	_	_
public	_	_
data	_	_
sets	_	_
which	_	_
may	_	_
not	_	_
fit	_	_
their	_	_
niche	_	_
of	_	_
study	_	_
.	_	_

#21
We	_	_
considered	_	_
the	_	_
Reconyx	_	_
Camera	_	_
Trap	_	_
data	_	_
set	_	_
,	_	_
which	_	_
contains	_	_
946	_	_
labeled	_	_
images	_	_
with	_	_
20	_	_
species	_	_
classifications	_	_
and	_	_
bounding	_	_
box	_	_
coordinates	_	_
,	_	_
as	_	_
well	_	_
as	_	_
the	_	_
Gold	_	_
Standard	_	_
Snapshot	_	_
Serengeti	_	_
data	_	_
set	_	_
,	_	_
which	_	_
contains	_	_
4,096	_	_
labeled	_	_
images	_	_
of	_	_
48	_	_
species	_	_
classifications	_	_
[	_	_
5	_	_
]	_	_
,	_	_
[	_	_
7	_	_
]	_	_
.	_	_

#22
Current	_	_
methods	_	_
for	_	_
object	_	_
detection	_	_
require	_	_
the	_	_
bounding	_	_
box	_	_
coordinates	_	_
for	_	_
training	_	_
,	_	_
and	_	_
as	_	_
a	_	_
result	_	_
,	_	_
we	_	_
hand-labeled	_	_
the	_	_
bounding	_	_
box	_	_
coordinates	_	_
for	_	_
the	_	_
Gold	_	_
Standard	_	_
Snapshot	_	_
Serengeti	_	_
data	_	_
set	_	_
and	_	_
offer	_	_
it	_	_
to	_	_
the	_	_
camera	_	_
trap	_	_
and	_	_
deep	_	_
learning	_	_
community	_	_
.	_	_

#23
We	_	_
compare	_	_
two	_	_
methods	_	_
for	_	_
object	_	_
detection	_	_
using	_	_
deep	_	_
learning	_	_
,	_	_
Faster	_	_
Region-Convolutional	_	_
Neural	_	_
Network	_	_
and	_	_
You-Only-Look-Once	_	_
v2.0	_	_
(	_	_
hereafter	_	_
referred	_	_
to	_	_
as	_	_
Faster	_	_
R-CNN	_	_
and	_	_
YOLO	_	_
,	_	_
respectively	_	_
)	_	_
[	_	_
8	_	_
]	_	_
,	_	_
[	_	_
9	_	_
]	_	_
.	_	_

#24
These	_	_
two	_	_
approaches	_	_
are	_	_
generally	_	_
considered	_	_
by	_	_
the	_	_
trade-off	_	_
of	_	_
data	_	_
efficiency	_	_
versus	_	_
speed	_	_
,	_	_
as	_	_
YOLO	_	_
can	_	_
be	_	_
used	_	_
in	_	_
real	_	_
time	_	_
,	_	_
but	_	_
requires	_	_
additional	_	_
training	_	_
data	_	_
[	_	_
8	_	_
]	_	_
.	_	_

#25
Our	_	_
results	_	_
demonstrate	_	_
Faster	_	_
R-CNN	_	_
shows	_	_
promise	_	_
for	_	_
accurate	_	_
and	_	_
autonomous	_	_
analysis	_	_
of	_	_
camera	_	_
trap	_	_
data	_	_
,	_	_
while	_	_
YOLO	_	_
fails	_	_
to	_	_
perform	_	_
.	_	_

#26
These	_	_
results	_	_
demonstrate	_	_
that	_	_
ecologists	_	_
should	_	_
consider	_	_
utilizing	_	_
Faster	_	_
R-CNN	_	_
or	_	_
its	_	_
successors	_	_
as	_	_
the	_	_
ar	_	_
X	_	_
iv	_	_
:1	_	_
3	_	_
.	_	_

#27
2v	_	_
1	_	_
[	_	_
cs	_	_
.C	_	_
V	_	_
]	_	_
2	_	_
8	_	_
M	_	_
ar	_	_
2	_	_
method	_	_
of	_	_
object	_	_
detection	_	_
to	_	_
autonomously	_	_
extract	_	_
ecological	_	_
information	_	_
from	_	_
camera	_	_
trap	_	_
images	_	_
.	_	_

#28
II	_	_
.	_	_

#29
BACKGROUND	_	_
AND	_	_
RELATED	_	_
WORK	_	_
Deep	_	_
Learning	_	_
for	_	_
Object	_	_
Detection	_	_
:	_	_
Many	_	_
recent	_	_
advancements	_	_
in	_	_
deep	_	_
learning	_	_
have	_	_
come	_	_
from	_	_
improving	_	_
the	_	_
architectures	_	_
of	_	_
a	_	_
neural	_	_
network	_	_
.	_	_

#30
One	_	_
such	_	_
architecture	_	_
is	_	_
the	_	_
Convolutional	_	_
Neural	_	_
Network	_	_
(	_	_
CNN	_	_
)	_	_
,	_	_
which	_	_
is	_	_
now	_	_
the	_	_
most	_	_
commonly	_	_
used	_	_
architecture	_	_
for	_	_
computer	_	_
vision	_	_
tasks	_	_
[	_	_
10	_	_
]	_	_
,	_	_
[	_	_
11	_	_
]	_	_
.	_	_

#31
CNNs	_	_
introduce	_	_
convolutional	_	_
layers	_	_
within	_	_
a	_	_
network	_	_
which	_	_
,	_	_
for	_	_
a	_	_
given	_	_
image	_	_
,	_	_
learn	_	_
many	_	_
feature	_	_
maps	_	_
which	_	_
represent	_	_
the	_	_
spatial	_	_
similarity	_	_
of	_	_
patterns	_	_
found	_	_
within	_	_
the	_	_
image	_	_
(	_	_
such	_	_
as	_	_
colour	_	_
clusters	_	_
,	_	_
or	_	_
the	_	_
presence	_	_
or	_	_
absence	_	_
of	_	_
lines	_	_
)	_	_
[	_	_
12	_	_
]	_	_
.	_	_

#32
Each	_	_
feature	_	_
map	_	_
is	_	_
governed	_	_
by	_	_
a	_	_
set	_	_
of	_	_
‘filter	_	_
banks’	_	_
,	_	_
which	_	_
are	_	_
matrices	_	_
of	_	_
scalar	_	_
values	_	_
that	_	_
can	_	_
generally	_	_
be	_	_
considered	_	_
synonymous	_	_
to	_	_
the	_	_
weights	_	_
of	_	_
a	_	_
feedforward	_	_
network	_	_
.	_	_

#33
For	_	_
each	_	_
convolutional	_	_
layer	_	_
,	_	_
the	_	_
filter	_	_
banks	_	_
are	_	_
similarly	_	_
passed	_	_
through	_	_
a	_	_
non-linear	_	_
transformation	_	_
and	_	_
learned	_	_
using	_	_
gradient	_	_
descent	_	_
with	_	_
backpropagation	_	_
[	_	_
12	_	_
]	_	_
.	_	_

#34
CNNs	_	_
also	_	_
introduce	_	_
max	_	_
pooling	_	_
layers	_	_
,	_	_
a	_	_
method	_	_
that	_	_
reduces	_	_
computation	_	_
and	_	_
increases	_	_
robustness	_	_
by	_	_
evenly	_	_
dividing	_	_
the	_	_
feature	_	_
map	_	_
into	_	_
regions	_	_
and	_	_
returning	_	_
only	_	_
the	_	_
highest	_	_
activation	_	_
values	_	_
[	_	_
12	_	_
]	_	_
.	_	_

#35
As	_	_
a	_	_
result	_	_
of	_	_
having	_	_
numerous	_	_
feature	_	_
maps	_	_
for	_	_
a	_	_
given	_	_
input	_	_
,	_	_
CNNs	_	_
are	_	_
particularly	_	_
well	_	_
suited	_	_
for	_	_
dealing	_	_
with	_	_
data	_	_
from	_	_
multiple	_	_
arrays	_	_
,	_	_
such	_	_
as	_	_
colour	_	_
images	_	_
,	_	_
which	_	_
have	_	_
three	_	_
colour	_	_
channels	_	_
[	_	_
12	_	_
]	_	_
.	_	_

#36
Deep	_	_
learning	_	_
researchers	_	_
continually	_	_
experiment	_	_
with	_	_
the	_	_
modular	_	_
architectures	_	_
of	_	_
neural	_	_
networks	_	_
and	_	_
four	_	_
CNN	_	_
frameworks	_	_
have	_	_
been	_	_
standardized	_	_
as	_	_
wellperforming	_	_
with	_	_
differences	_	_
including	_	_
computation	_	_
cost	_	_
and	_	_
memory	_	_
in	_	_
comparison	_	_
to	_	_
accuracy	_	_
.	_	_

#37
These	_	_
networks	_	_
include	_	_
AlexNet	_	_
,	_	_
VGG	_	_
,	_	_
GoogLeNet/InceptionNet	_	_
(	_	_
which	_	_
introduced	_	_
the	_	_
inception	_	_
module	_	_
)	_	_
,	_	_
and	_	_
ResNet	_	_
,	_	_
which	_	_
introduced	_	_
skip	_	_
connections	_	_
[	_	_
11	_	_
]	_	_
,	_	_
[	_	_
13	_	_
]	_	_
–	_	_
[	_	_
15	_	_
]	_	_
.	_	_

#38
These	_	_
networks	_	_
range	_	_
from	_	_
7	_	_
to	_	_
152	_	_
layers	_	_
.	_	_

#39
A	_	_
common	_	_
approach	_	_
to	_	_
training	_	_
deep	_	_
learning	_	_
classification	_	_
tasks	_	_
is	_	_
to	_	_
use	_	_
publicly	_	_
available	_	_
weights	_	_
from	_	_
one	_	_
of	_	_
these	_	_
four	_	_
network	_	_
structures	_	_
trained	_	_
on	_	_
a	_	_
public	_	_
data	_	_
set	_	_
as	_	_
initialization	_	_
parameters	_	_
,	_	_
and	_	_
retraining	_	_
the	_	_
network	_	_
using	_	_
your	_	_
own	_	_
limited	_	_
data	_	_
set	_	_
[	_	_
16	_	_
]	_	_
.	_	_

#40
This	_	_
allows	_	_
for	_	_
learned	_	_
filters	_	_
,	_	_
such	_	_
as	_	_
edge	_	_
or	_	_
colour	_	_
detectors	_	_
,	_	_
to	_	_
be	_	_
used	_	_
without	_	_
having	_	_
to	_	_
be	_	_
re-learned	_	_
on	_	_
limited	_	_
data	_	_
.	_	_

#41
This	_	_
technique	_	_
is	_	_
known	_	_
as	_	_
Transfer	_	_
Learning	_	_
[	_	_
16	_	_
]	_	_
.	_	_

#42
CNNs	_	_
have	_	_
demonstrated	_	_
great	_	_
success	_	_
for	_	_
image	_	_
classification	_	_
,	_	_
conditioned	_	_
on	_	_
the	_	_
network	_	_
being	_	_
trained	_	_
to	_	_
return	_	_
a	_	_
single	_	_
label	_	_
for	_	_
a	_	_
given	_	_
image	_	_
[	_	_
11	_	_
]	_	_
.	_	_

#43
In	_	_
order	_	_
to	_	_
determine	_	_
the	_	_
classification	_	_
of	_	_
more	_	_
than	_	_
one	_	_
object	_	_
within	_	_
an	_	_
image	_	_
,	_	_
computer	_	_
vision	_	_
researchers	_	_
train	_	_
an	_	_
object	_	_
detector	_	_
,	_	_
where	_	_
the	_	_
image	_	_
is	_	_
segregated	_	_
into	_	_
overlapping	_	_
regions	_	_
(	_	_
often	_	_
called	_	_
‘proposals’	_	_
)	_	_
[	_	_
17	_	_
]	_	_
.	_	_

#44
Two	_	_
approaches	_	_
for	_	_
object	_	_
detection	_	_
have	_	_
seen	_	_
wide-spread	_	_
success	_	_
.	_	_

#45
The	_	_
earliest	_	_
approach	_	_
was	_	_
R-CNN	_	_
,	_	_
where	_	_
an	_	_
image	_	_
is	_	_
crudely	_	_
segregate	_	_
into	_	_
a	_	_
series	_	_
of	_	_
different	_	_
sized	_	_
boxes	_	_
using	_	_
an	_	_
image	_	_
segregation	_	_
algorithm	_	_
,	_	_
and	_	_
each	_	_
region	_	_
is	_	_
passed	_	_
through	_	_
a	_	_
CNN	_	_
.	_	_

#46
Fast	_	_
R-CNN	_	_
introduced	_	_
region	_	_
proposals	_	_
generated	_	_
based	_	_
on	_	_
the	_	_
refined	_	_
last	_	_
feature	_	_
map	_	_
of	_	_
the	_	_
network	_	_
to	_	_
decrease	_	_
proposal	_	_
computation	_	_
[	_	_
17	_	_
]	_	_
.	_	_

#47
Soon	_	_
after	_	_
,	_	_
Faster	_	_
R-CNN	_	_
,	_	_
which	_	_
introduces	_	_
a	_	_
Region	_	_
Proposal	_	_
Network	_	_
(	_	_
RPN	_	_
)	_	_
to	_	_
the	_	_
framework	_	_
,	_	_
enabled	_	_
nearly	_	_
cost-free	_	_
region	_	_
proposals	_	_
[	_	_
15	_	_
]	_	_
.	_	_

#48
A	_	_
second	_	_
approach	_	_
for	_	_
object	_	_
detection	_	_
is	_	_
YOLO	_	_
,	_	_
which	_	_
divides	_	_
an	_	_
image	_	_
into	_	_
a	_	_
grid	_	_
,	_	_
with	_	_
each	_	_
gridcell	_	_
acting	_	_
as	_	_
the	_	_
origin	_	_
for	_	_
numerous	_	_
predefined	_	_
‘anchors’	_	_
relevant	_	_
to	_	_
the	_	_
size	_	_
classifications	_	_
of	_	_
interest	_	_
.	_	_

#49
For	_	_
example	_	_
,	_	_
when	_	_
searching	_	_
for	_	_
a	_	_
cat	_	_
,	_	_
one	_	_
may	_	_
implement	_	_
three	_	_
anchors	_	_
:	_	_
a	_	_
square	_	_
,	_	_
a	_	_
horizontal	_	_
rectangle	_	_
,	_	_
and	_	_
a	_	_
vertical	_	_
rectangle	_	_
,	_	_
as	_	_
a	_	_
cat	_	_
may	_	_
approximately	_	_
fit	_	_
into	_	_
each	_	_
shape	_	_
.	_	_

#50
When	_	_
training	_	_
and	_	_
using	_	_
YOLO	_	_
,	_	_
output	_	_
classifications	_	_
are	_	_
returned	_	_
for	_	_
every	_	_
anchor	_	_
in	_	_
a	_	_
single	_	_
iteration	_	_
.	_	_

#51
[	_	_
8	_	_
]	_	_
.	_	_

#52
YOLO	_	_
is	_	_
often	_	_
less	_	_
accurate	_	_
due	_	_
to	_	_
the	_	_
static	_	_
nature	_	_
of	_	_
the	_	_
anchor	_	_
boxes	_	_
,	_	_
but	_	_
has	_	_
been	_	_
shown	_	_
to	_	_
be	_	_
3x	_	_
faster	_	_
than	_	_
Faster	_	_
R-CNN	_	_
[	_	_
8	_	_
]	_	_
.	_	_

#53
Automating	_	_
the	_	_
Analysis	_	_
of	_	_
Camera	_	_
Trap	_	_
Images	_	_
:	_	_
Prior	_	_
to	_	_
the	_	_
wide-spread	_	_
adoption	_	_
of	_	_
deep	_	_
learning	_	_
systems	_	_
,	_	_
computer	_	_
vision	_	_
researchers	_	_
developed	_	_
a	_	_
variety	_	_
of	_	_
creative	_	_
and	_	_
moderately	_	_
successful	_	_
methodologies	_	_
for	_	_
the	_	_
automated	_	_
analysis	_	_
of	_	_
animals	_	_
from	_	_
camera	_	_
traps	_	_
based	_	_
on	_	_
the	_	_
raw	_	_
pixel	_	_
data	_	_
from	_	_
images	_	_
.	_	_

#54
Initial	_	_
approaches	_	_
for	_	_
species	_	_
classification	_	_
required	_	_
a	_	_
domain	_	_
expert	_	_
to	_	_
identify	_	_
meaningful	_	_
features	_	_
for	_	_
the	_	_
desired	_	_
classification	_	_
(	_	_
such	_	_
as	_	_
the	_	_
unique	_	_
characteristics	_	_
of	_	_
animal	_	_
species	_	_
)	_	_
,	_	_
design	_	_
an	_	_
algorithm	_	_
to	_	_
extract	_	_
these	_	_
features	_	_
from	_	_
the	_	_
image	_	_
,	_	_
and	_	_
compare	_	_
individual	_	_
differences	_	_
using	_	_
a	_	_
statistical	_	_
analysis	_	_
.	_	_

#55
Computer	_	_
vision	_	_
systems	_	_
were	_	_
first	_	_
introduced	_	_
for	_	_
species	_	_
classification	_	_
within	_	_
the	_	_
microbial	_	_
and	_	_
zooplankton	_	_
community	_	_
to	_	_
help	_	_
standardized	_	_
species	_	_
classification	_	_
,	_	_
and	_	_
considered	_	_
morphological	_	_
silhouettes	_	_
[	_	_
18	_	_
]	_	_
–	_	_
[	_	_
20	_	_
]	_	_
.	_	_

#56
The	_	_
first	_	_
complete	_	_
camera	_	_
trap	_	_
analysis	_	_
was	_	_
done	_	_
in	_	_
2013	_	_
using	_	_
the	_	_
Scale-Invariant	_	_
Feature	_	_
Transformation	_	_
algorithm	_	_
in	_	_
combination	_	_
with	_	_
a	_	_
Support	_	_
Vector	_	_
Machine	_	_
to	_	_
classify	_	_
species	_	_
using	_	_
the	_	_
Reconyx	_	_
Camera	_	_
Trap	_	_
data	_	_
set	_	_
after	_	_
a	_	_
foreground	_	_
extraction	_	_
technique	_	_
was	_	_
applied	_	_
to	_	_
separate	_	_
the	_	_
animal	_	_
from	_	_
the	_	_
background	_	_
[	_	_
7	_	_
]	_	_
,	_	_
[	_	_
21	_	_
]	_	_
,	_	_
[	_	_
22	_	_
]	_	_
.	_	_

#57
In	_	_
2014	_	_
,	_	_
Chen	_	_
et	_	_
al.	_	_
[	_	_
23	_	_
]	_	_
reported	_	_
the	_	_
first	_	_
paper	_	_
for	_	_
animal	_	_
species	_	_
classification	_	_
using	_	_
a	_	_
CNN	_	_
that	_	_
considered	_	_
the	_	_
Reconyx	_	_
Camera	_	_
Trap	_	_
data	_	_
set	_	_
.	_	_

#58
Their	_	_
CNN	_	_
was	_	_
a	_	_
shallow	_	_
network	_	_
by	_	_
modern	_	_
standards	_	_
,	_	_
with	_	_
3	_	_
convolution	_	_
and	_	_
3	_	_
pooling	_	_
layers	_	_
.	_	_

#59
In	_	_
2016	_	_
,	_	_
Gomez	_	_
et	_	_
al.	_	_
[	_	_
24	_	_
]	_	_
used	_	_
deep	_	_
CNNs	_	_
for	_	_
camera	_	_
trap	_	_
species	_	_
recognition	_	_
,	_	_
comparing	_	_
8	_	_
variations	_	_
of	_	_
the	_	_
established	_	_
CNN	_	_
frameworks	_	_
AlexNet	_	_
,	_	_
VGG	_	_
,	_	_
GoogLeNet	_	_
,	_	_
and	_	_
ResNet	_	_
to	_	_
train	_	_
species	_	_
classification	_	_
on	_	_
the	_	_
complete	_	_
Snapshot	_	_
Serengeti	_	_
data	_	_
set	_	_
of	_	_
3.2	_	_
million	_	_
images	_	_
with	_	_
48	_	_
species	_	_
classifications	_	_
.	_	_

#60
The	_	_
ResNet-101	_	_
architecture	_	_
achieved	_	_
the	_	_
best	_	_
performance	_	_
.	_	_

#61
Following	_	_
this	_	_
work	_	_
,	_	_
they	_	_
also	_	_
utilized	_	_
deep	_	_
learning	_	_
to	_	_
improve	_	_
low	_	_
resolution	_	_
animal	_	_
species	_	_
recognition	_	_
by	_	_
training	_	_
deep	_	_
CNNs	_	_
on	_	_
poor	_	_
quality	_	_
images	_	_
.	_	_

#62
The	_	_
data	_	_
was	_	_
labeled	_	_
by	_	_
experts	_	_
into	_	_
two	_	_
data	_	_
sets	_	_
,	_	_
the	_	_
first	_	_
classifying	_	_
between	_	_
birds	_	_
and	_	_
mammals	_	_
and	_	_
the	_	_
second	_	_
classification	_	_
of	_	_
different	_	_
mammal	_	_
species	_	_
[	_	_
25	_	_
]	_	_
,	_	_
[	_	_
26	_	_
]	_	_
.	_	_

#63
In	_	_
2017	_	_
,	_	_
Norouzzadeh	_	_
et	_	_
al.	_	_
[	_	_
5	_	_
]	_	_
,	_	_
utilized	_	_
the	_	_
ability	_	_
of	_	_
a	_	_
network	_	_
to	_	_
return	_	_
numerous	_	_
output	_	_
classifications	_	_
for	_	_
a	_	_
given	_	_
image	_	_
,	_	_
a	_	_
technique	_	_
known	_	_
as	_	_
multitask	_	_
learning	_	_
,	_	_
to	_	_
consider	_	_
the	_	_
species	_	_
,	_	_
quantify	_	_
the	_	_
number	_	_
of	_	_
animals	_	_
,	_	_
as	_	_
well	_	_
as	_	_
to	_	_
determine	_	_
additional	_	_
attributes	_	_
.	_	_

#64
This	_	_
approach	_	_
operates	_	_
differently	_	_
than	_	_
object	_	_
detection	_	_
methods	_	_
,	_	_
as	_	_
their	_	_
classifier	_	_
learns	_	_
what	_	_
an	_	_
image	_	_
with	_	_
a	_	_
given	_	_
number	_	_
of	_	_
animals	_	_
looks	_	_
like	_	_
,	_	_
rather	_	_
than	_	_
individually	_	_
detecting	_	_
the	_	_
number	_	_
of	_	_
individuals	_	_
within	_	_
the	_	_
image	_	_
.	_	_

#65
Nine	_	_
independent	_	_
architectures	_	_
were	_	_
trained	_	_
,	_	_
including	_	_
AlexNet	_	_
,	_	_
VGG	_	_
,	_	_
GoogLeNet	_	_
,	_	_
and	_	_
numerous	_	_
variations	_	_
of	_	_
ResNet	_	_
.	_	_

#66
The	_	_
authors	_	_
report	_	_
a	_	_
species	_	_
classification	_	_
accuracy	_	_
,	_	_
counting	_	_
,	_	_
and	_	_
attribute	_	_
accuracy	_	_
considering	_	_
an	_	_
ensemble	_	_
of	_	_
their	_	_
nine	_	_
models	_	_
[	_	_
5	_	_
]	_	_
.	_	_

#67
These	_	_
approaches	_	_
all	_	_
share	_	_
the	_	_
common	_	_
limitation	_	_
of	_	_
returning	_	_
only	_	_
one	_	_
output	_	_
per	_	_
classification	_	_
task	_	_
per	_	_
image	_	_
,	_	_
which	_	_
is	_	_
unrealistic	_	_
for	_	_
meaningful	_	_
camera	_	_
trap	_	_
data	_	_
analyses	_	_
.	_	_

#68
Object	_	_
detection	_	_
methods	_	_
account	_	_
for	_	_
this	_	_
limitation	_	_
,	_	_
allowing	_	_
for	_	_
a	_	_
classifier	_	_
to	_	_
return	_	_
multiple	_	_
species	_	_
as	_	_
output	_	_
.	_	_

#69
III	_	_
.	_	_

#70
EXPERIMENTS	_	_
AND	_	_
RESULTS	_	_
Reconyx	_	_
Camera	_	_
Trap	_	_
data	_	_
set	_	_
and	_	_
Snapshot	_	_
Serengeti	_	_
Project	_	_
:	_	_
The	_	_
Reconyx	_	_
Camera	_	_
Trap	_	_
(	_	_
further	_	_
referred	_	_
to	_	_
as	_	_
RCT	_	_
)	_	_
data	_	_
set	_	_
is	_	_
a	_	_
collection	_	_
of	_	_
7,193	_	_
camera	_	_
trap	_	_
images	_	_
from	_	_
two	_	_
locations	_	_
in	_	_
Panama	_	_
and	_	_
the	_	_
Netherlands	_	_
,	_	_
capturing	_	_
colour	_	_
images	_	_
during	_	_
the	_	_
day	_	_
,	_	_
and	_	_
gray-scale	_	_
at	_	_
night	_	_
[	_	_
7	_	_
]	_	_
.	_	_

#71
Of	_	_
all	_	_
the	_	_
images	_	_
,	_	_
only	_	_
a	_	_
subset	_	_
of	_	_
946	_	_
images	_	_
include	_	_
labeled	_	_
bounding	_	_
box	_	_
coordinates	_	_
,	_	_
and	_	_
so	_	_
we	_	_
only	_	_
considered	_	_
these	_	_
images	_	_
.	_	_

#72
The	_	_
Snapshot	_	_
Serengeti	_	_
data	_	_
set	_	_
is	_	_
the	_	_
world’s	_	_
largest	_	_
publicly	_	_
available	_	_
collection	_	_
of	_	_
camera	_	_
trap	_	_
images	_	_
,	_	_
with	_	_
approximately	_	_
1.2	_	_
million	_	_
images	_	_
collected	_	_
using	_	_
225	_	_
camera	_	_
traps	_	_
since	_	_
2011	_	_
[	_	_
27	_	_
]	_	_
.	_	_

#73
To	_	_
provide	_	_
labels	_	_
,	_	_
the	_	_
organization	_	_
has	_	_
created	_	_
a	_	_
website	_	_
where	_	_
nearly	_	_
70,000	_	_
individuals	_	_
help	_	_
label	_	_
the	_	_
images	_	_
by	_	_
selecting	_	_
predefined	_	_
classifications	_	_
of	_	_
the	_	_
species	_	_
,	_	_
the	_	_
number	_	_
of	_	_
individuals	_	_
(	_	_
1	_	_
,	_	_
2	_	_
,	_	_
3	_	_
,	_	_
4	_	_
,	_	_
5	_	_
,	_	_
6	_	_
,	_	_
7	_	_
,	_	_
8	_	_
,	_	_
9	_	_
,	_	_
10	_	_
,	_	_
11-50	_	_
,	_	_
50+	_	_
)	_	_
,	_	_
various	_	_
behaviours	_	_
(	_	_
i.e.	_	_
,	_	_
standing	_	_
,	_	_
resting	_	_
,	_	_
moving	_	_
,	_	_
eating	_	_
,	_	_
or	_	_
interacting	_	_
)	_	_
,	_	_
and	_	_
the	_	_
presence	_	_
of	_	_
young	_	_
.	_	_

#74
In	_	_
additional	_	_
,	_	_
there	_	_
is	_	_
the	_	_
Gold	_	_
Standard	_	_
Snapshot	_	_
Serengeti	_	_
(	_	_
further	_	_
referred	_	_
to	_	_
as	_	_
GSSS	_	_
)	_	_
data	_	_
set	_	_
which	_	_
contains	_	_
4,432	_	_
images	_	_
labeled	_	_
by	_	_
experts	_	_
within	_	_
the	_	_
field	_	_
;	_	_
however	_	_
only	_	_
classification	_	_
and	_	_
not	_	_
bounding	_	_
box	_	_
co-ordinates	_	_
.	_	_

#75
We	_	_
annotated	_	_
the	_	_
GSSS	_	_
data	_	_
set	_	_
to	_	_
test	_	_
object	_	_
detection	_	_
methods	_	_
and	_	_
give	_	_
these	_	_
to	_	_
the	_	_
Snapshot	_	_
Serengeti	_	_
community	_	_
.	_	_

#76
The	_	_
labeled	_	_
data	_	_
set	_	_
is	_	_
available	_	_
at	_	_
:	_	_
https	_	_
:	_	_
//dataverse.scholarsportal.info/dataset.xhtml	_	_
?	_	_
persistentId	_	_
=doi:10.5683/SP/TPB5ID	_	_
.	_	_

#77
For	_	_
this	_	_
experiment	_	_
,	_	_
we	_	_
consider	_	_
the	_	_
ResNet-101	_	_
architecture	_	_
for	_	_
both	_	_
object	_	_
detection	_	_
methods	_	_
.	_	_

#78
ResNet-101	_	_
is	_	_
a	_	_
robust	_	_
network	_	_
that	_	_
showed	_	_
great	_	_
success	_	_
in	_	_
other	_	_
camera	_	_
trap	_	_
studies	_	_
[	_	_
24	_	_
]	_	_
.	_	_

#79
We	_	_
initialized	_	_
both	_	_
object	_	_
detection	_	_
classifiers	_	_
using	_	_
a	_	_
pre-trained	_	_
model	_	_
of	_	_
the	_	_
Common	_	_
Object	_	_
in	_	_
Context	_	_
2017	_	_
data	_	_
set	_	_
[	_	_
28	_	_
]	_	_
.	_	_

#80
The	_	_
weights	_	_
of	_	_
the	_	_
final	_	_
layer	_	_
were	_	_
initialized	_	_
using	_	_
the	_	_
Xavier	_	_
initialization	_	_
[	_	_
29	_	_
]	_	_
.	_	_

#81
Each	_	_
model	_	_
was	_	_
trained	_	_
using	_	_
the	_	_
adaptive	_	_
momentum	_	_
optimizer	_	_
,	_	_
and	_	_
training	_	_
concluded	_	_
after	_	_
the	_	_
loss	_	_
failed	_	_
to	_	_
improve	_	_
after	_	_
3	_	_
successive	_	_
epochs	_	_
[	_	_
30	_	_
]	_	_
.	_	_

#82
For	_	_
both	_	_
data	_	_
sets	_	_
,	_	_
the	_	_
bounding	_	_
box	_	_
coordinates	_	_
only	_	_
pertain	_	_
to	_	_
a	_	_
subset	_	_
of	_	_
the	_	_
larger	_	_
data	_	_
set	_	_
.	_	_

#83
As	_	_
a	_	_
result	_	_
,	_	_
there	_	_
has	_	_
been	_	_
no	_	_
prior	_	_
experimentation	_	_
and	_	_
division	_	_
of	_	_
standardized	_	_
train/test	_	_
labels	_	_
.	_	_

#84
In	_	_
order	_	_
to	_	_
account	_	_
for	_	_
this	_	_
,	_	_
we	_	_
perform	_	_
a	_	_
cross-validation-based	_	_
evaluation	_	_
,	_	_
repeating	_	_
the	_	_
procedure	_	_
five	_	_
times	_	_
and	_	_
reporting	_	_
the	_	_
mean	_	_
and	_	_
standard	_	_
deviation	_	_
across	_	_
these	_	_
runs	_	_
considering	_	_
a	_	_
80/20	_	_
train/test	_	_
split	_	_
.	_	_

#85
To	_	_
improve	_	_
accuracy	_	_
,	_	_
bounding	_	_
boxes	_	_
containing	_	_
less	_	_
than	_	_
750	_	_
pixels	_	_
were	_	_
removed	_	_
from	_	_
the	_	_
data	_	_
set	_	_
.	_	_

#86
We	_	_
consider	_	_
two	_	_
performance	_	_
metrics	_	_
,	_	_
accuracy	_	_
and	_	_
Intersection	_	_
Over	_	_
Union	_	_
(	_	_
IOU	_	_
)	_	_
.	_	_

#87
Accuracy	_	_
represents	_	_
the	_	_
percentage	_	_
of	_	_
correctly	_	_
classified	_	_
species	_	_
.	_	_

#88
IOU	_	_
is	_	_
an	_	_
evaluation	_	_
metric	_	_
specific	_	_
to	_	_
the	_	_
performance	_	_
of	_	_
object	_	_
detection	_	_
methods	_	_
.	_	_

#89
IOU	_	_
returns	_	_
performance	_	_
as	_	_
the	_	_
area	_	_
of	_	_
overlap	_	_
of	_	_
the	_	_
true	_	_
and	_	_
predicted	_	_
regions	_	_
divided	_	_
by	_	_
the	_	_
entire	_	_
area	_	_
of	_	_
the	_	_
true	_	_
and	_	_
predicted	_	_
regions	_	_
[	_	_
31	_	_
]	_	_
.	_	_

#90
To	_	_
quantify	_	_
accuracy	_	_
using	_	_
object	_	_
detection	_	_
,	_	_
numerous	_	_
classification	_	_
comparisons	_	_
are	_	_
calculated	_	_
per	_	_
image	_	_
.	_	_

#91
To	_	_
do	_	_
this	_	_
,	_	_
we	_	_
calculate	_	_
the	_	_
IOU	_	_
for	_	_
each	_	_
predicted	_	_
box	_	_
for	_	_
an	_	_
image	_	_
in	_	_
comparison	_	_
to	_	_
a	_	_
test	_	_
box	_	_
,	_	_
select	_	_
the	_	_
highest	_	_
IOU	_	_
,	_	_
and	_	_
then	_	_
compare	_	_
its	_	_
classification	_	_
output	_	_
to	_	_
the	_	_
true	_	_
classification	_	_
.	_	_

#92
After	_	_
bounding	_	_
boxes	_	_
are	_	_
used	_	_
for	_	_
a	_	_
classification	_	_
,	_	_
they	_	_
are	_	_
removed	_	_
for	_	_
future	_	_
comparisons	_	_
.	_	_

#93
IOU	_	_
values	_	_
above	_	_
0.70	_	_
are	_	_
considered	_	_
well	_	_
performing	_	_
[	_	_
31	_	_
]	_	_
.	_	_

#94
Faster	_	_
R-CNN	_	_
returned	_	_
an	_	_
accuracy	_	_
of	_	_
93.0	_	_
%	_	_
and	_	_
76.7	_	_
%	_	_
,	_	_
and	_	_
IOU	_	_
values	_	_
of	_	_
0.804	_	_
and	_	_
0.722	_	_
on	_	_
the	_	_
RCT	_	_
data	_	_
set	_	_
and	_	_
GSSS	_	_
data	_	_
set	_	_
,	_	_
while	_	_
YOLO	_	_
returned	_	_
an	_	_
accuracy	_	_
of	_	_
73.0	_	_
%	_	_
and	_	_
40.3	_	_
%	_	_
and	_	_
IOU	_	_
of	_	_
0.570	_	_
and	_	_
0.221	_	_
,	_	_
respectively	_	_
(	_	_
Table	_	_
1	_	_
)	_	_
.	_	_

#95
Faster	_	_
R-CNN	_	_
returned	_	_
an	_	_
accuracy	_	_
of	_	_
100	_	_
%	_	_
on	_	_
13	_	_
of	_	_
the	_	_
18	_	_
species	_	_
considered	_	_
in	_	_
the	_	_
RCT	_	_
data	_	_
set	_	_
,	_	_
and	_	_
80	_	_
%	_	_
accuracy	_	_
on	_	_
5	_	_
of	_	_
the	_	_
11	_	_
species	_	_
considering	_	_
species	_	_
with	_	_
more	_	_
than	_	_
100	_	_
images	_	_
in	_	_
the	_	_
GSSS	_	_
data	_	_
set	_	_
(	_	_
Table	_	_
2	_	_
&	_	_
3	_	_
)	_	_
.	_	_

#96
Figures	_	_
1-3	_	_
and	_	_
4-6	_	_
are	_	_
examples	_	_
of	_	_
the	_	_
Faster	_	_
R-CNN	_	_
performance	_	_
for	_	_
the	_	_
RCT	_	_
and	_	_
GSSS	_	_
data	_	_
set	_	_
respectively	_	_
.	_	_

#97
TABLE	_	_
I	_	_
COMPARISON	_	_
OF	_	_
FASTER	_	_
R-CNN	_	_
AND	_	_
YOLO	_	_
PERFORMANCE	_	_
BASED	_	_
ON	_	_
ACCURACY	_	_
AND	_	_
IOU	_	_
Data	_	_
Set	_	_
Model	_	_
Acc	_	_
.	_	_

#98
(	_	_
%	_	_
)	_	_
IOU	_	_
RCT	_	_
Faster	_	_
R-CNN	_	_
93.0	_	_
±	_	_
3.20	_	_
0.80	_	_
±	_	_
0.03	_	_
YOLO	_	_
65.0	_	_
±	_	_
12.1	_	_
0.57	_	_
±	_	_
0.09	_	_
GSSS	_	_
Faster	_	_
R-CNN	_	_
76.7	_	_
±	_	_
8.31	_	_
0.72	_	_
±	_	_
0.08	_	_
YOLO	_	_
43.3	_	_
±	_	_
14.5	_	_
0.22	_	_
±	_	_
0.12	_	_
IV	_	_
.	_	_

#99
DISCUSSION	_	_
By	_	_
utilizing	_	_
modern	_	_
approaches	_	_
for	_	_
object-detection	_	_
,	_	_
we	_	_
demonstrate	_	_
that	_	_
researchers	_	_
that	_	_
require	_	_
the	_	_
analysis	_	_
of	_	_
camera	_	_
trap	_	_
images	_	_
can	_	_
automate	_	_
animal	_	_
identification	_	_
,	_	_
quantification	_	_
,	_	_
and	_	_
localization	_	_
within	_	_
images	_	_
.	_	_

#100
Previous	_	_
studies	_	_
have	_	_
demonstrated	_	_
the	_	_
quantification	_	_
of	_	_
animal	_	_
individuals	_	_
from	_	_
camera	_	_
trap	_	_
data	_	_
,	_	_
but	_	_
they	_	_
suffer	_	_
the	_	_
limitation	_	_
of	_	_
returning	_	_
a	_	_
single	_	_
classification	_	_
per	_	_
image	_	_
,	_	_
which	_	_
is	_	_
unrealistic	_	_
for	_	_
camera	_	_
trap	_	_
data	_	_
.	_	_

#101
We	_	_
demonstrate	_	_
that	_	_
Faster	_	_
R-CNN	_	_
is	_	_
capable	_	_
of	_	_
accurately	_	_
classifying	_	_
more	_	_
than	_	_
one	_	_
species	_	_
per	_	_
image	_	_
given	_	_
limited	_	_
data	_	_
when	_	_
utilizing	_	_
transfer	_	_
learning	_	_
.	_	_

#102
Deep	_	_
learning	_	_
has	_	_
demonstrated	_	_
super-human	_	_
performance	_	_
on	_	_
tasks	_	_
with	_	_
large	_	_
amounts	_	_
of	_	_
data	_	_
;	_	_
however	_	_
we	_	_
test	_	_
the	_	_
reliability	_	_
of	_	_
deep	_	_
learning	_	_
methods	_	_
on	_	_
realistically	_	_
sized	_	_
ecological	_	_
camera	_	_
trap	_	_
data	_	_
sets	_	_
.	_	_

#103
Without	_	_
this	_	_
distinction	_	_
,	_	_
deep	_	_
learning	_	_
approaches	_	_
for	_	_
autonomous	_	_
camera	_	_
trap	_	_
data	_	_
analysis	_	_
would	_	_
be	_	_
limited	_	_
to	_	_
ecosystems	_	_
with	_	_
large	_	_
numbers	_	_
of	_	_
labeled	_	_
camera	_	_
trap	_	_
data	_	_
,	_	_
like	_	_
Snapshot	_	_
Serengeti	_	_
,	_	_
which	_	_
required	_	_
the	_	_
effort	_	_
of	_	_
thousands	_	_
of	_	_
individuals	_	_
to	_	_
label	_	_
.	_	_

#104
We	_	_
demonstrate	_	_
that	_	_
if	_	_
a	_	_
research	_	_
group	_	_
performs	_	_
a	_	_
one-time	_	_
labeling	_	_
of	_	_
less	_	_
than	_	_
1,000	_	_
images	_	_
,	_	_
one	_	_
can	_	_
create	_	_
a	_	_
reliable	_	_
model	_	_
using	_	_
Faster	_	_
R-CNN	_	_
.	_	_

#105
Our	_	_
YOLO	_	_
model	_	_
performed	_	_
poorly	_	_
on	_	_
both	_	_
data	_	_
sets	_	_
,	_	_
likely	_	_
due	_	_
to	_	_
limited	_	_
data	_	_
.	_	_

#106
While	_	_
the	_	_
GSSS	_	_
data	_	_
set	_	_
contained	_	_
approximately	_	_
4x	_	_
the	_	_
number	_	_
of	_	_
images	_	_
,	_	_
the	_	_
trained	_	_
model	_	_
for	_	_
the	_	_
data	_	_
set	_	_
performed	_	_
worse	_	_
than	_	_
the	_	_
trained	_	_
model	_	_
for	_	_
the	_	_
RCT	_	_
data	_	_
set	_	_
using	_	_
Faster	_	_
R-CNN	_	_
.	_	_

#107
There	_	_
are	_	_
numerous	_	_
explanations	_	_
for	_	_
this	_	_
.	_	_

#108
First	_	_
,	_	_
the	_	_
GSSS	_	_
data	_	_
set	_	_
has	_	_
extreme	_	_
class	_	_
imbalances	_	_
,	_	_
a	_	_
well	_	_
documented	_	_
scenario	_	_
where	_	_
machine	_	_
learning	_	_
classifiers	_	_
have	_	_
had	_	_
difficulty	_	_
[	_	_
32	_	_
]	_	_
.	_	_

#109
In	_	_
addition	_	_
,	_	_
the	_	_
GSSS	_	_
data	_	_
set	_	_
is	_	_
much	_	_
‘messier’	_	_
than	_	_
the	_	_
RCT	_	_
data	_	_
set	_	_
,	_	_
with	_	_
the	_	_
majority	_	_
of	_	_
images	_	_
containing	_	_
animals	_	_
either	_	_
extremely	_	_
far	_	_
away	_	_
,	_	_
cropped	_	_
by	_	_
the	_	_
camera	_	_
,	_	_
obstructed	_	_
behind	_	_
another	_	_
object/animal	_	_
,	_	_
and/or	_	_
extremely	_	_
close	_	_
to	_	_
the	_	_
camera	_	_
.	_	_

#110
While	_	_
the	_	_
RCT	_	_
data	_	_
set	_	_
does	_	_
contain	_	_
some	_	_
of	_	_
these	_	_
difficult	_	_
scenarios	_	_
,	_	_
there	_	_
are	_	_
far	_	_
fewer	_	_
occurrences	_	_
.	_	_

#111
When	_	_
implementing	_	_
models	_	_
such	_	_
as	_	_
these	_	_
,	_	_
our	_	_
results	_	_
reiterate	_	_
the	_	_
importance	_	_
of	_	_
class	_	_
balance	_	_
.	_	_

#112
For	_	_
real-life	_	_
applications	_	_
,	_	_
if	_	_
an	_	_
animal	_	_
of	_	_
interest	_	_
rarely	_	_
appears	_	_
in	_	_
the	_	_
camera	_	_
trap	_	_
data	_	_
,	_	_
we	_	_
recommend	_	_
finding	_	_
and	_	_
labeling	_	_
additional	_	_
images	_	_
from	_	_
outside	_	_
sources	_	_
to	_	_
build	_	_
a	_	_
balanced	_	_
data	_	_
set	_	_
,	_	_
or	_	_
exploring	_	_
additional	_	_
techniques	_	_
for	_	_
class	_	_
imbalance	_	_
.	_	_

#113
Considering	_	_
the	_	_
success	_	_
of	_	_
the	_	_
Faster	_	_
R-CNN	_	_
model	_	_
,	_	_
our	_	_
method	_	_
allows	_	_
for	_	_
future	_	_
possibilities	_	_
regarding	_	_
detailed	_	_
individual	_	_
and	_	_
behaviour	_	_
analysis	_	_
from	_	_
camera	_	_
trap	_	_
images	_	_
.	_	_

#114
Norouzzadeh	_	_
et	_	_
al.	_	_
(	_	_
2017	_	_
)	_	_
demonstrated	_	_
this	_	_
in	_	_
its	_	_
infancy	_	_
by	_	_
returning	_	_
labeled	_	_
classifications	_	_
of	_	_
young	_	_
versus	_	_
adult	_	_
and	_	_
male	_	_
versus	_	_
female	_	_
classifications	_	_
,	_	_
and	_	_
the	_	_
specific	_	_
behaviour	_	_
found	_	_
within	_	_
the	_	_
image	_	_
[	_	_
5	_	_
]	_	_
.	_	_

#115
This	_	_
approach	_	_
is	_	_
not	_	_
reliable	_	_
,	_	_
as	_	_
if	_	_
more	_	_
then	_	_
one	_	_
species	_	_
,	_	_
age	_	_
,	_	_
sex	_	_
,	_	_
or	_	_
behaviour	_	_
are	_	_
present	_	_
,	_	_
the	_	_
classifier	_	_
returns	_	_
erroneous	_	_
results	_	_
.	_	_

#116
Object	_	_
detection	_	_
methods	_	_
allow	_	_
for	_	_
the	_	_
classifier	_	_
to	_	_
identify	_	_
an	_	_
age	_	_
,	_	_
sex	_	_
,	_	_
and	_	_
behaviour	_	_
of	_	_
each	_	_
individual	_	_
within	_	_
the	_	_
image	_	_
.	_	_

#117
Using	_	_
this	_	_
method	_	_
of	_	_
data	_	_
collection	_	_
,	_	_
examples	_	_
of	_	_
autonomous	_	_
ecological	_	_
reports	_	_
based	_	_
on	_	_
images	_	_
with	_	_
time-stamps	_	_
include	_	_
:	_	_
comparing	_	_
the	_	_
movement	_	_
patterns	_	_
of	_	_
genders	_	_
within	_	_
and	_	_
across	_	_
species	_	_
,	_	_
identifying	_	_
seasonally	_	_
when	_	_
reproduction	_	_
occurs	_	_
by	_	_
quantifying	_	_
when	_	_
infants	_	_
are	_	_
most	_	_
active	_	_
,	_	_
and	_	_
general	_	_
comparisons	_	_
of	_	_
activity/behaviour	_	_
across	_	_
species	_	_
,	_	_
sex	_	_
,	_	_
and	_	_
age	_	_
.	_	_

#118
While	_	_
object	_	_
detection	_	_
provides	_	_
promising	_	_
steps	_	_
forward	_	_
,	_	_
in	_	_
order	_	_
to	_	_
reliably	_	_
quantify	_	_
population	_	_
metrics	_	_
,	_	_
an	_	_
automated	_	_
system	_	_
must	deontic	_
be	_	_
able	_	_
to	_	_
re-identify	_	_
an	_	_
individual	_	_
it	_	_
has	_	_
previously	_	_
seen	_	_
.	_	_

#119
Camera	_	_
trap	_	_
re-identification	_	_
methods	_	_
suffer	_	_
from	_	_
an	_	_
unavoidable	_	_
bias	_	_
when	_	_
analyzed	_	_
by	_	_
a	_	_
human	_	_
and	_	_
there	_	_
is	_	_
debate	_	_
arguing	_	_
against	_	_
the	_	_
reliability	_	_
of	_	_
humans	_	_
when	_	_
re-identifying	_	_
animal	_	_
individuals	_	_
from	_	_
camera	_	_
trap	_	_
data	_	_
[	_	_
33	_	_
]	_	_
.	_	_

#120
The	_	_
development	_	_
of	_	_
a	_	_
method	_	_
for	_	_
reliable	_	_
animal	_	_
re-identification	_	_
would	_	_
allow	_	_
for	_	_
autonomous	_	_
population	_	_
estimation	_	_
of	_	_
a	_	_
given	_	_
habitat	_	_
using	_	_
a	_	_
formal	_	_
mark	_	_
and	_	_
recapture	_	_
model	_	_
,	_	_
such	_	_
as	_	_
Lincoln-Petersen	_	_
[	_	_
34	_	_
]	_	_
.	_	_

#121
Population	_	_
estimates	_	_
are	_	_
reliant	_	_
on	_	_
accurate	_	_
animal	_	_
identification	_	_
and	_	_
if	_	_
a	_	_
deep	_	_
learning	_	_
system	_	_
can	_	_
demonstrate	_	_
accurate	_	_
animal	_	_
re-identification	_	_
,	_	_
one	_	_
could	_	_
<	_	_
capability-feasibility-uncertainty	_	_
>	_	_
utilize	_	_
these	_	_
methodologies	_	_
to	_	_
create	_	_
autonomous	_	_
systems	_	_
to	_	_
extract	_	_
a	_	_
variety	_	_
of	_	_
ecological	_	_
metrics	_	_
,	_	_
such	_	_
as	_	_
diversity	_	_
,	_	_
relative	_	_
abundance	_	_
distribution	_	_
,	_	_
and	_	_
carrying	_	_
capacity	_	_
,	_	_
contributing	_	_
to	_	_
larger	_	_
overarching	_	_
ecological	_	_
interpretations	_	_
of	_	_
trophic	_	_
interactions	_	_
and	_	_
population	_	_
dynamics	_	_
.	_	_

#122
V.	_	_
CONCLUSION	_	_

#123
Recent	_	_
advancements	_	_
in	_	_
the	_	_
field	_	_
of	_	_
computer	_	_
vision	_	_
and	_	_
deep	_	_
learning	_	_
have	_	_
given	_	_
rise	_	_
to	_	_
reliable	_	_
methods	_	_
of	_	_
object	_	_
detection	_	_
.	_	_

#124
We	_	_
demonstrated	_	_
the	_	_
successful	_	_
training	_	_
of	_	_
an	_	_
object	_	_
detection	_	_
classifier	_	_
using	_	_
the	_	_
Faster	_	_
R-CNN	_	_
model	_	_
considering	_	_
limited	_	_
ecological	_	_
camera	_	_
trap	_	_
data	_	_
.	_	_

#125
Utilizing	_	_
object	_	_
detection	_	_
techniques	_	_
,	_	_
ecologists	_	_
can	_	_
now	_	_
autonomously	_	_
identify	_	_
,	_	_
quantify	_	_
,	_	_
and	_	_
localize	_	_
individual	_	_
species	_	_
within	_	_
camera	_	_
trap	_	_
data	_	_
without	_	_
the	_	_
previous	_	_
limitation	_	_
of	_	_
returning	_	_
only	_	_
one	_	_
species	_	_
classification	_	_
per	_	_
image	_	_
.	_	_

#126
Our	_	_
findings	_	_
show	_	_
promising	_	_
steps	_	_
towards	_	_
the	_	_
automation	_	_
of	_	_
the	_	_
labourious	_	_
task	_	_
of	_	_
labeling	_	_
camera	_	_
trap	_	_
images	_	_
which	_	_
can	_	_
be	_	_
used	_	_
to	_	_
improve	_	_
our	_	_
understanding	_	_
of	_	_
the	_	_
population	_	_
dynamics	_	_
of	_	_
ecosystems	_	_
across	_	_
the	_	_
planet	_	_
.	_	_

#127
ACKNOWLEDGMENTS	_	_
The	_	_
authors	_	_
would	_	_
like	_	_
to	_	_
thank	_	_
all	_	_
the	_	_
Snapshot	_	_
Serengeti	_	_
volunteers	_	_
and	_	_
the	_	_
camera	_	_
trap	_	_
community	_	_
at	_	_
large	_	_
for	_	_
uploading	_	_
their	_	_
data	_	_
for	_	_
public	_	_
access	_	_
.	_	_

#128
We	_	_
also	_	_
thank	_	_
the	_	_
deep	_	_
learning	_	_
community	_	_
at	_	_
large	_	_
for	_	_
their	_	_
continued	_	_
pursuit	_	_
of	_	_
open	_	_
sourcing	_	_
new	_	_
methodologies	_	_
encouraging	_	_
interdisciplinary	_	_
works	_	_
.	_	_