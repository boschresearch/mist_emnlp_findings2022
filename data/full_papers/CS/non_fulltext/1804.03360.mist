#0
Reference-Conditioned	_	_
Super-Resolution	_	_
by	_	_
Neural	_	_
Texture	_	_
Transfer	_	_
Zhifei	_	_
Zhang1	_	_
,	_	_
Zhaowen	_	_
Wang2	_	_
,	_	_
Zhe	_	_
Lin2	_	_
,	_	_
and	_	_
Hairong	_	_
Qi1	_	_

#1
1	_	_
Department	_	_
of	_	_
Electrical	_	_
Engineering	_	_
and	_	_
Computer	_	_
Science	_	_
,	_	_

#2
University	_	_
of	_	_
Tennessee	_	_
,	_	_
Knoxville	_	_
.	_	_

#3
{	_	_
zzhang61	_	_
,	_	_
hqi	_	_
}	_	_
@	_	_
utk.edu	_	_
2	_	_
Adobe	_	_
Research	_	_
.	_	_

#4
{	_	_
zhawang	_	_
,	_	_
zlin	_	_
}	_	_
@	_	_
adobe.com	_	_
Abstract	_	_
.	_	_

#5
With	_	_
the	_	_
recent	_	_
advancement	_	_
in	_	_
deep	_	_
learning	_	_
,	_	_
we	_	_
have	_	_
witnessed	_	_
a	_	_
great	_	_
progress	_	_
in	_	_
single	_	_
image	_	_
super-resolution	_	_
.	_	_

#6
However	_	_
,	_	_
due	_	_
to	_	_
the	_	_
significant	_	_
information	_	_
loss	_	_
of	_	_
the	_	_
image	_	_
downscaling	_	_
process	_	_
,	_	_
it	_	_
has	_	_
become	_	_
extremely	_	_
challenging	_	_
to	_	_
further	_	_
advance	_	_
the	_	_
stateoftheart	_	_
,	_	_
especially	_	_
for	_	_
large	_	_
upscaling	_	_
factors	_	_
.	_	_

#7
This	_	_
paper	_	_
explores	_	_
a	_	_
new	_	_
research	_	_
direction	_	_
in	_	_
super	_	_
resolution	_	_
,	_	_
called	_	_
reference-conditioned	_	_
superresolution	_	_
,	_	_
in	_	_
which	_	_
a	_	_
reference	_	_
image	_	_
containing	_	_
desired	_	_
high-resolution	_	_
texture	_	_
details	_	_
is	_	_
provided	_	_
besides	_	_
the	_	_
low-resolution	_	_
image	_	_
.	_	_

#8
We	_	_
focus	_	_
on	_	_
transferring	_	_
the	_	_
high-resolution	_	_
texture	_	_
from	_	_
reference	_	_
images	_	_
to	_	_
the	_	_
super-resolution	_	_
process	_	_
without	_	_
the	_	_
constraint	_	_
of	_	_
content	_	_
similarity	_	_
between	_	_
reference	_	_
and	_	_
target	_	_
images	_	_
,	_	_
which	_	_
is	_	_
a	_	_
key	_	_
difference	_	_
from	_	_
previous	_	_
example-based	_	_
methods	_	_
.	_	_

#9
Inspired	_	_
by	_	_
recent	_	_
work	_	_
on	_	_
image	_	_
stylization	_	_
,	_	_
we	_	_
address	_	_
the	_	_
problem	_	_
via	_	_
neural	_	_
texture	_	_
transfer	_	_
.	_	_

#10
We	_	_
design	_	_
an	_	_
end-to-end	_	_
trainable	_	_
deep	_	_
model	_	_
which	_	_
generates	_	_
detail	_	_
enriched	_	_
results	_	_
by	_	_
adaptively	_	_
fusing	_	_
the	_	_
content	_	_
from	_	_
the	_	_
low-resolution	_	_
image	_	_
with	_	_
the	_	_
texture	_	_
patterns	_	_
from	_	_
the	_	_
reference	_	_
image	_	_
.	_	_

#11
We	_	_
create	_	_
a	_	_
benchmark	_	_
dataset	_	_
for	_	_
the	_	_
general	_	_
research	_	_
of	_	_
reference-based	_	_
super-resolution	_	_
,	_	_
which	_	_
contains	_	_
reference	_	_
images	_	_
paired	_	_
with	_	_
low-resolution	_	_
inputs	_	_
with	_	_
varying	_	_
degrees	_	_
of	_	_
similarity	_	_
.	_	_

#12
Both	_	_
objective	_	_
and	_	_
subjective	_	_
evaluations	_	_
demonstrate	_	_
the	_	_
great	_	_
potential	_	_
of	_	_
using	_	_
reference	_	_
images	_	_
as	_	_
well	_	_
as	_	_
the	_	_
superiority	_	_
of	_	_
our	_	_
results	_	_
over	_	_
other	_	_
state-of-the-art	_	_
methods	_	_
.	_	_

#13
Keywords	_	_
:	_	_
Super-resolution	_	_
,	_	_
reference-conditioned	_	_
,	_	_
texture	_	_
transfer	_	_

#14
1	_	_
Introduction	_	_

#15
The	_	_
traditional	_	_
single	_	_
image	_	_
super-resolution	_	_
(	_	_
SR	_	_
)	_	_
problem	_	_
is	_	_
defined	_	_
as	_	_
recovering	_	_
a	_	_
high-resolution	_	_
(	_	_
HR	_	_
)	_	_
image	_	_
from	_	_
its	_	_
low-resolution	_	_
(	_	_
LR	_	_
)	_	_
observation	_	_
[	_	_
32	_	_
]	_	_
,	_	_
which	_	_
has	_	_
received	_	_
substantial	_	_
attention	_	_
in	_	_
the	_	_
computer	_	_
vision	_	_
community	_	_
.	_	_

#16
As	_	_
in	_	_
other	_	_
fields	_	_
of	_	_
computer	_	_
vision	_	_
studies	_	_
,	_	_
the	_	_
introduction	_	_
of	_	_
convolutional	_	_
neural	_	_
networks	_	_
(	_	_
CNNs	_	_
)	_	_
[	_	_
5,31,18,21	_	_
]	_	_
has	_	_
greatly	_	_
advanced	_	_
the	_	_
state-of-the-art	_	_
performance	_	_
of	_	_
SR	_	_
.	_	_

#17
However	_	_
,	_	_
due	_	_
to	_	_
the	_	_
ill-posed	_	_
nature	_	_
of	_	_
SR	_	_
problems	_	_
,	_	_
most	_	_
existing	_	_
methods	_	_
still	_	_
suffer	_	_
from	_	_
blurry	_	_
results	_	_
at	_	_
large	_	_
upscaling	_	_
factors	_	_
,	_	_
e.g.	_	_
,	_	_
4×	_	_
,	_	_
especially	_	_
when	_	_
it	_	_
comes	_	_
down	_	_
to	_	_
the	_	_
recovery	_	_
of	_	_
fine	_	_
texture	_	_
details	_	_
in	_	_
Code	_	_
:	_	_
http	_	_
:	_	_
//web.eecs.utk.edu/~zzhang61/project_page/SRNTT/SRNTT.html	_	_
ar	_	_
X	_	_
iv	_	_
:1	_	_
4	_	_
.	_	_

#18
0v	_	_
1	_	_
[	_	_
cs	_	_
.C	_	_
V	_	_
]	_	_
1	_	_
0	_	_
A	_	_
pr	_	_
2	_	_

#19
2	_	_
Zhifei	_	_
Zhang	_	_
,	_	_
Zhaowen	_	_
Wang	_	_
,	_	_
Zhe	_	_
Lin	_	_
,	_	_
and	_	_
Hairong	_	_
Qi	_	_

#20
Bicubic	_	_
SRCNN	_	_
SRGAN	_	_
SRNTT	_	_
Reference	_	_
Fig.	_	_
1	_	_
:	_	_
From	_	_
left	_	_
to	_	_
right	_	_
:	_	_
bicubic	_	_
interpolation	_	_
,	_	_
SRCNN	_	_
that	_	_
minimizes	_	_
MSR	_	_
,	_	_
SRGAN	_	_
that	_	_
further	_	_
incorporates	_	_
perceptual-related	_	_
constraints	_	_
,	_	_
the	_	_
proposed	_	_
SRNTT	_	_
conditioned	_	_
on	_	_
the	_	_
reference	_	_
shown	_	_
in	_	_
the	_	_
upper-right	_	_
corner	_	_
,	_	_
and	_	_
the	_	_
reference	_	_
image	_	_
for	_	_
SRNTT	_	_
.	_	_

#21
The	_	_
upscaling	_	_
factor	_	_
is	_	_
4×	_	_
.	_	_

#22
the	_	_
original	_	_
HR	_	_
image	_	_
which	_	_
are	_	_
lost	_	_
in	_	_
the	_	_
LR	_	_
counterpart	_	_
.	_	_

#23
In	_	_
recent	_	_
years	_	_
,	_	_
perceptual-related	_	_
constraints	_	_
,	_	_
e.g.	_	_
,	_	_
perception	_	_
loss	_	_
[	_	_
16	_	_
]	_	_
and	_	_
adversarial	_	_
loss	_	_
[	_	_
12	_	_
]	_	_
,	_	_
have	_	_
been	_	_
introduced	_	_
to	_	_
the	_	_
SR	_	_
problem	_	_
formulation	_	_
,	_	_
leading	_	_
to	_	_
major	_	_
breakthroughs	_	_
on	_	_
visual	_	_
quality	_	_
under	_	_
large	_	_
upscaling	_	_
factors	_	_
[	_	_
20,26	_	_
]	_	_
.	_	_

#24
However	_	_
,	_	_
they	_	_
tend	_	_
to	_	_
add	_	_
fake	_	_
textures	_	_
and	_	_
even	_	_
artifacts	_	_
to	_	_
make	_	_
the	_	_
SR	_	_
image	_	_
of	_	_
visually	_	_
higher-resolution	_	_
.	_	_

#25
This	_	_
paper	_	_
diverts	_	_
from	_	_
the	_	_
traditional	_	_
SR	_	_
and	_	_
explores	_	_
a	_	_
new	_	_
research	_	_
direction	_	_
—	_	_
reference-conditioned	_	_
super-resolution	_	_
,	_	_
which	_	_
utilizes	_	_
the	_	_
rich	_	_
textures	_	_
from	_	_
HR	_	_
references	_	_
to	_	_
compensate	_	_
for	_	_
the	_	_
lost	_	_
details	_	_
in	_	_
the	_	_
LR	_	_
images	_	_
,	_	_
relaxing	_	_
the	_	_
ill-posed	_	_
issue	_	_
and	_	_
producing	_	_
more	_	_
detailed	_	_
and	_	_
realistic	_	_
textures	_	_
with	_	_
the	_	_
help	_	_
of	_	_
reference	_	_
images	_	_
.	_	_

#26
The	_	_
reference	_	_
images	_	_
may	_	_
come	_	_
from	_	_
photo	_	_
albums	_	_
,	_	_
video	_	_
frames	_	_
,	_	_
or	_	_
web	_	_
image	_	_
search	_	_
.	_	_

#27
There	_	_
are	_	_
existing	_	_
example-based	_	_
SR	_	_
approaches	_	_
[	_	_
9,3,8,33,29,23	_	_
]	_	_
that	_	_
adopted	_	_
external	_	_
high-frequency	_	_
information	_	_
to	_	_
enhance	_	_
textures	_	_
.	_	_

#28
However	_	_
,	_	_
they	_	_
assume	_	_
the	_	_
reference	_	_
images	_	_
could	_	_
be	_	_
well	_	_
aligned	_	_
or	_	_
present	_	_
similar	_	_
texture	_	_
to	_	_
the	_	_
LR	_	_
images	_	_
.	_	_

#29
By	_	_
contrast	_	_
,	_	_
the	_	_
reference	_	_
image	_	_
plays	_	_
a	_	_
different	_	_
role	_	_
in	_	_
our	_	_
setting	_	_
:	_	_
it	_	_
does	_	_
not	_	_
need	_	_
to	_	_
have	_	_
similar	_	_
content	_	_
with	_	_
target	_	_
HR	_	_
image	_	_
.	_	_

#30
Instead	_	_
,	_	_
we	_	_
only	_	_
intend	_	_
to	_	_
transfer	_	_
the	_	_
relevant	_	_
texture	_	_
from	_	_
reference	_	_
image	_	_
to	_	_
target	_	_
image	_	_
.	_	_

#31
Inspired	_	_
by	_	_
recent	_	_
work	_	_
on	_	_
image	_	_
stylization	_	_
[	_	_
11,16,4	_	_
]	_	_
,	_	_
we	_	_
propose	_	_
the	_	_
Super-Resolution	_	_
by	_	_
Neural	_	_
Texture	_	_
Transfer	_	_
(	_	_
SRNTT	_	_
)	_	_
,	_	_
which	_	_
adaptively	_	_
transfers	_	_
textures	_	_
to	_	_
the	_	_
SR	_	_
image	_	_
conditioned	_	_
on	_	_
the	_	_
reference	_	_
image	_	_
.	_	_

#32
More	_	_
specifically	_	_
,	_	_
SRNTT	_	_
conducts	_	_
local	_	_
texture	_	_
matching	_	_
in	_	_
the	_	_
high-level	_	_
feature	_	_
space	_	_
and	_	_
adaptively	_	_
fuses	_	_
matched	_	_
textures	_	_
with	_	_
a	_	_
deep	_	_
model	_	_
.	_	_

#33
Fig.	_	_
1	_	_
illustrates	_	_
the	_	_
advantage	_	_
of	_	_
the	_	_
proposed	_	_
SRNTT	_	_
compared	_	_
with	_	_
two	_	_
representative	_	_
works	_	_
,	_	_
SRCNN	_	_
[	_	_
5,6	_	_
]	_	_
and	_	_
SRGAN	_	_
[	_	_
20	_	_
]	_	_
,	_	_
which	_	_
are	_	_
without	_	_
and	_	_
with	_	_
perceptual-related	_	_
constraints	_	_
,	_	_
respectively	_	_
.	_	_

#34
SRNTT	_	_
shows	_	_
improved	_	_
texture	_	_
transferred	_	_
from	_	_
the	_	_
reference	_	_
.	_	_

#35
Note	_	_
that	_	_
the	_	_
texture	_	_
in	_	_
reference	_	_
does	_	_
not	_	_
have	_	_
to	_	_
match	_	_
the	_	_
one	_	_
in	_	_
HR	_	_
ground	_	_
truth	_	_
.	_	_

#36
We	_	_
emphasize	_	_
the	_	_
capacity	_	_
of	_	_
SRNTT	_	_
in	_	_
handling	_	_
arbitrary	_	_
reference	_	_
images	_	_
.	_	_

#37
For	_	_
example	_	_
,	_	_
as	_	_
shown	_	_
in	_	_
Fig.	_	_
9	_	_
with	_	_
the	_	_
extreme	_	_
case	_	_
of	_	_
the	_	_
Reference-Conditioned	_	_
Super-Resolution	_	_
by	_	_
Neural	_	_
Texture	_	_
Transfer	_	_
3	_	_
reference	_	_
image	_	_
being	_	_
simply	_	_
random	_	_
noise	_	_
,	_	_
the	_	_
proposed	_	_
SRNTT	_	_
is	_	_
still	_	_
able	_	_
to	_	_
generate	_	_
the	_	_
SR	_	_
image	_	_
with	_	_
comparable	_	_
visual	_	_
quality	_	_
as	_	_
that	_	_
from	_	_
SRGAN	_	_
.	_	_

#38
That	_	_
being	_	_
said	_	_
,	_	_
similarity	_	_
between	_	_
the	_	_
reference	_	_
and	_	_
LR	_	_
image	_	_
is	_	_
still	_	_
the	_	_
key	_	_
factor	_	_
that	_	_
affects	_	_
the	_	_
performance	_	_
of	_	_
reference-conditioned	_	_
SR	_	_
.	_	_

#39
However	_	_
,	_	_
there	_	_
is	_	_
no	_	_
existing	_	_
benchmark	_	_
dataset	_	_
that	_	_
could	_	_
provide	_	_
different	_	_
similarity	_	_
levels	_	_
of	_	_
references	_	_
for	_	_
the	_	_
investigation	_	_
of	_	_
adaptiveness	_	_
and	_	_
robustness	_	_
.	_	_

#40
To	_	_
facilitate	_	_
fair	_	_
comparison	_	_
and	_	_
further	_	_
research	_	_
on	_	_
the	_	_
reference-conditioned	_	_
SR	_	_
problem	_	_
,	_	_
we	_	_
propose	_	_
a	_	_
new	_	_
dataset	_	_
,	_	_
named	_	_
CUFED5	_	_
,	_	_
which	_	_
provides	_	_
training	_	_
and	_	_
testing	_	_
sets	_	_
accompanied	_	_
with	_	_
references	_	_
of	_	_
five	_	_
similarity	_	_
levels	_	_
that	_	_
vary	_	_
in	_	_
content	_	_
,	_	_
texture	_	_
,	_	_
color	_	_
,	_	_
illumination	_	_
,	_	_
and	_	_
view	_	_
point	_	_
.	_	_

#41
For	_	_
example	_	_
,	_	_
as	_	_
shown	_	_
in	_	_
Fig.	_	_
5	_	_
,	_	_
the	_	_
least	_	_
similar	_	_
reference	_	_
for	_	_
an	_	_
image	_	_
of	_	_
a	_	_
building	_	_
could	_	_
be	_	_
a	_	_
person	_	_
.	_	_

#42
The	_	_
main	_	_
contributions	_	_
of	_	_
this	_	_
paper	_	_
are	_	_
:	_	_
–	_	_
We	_	_
explore	_	_
a	_	_
new	_	_
research	_	_
direction	_	_
of	_	_
SR	_	_
,	_	_
i.e.	_	_
,	_	_
reference-conditioned	_	_
superresolution	_	_
,	_	_
as	_	_
opposed	_	_
to	_	_
SISR	_	_
which	_	_
only	_	_
relies	_	_
on	_	_
the	_	_
LR	_	_
input	_	_
image	_	_
,	_	_
and	_	_
example-based	_	_
SR	_	_
which	_	_
makes	_	_
rigid	_	_
assumptions	_	_
on	_	_
the	_	_
external	_	_
example	_	_
image	_	_
used	_	_
.	_	_

#43
Reference-conditioned	_	_
SR	_	_
aims	_	_
to	_	_
generate	_	_
HR	_	_
texture	_	_
information	_	_
for	_	_
LR	_	_
input	_	_
image	_	_
by	_	_
referring	_	_
to	_	_
an	_	_
arbitrary	_	_
external	_	_
image	_	_
,	_	_
and	_	_
thus	_	_
enables	_	_
the	_	_
generation	_	_
of	_	_
SR	_	_
images	_	_
with	_	_
plausible	_	_
texture	_	_
details	_	_
even	_	_
at	_	_
large	_	_
upscale	_	_
factor	_	_
,	_	_
further	_	_
advancing	_	_
the	_	_
state-of-the-art	_	_
in	_	_
SR	_	_
research	_	_
.	_	_

#44
–	_	_
We	_	_
propose	_	_
an	_	_
end-to-end	_	_
deep	_	_
model	_	_
,	_	_
SRNTT	_	_
,	_	_
to	_	_
recover	_	_
the	_	_
LR	_	_
image	_	_
conditioned	_	_
on	_	_
any	_	_
given	_	_
reference	_	_
.	_	_

#45
We	_	_
demonstrate	_	_
the	_	_
adaptiveness	_	_
,	_	_
effectiveness	_	_
,	_	_
and	_	_
visual	_	_
improvement	_	_
of	_	_
the	_	_
proposed	_	_
SRNTT	_	_
by	_	_
extensive	_	_
empirical	_	_
studies	_	_
.	_	_

#46
–	_	_
We	_	_
create	_	_
a	_	_
benchmark	_	_
dataset	_	_
,	_	_
CUFED5	_	_
,	_	_
to	_	_
facilitate	_	_
the	_	_
performance	_	_
evaluation	_	_
of	_	_
SR	_	_
methods	_	_
in	_	_
handling	_	_
references	_	_
with	_	_
different	_	_
levels	_	_
of	_	_
similarity	_	_
to	_	_
the	_	_
LR	_	_
input	_	_
image	_	_
.	_	_

#47
In	_	_
the	_	_
rest	_	_
of	_	_
this	_	_
paper	_	_
,	_	_
we	_	_
review	_	_
the	_	_
related	_	_
works	_	_
in	_	_
Section	_	_
2	_	_
.	_	_

#48
The	_	_
network	_	_
architecture	_	_
and	_	_
training	_	_
criteria	_	_
are	_	_
discussed	_	_
in	_	_
Section	_	_
3	_	_
.	_	_

#49
In	_	_
Section	_	_
4	_	_
,	_	_
the	_	_
proposed	_	_
dataset	_	_
CUFED5	_	_
is	_	_
described	_	_
in	_	_
detail	_	_
.	_	_

#50
The	_	_
results	_	_
of	_	_
quantitative	_	_
and	_	_
qualitative	_	_
evaluations	_	_
are	_	_
presented	_	_
in	_	_
Section	_	_
5	_	_
.	_	_

#51
Finally	_	_
,	_	_
Section	_	_
6	_	_
concludes	_	_
this	_	_
paper	_	_
.	_	_

#52
2	_	_
Related	_	_
Works	_	_

#53
2.1	_	_
Deep	_	_
learning	_	_
based	_	_
single	_	_
image	_	_
SR	_	_

#54
In	_	_
recent	_	_
years	_	_
,	_	_
deep	_	_
learning	_	_
based	_	_
SISR	_	_
has	_	_
shown	_	_
superior	_	_
performance	_	_
in	_	_
either	_	_
PSNR	_	_
or	_	_
visual	_	_
quality	_	_
compared	_	_
to	_	_
those	_	_
non-deep-learning	_	_
based	_	_
methods	_	_
[	_	_
5,31,20	_	_
]	_	_
.	_	_

#55
The	_	_
reader	_	_
could	_	_
refer	_	_
to	_	_
[	_	_
25,32	_	_
]	_	_
for	_	_
more	_	_
comprehensive	_	_
review	_	_
of	_	_
SR	_	_
.	_	_

#56
Here	_	_
we	_	_
only	_	_
cover	_	_
deep	_	_
learning	_	_
based	_	_
methods	_	_
.	_	_

#57
A	_	_
milestone	_	_
work	_	_
that	_	_
introduced	_	_
CNN	_	_
into	_	_
SR	_	_
was	_	_
proposed	_	_
by	_	_
Dong	_	_
et	_	_
al.	_	_
[	_	_
5	_	_
]	_	_
,	_	_
where	_	_
a	_	_
three-layer	_	_
fully	_	_
convolutional	_	_
network	_	_
was	_	_
trained	_	_
to	_	_
minimize	_	_
MSE	_	_
between	_	_
the	_	_
SR	_	_
image	_	_
and	_	_
original	_	_
HR	_	_
image	_	_
.	_	_

#58
It	_	_
demonstrated	_	_
the	_	_
effectiveness	_	_
of	_	_
deep	_	_
learning	_	_
in	_	_
SR	_	_
and	_	_
achieved	_	_
the	_	_
state-of-the-art	_	_
performance	_	_
.	_	_

#59
4	_	_
Zhifei	_	_
Zhang	_	_
,	_	_
Zhaowen	_	_
Wang	_	_
,	_	_
Zhe	_	_
Lin	_	_
,	_	_
and	_	_
Hairong	_	_
Qi	_	_

#60
Wang	_	_
et	_	_
al.	_	_
[	_	_
31	_	_
]	_	_
combined	_	_
the	_	_
strengths	_	_
of	_	_
sparse	_	_
coding	_	_
and	_	_
deep	_	_
network	_	_
and	_	_
made	_	_
considerable	_	_
improvement	_	_
over	_	_
previous	_	_
models	_	_
.	_	_

#61
To	_	_
speed	_	_
up	_	_
the	_	_
SR	_	_
process	_	_
,	_	_
Dong	_	_
et	_	_
al.	_	_
[	_	_
7	_	_
]	_	_
and	_	_
Shi	_	_
et	_	_
al.	_	_
[	_	_
27	_	_
]	_	_
extracted	_	_
features	_	_
directly	_	_
from	_	_
the	_	_
LR	_	_
image	_	_
,	_	_
that	_	_
also	_	_
achieved	_	_
better	_	_
performance	_	_
compared	_	_
to	_	_
processing	_	_
the	_	_
upscaled	_	_
LR	_	_
image	_	_
through	_	_
bicubic	_	_
.	_	_

#62
To	_	_
further	_	_
reduce	_	_
the	_	_
number	_	_
of	_	_
parameters	_	_
,	_	_
Lai	_	_
et	_	_
al.	_	_
[	_	_
19	_	_
]	_	_
progressively	_	_
reconstructed	_	_
the	_	_
sub-band	_	_
residuals	_	_
of	_	_
HR	_	_
images	_	_
at	_	_
multiple	_	_
pyramid	_	_
levels	_	_
.	_	_

#63
In	_	_
recent	_	_
two	_	_
years	_	_
,	_	_
the	_	_
state-of-the-art	_	_
performance	_	_
(	_	_
in	_	_
PSNR	_	_
)	_	_
were	_	_
all	_	_
achieved	_	_
by	_	_
deep	_	_
learning	_	_
based	_	_
models	_	_
[	_	_
18,17,21	_	_
]	_	_
.	_	_

#64
The	_	_
above	_	_
mentioned	_	_
methods	_	_
,	_	_
in	_	_
general	_	_
,	_	_
aim	_	_
at	_	_
minimizing	_	_
the	_	_
mean	_	_
squared	_	_
error	_	_
(	_	_
MSE	_	_
)	_	_
between	_	_
the	_	_
SR	_	_
and	_	_
HR	_	_
images	_	_
,	_	_
which	_	_
might	options	_
not	_	_
always	_	_
be	_	_
consistent	_	_
with	_	_
the	_	_
human	_	_
evaluation	_	_
results	_	_
(	_	_
i.e.	_	_
,	_	_
perceptual	_	_
quality	_	_
)	_	_
[	_	_
20,26	_	_
]	_	_
.	_	_

#65
As	_	_
a	_	_
result	_	_
,	_	_
perceptual-related	_	_
constraints	_	_
were	_	_
incorporated	_	_
to	_	_
achieve	_	_
better	_	_
visual	_	_
quality	_	_
.	_	_

#66
Johnson	_	_
et	_	_
al.	_	_
[	_	_
16	_	_
]	_	_
demonstrated	_	_
the	_	_
effectiveness	_	_
of	_	_
adding	_	_
perception	_	_
loss	_	_
using	_	_
VGG	_	_
[	_	_
28	_	_
]	_	_
in	_	_
SR	_	_
.	_	_

#67
Ledig	_	_
et	_	_
al.	_	_
[	_	_
20	_	_
]	_	_
introduced	_	_
adversarial	_	_
loss	_	_
from	_	_
the	_	_
generative	_	_
adversarial	_	_
nets	_	_
(	_	_
GANs	_	_
)	_	_
[	_	_
12	_	_
]	_	_
to	_	_
minimize	_	_
the	_	_
perceptually	_	_
relevant	_	_
distance	_	_
between	_	_
the	_	_
SR	_	_
and	_	_
HR	_	_
images	_	_
.	_	_

#68
Sajjadi	_	_
et	_	_
al.	_	_
[	_	_
26	_	_
]	_	_
further	_	_
incorporated	_	_
the	_	_
texture	_	_
matching	_	_
loss	_	_
based	_	_
on	_	_
the	_	_
idea	_	_
of	_	_
style	_	_
transfer	_	_
[	_	_
10,11	_	_
]	_	_
,	_	_
to	_	_
enhance	_	_
the	_	_
texture	_	_
in	_	_
the	_	_
SR	_	_
image	_	_
.	_	_

#69
The	_	_
proposed	_	_
SRNTT	_	_
is	_	_
more	_	_
related	_	_
to	_	_
[	_	_
20,26	_	_
]	_	_
,	_	_
where	_	_
perceptual-related	_	_
constraints	_	_
(	_	_
i.e.	_	_
,	_	_
perceptual	_	_
loss	_	_
and	_	_
adversarial	_	_
loss	_	_
)	_	_
are	_	_
incorporated	_	_
to	_	_
recover	_	_
more	_	_
visually	_	_
plausible	_	_
SR	_	_
images	_	_
.	_	_

#70
2.2	_	_
Example-based	_	_
SR	_	_
methods	_	_

#71
In	_	_
contrast	_	_
to	_	_
SISR	_	_
where	_	_
only	_	_
the	_	_
single	_	_
LR	_	_
image	_	_
is	_	_
used	_	_
as	_	_
input	_	_
,	_	_
example-based	_	_
SR	_	_
methods	_	_
introduce	_	_
additional	_	_
images	_	_
to	_	_
assist	_	_
the	_	_
SR	_	_
process	_	_
.	_	_

#72
In	_	_
general	_	_
,	_	_
the	_	_
example	_	_
images	_	_
need	_	_
to	_	_
possess	_	_
very	_	_
similar	_	_
texture	_	_
or	_	_
content	_	_
structure	_	_
with	_	_
the	_	_
LR	_	_
image	_	_
.	_	_

#73
The	_	_
examples	_	_
could	_	_
be	_	_
selected	_	_
from	_	_
adjacent	_	_
frames	_	_
in	_	_
a	_	_
video	_	_
[	_	_
22,2	_	_
]	_	_
,	_	_
images	_	_
from	_	_
web	_	_
retrieval	_	_
[	_	_
33	_	_
]	_	_
,	_	_
or	_	_
self	_	_
patches	_	_
[	_	_
9,8	_	_
]	_	_
.	_	_

#74
We	_	_
will	_	_
not	_	_
discuss	_	_
video	_	_
(	_	_
multi-frame	_	_
)	_	_
super-resolution	_	_
which	_	_
are	_	_
specifically	_	_
designed	_	_
taking	_	_
advantage	_	_
of	_	_
the	_	_
similarity	_	_
nature	_	_
of	_	_
adjacent	_	_
frames	_	_
.	_	_

#75
The	_	_
proposed	_	_
reference-conditioned	_	_
SR	_	_
allows	_	_
a	_	_
more	_	_
relaxed	_	_
scenario	_	_
—	_	_
the	_	_
reference	_	_
could	_	_
be	_	_
an	_	_
arbitrary	_	_
image	_	_
.	_	_

#76
Those	_	_
early	_	_
works	_	_
[	_	_
9,3	_	_
]	_	_
not	_	_
using	_	_
deep	_	_
learning	_	_
mostly	_	_
built	_	_
the	_	_
mapping	_	_
from	_	_
LR	_	_
to	_	_
HR	_	_
patches	_	_
and	_	_
fused	_	_
the	_	_
HR	_	_
patches	_	_
at	_	_
the	_	_
pixel	_	_
level	_	_
and	_	_
by	_	_
a	_	_
shallow	_	_
model	_	_
,	_	_
which	_	_
is	_	_
insufficient	_	_
to	_	_
model	_	_
the	_	_
complicated	_	_
dependency	_	_
between	_	_
the	_	_
LR	_	_
image	_	_
and	_	_
extracted	_	_
details	_	_
from	_	_
the	_	_
HR	_	_
patches	_	_
,	_	_
i.e.	_	_
,	_	_
examples	_	_
.	_	_

#77
In	_	_
addition	_	_
,	_	_
they	_	_
implied	_	_
that	_	_
each	_	_
LR	_	_
patch	_	_
could	_	_
be	_	_
matched	_	_
to	_	_
an	_	_
appropriate	_	_
HR	_	_
patch	_	_
(	_	_
similar	_	_
textures	_	_
always	_	_
present	_	_
in	_	_
the	_	_
example	_	_
)	_	_
.	_	_

#78
Freedman	_	_
and	_	_
Fattal	_	_
[	_	_
8	_	_
]	_	_
and	_	_
Huang	_	_
et	_	_
al.	_	_
[	_	_
15	_	_
]	_	_
referred	_	_
to	_	_
self	_	_
examples	_	_
for	_	_
similar	_	_
textures	_	_
and	_	_
used	_	_
a	_	_
shallow	_	_
model	_	_
for	_	_
texture	_	_
transfer	_	_
.	_	_

#79
A	_	_
more	_	_
generic	_	_
scenario	_	_
of	_	_
utilizing	_	_
the	_	_
examples	_	_
was	_	_
proposed	_	_
by	_	_
Yue	_	_
et	_	_
al.	_	_
[	_	_
33	_	_
]	_	_
,	_	_
which	_	_
instantly	_	_
retrieved	_	_
similar	_	_
images	_	_
from	_	_
web	_	_
and	_	_
conducted	_	_
global	_	_
registration	_	_
and	_	_
local	_	_
matching	_	_
.	_	_

#80
However	_	_
,	_	_
they	_	_
made	_	_
a	_	_
strong	_	_
assumption	_	_
on	_	_
the	_	_
example	_	_
–	_	_
the	_	_
example	_	_
has	_	_
to	_	_
be	_	_
well	_	_
aligned	_	_
to	_	_
the	_	_
LR	_	_
image	_	_
.	_	_

#81
In	_	_
addition	_	_
,	_	_
the	_	_
shallow	_	_
model	_	_
for	_	_
patch	_	_
blending	_	_
made	_	_
its	_	_
performance	_	_
highly	_	_
dependent	_	_
on	_	_
how	_	_
well	_	_
the	_	_
example	_	_
could	_	_
be	_	_
aligned	_	_
,	_	_
limiting	_	_
its	_	_
adaptiveness	_	_
to	_	_
a	_	_
more	_	_
generic	_	_
setting	_	_
.	_	_

#82
The	_	_
proposed	_	_
SRNTT	_	_
adopts	_	_
the	_	_
ideas	_	_
of	_	_
local	_	_
texture	_	_
Reference-Conditioned	_	_
Super-Resolution	_	_
by	_	_
Neural	_	_
Texture	_	_
Transfer	_	_
5	_	_
matching	_	_
and	_	_
texture	_	_
fusion	_	_
like	_	_
existing	_	_
works	_	_
,	_	_
but	_	_
we	_	_
perform	_	_
with	_	_
high-level	_	_
features	_	_
and	_	_
deep	_	_
models	_	_
targeting	_	_
at	_	_
the	_	_
most	_	_
generic	_	_
scenario	_	_
where	_	_
the	_	_
reference	_	_
images	_	_
can	_	_
be	_	_
arbitrary	_	_
.	_	_

#83
3	_	_
Approach	_	_

#84
The	_	_
reference-conditioned	_	_
image	_	_
super-resolution	_	_
aims	_	_
to	_	_
estimate	_	_
the	_	_
SR	_	_
image	_	_
ISR	_	_
from	_	_
its	_	_
LR	_	_
counterpart	_	_
ILR	_	_
and	_	_
the	_	_
given	_	_
reference	_	_
image	_	_
IRef	_	_
,	_	_
increasing	_	_
plausible	_	_
textures	_	_
conditioned	_	_
on	_	_
the	_	_
reference	_	_
,	_	_
while	_	_
preserving	_	_
the	_	_
consistency	_	_
to	_	_
the	_	_
LR	_	_
image	_	_
in	_	_
color	_	_
and	_	_
content	_	_
.	_	_

#85
In	_	_
the	_	_
proposed	_	_
SRNTT	_	_
,	_	_
beyond	_	_
minimizing	_	_
the	_	_
distance	_	_
between	_	_
ISR	_	_
and	_	_
the	_	_
original	_	_
HR	_	_
image	_	_
IHR	_	_
as	_	_
most	_	_
existing	_	_
SR	_	_
methods	_	_
do	_	_
,	_	_
we	_	_
further	_	_
regularize	_	_
on	_	_
the	_	_
texture	_	_
consistency	_	_
between	_	_
ISR	_	_
and	_	_
IRef	_	_
.	_	_

#86
The	_	_
general	_	_
objective	_	_
could	_	_
be	_	_
expressed	_	_
by	_	_
θ̂	_	_
=	_	_
arg	_	_
min	_	_
θ	_	_
n	_	_
n∑	_	_
i=1	_	_
{	_	_
Lc	_	_
(	_	_
Gθ	_	_
(	_	_
I	_	_
LR	_	_
i	_	_
)	_	_
,	_	_
IHRi	_	_
)	_	_
+	_	_
λLt	_	_
(	_	_
Gθ	_	_
(	_	_
I	_	_
LR	_	_
i	_	_
)	_	_
,	_	_
IRefi	_	_
)	_	_
}	_	_
,	_	_
(	_	_
1	_	_
)	_	_
where	_	_
G	_	_
denotes	_	_
the	_	_
SR	_	_
network	_	_
with	_	_
parameter	_	_
θ.	_	_
Lc	_	_
(	_	_
·	_	_
,	_	_
·	_	_
)	_	_
and	_	_
Lt	_	_
(	_	_
·	_	_
,	_	_
·	_	_
)	_	_
indicate	_	_
the	_	_
content	_	_
loss	_	_
and	_	_
texture	_	_
loss	_	_
,	_	_
respectively	_	_
.	_	_

#87
For	_	_
simplicity	_	_
,	_	_
assume	_	_
each	_	_
LR	_	_
image	_	_
corresponds	_	_
to	_	_
one	_	_
reference	_	_
,	_	_
and	_	_
there	_	_
are	_	_
n	_	_
LR	_	_
images	_	_
.	_	_

#88
Section	_	_
3.3	_	_
will	_	_
discuss	_	_
the	_	_
loss	_	_
functions	_	_
in	_	_
detail	_	_
.	_	_

#89
Content	_	_
Extractor	_	_
Texture	_	_
Swapping	_	_
Conditional	_	_
texture	_	_
transferLRI	_	_
RefI	_	_
SRI	_	_
cM	_	_
LRM	_	_
RefM	_	_
LRefM	_	_
Patch	_	_
Matching	_	_
tM	_	_
LRefI	_	_
Texture	_	_
Extractor	_	_
Fig.	_	_
2	_	_
:	_	_
Overview	_	_
of	_	_
the	_	_
proposed	_	_
SRNTT	_	_
.	_	_

#90
ILR	_	_
and	_	_
IRef	_	_
are	_	_
the	_	_
inputs	_	_
to	_	_
SRNTT	_	_
.	_	_

#91
ILR	_	_
is	_	_
fed	_	_
to	_	_
the	_	_
content	_	_
extractor	_	_
,	_	_
obtaining	_	_
the	_	_
content	_	_
feature	_	_
map	_	_
M	_	_
c.	_	_
In	_	_
parallel	_	_
,	_	_
IRef	_	_
and	_	_
ILR	_	_
are	_	_
fed	_	_
to	_	_
the	_	_
texture	_	_
extractor	_	_
after	_	_
scale	_	_
adjustment	_	_
,	_	_
yielding	_	_
a	_	_
series	_	_
of	_	_
feature	_	_
maps	_	_
for	_	_
patch	_	_
matching	_	_
and	_	_
texture	_	_
swapping	_	_
.	_	_

#92
The	_	_
swapped	_	_
texture	_	_
map	_	_
M	_	_
t	_	_
carries	_	_
rich	_	_
texture	_	_
from	_	_
IRef	_	_
while	_	_
preserving	_	_
the	_	_
content	_	_
structure	_	_
of	_	_
ILR	_	_
.	_	_

#93
Finally	_	_
,	_	_
M	_	_
c	_	_
and	_	_
M	_	_
t	_	_
are	_	_
adaptively	_	_
fused	_	_
through	_	_
the	_	_
conditional	_	_
texture	_	_
transfer	_	_
,	_	_
producing	_	_
ISR	_	_
with	_	_
enhanced	_	_
texture	_	_
.	_	_

#94
An	_	_
overall	_	_
structure	_	_
of	_	_
the	_	_
proposed	_	_
SRNTT	_	_
is	_	_
shown	_	_
in	_	_
Fig.	_	_
2	_	_
.	_	_

#95
The	_	_
main	_	_
idea	_	_
is	_	_
to	_	_
search	_	_
for	_	_
locally	_	_
matched	_	_
textures	_	_
from	_	_
the	_	_
reference	_	_
and	_	_
adaptively	_	_
transfer	_	_
these	_	_
textures	_	_
to	_	_
the	_	_
SR	_	_
image	_	_
.	_	_

#96
We	_	_
design	_	_
the	_	_
structure	_	_
as	_	_
fusing	_	_
two	_	_
parallel	_	_
streams	_	_
,	_	_
i.e.	_	_
,	_	_
content	_	_
and	_	_
texture	_	_
,	_	_
which	_	_
is	_	_
consistent	_	_
to	_	_
the	_	_
intuition	_	_
of	_	_
fusing	_	_
texture	_	_
to	_	_
content	_	_
.	_	_

#97
The	_	_
content	_	_
and	_	_
texture	_	_
are	_	_
represented	_	_
as	_	_
high-level	_	_
features	_	_
extracted	_	_
through	_	_
deep	_	_
models	_	_
(	_	_
i.e.	_	_
,	_	_
content	_	_
extractor	_	_
and	_	_
texture	_	_
extractor	_	_
,	_	_
respectively	_	_
)	_	_
,	_	_
facilitating	_	_
deep	_	_
texture	_	_
fusion	_	_
which	_	_
is	_	_
more	_	_
adaptive	_	_
than	_	_
using	_	_
a	_	_
shallow	_	_
model	_	_
.	_	_

#98
The	_	_
content	_	_
feature	_	_
M	_	_
c	_	_
extracted	_	_
from	_	_
ILR	_	_
and	_	_

#99
6	_	_
Zhifei	_	_
Zhang	_	_
,	_	_
Zhaowen	_	_
Wang	_	_
,	_	_
Zhe	_	_
Lin	_	_
,	_	_
and	_	_
Hairong	_	_
Qi	_	_

#100
the	_	_
texture	_	_
feature	_	_
M	_	_
t	_	_
extracted	_	_
from	_	_
IRef	_	_
are	_	_
fused	_	_
by	_	_
the	_	_
conditional	_	_
texture	_	_
transfer	_	_
,	_	_
which	_	_
could	_	_
learn	_	_
to	_	_
adaptively	_	_
transfer	_	_
perceptually	_	_
consistent	_	_
texture	_	_
from	_	_
M	_	_
t	_	_
to	_	_
M	_	_
c.	_	_
More	_	_
details	_	_
on	_	_
conditional	_	_
texture	_	_
transfer	_	_
will	_	_
be	_	_
discussed	_	_
in	_	_
Section	_	_
3.2	_	_
.	_	_

#101
The	_	_
content	_	_
feature	_	_
map	_	_
M	_	_
c	_	_
is	_	_
directly	_	_
extracted	_	_
from	_	_
ILR	_	_
through	_	_
the	_	_
content	_	_
extractor	_	_
.	_	_

#102
The	_	_
corresponding	_	_
texture	_	_
feature	_	_
map	_	_
M	_	_
t	_	_
is	_	_
obtained	_	_
by	_	_
local	_	_
matching	_	_
between	_	_
the	_	_
LR	_	_
image	_	_
ILR	_	_
and	_	_
reference	_	_
IRef	_	_
.	_	_

#103
Because	_	_
ILR	_	_
and	_	_
IRef	_	_
may	_	_
differ	_	_
from	_	_
each	_	_
other	_	_
in	_	_
color	_	_
and	_	_
illumination	_	_
,	_	_
affecting	_	_
texture	_	_
matching	_	_
and	_	_
transfer	_	_
,	_	_
we	_	_
choose	_	_
to	_	_
perform	_	_
in	_	_
the	_	_
high-level	_	_
feature	_	_
space	_	_
where	_	_
most	_	_
content	_	_
structure	_	_
as	_	_
well	_	_
as	_	_
texture-related	_	_
information	_	_
are	_	_
preserved	_	_
.	_	_

#104
Typically	_	_
,	_	_
the	_	_
VGG19	_	_
[	_	_
28	_	_
]	_	_
model	_	_
is	_	_
adopted	_	_
as	_	_
the	_	_
texture	_	_
extractor	_	_
,	_	_
whose	_	_
effectiveness	_	_
on	_	_
texture	_	_
representation	_	_
has	_	_
been	_	_
demonstrated	_	_
by	_	_
many	_	_
empirical	_	_
studies	_	_
[	_	_
10,11	_	_
]	_	_
.	_	_

#105
To	_	_
offset	_	_
the	_	_
bias	_	_
from	_	_
scale/resolution	_	_
in	_	_
patch	_	_
matching	_	_
,	_	_
ILR	_	_
and	_	_
IRef	_	_
should	_	_
be	_	_
matched	_	_
at	_	_
similar	_	_
scale	_	_
.	_	_

#106
Intuitively	_	_
,	_	_
IRef	_	_
could	_	_
be	_	_
downsampled	_	_
to	_	_
the	_	_
scale	_	_
of	_	_
ILR	_	_
,	_	_
or	_	_
ILR	_	_
upsampled	_	_
to	_	_
the	_	_
scale	_	_
of	_	_
IRef	_	_
.	_	_

#107
The	_	_
former	_	_
is	_	_
easier	_	_
but	_	_
the	_	_
latter	_	_
achieves	_	_
more	_	_
accurate	_	_
matching	_	_
with	_	_
respect	_	_
to	_	_
location	_	_
since	_	_
matching	_	_
is	_	_
done	_	_
at	_	_
a	_	_
larger	_	_
scale	_	_
.	_	_

#108
In	_	_
addition	_	_
,	_	_
upscaling	_	_
ILR	_	_
preserves	_	_
scale	_	_
consistency	_	_
with	_	_
MRef	_	_
,	_	_
facilitating	_	_
texture	_	_
swapping	_	_
from	_	_
MRef	_	_
that	_	_
carries	_	_
richer	_	_
texture	_	_
information	_	_
.	_	_

#109
Therefore	_	_
,	_	_
we	_	_
upscale	_	_
ILR	_	_
before	_	_
feeding	_	_
it	_	_
to	_	_
the	_	_
texture	_	_
extractor	_	_
.	_	_

#110
However	_	_
,	_	_
we	_	_
do	_	_
not	_	_
feed	_	_
IRef	_	_
directly	_	_
for	_	_
patch	_	_
matching	_	_
because	_	_
the	_	_
upscaling	_	_
process	_	_
of	_	_
ILR	_	_
may	_	_
introduce	_	_
artifacts	_	_
and	_	_
blurry	_	_
effects	_	_
that	_	_
would	_	_
negatively	_	_
affect	_	_
the	_	_
matching	_	_
result	_	_
.	_	_

#111
Hence	_	_
,	_	_
we	_	_
downscale	_	_
IRef	_	_
and	_	_
followed	_	_
by	_	_
the	_	_
same	_	_
upscaling	_	_
process	_	_
as	_	_
that	_	_
of	_	_
ILR	_	_
to	_	_
achieve	_	_
more	_	_
accurate	_	_
patch	_	_
matching	_	_
.	_	_

#112
Typically	_	_
,	_	_
the	_	_
downscaling	_	_
uses	_	_
bicubic	_	_
interpolation	_	_
,	_	_
while	_	_
the	_	_
upscaling	_	_
could	_	_
be	_	_
an	_	_
existing	_	_
SR	_	_
method	_	_
or	_	_
even	_	_
bicubic	_	_
interpolation	_	_
.	_	_

#113
Section	_	_
3.1	_	_
will	_	_
further	_	_
detail	_	_
the	_	_
patching	_	_
matching	_	_
and	_	_
texture	_	_
swapping	_	_
.	_	_

#114
3.1	_	_
Patch	_	_
matching	_	_
and	_	_
texture	_	_
swapping	_	_

#115
Patch	_	_
matching	_	_
and	_	_
texture	_	_
swapping	_	_
generate	_	_
the	_	_
texture	_	_
map	_	_
M	_	_
t	_	_
that	_	_
carries	_	_
rich	_	_
texture	_	_
information	_	_
from	_	_
IRef	_	_
while	_	_
preserving	_	_
the	_	_
content	_	_
structure	_	_
of	_	_
ILR	_	_
.	_	_

#116
The	_	_
details	_	_
are	_	_
shown	_	_
in	_	_
Fig.	_	_
3	_	_
.	_	_

#117
For	_	_
simplicity	_	_
,	_	_
all	_	_
feature	_	_
maps	_	_
are	_	_
shown	_	_
as	_	_
single	_	_
channel	_	_
.	_	_

#118
Conv	_	_
.	_	_

#119
Similarity	_	_
score	_	_
maps	_	_
Patch	_	_
sampling	_	_
Max	_	_
score	_	_
Location	_	_
correspondence	_	_
LRM	_	_
RefM	_	_
LRefM	_	_
tM	_	_
sM	_	_
Fig.	_	_
3	_	_
:	_	_
Patch	_	_
matching	_	_
and	_	_
texture	_	_
swapping	_	_
.	_	_

#120
Patch	_	_
matching	_	_
is	_	_
first	_	_
performed	_	_
between	_	_
MLR	_	_
and	_	_
MLRef	_	_
.	_	_

#121
The	_	_
patch-wise	_	_
similarity	_	_
is	_	_
measured	_	_
by	_	_
inner	_	_
product	_	_
,	_	_
si	_	_
,	_	_
j	_	_
=	_	_
〈	_	_
pLRi	_	_
‖pLRi	_	_
‖	_	_
,	_	_
pLRefj	_	_
‖pLRefj	_	_
‖	_	_
〉	_	_
(	_	_
2	_	_
)	_	_
Reference-Conditioned	_	_
Super-Resolution	_	_
by	_	_
Neural	_	_
Texture	_	_
Transfer	_	_
7	_	_
where	_	_
si	_	_
,	_	_
j	_	_
denotes	_	_
the	_	_
similarity	_	_
score	_	_
between	_	_
the	_	_
ith	_	_
patch	_	_
from	_	_
MLR	_	_
(	_	_
i.e.	_	_
,	_	_
pLRi	_	_
)	_	_
and	_	_
the	_	_
jth	_	_
patch	_	_
from	_	_
MLRef	_	_
(	_	_
i.e.	_	_
,	_	_
pLRefj	_	_
)	_	_
.	_	_

#122
As	_	_
shown	_	_
in	_	_
Fig.	_	_
3	_	_
,	_	_
MLRef	_	_
is	_	_
reshaped	_	_
to	_	_
a	_	_
sequence	_	_
of	_	_
patches	_	_
by	_	_
dense	_	_
sampling	_	_
.	_	_

#123
The	_	_
patches	_	_
can	_	_
be	_	_
considered	_	_
as	_	_
kernels	_	_
,	_	_
hence	_	_
the	_	_
inner	_	_
product	_	_
can	_	_
be	_	_
approximated	_	_
by	_	_
performing	_	_
convolution	_	_
between	_	_
MLR	_	_
and	_	_
the	_	_
patch	_	_
kernels	_	_
,	_	_
to	_	_
yield	_	_
a	_	_
sequence	_	_
of	_	_
similarity	_	_
score	_	_
maps	_	_
.	_	_

#124
The	_	_
maximum	_	_
score	_	_
at	_	_
each	_	_
pixel	_	_
location	_	_
across	_	_
the	_	_
similarity	_	_
score	_	_
maps	_	_
indicates	_	_
the	_	_
best	_	_
matched	_	_
MLRef	_	_
patch	_	_
.	_	_

#125
The	_	_
similarity	_	_
map	_	_
Ms	_	_
records	_	_
those	_	_
maximum	_	_
scores	_	_
with	_	_
structural	_	_
identity	_	_
to	_	_
MLR	_	_
.	_	_

#126
Since	_	_
MRef	_	_
is	_	_
structurally	_	_
identical	_	_
to	_	_
MLRef	_	_
,	_	_
the	_	_
patch	_	_
matching	_	_
correspondence	_	_
between	_	_
MLR	_	_
and	_	_
MLRef	_	_
is	_	_
identical	_	_
to	_	_
that	_	_
between	_	_
MLR	_	_
and	_	_
MRef	_	_
.	_	_

#127
Therefore	_	_
,	_	_
texturericher	_	_
patches	_	_
from	_	_
MRef	_	_
is	_	_
swapped	_	_
to	_	_
MLR	_	_
according	_	_
to	_	_
the	_	_
correspondence	_	_
.	_	_

#128
The	_	_
overlaps	_	_
between	_	_
swapped	_	_
patches	_	_
are	_	_
averaged	_	_
.	_	_

#129
Considering	_	_
the	_	_
uncorrelated	_	_
texture	_	_
that	_	_
may	_	_
degrade	_	_
the	_	_
SR	_	_
performance	_	_
,	_	_
the	_	_
swapped	_	_
texture	_	_
map	_	_
is	_	_
multiplied	_	_
by	_	_
Ms	_	_
,	_	_
which	_	_
weights	_	_
down	_	_
those	_	_
uncorrelated	_	_
texture	_	_
because	_	_
of	_	_
its	_	_
low	_	_
similarity	_	_
score	_	_
.	_	_

#130
This	_	_
significantly	_	_
boost	_	_
the	_	_
adaptiveness	_	_
of	_	_
texture	_	_
transfer	_	_
,	_	_
which	_	_
will	_	_
be	_	_
demonstrated	_	_
in	_	_
Section	_	_
5.5	_	_
.	_	_

#131
Finally	_	_
,	_	_
we	_	_
obtain	_	_
a	_	_
weighted	_	_
texture	_	_
map	_	_
M	_	_
t	_	_
.	_	_

#132
3.2	_	_
Conditional	_	_
texture	_	_
transfer	_	_

#133
Based	_	_
on	_	_
the	_	_
content	_	_
feature	_	_
map	_	_
M	_	_
c	_	_
and	_	_
weighted	_	_
texture	_	_
map	_	_
M	_	_
t	_	_
,	_	_
the	_	_
conditional	_	_
texture	_	_
transfer	_	_
would	_	_
adaptively	_	_
fuse	_	_
textures	_	_
from	_	_
M	_	_
t	_	_
to	_	_
M	_	_
c	_	_
by	_	_
a	_	_
deep	_	_
residual	_	_
network	_	_
.	_	_

#134
The	_	_
pipeline	_	_
of	_	_
conditional	_	_
texture	_	_
transfer	_	_
is	_	_
shown	_	_
in	_	_
Fig.	_	_
4	_	_
,	_	_
where	_	_
⊕	_	_
and	_	_
⊗	_	_
represent	_	_
element-wise	_	_
summation	_	_
and	_	_
multiplication	_	_
,	_	_
respecConditional	_	_
texture	_	_
transfer	_	_
sM	_	_
tM	_	_
cM	_	_
SRI	_	_
×2	_	_
×2	_	_
Texture	_	_
Extractor	_	_
Texture	_	_
loss	_	_
Sub-pixel	_	_
Residual	_	_
blocks	_	_
C	_	_
o	_	_
n	_	_
v	_	_
B	_	_
N	_	_
R	_	_
e	_	_
LU	_	_
C	_	_
o	_	_
n	_	_
v	_	_
B	_	_
N	_	_
Fig.	_	_
4	_	_
:	_	_
The	_	_
pipeline	_	_
of	_	_
conditional	_	_
texture	_	_
transfer	_	_
.	_	_

#135
The	_	_
transfered	_	_
feature	_	_
map	_	_
is	_	_
fed	_	_
to	_	_
the	_	_
sub-pixel	_	_
layers	_	_
for	_	_
upscaling	_	_
.	_	_

#136
The	_	_
texture	_	_
loss	_	_
is	_	_
is	_	_
computed	_	_
between	_	_
M	_	_
t	_	_
and	_	_
the	_	_
weighted	_	_
feature	_	_
map	_	_
extracted	_	_
from	_	_
ISR	_	_
.	_	_

#137
tively	_	_
.	_	_

#138
Since	_	_
the	_	_
texture	_	_
transferred	_	_
to	_	_
ISR	_	_
is	_	_
supposed	_	_
to	_	_
be	_	_
visually	_	_
consistent	_	_
with	_	_
ILR	_	_
,	_	_
it	_	_
is	_	_
necessary	_	_
to	_	_
transfer	_	_
M	_	_
t	_	_
conditioned	_	_
on	_	_
M	_	_
c.	_	_
As	_	_
shown	_	_
in	_	_
the	_	_
blue	_	_
block	_	_
of	_	_
Fig.	_	_
4	_	_
,	_	_
M	_	_
c	_	_
is	_	_
concatenated	_	_
to	_	_
M	_	_
t	_	_
as	_	_
the	_	_
condition	_	_
,	_	_
and	_	_
they	_	_
are	_	_
fed	_	_
to	_	_
the	_	_
deep	_	_
residual	_	_
blocks	_	_
[	_	_
14	_	_
]	_	_
,	_	_
which	_	_
learn	_	_
to	_	_
adaptively	_	_
extract	_	_
consistent	_	_
texture	_	_
from	_	_
M	_	_
t	_	_
conditioned	_	_
on	_	_
M	_	_
c.	_	_
The	_	_
extracted	_	_
texture	_	_
is	_	_
then	_	_
added	_	_
to	_	_
M	_	_
c.	_	_
Finally	_	_
,	_	_
sub-pixel	_	_
convolution	_	_
[	_	_
27	_	_
]	_	_
is	_	_
employed	_	_
as	_	_
the	_	_
upscaling	_	_
process	_	_
,	_	_
which	_	_
is	_	_
beneficial	_	_
in	_	_
both	_	_
accuracy	_	_
and	_	_
speed	_	_
.	_	_

#139
Different	_	_
from	_	_
traditional	_	_
SISR	_	_
methods	_	_
that	_	_
only	_	_
focus	_	_
on	_	_
losses	_	_
between	_	_
ISR	_	_
and	_	_
the	_	_
ground	_	_
truth	_	_
,	_	_
the	_	_
reference-conditioned	_	_
SR	_	_
also	_	_
takes	_	_
into	_	_
account	_	_

#140
8	_	_
Zhifei	_	_
Zhang	_	_
,	_	_
Zhaowen	_	_
Wang	_	_
,	_	_
Zhe	_	_
Lin	_	_
,	_	_
and	_	_
Hairong	_	_
Qi	_	_

#141
the	_	_
loss	_	_
between	_	_
ISR	_	_
and	_	_
IRef	_	_
,	_	_
which	_	_
we	_	_
refer	_	_
to	_	_
as	_	_
the	_	_
texture	_	_
loss	_	_
.	_	_

#142
Specifically	_	_
,	_	_
the	_	_
texture	_	_
loss	_	_
is	_	_
calculated	_	_
between	_	_
M	_	_
t	_	_
derived	_	_
from	_	_
IRef	_	_
and	_	_
the	_	_
weighted	_	_
feature	_	_
map	_	_
extracted	_	_
from	_	_
ISR	_	_
with	_	_
Ms	_	_
being	_	_
the	_	_
weight	_	_
.	_	_

#143
More	_	_
details	_	_
on	_	_
loss	_	_
functions	_	_
will	_	_
be	_	_
discussed	_	_
in	_	_
Section	_	_
3.3	_	_
.	_	_

#144
3.3	_	_
Content	_	_
loss	_	_
Lc	_	_
and	_	_
texture	_	_
loss	_	_
Lt	_	_

#145
As	_	_
briefly	_	_
discussed	_	_
at	_	_
the	_	_
beginning	_	_
of	_	_
Section	_	_
3	_	_
,	_	_
in	_	_
order	_	_
to	_	_
preserve	_	_
the	_	_
structural	_	_
information	_	_
of	_	_
the	_	_
LR	_	_
image	_	_
,	_	_
improve	_	_
the	_	_
visual	_	_
quality	_	_
of	_	_
the	_	_
SR	_	_
image	_	_
,	_	_
as	_	_
well	_	_
as	_	_
taking	_	_
advantage	_	_
of	_	_
the	_	_
rich	_	_
texture	_	_
details	_	_
from	_	_
the	_	_
reference	_	_
image	_	_
,	_	_
the	_	_
objective	_	_
function	_	_
we	_	_
develop	_	_
involves	_	_
both	_	_
content	_	_
loss	_	_
Lc	_	_
and	_	_
texture	_	_
loss	_	_
Lt	_	_
.	_	_

#146
The	_	_
content	_	_
loss	_	_
is	_	_
three-fold	_	_
,	_	_
including	_	_
the	_	_
reconstruction	_	_
loss	_	_
,	_	_
Lrec	_	_
,	_	_
to	_	_
preserve	_	_
the	_	_
structural	_	_
information	_	_
,	_	_
the	_	_
perceptual	_	_
loss	_	_
,	_	_
Lper	_	_
,	_	_
and	_	_
the	_	_
adversarial	_	_
loss	_	_
,	_	_
Ladv	_	_
,	_	_
to	_	_
boost	_	_
the	_	_
visual	_	_
quality	_	_
.	_	_

#147
The	_	_
texture	_	_
loss	_	_
is	_	_
added	_	_
for	_	_
the	_	_
network	_	_
to	_	_
adaptively	_	_
enhance	_	_
the	_	_
texture	_	_
transferred	_	_
from	_	_
the	_	_
reference	_	_
image	_	_
.	_	_

#148
Reconstruction	_	_
loss	_	_
is	_	_
widely	_	_
adopted	_	_
in	_	_
most	_	_
SR	_	_
works	_	_
.	_	_

#149
To	_	_
achieve	_	_
the	_	_
objective	_	_
of	_	_
obtaining	_	_
higher	_	_
PSNR	_	_
,	_	_
MSE	_	_
is	_	_
usually	_	_
used	_	_
to	_	_
measure	_	_
the	_	_
reconstruction	_	_
loss	_	_
.	_	_

#150
In	_	_
this	_	_
paper	_	_
,	_	_
we	_	_
adopt	_	_
the	_	_
`1-norm	_	_
,	_	_
Lrec	_	_
=	_	_
HW	_	_
H∑	_	_
x=1	_	_
W∑	_	_
y=1	_	_
|IHRx	_	_
,	_	_
y	_	_
−	_	_
ISRx	_	_
,	_	_
y	_	_
|	_	_
,	_	_
(	_	_
3	_	_
)	_	_
where	_	_
H	_	_
and	_	_
W	_	_
denote	_	_
the	_	_
height	_	_
and	_	_
width	_	_
of	_	_
the	_	_
HR/SR	_	_
image	_	_
,	_	_
respectively	_	_
.	_	_

#151
The	_	_
`1-norm	_	_
would	_	_
further	_	_
sharpen	_	_
ISR	_	_
as	_	_
compared	_	_
to	_	_
MSE	_	_
.	_	_

#152
In	_	_
addition	_	_
,	_	_
it	_	_
is	_	_
consistent	_	_
to	_	_
the	_	_
objective	_	_
of	_	_
WGAN-GP	_	_
,	_	_
which	_	_
will	_	_
be	_	_
discussed	_	_
later	_	_
in	_	_
the	_	_
adversarial	_	_
loss	_	_
.	_	_

#153
Perceptual	_	_
loss	_	_
has	_	_
been	_	_
investigated	_	_
in	_	_
recent	_	_
SR	_	_
works	_	_
[	_	_
1,16,20,26	_	_
]	_	_
for	_	_
better	_	_
visual	_	_
quality	_	_
.	_	_

#154
We	_	_
calculate	_	_
the	_	_
perceptual	_	_
loss	_	_
based	_	_
on	_	_
the	_	_
relu5	_	_
1	_	_
layer	_	_
of	_	_
VGG19	_	_
[	_	_
28	_	_
]	_	_
,	_	_
Lper	_	_
=	_	_
V	_	_
C∑	_	_
i=1	_	_
∥∥φi	_	_
(	_	_
IHR	_	_
)	_	_
−	_	_
φi	_	_
(	_	_
ISR	_	_
)	_	_
∥∥	_	_
F	_	_
,	_	_
(	_	_
4	_	_
)	_	_
where	_	_
V	_	_
and	_	_
C	_	_
indicate	_	_
the	_	_
tensor	_	_
volume	_	_
and	_	_
channel	_	_
number	_	_
of	_	_
the	_	_
feature	_	_
maps	_	_
,	_	_
respectively	_	_
,	_	_
and	_	_
φi	_	_
denotes	_	_
the	_	_
ith	_	_
channel	_	_
of	_	_
the	_	_
feature	_	_
maps	_	_
extracted	_	_
from	_	_
the	_	_
hidden	_	_
layer	_	_
of	_	_
VGG19	_	_
model	_	_
.	_	_

#155
‖	_	_
·	_	_
‖F	_	_
denotes	_	_
the	_	_
Frobenius	_	_
norm	_	_
.	_	_

#156
Adversarial	_	_
loss	_	_
could	_	_
significantly	_	_
enhance	_	_
the	_	_
sharpness/visual	_	_
quality	_	_
of	_	_
ISR	_	_
.	_	_

#157
Here	_	_
,	_	_
we	_	_
adopt	_	_
WGAN-GP	_	_
[	_	_
13	_	_
]	_	_
,	_	_
which	_	_
improves	_	_
upon	_	_
WGAN	_	_
by	_	_
penalizing	_	_
the	_	_
gradient	_	_
,	_	_
achieving	_	_
more	_	_
stable	_	_
results	_	_
.	_	_

#158
Because	_	_
the	_	_
Wasserstein	_	_
distance	_	_
in	_	_
WGAN	_	_
is	_	_
based	_	_
on	_	_
`1-norm	_	_
,	_	_
we	_	_
also	_	_
use	_	_
`1-norm	_	_
as	_	_
the	_	_
reconstruction	_	_
loss	_	_
(	_	_
Eq.	_	_
3	_	_
)	_	_
.	_	_

#159
Intuitively	_	_
,	_	_
consistent	_	_
objectives	_	_
in	_	_
optimization	_	_
would	_	_
help	_	_
yield	_	_
more	_	_
stable	_	_
results	_	_
.	_	_

#160
The	_	_
adversarial	_	_
loss	_	_
and	_	_
objective	_	_
of	_	_
WGAN	_	_
are	_	_
expressed	_	_
as	_	_
Ladv	_	_
=	_	_
−Ex̃∼Pg	_	_
[	_	_
D	_	_
(	_	_
x̃	_	_
)	_	_
]	_	_
,	_	_
min	_	_
G	_	_
max	_	_
D∈D	_	_
Ex∼Pr	_	_
[	_	_
D	_	_
(	_	_
x	_	_
)	_	_
]	_	_
−	_	_
Ex̃∼Pg	_	_
[	_	_
D	_	_
(	_	_
x̃	_	_
)	_	_
]	_	_
,	_	_
(	_	_
5	_	_
)	_	_
where	_	_
D	_	_
is	_	_
the	_	_
set	_	_
of	_	_
1-Lipschitz	_	_
functions	_	_
,	_	_
and	_	_
Pr	_	_
and	_	_
Pg	_	_
are	_	_
the	_	_
model	_	_
distribution	_	_
and	_	_
real	_	_
data	_	_
distribution	_	_
,	_	_
respectively	_	_
.	_	_

#161
Reference-Conditioned	_	_
Super-Resolution	_	_
by	_	_
Neural	_	_
Texture	_	_
Transfer	_	_
9	_	_
Texture	_	_
loss	_	_
is	_	_
built	_	_
on	_	_
the	_	_
idea	_	_
of	_	_
Gatys	_	_
et	_	_
al.	_	_
[	_	_
10,11	_	_
]	_	_
,	_	_
where	_	_
Gram	_	_
matrix	_	_
was	_	_
applied	_	_
to	_	_
statistically	_	_
preserve	_	_
the	_	_
texture	_	_
from	_	_
the	_	_
style	_	_
image	_	_
.	_	_

#162
To	_	_
preserve	_	_
the	_	_
consistency	_	_
between	_	_
the	_	_
content	_	_
and	_	_
transferred	_	_
texture	_	_
,	_	_
the	_	_
similarity	_	_
map	_	_
Ms	_	_
is	_	_
utilized	_	_
,	_	_
as	_	_
illustrated	_	_
in	_	_
Fig.	_	_
4	_	_
,	_	_
to	_	_
suppress	_	_
uncorrelated	_	_
texture	_	_
.	_	_

#163
The	_	_
texture	_	_
loss	_	_
is	_	_
written	_	_
as	_	_
Lt	_	_
=	_	_
4V	_	_
2	_	_
∥∥Gr	_	_
(	_	_
φ	_	_
(	_	_
ISR	_	_
)	_	_
⊗Ms	_	_
)	_	_
−Gr	_	_
(	_	_
M	_	_
t	_	_
)	_	_
∥∥	_	_
F	_	_
,	_	_
(	_	_
6	_	_
)	_	_
where	_	_
Gr	_	_
(	_	_
·	_	_
)	_	_
denotes	_	_
the	_	_
operator	_	_
that	_	_
computes	_	_
the	_	_
Gram	_	_
matrix	_	_
,	_	_
and	_	_
φ	_	_
(	_	_
·	_	_
)	_	_
indicates	_	_
the	_	_
feature	_	_
maps	_	_
from	_	_
the	_	_
relu3	_	_
1	_	_
layer	_	_
of	_	_
VGG19	_	_
model	_	_
,	_	_
whose	_	_
scale	_	_
is	_	_
the	_	_
same	_	_
as	_	_
that	_	_
of	_	_
the	_	_
texture	_	_
feature	_	_
map	_	_
M	_	_
t.	_	_
V	_	_
is	_	_
the	_	_
volume	_	_
of	_	_
the	_	_
feature	_	_
map	_	_
tensor	_	_
from	_	_
VGG19	_	_
,	_	_
and	_	_
⊗	_	_
denotes	_	_
the	_	_
element-wise	_	_
multiplication	_	_
.	_	_

#164
4	_	_
Dataset	_	_

#165
For	_	_
reference-based	_	_
SR	_	_
problems	_	_
,	_	_
the	_	_
similarity	_	_
between	_	_
the	_	_
LR	_	_
image	_	_
and	_	_
reference	_	_
affects	_	_
SR	_	_
results	_	_
significantly	_	_
.	_	_

#166
In	_	_
general	_	_
,	_	_
references	_	_
with	_	_
various	_	_
similarity	_	_
levels	_	_
to	_	_
the	_	_
corresponding	_	_
LR	_	_
image	_	_
should	_	_
be	_	_
provided	_	_
for	_	_
the	_	_
purpose	_	_
of	_	_
learning	_	_
and	_	_
evaluating	_	_
the	_	_
adaptiveness	_	_
to	_	_
similar	_	_
and	_	_
dissimilar	_	_
textures	_	_
in	_	_
references	_	_
.	_	_

#167
We	_	_
refer	_	_
to	_	_
pairs	_	_
of	_	_
LR	_	_
and	_	_
reference	_	_
images	_	_
as	_	_
LR-Ref	_	_
pairs	_	_
.	_	_

#168
We	_	_
use	_	_
SIFT	_	_
[	_	_
24	_	_
]	_	_
features	_	_
to	_	_
measure	_	_
the	_	_
similarity	_	_
between	_	_
two	_	_
images	_	_
because	_	_
SIFT	_	_
features	_	_
characterize	_	_
local	_	_
texture	_	_
information	_	_
that	_	_
is	_	_
in	_	_
line	_	_
with	_	_
the	_	_
objective	_	_
of	_	_
local	_	_
texture	_	_
matching	_	_
.	_	_

#169
In	_	_
addition	_	_
,	_	_
SIFT	_	_
feature	_	_
matching	_	_
is	_	_
conducted	_	_
in	_	_
the	_	_
pixel	_	_
space	_	_
which	_	_
is	_	_
more	_	_
rigorous	_	_
than	_	_
high-level	_	_
feature	_	_
matching	_	_
,	_	_
providing	_	_
more	_	_
visually	_	_
correlated	_	_
pairs	_	_
.	_	_

#170
We	_	_
build	_	_
the	_	_
training	_	_
and	_	_
validation	_	_
datasets	_	_
based	_	_
on	_	_
CUFED	_	_
[	_	_
30	_	_
]	_	_
that	_	_
contains	_	_
1,883	_	_
albums	_	_
.	_	_

#171
We	_	_
choose	_	_
to	_	_
use	_	_
album	_	_
images	_	_
since	_	_
images	_	_
collected	_	_
from	_	_
the	_	_
same	_	_
event	_	_
are	_	_
supposed	_	_
to	_	_
be	_	_
taken	_	_
in	_	_
similar	_	_
environment	_	_
.	_	_

#172
Each	_	_
album	_	_
describes	_	_
one	_	_
of	_	_
the	_	_
23	_	_
most	_	_
common	_	_
events	_	_
in	_	_
our	_	_
daily	_	_
life	_	_
,	_	_
ranging	_	_
from	_	_
Wedding	_	_
to	_	_
Nature	_	_
Trip	_	_
.	_	_

#173
The	_	_
size	_	_
of	_	_
albums	_	_
varies	_	_
between	_	_
30	_	_
and	_	_
100	_	_
images	_	_
.	_	_

#174
Within	_	_
each	_	_
album	_	_
,	_	_
we	_	_
collect	_	_
image	_	_
pairs	_	_
in	_	_
different	_	_
similarity	_	_
levels	_	_
based	_	_
on	_	_
SIFT	_	_
feature	_	_
matching	_	_
.	_	_

#175
We	_	_
quantitatively	_	_
collect	_	_
five	_	_
similarity	_	_
levels	_	_
denoted	_	_
as	_	_
XH	_	_
(	_	_
extra-high	_	_
)	_	_
,	_	_
H	_	_
(	_	_
high	_	_
)	_	_
,	_	_
M	_	_
(	_	_
medium	_	_
)	_	_
,	_	_
L	_	_
(	_	_
low	_	_
)	_	_
,	_	_
and	_	_
XL	_	_
(	_	_
extralow	_	_
)	_	_
.	_	_

#176
From	_	_
each	_	_
paired	_	_
images	_	_
,	_	_
we	_	_
randomly	_	_
crop	_	_
160×160	_	_
patches	_	_
from	_	_
one	_	_
image	_	_
as	_	_
the	_	_
original	_	_
HR	_	_
images	_	_
(	_	_
LR	_	_
images	_	_
are	_	_
obtained	_	_
by	_	_
downscaling	_	_
)	_	_
,	_	_
and	_	_
the	_	_
corresponding	_	_
references	_	_
are	_	_
cropped	_	_
from	_	_
the	_	_
other	_	_
image	_	_
.	_	_

#177
In	_	_
this	_	_
way	_	_
,	_	_
we	_	_
collect	_	_
13,761	_	_
LR-Ref	_	_
pairs	_	_
for	_	_
training	_	_
purpose	_	_
.	_	_

#178
It	_	_
is	_	_
worth	_	_
noting	_	_
that	_	_
in	_	_
building	_	_
the	_	_
training	_	_
dataset	_	_
,	_	_
it	_	_
is	_	_
not	_	_
necessary	_	_
to	_	_
present	_	_
references	_	_
at	_	_
all	_	_
five	_	_
similarity	_	_
levels	_	_
for	_	_
‘each’	_	_
LR	_	_
image	_	_
although	_	_
the	_	_
training	_	_
set	_	_
as	_	_
a	_	_
whole	_	_
should	_	_
contain	_	_
LR-Ref	_	_
pairs	_	_
at	_	_
different	_	_
similarity	_	_
levels	_	_
.	_	_

#179
On	_	_
the	_	_
other	_	_
hand	_	_
,	_	_
the	_	_
validation	_	_
dataset	_	_
does	_	_
need	_	_
each	_	_
LR	_	_
image	_	_
to	_	_
have	_	_
references	_	_
at	_	_
all	_	_
five	_	_
similarity	_	_
levels	_	_
in	_	_
order	_	_
to	_	_
extensively	_	_
evaluate	_	_
the	_	_
adaptiveness	_	_
of	_	_
the	_	_
network	_	_
to	_	_
references	_	_
with	_	_
different	_	_
similarity	_	_
levels	_	_
.	_	_

#180
We	_	_
use	_	_
the	_	_
same	_	_
way	_	_
to	_	_
collect	_	_
image	_	_
pairs	_	_
as	_	_
in	_	_
building	_	_
the	_	_
training	_	_
dataset	_	_
.	_	_

#181
In	_	_
total	_	_
,	_	_
the	_	_
validation	_	_
set	_	_
contains	_	_
126	_	_
groups	_	_
of	_	_
testing	_	_
samples	_	_
with	_	_
each	_	_
group	_	_
consisting	_	_
of	_	_
one	_	_
HR	_	_
image	_	_
and	_	_
five	_	_
references	_	_
at	_	_
five	_	_
different	_	_
similarity	_	_
levels	_	_
.	_	_

#182
Some	_	_

#183
10	_	_
Zhifei	_	_
Zhang	_	_
,	_	_
Zhaowen	_	_
Wang	_	_
,	_	_
Zhe	_	_
Lin	_	_
,	_	_
and	_	_
Hairong	_	_
Qi	_	_

#184
randomly	_	_
selected	_	_
testing	_	_
groups	_	_
are	_	_
shown	_	_
in	_	_
Fig.	_	_
5	_	_
.	_	_

#185
We	_	_
refer	_	_
to	_	_
the	_	_
collected	_	_
training	_	_
and	_	_
validation	_	_
sets	_	_
as	_	_
CUFED5	_	_
.	_	_

#186
The	_	_
construction	_	_
of	_	_
CUFED5	_	_
largely	_	_
facilitates	_	_
performance	_	_
evaluation	_	_
of	_	_
the	_	_
proposed	_	_
reference-conditioned	_	_
SR	_	_
research	_	_
,	_	_
providing	_	_
a	_	_
benchmark	_	_
for	_	_
the	_	_
study	_	_
of	_	_
reference-based	_	_
SR	_	_
in	_	_
general	_	_
.	_	_

#187
HR	_	_
XH	_	_
H	_	_
M	_	_
L	_	_
XL	_	_
Fig.	_	_
5	_	_
:	_	_
Examples	_	_
from	_	_
the	_	_
CUFED5	_	_
dataset	_	_
.	_	_

#188
The	_	_
left	_	_
column	_	_
is	_	_
the	_	_
HR	_	_
image	_	_
for	_	_
testing	_	_
.	_	_

#189
The	_	_
right	_	_
columns	_	_
are	_	_
corresponding	_	_
references	_	_
in	_	_
five	_	_
similarity	_	_
levels	_	_
,	_	_
i.e.	_	_
,	_	_
extra-high	_	_
(	_	_
XH	_	_
)	_	_
,	_	_
high	_	_
(	_	_
H	_	_
)	_	_
,	_	_
medium	_	_
(	_	_
M	_	_
)	_	_
,	_	_
low	_	_
(	_	_
L	_	_
)	_	_
,	_	_
and	_	_
extra-low	_	_
(	_	_
XL	_	_
)	_	_
.	_	_

#190
5	_	_
Experimental	_	_
Results	_	_

#191
In	_	_
this	_	_
section	_	_
,	_	_
both	_	_
quantitative	_	_
and	_	_
qualitative	_	_
comparisons	_	_
are	_	_
conducted	_	_
to	_	_
demonstrate	_	_
the	_	_
effectiveness	_	_
of	_	_
the	_	_
proposed	_	_
SRNTT	_	_
in	_	_
boosting	_	_
SR	_	_
performance	_	_
in	_	_
aspects	_	_
of	_	_
visual	_	_
quality	_	_
,	_	_
texture	_	_
richness	_	_
,	_	_
and	_	_
content	_	_
consistency	_	_
.	_	_

#192
5.1	_	_
Training	_	_
details	_	_
and	_	_
parameters	_	_

#193
In	_	_
training	_	_
,	_	_
the	_	_
LR	_	_
images	_	_
are	_	_
obtained	_	_
by	_	_
downscaling	_	_
(	_	_
4×	_	_
)	_	_
the	_	_
HR	_	_
images	_	_
through	_	_
bicubic	_	_
interpolation	_	_
,	_	_
thus	_	_
the	_	_
LR	_	_
images	_	_
are	_	_
of	_	_
the	_	_
size	_	_
40	_	_
×	_	_
40	_	_
.	_	_

#194
The	_	_
corresponding	_	_
reference	_	_
is	_	_
fed	_	_
with	_	_
the	_	_
original	_	_
size	_	_
,	_	_
160×160	_	_
.	_	_

#195
All	_	_
feature	_	_
maps	_	_
keep	_	_
the	_	_
same	_	_
size	_	_
of	_	_
40×40	_	_
,	_	_
to	_	_
facilitate	_	_
patch	_	_
matching	_	_
,	_	_
texture	_	_
swapping	_	_
,	_	_
and	_	_
concatenation	_	_
of	_	_
content	_	_
and	_	_
texture	_	_
maps	_	_
.	_	_

#196
The	_	_
weights	_	_
parameters	_	_
for	_	_
Lper	_	_
,	_	_
Ladv	_	_
,	_	_
and	_	_
Lt	_	_
are	_	_
α=1e-4	_	_
,	_	_
β=1e-6	_	_
,	_	_
and	_	_
λ=1e-4	_	_
,	_	_
respectively	_	_
.	_	_

#197
Adam	_	_
optimizer	_	_
is	_	_
used	_	_
with	_	_
the	_	_
initial	_	_
learning	_	_
rate	_	_
of	_	_
1e-4	_	_
.	_	_

#198
The	_	_
network	_	_
is	_	_
pre-trained	_	_
for	_	_
5	_	_
epochs	_	_
,	_	_
where	_	_
only	_	_
Lrec	_	_
is	_	_
applied	_	_
.	_	_

#199
Then	_	_
,	_	_
all	_	_
losses	_	_
are	_	_
involved	_	_
to	_	_
train	_	_
another	_	_
100	_	_
epochs	_	_
,	_	_
during	_	_
which	_	_
the	_	_
learning	_	_
rate	_	_
is	_	_
decayed	_	_
by	_	_
0.1	_	_
for	_	_
each	_	_
50	_	_
epochs	_	_
.	_	_

#200
Note	_	_
that	_	_
Lt	_	_
is	_	_
only	_	_
applied	_	_
on	_	_
the	_	_
conditional	_	_
texture	_	_
transfer	_	_
network	_	_
.	_	_

#201
The	_	_
whole	_	_
framework	_	_
could	_	_
be	_	_
trained	_	_
end-to-end	_	_
.	_	_

#202
However	_	_
,	_	_
the	_	_
patch	_	_
matching	_	_
is	_	_
timeconsuming	_	_
,	_	_
occupying	_	_
over	_	_
90	_	_
%	_	_
run	_	_
time	_	_
during	_	_
training	_	_
.	_	_

#203
Hence	_	_
we	_	_
calculate	_	_
M	_	_
t	_	_
offline	_	_
for	_	_
each	_	_
training	_	_
pair	_	_
because	_	_
the	_	_
process	_	_
of	_	_
generating	_	_
M	_	_
t	_	_
only	_	_
involves	_	_
the	_	_
pre-trained	_	_
VGG19	_	_
model	_	_
.	_	_

#204
To	_	_
further	_	_
speed	_	_
up	_	_
the	_	_
training	_	_
process	_	_
,	_	_
we	_	_
could	_	_
use	_	_
a	_	_
pre-trained	_	_
SR	_	_
network	_	_
,	_	_
e.g.	_	_
,	_	_
MSE-based	_	_
EDSR	_	_
or	_	_
GAN-based	_	_
SRGAN	_	_
,	_	_
as	_	_
the	_	_
content	_	_
extractor	_	_
to	_	_
obtain	_	_
M	_	_
c	_	_
.	_	_

#205
5.2	_	_
Quantitative	_	_
evaluation	_	_

#206
We	_	_
compare	_	_
the	_	_
PSNR	_	_
and	_	_
SSIM	_	_
with	_	_
other	_	_
SR	_	_
methods	_	_
,	_	_
as	_	_
shown	_	_
in	_	_
Table	_	_
1	_	_
.	_	_

#207
SelfEx	_	_
[	_	_
15	_	_
]	_	_
is	_	_
a	_	_
non-learning-based	_	_
method	_	_
using	_	_
the	_	_
LR	_	_
input	_	_
itself	_	_
as	_	_
Reference-Conditioned	_	_
Super-Resolution	_	_
by	_	_
Neural	_	_
Texture	_	_
Transfer	_	_
11	_	_
reference	_	_
.	_	_

#208
SRCNN	_	_
[	_	_
5	_	_
]	_	_
,	_	_
SCN	_	_
[	_	_
31	_	_
]	_	_
,	_	_
DRCN	_	_
[	_	_
18	_	_
]	_	_
,	_	_
LapSRN	_	_
[	_	_
34	_	_
]	_	_
,	_	_
and	_	_
EDSR	_	_
[	_	_
21	_	_
]	_	_
are	_	_
learning-based	_	_
methods	_	_
by	_	_
minimizing	_	_
MSE	_	_
.	_	_

#209
ENet	_	_
[	_	_
26	_	_
]	_	_
and	_	_
SRGAN	_	_
[	_	_
20	_	_
]	_	_
are	_	_
also	_	_
learning-based	_	_
but	_	_
further	_	_
utilize	_	_
the	_	_
perceptual-related	_	_
constraints	_	_
to	_	_
enhance	_	_
the	_	_
visual	_	_
quality	_	_
.	_	_

#210
Landmark	_	_
[	_	_
33	_	_
]	_	_
is	_	_
a	_	_
reference-based	_	_
SR	_	_
method	_	_
,	_	_
retrieving	_	_
references	_	_
that	_	_
could	_	_
be	_	_
well-aligned	_	_
to	_	_
ILR	_	_
.	_	_

#211
The	_	_
“SRNTT-”	_	_
denotes	_	_
a	_	_
simplified	_	_
version	_	_
of	_	_
SRNTT	_	_
by	_	_
removing	_	_
the	_	_
adversarial	_	_
loss	_	_
,	_	_
which	_	_
is	_	_
supposed	_	_
to	_	_
achieve	_	_
comparable	_	_
PSNR	_	_
as	_	_
the	_	_
MSE-based	_	_
methods	_	_
.	_	_

#212
All	_	_
methods	_	_
are	_	_
tested	_	_
on	_	_
the	_	_
CUFED5	_	_
dataset	_	_
.	_	_

#213
The	_	_
Landmark	_	_
method	_	_
is	_	_
tested	_	_
with	_	_
the	_	_
reference	_	_
of	_	_
similarity	_	_
level	_	_
M.	_	_
Our	_	_
methods	_	_
are	_	_
tested	_	_
with	_	_
each	_	_
of	_	_
the	_	_
five	_	_
references	_	_
and	_	_
results	_	_
averaged	_	_
.	_	_

#214
This	_	_
individual	_	_
performance	_	_
is	_	_
listed	_	_
in	_	_
Table	_	_
2	_	_
.	_	_

#215
Table	_	_
1	_	_
:	_	_
Comparison	_	_
of	_	_
different	_	_
SR	_	_
methods	_	_
in	_	_
PSNR	_	_
and	_	_
SSIM	_	_
.	_	_

#216
Bicubic	_	_
SRCNN	_	_
SCN	_	_
DRCN	_	_
LapSRN	_	_
EDSR	_	_
PSNR	_	_
24.18	_	_
25.33	_	_
25.45	_	_
25.26	_	_
24.92	_	_
26.81	_	_
SSIM	_	_
.6837	_	_
.7451	_	_
.7426	_	_
.7337	_	_
.7299	_	_
.7923	_	_
SelfEx	_	_
Landmark	_	_
ENet	_	_
SRGAN	_	_
SRNTT-	_	_
SRNTT	_	_
PSNR	_	_
23.22	_	_
24.91	_	_
24.24	_	_
24.40	_	_
26.23	_	_
24.60	_	_
SSIM	_	_
.6799	_	_
.7176	_	_
.6948	_	_
.7021	_	_
.7737	_	_
.7086	_	_
Table	_	_
2	_	_
:	_	_
PSNR	_	_
and	_	_
SSIM	_	_
of	_	_
SRNTT	_	_
with	_	_
different	_	_
reference	_	_
levels	_	_
.	_	_

#217
XH	_	_
H	_	_
M	_	_
L	_	_
XL	_	_
Average	_	_
PSNR	_	_
24.57	_	_
24.58	_	_
24.56	_	_
24.63	_	_
24.69	_	_
24.60	_	_
SSIM	_	_
.7099	_	_
.7082	_	_
.7075	_	_
.7079	_	_
.7094	_	_
.7086	_	_
Table	_	_
3	_	_
:	_	_
Texture	_	_
distance	_	_
to	_	_
the	_	_
reference	_	_
based	_	_
on	_	_
Gram	_	_
matrix	_	_
.	_	_

#218
Landmark	_	_
EDSR	_	_
ENet	_	_
SRGAN	_	_
SRNTT-	_	_
SRNTT	_	_
Gram	_	_
55.25	_	_
37.00	_	_
27.26	_	_
32.21	_	_
33.72	_	_
22.77	_	_
From	_	_
PSNR	_	_
and	_	_
SSIM	_	_
,	_	_
we	_	_
observe	_	_
that	_	_
those	_	_
methods	_	_
minimizing	_	_
MSE	_	_
perform	_	_
better	_	_
than	_	_
GAN-based	_	_
methods	_	_
.	_	_

#219
However	_	_
,	_	_
PSNR	_	_
and	_	_
SSIM	_	_
can	_	_
not	_	_
adequately	_	_
reflect	_	_
visual	_	_
quality	_	_
of	_	_
the	_	_
image	_	_
,	_	_
especially	_	_
when	_	_
the	_	_
upscaling	_	_
factor	_	_
is	_	_
relatively	_	_
large	_	_
(	_	_
e.g.	_	_
,	_	_
4×	_	_
)	_	_
and/or	_	_
the	_	_
image	_	_
is	_	_
originally	_	_
with	_	_
rich	_	_
texture	_	_
.	_	_

#220
The	_	_
GAN-based	_	_
methods	_	_
would	_	_
present	_	_
more	_	_
details	_	_
that	_	_
may	_	_
deviate	_	_
from	_	_
the	_	_
content	_	_
of	_	_
the	_	_
original	_	_
image	_	_
,	_	_
or	_	_
even	_	_
introduce	_	_
artifacts	_	_
to	_	_
make	_	_
the	_	_
generated	_	_
images	_	_
look	_	_
sharper	_	_
.	_	_

#221
Note	_	_
that	_	_
SRNTT-	_	_
achieves	_	_
comparable	_	_
PSNR	_	_
and	_	_
SSIM	_	_
with	_	_
the	_	_
state-of-the-art	_	_
,	_	_
i.e.	_	_
,	_	_
EDSR	_	_
.	_	_

#222
In	_	_
the	_	_
individual	_	_
performance	_	_
of	_	_
SRNTT	_	_
with	_	_
each	_	_
reference	_	_
level	_	_
,	_	_
the	_	_
highest	_	_
PSNR/SSIM	_	_
is	_	_
achieved	_	_
at	_	_
XL	_	_
because	_	_
the	_	_
texture	_	_
from	_	_
reference	_	_
is	_	_
mostly	_	_
suppressed	_	_
,	_	_
yielding	_	_
relatively	_	_
smooth	_	_
results	_	_
.	_	_

#223
By	_	_
contrast	_	_
,	_	_
the	_	_
score	_	_
of	_	_
XH	_	_
is	_	_
lower	_	_
because	_	_
correlated	_	_
texture	_	_
are	_	_
transferred	_	_
to	_	_
the	_	_
SR	_	_
results	_	_
which	_	_
may	_	_
deviate	_	_
from	_	_
the	_	_
original	_	_
HR	_	_
image	_	_
.	_	_

#224
To	_	_
illustrate	_	_
the	_	_
conditioned	_	_
texture	_	_
transfer	_	_
,	_	_
we	_	_
measure	_	_
the	_	_
textural	_	_
similarity	_	_
between	_	_
ISR	_	_
and	_	_
IRef	_	_
(	_	_
level	_	_
M	_	_
)	_	_
based	_	_
on	_	_
the	_	_
Gram	_	_
matrix	_	_
as	_	_
shown	_	_
in	_	_
Table	_	_
3	_	_
.	_	_

#225
SRNTT	_	_
presents	_	_
the	_	_
smallest	_	_
distance	_	_
since	_	_
it	_	_
transfers	_	_
texture	_	_
from	_	_
the	_	_
reference	_	_
.	_	_

#226
ENet	_	_
also	_	_
achieves	_	_
a	_	_
relatively	_	_
small	_	_
distance	_	_
because	_	_
it	_	_
also	_	_
regularizes	_	_
on	_	_
texture	_	_
but	_	_
between	_	_
ISR	_	_
and	_	_
the	_	_
original	_	_
HR	_	_
image	_	_
.	_	_

#227
Some	_	_
typical	_	_
testing	_	_
results	_	_
are	_	_
shown	_	_
in	_	_
Fig.	_	_
6	_	_
,	_	_
where	_	_
SRNTT	_	_
and	_	_
SRNTT-	_	_
present	_	_
more	_	_
textures	_	_

#228
12	_	_
Zhifei	_	_
Zhang	_	_
,	_	_
Zhaowen	_	_
Wang	_	_
,	_	_
Zhe	_	_
Lin	_	_
,	_	_
and	_	_
Hairong	_	_
Qi	_	_

#229
that	_	_
are	_	_
transferred	_	_
from	_	_
the	_	_
references	_	_
.	_	_

#230
We	_	_
observe	_	_
that	_	_
Landmark	_	_
could	_	_
well	_	_
utilize	_	_
the	_	_
texture	_	_
from	_	_
references	_	_
only	_	_
when	_	_
the	_	_
reference	_	_
can	_	_
be	_	_
well	_	_
aligned	_	_
to	_	_
the	_	_
input	_	_
.	_	_

#231
For	_	_
example	_	_
,	_	_
Landmark	_	_
can	_	_
better	_	_
recover	_	_
the	_	_
flag	_	_
since	_	_
it	_	_
can	_	_
find	_	_
well	_	_
aligned	_	_
patch	_	_
in	_	_
the	_	_
reference	_	_
.	_	_

#232
For	_	_
the	_	_
other	_	_
examples	_	_
,	_	_
Landmark	_	_
fails	_	_
to	_	_
recover	_	_
details	_	_
.	_	_

#233
Our	_	_
method	_	_
could	_	_
better	_	_
tolerate	_	_
misaligned	_	_
or	_	_
unrelated	_	_
texture	_	_
.	_	_

#234
The	_	_
MSE-based	_	_
methods	_	_
tend	_	_
to	_	_
generate	_	_
clean	_	_
but	_	_
blurry	_	_
images	_	_
.	_	_

#235
By	_	_
contrast	_	_
,	_	_
SRNTT-	_	_
gains	_	_
rich	_	_
textures	_	_
from	_	_
references	_	_
.	_	_

#236
The	_	_
GAN-based	_	_
methods	_	_
present	_	_
better	_	_
visual	_	_
quality	_	_
,	_	_
but	_	_
still	_	_
can	_	_
not	_	_
recover	_	_
plausible	_	_
textures	_	_
like	_	_
SRNTT	_	_
.	_	_

#237
Landmark	_	_
EDSR	_	_
SRNTT-	_	_
Original	_	_
ENet	_	_
SRGAN	_	_
SRNTT	_	_
Reference	_	_
Fig.	_	_
6	_	_
:	_	_
Visual	_	_
comparison	_	_
to	_	_
other	_	_
SR	_	_
methods	_	_
.	_	_

#238
5.3	_	_
Qualitative	_	_
evaluation	_	_
by	_	_
user	_	_
study	_	_

#239
To	_	_
evaluate	_	_
the	_	_
visual	_	_
quality	_	_
of	_	_
the	_	_
SR	_	_
images	_	_
,	_	_
we	_	_
conduct	_	_
user	_	_
study	_	_
which	_	_
is	_	_
widely	_	_
adopted	_	_
in	_	_
many	_	_
GAN-related	_	_
works	_	_
[	_	_
20,26	_	_
]	_	_
.	_	_

#240
SRNTT	_	_
is	_	_
compared	_	_
to	_	_
Reference-Conditioned	_	_
Super-Resolution	_	_
by	_	_
Neural	_	_
Texture	_	_
Transfer	_	_
13	_	_
Landmark	_	_
SCN	_	_
DRCN	_	_
EDSR	_	_
ENet	_	_
SRGAN	_	_
70	_	_
%	_	_
75	_	_
%	_	_
80	_	_
%	_	_
85	_	_
%	_	_
90	_	_
%	_	_
95	_	_
%	_	_
100	_	_
%	_	_
V	_	_
o	_	_
ti	_	_
n	_	_
g	_	_
p	_	_
e	_	_
rc	_	_
e	_	_
n	_	_
ta	_	_
g	_	_
e	_	_
t	_	_
o	_	_
S	_	_
R	_	_
N	_	_
T	_	_
T	_	_
XH	_	_
H	_	_
M	_	_
L	_	_
XL	_	_
Fig.	_	_
7	_	_
:	_	_
Percentage	_	_
of	_	_
votes	_	_
of	_	_
SRNTT	_	_
as	_	_
compared	_	_
to	_	_
each	_	_
of	_	_
other	_	_
methods	_	_
.	_	_

#241
Fig.	_	_
8	_	_
:	_	_
The	_	_
texture	_	_
is	_	_
enhanced	_	_
conditioned	_	_
on	_	_
the	_	_
reference	_	_
that	_	_
is	_	_
shown	_	_
in	_	_
the	_	_
bottom-right	_	_
corner	_	_
.	_	_

#242
Please	_	_
zoom	_	_
in	_	_
for	_	_
better	_	_
view	_	_
.	_	_

#243
other	_	_
six	_	_
methods	_	_
,	_	_
i.e.	_	_
,	_	_
Landmark	_	_
,	_	_
SCN	_	_
,	_	_
DRCN	_	_
,	_	_
EDSR	_	_
,	_	_
ENet	_	_
,	_	_
and	_	_
SRGAN	_	_
.	_	_

#244
We	_	_
present	_	_
the	_	_
users	_	_
with	_	_
pair-wise	_	_
comparisons	_	_
,	_	_
i.e.	_	_
,	_	_
SRNTT	_	_
vs.	_	_
other	_	_
,	_	_
and	_	_
ask	_	_
the	_	_
users	_	_
to	_	_
select	_	_
the	_	_
one	_	_
with	_	_
better	_	_
visual	_	_
quality	_	_
and	_	_
more	_	_
natural	_	_
looking	_	_
.	_	_

#245
For	_	_
each	_	_
reference	_	_
level	_	_
,	_	_
1,890	_	_
votes	_	_
are	_	_
collected	_	_
on	_	_
the	_	_
testing	_	_
results	_	_
randomly	_	_
selected	_	_
from	_	_
the	_	_
CUFED5	_	_
dataset	_	_
.	_	_

#246
Fig.	_	_
7	_	_
shows	_	_
the	_	_
voting	_	_
results	_	_
,	_	_
where	_	_
the	_	_
percentages	_	_
of	_	_
votes	_	_
of	_	_
SRNTT	_	_
as	_	_
compared	_	_
to	_	_
other	_	_
methods	_	_
,	_	_
and	_	_
demonstrate	_	_
a	_	_
roughly	_	_
descending	_	_
trend	_	_
as	_	_
the	_	_
references	_	_
become	_	_
less	_	_
similar	_	_
to	_	_
the	_	_
LR	_	_
image	_	_
.	_	_

#247
5.4	_	_
Texture	_	_
transfer	_	_
results	_	_

#248
More	_	_
general	_	_
but	_	_
still	_	_
extreme	_	_
for	_	_
existing	_	_
reference-based	_	_
SR	_	_
methods	_	_
,	_	_
the	_	_
reference	_	_
could	_	_
be	_	_
an	_	_
arbitrary	_	_
image	_	_
,	_	_
which	_	_
may	_	_
significantly	_	_
deviate	_	_
from	_	_
ILR	_	_
in	_	_
aspect	_	_
of	_	_
content	_	_
and	_	_
texture	_	_
.	_	_

#249
An	_	_
example	_	_
is	_	_
shown	_	_
in	_	_
Fig.	_	_
8	_	_
,	_	_
where	_	_
the	_	_
SR	_	_
results	_	_
are	_	_
conditioned	_	_
on	_	_
the	_	_
references	_	_
shown	_	_
in	_	_
the	_	_
bottom-right	_	_
corner	_	_
.	_	_

#250
SRNTT	_	_
could	_	_
adaptively	_	_
transfer	_	_
correlated	_	_
textures	_	_
to	_	_
ISR	_	_
,	_	_
thus	_	_
presenting	_	_
enhanced	_	_
texture	_	_
conditioned	_	_
on	_	_
the	_	_
reference	_	_
.	_	_

#251
Comparing	_	_
the	_	_
first	_	_
and	_	_
last	_	_
results	_	_
,	_	_
the	_	_
latter	_	_
is	_	_
visually	_	_
sharper	_	_
because	_	_
its	_	_
reference	_	_
carries	_	_
richer	_	_
texture	_	_
and	_	_
with	_	_
higher	_	_
resolution	_	_
.	_	_

#252
The	_	_
third	_	_
result	_	_
shows	_	_
strong	_	_
edge	_	_
as	_	_
the	_	_
reference	_	_
.	_	_

#253
5.5	_	_
Investigation	_	_
on	_	_
extreme	_	_
conditions	_	_

#254
This	_	_
section	_	_
investigates	_	_
extreme	_	_
cases	_	_
in	_	_
reference-conditioned	_	_
SR	_	_
where	_	_
the	_	_
reference	_	_
is	_	_
simply	_	_
image	_	_
with	_	_
homogeneous	_	_
intensity	_	_
levels	_	_
or	_	_
even	_	_
random	_	_
noise	_	_
.	_	_

#255
The	_	_
proposed	_	_
SRNTT	_	_
can	_	_
cope	_	_
with	_	_
these	_	_
extreme	_	_
cases	_	_
by	_	_
introducing	_	_
the	_	_
similarity	_	_
map	_	_
Ms	_	_
,	_	_
which	_	_
could	_	_
effectively	_	_
suppress	_	_
unrelated	_	_
textures	_	_
.	_	_

#256
We	_	_
also	_	_
train	_	_
SRNTT	_	_
without	_	_
Ms	_	_
,	_	_
which	_	_
is	_	_
referred	_	_
to	_	_
as	_	_
SRNTT/Ms	_	_
.	_	_

#257
Without	_	_
considering	_	_
the	_	_
extreme	_	_
references	_	_
,	_	_
SRNTT	_	_
and	_	_
SRNTT/Ms	_	_
show	_	_
similar	_	_

#258
14	_	_
Zhifei	_	_
Zhang	_	_
,	_	_
Zhaowen	_	_
Wang	_	_
,	_	_
Zhe	_	_
Lin	_	_
,	_	_
and	_	_
Hairong	_	_
Qi	_	_

#259
Dark	_	_
Bright	_	_
Noise	_	_
Original	_	_
S	_	_
R	_	_
N	_	_
T	_	_
T	_	_
S	_	_
R	_	_
N	_	_
T	_	_
T	_	_
/M	_	_
s	_	_
R	_	_
ef	_	_
er	_	_
en	_	_
ce	_	_
s	_	_
(	_	_
a	_	_
)	_	_
Our	_	_
results	_	_
with	_	_
extreme	_	_
references	_	_
S	_	_
R	_	_
G	_	_
A	_	_
N	_	_
E	_	_
N	_	_
et	_	_
E	_	_
D	_	_
S	_	_
R	_	_
(	_	_
b	_	_
)	_	_
Baselines	_	_
Fig.	_	_
9	_	_
:	_	_
(	_	_
a	_	_
)	_	_
The	_	_
extreme	_	_
references	_	_
and	_	_
the	_	_
corresponding	_	_
SR	_	_
results	_	_
from	_	_
the	_	_
proposed	_	_
SRNTT	_	_
and	_	_
SRNTT/Ms	_	_
which	_	_
is	_	_
a	_	_
trimmed	_	_
version	_	_
of	_	_
SRNTT	_	_
by	_	_
removing	_	_
Ms.	_	_
(	_	_
b	_	_
)	_	_
Baseline	_	_
results	_	_
for	_	_
comparison	_	_
purpose	_	_
.	_	_

#260
performance	_	_
.	_	_

#261
However	_	_
,	_	_
when	_	_
given	_	_
extreme	_	_
references	_	_
,	_	_
SRNTT/Ms	_	_
may	_	_
introduce	_	_
negative	_	_
effects	_	_
from	_	_
the	_	_
reference	_	_
as	_	_
shown	_	_
in	_	_
Fig.	_	_
9	_	_
.	_	_

#262
Given	_	_
all-dark	_	_
or	_	_
all-bright	_	_
references	_	_
,	_	_
which	_	_
do	_	_
not	_	_
provide	_	_
any	_	_
extra	_	_
texture	_	_
information	_	_
to	_	_
the	_	_
conditional	_	_
texture	_	_
transfer	_	_
network	_	_
,	_	_
the	_	_
results	_	_
of	_	_
SRNTT	_	_
and	_	_
SRNTT/Ms	_	_
are	_	_
close	_	_
to	_	_
the	_	_
state-of-the-art	_	_
GAN-based	_	_
methods	_	_
,	_	_
i.e.	_	_
,	_	_
ENet	_	_
and	_	_
SRGAN	_	_
.	_	_

#263
However	_	_
,	_	_
given	_	_
the	_	_
random	_	_
noise	_	_
as	_	_
reference	_	_
,	_	_
SRNTT/Ms	_	_
transfers	_	_
the	_	_
texture	_	_
of	_	_
noise	_	_
to	_	_
the	_	_
SR	_	_
image	_	_
by	_	_
mistake	_	_
,	_	_
while	_	_
such	_	_
uncorrelated	_	_
texture	_	_
is	_	_
successfully	_	_
suppressed	_	_
by	_	_
SRNTT	_	_
,	_	_
demonstrating	_	_
the	_	_
adaptiveness	_	_
gained	_	_
from	_	_
Ms	_	_
.	_	_

#264
When	_	_
the	_	_
reference	_	_
is	_	_
perfect	_	_
,	_	_
i.e.	_	_
,	_	_
the	_	_
original	_	_
image	_	_
,	_	_
the	_	_
results	_	_
from	_	_
both	_	_
SRNTT	_	_
and	_	_
SRNTT/Ms	_	_
show	_	_
much	_	_
finer	_	_
details	_	_
.	_	_

#265
Therefore	_	_
,	_	_
Ms	_	_
plays	_	_
a	_	_
critical	_	_
role	_	_
in	_	_
suppressing	_	_
uncorrelated	_	_
textures	_	_
while	_	_
encouraging	_	_
correlated	_	_
ones	_	_
.	_	_

#266
6	_	_
Conclusion	_	_

#267
This	_	_
paper	_	_
exploited	_	_
the	_	_
reference-conditioned	_	_
solution	_	_
for	_	_
solving	_	_
SR	_	_
problems	_	_
where	_	_
the	_	_
reference	_	_
can	_	_
be	_	_
an	_	_
arbitrary	_	_
image	_	_
.	_	_

#268
We	_	_
proposed	_	_
SRNTT	_	_
,	_	_
an	_	_
end-to-end	_	_
network	_	_
structure	_	_
that	_	_
performs	_	_
adaptive	_	_
texture	_	_
transfer	_	_
from	_	_
the	_	_
reference	_	_
to	_	_
recover	_	_
more	_	_
plausible	_	_
texture	_	_
in	_	_
the	_	_
SR	_	_
image	_	_
.	_	_

#269
Both	_	_
quantitative	_	_
and	_	_
qualitative	_	_
experiments	_	_
were	_	_
conducted	_	_
to	_	_
demonstrate	_	_
the	_	_
effectiveness	_	_
and	_	_
adaptiveness	_	_
of	_	_
SRNTT	_	_
,	_	_
even	_	_
with	_	_
extreme	_	_
cases	_	_
of	_	_
references	_	_
.	_	_

#270
In	_	_
addition	_	_
,	_	_
a	_	_
new	_	_
dataset	_	_
CUFED5	_	_
was	_	_
constructed	_	_
to	_	_
facilitate	_	_
the	_	_
evaluation	_	_
of	_	_
reference-conditioned	_	_
SR	_	_
methods	_	_
.	_	_

#271
It	_	_
also	_	_
provides	_	_
a	_	_
benchmark	_	_
for	_	_
future	_	_
reference-based	_	_
SR	_	_
research	_	_
in	_	_
general	_	_
.	_	_

#272
Reference-Conditioned	_	_
Super-Resolution	_	_
by	_	_
Neural	_	_
Texture	_	_
Transfer	_	_
15	_	_