#0
Detection	_	_
and	_	_
Analysis	_	_
of	_	_
Content	_	_
Creator	_	_
Collaborations	_	_
in	_	_
YouTube	_	_
Videos	_	_
using	_	_
Face-	_	_
and	_	_
Speaker-Recognition	_	_
Moritz	_	_
Lode1	_	_
,	_	_
Michael	_	_
Örtl1	_	_
,	_	_
Christian	_	_
Koch2	_	_
,	_	_
Amr	_	_
Rizk2	_	_
,	_	_
Ralf	_	_
Steinmetz2	_	_

#1
1	_	_
Technische	_	_
Universität	_	_
Darmstadt	_	_
,	_	_
Germany	_	_

#2
2	_	_
Multimedia	_	_
Communications	_	_
Lab	_	_
,	_	_
Technische	_	_
Universität	_	_
Darmstadt	_	_
,	_	_
Germany	_	_

#3
Email	_	_
:	_	_
{	_	_
Moritz.Lode	_	_
|	_	_
Michael.Oertl	_	_
}	_	_
@	_	_
stud.tu-darmstadt.de	_	_
,	_	_
{	_	_
Christian.Koch	_	_
|	_	_
Amr.Rizk	_	_
|	_	_
Ralf.Steinmetz	_	_
}	_	_
@	_	_
kom.tu-darmstadt.de	_	_
Abstract—This	_	_
paper	_	_
demonstrates	_	_
the	_	_
application	_	_
of	_	_
speaker	_	_
recognition	_	_
for	_	_
the	_	_
detection	_	_
of	_	_
collaborations	_	_
in	_	_
YouTube	_	_
videos	_	_
.	_	_

#4
Here	_	_
,	_	_
we	_	_
extend	_	_
CATANA	_	_
,	_	_
which	_	_
is	_	_
an	_	_
existing	_	_
framework	_	_
for	_	_
detection	_	_
and	_	_
analysis	_	_
of	_	_
YouTube	_	_
collaborations	_	_
that	_	_
utilizes	_	_
face	_	_
recognition	_	_
for	_	_
the	_	_
detection	_	_
of	_	_
collaborators	_	_
and	_	_
naturally	_	_
performs	_	_
poor	_	_
on	_	_
video-content	_	_
without	_	_
appearing	_	_
faces	_	_
.	_	_

#5
This	_	_
work	_	_
proposes	_	_
an	_	_
extension	_	_
that	_	_
uses	_	_
active	_	_
speaker	_	_
detection	_	_
and	_	_
speaker	_	_
recognition	_	_
to	_	_
improve	_	_
the	_	_
detection	_	_
accuracy	_	_
in	_	_
YouTube	_	_
collaborations	_	_
.	_	_

#6
I	_	_
.	_	_

#7
INTRODUCTION	_	_
YOUTUBE	_	_
is	_	_
one	_	_
of	_	_
the	_	_
most	_	_
popular	_	_
video-sharing	_	_
platforms	_	_
,	_	_
being	_	_
the	_	_
second	_	_
largest	_	_
traffic	_	_
source	_	_
among	_	_
all	_	_
websites	_	_
globally	_	_
[	_	_
1	_	_
]	_	_
.	_	_

#8
Since	_	_
Google	_	_
purchased	_	_
YouTube	_	_
in	_	_
2007	_	_
,	_	_
the	_	_
YouTube	_	_
environment	_	_
changed	_	_
significantly	_	_
,	_	_
with	_	_
Google	_	_
implementing	_	_
the	_	_
so-called	_	_
YouTube	_	_
Partner	_	_
Program	_	_
(	_	_
YPP	_	_
)	_	_
.	_	_

#9
As	_	_
of	_	_
then	_	_
,	_	_
the	_	_
users	_	_
were	_	_
given	_	_
the	_	_
possibility	_	_
to	_	_
monetize	_	_
their	_	_
uploaded	_	_
videos	_	_
.	_	_

#10
YouTube	_	_
thereby	_	_
monetizes	_	_
videos	_	_
through	_	_
advertisement	_	_
and	_	_
paid	_	_
subscriptions	_	_
.	_	_

#11
Through	_	_
this	_	_
,	_	_
the	_	_
number	_	_
of	_	_
uploaders	_	_
,	_	_
or	_	_
so-called	_	_
content-creator	_	_
increased	_	_
significantly	_	_
.	_	_

#12
There	_	_
are	_	_
now	_	_
more	_	_
than	_	_
10,000	_	_
of	_	_
these	_	_
content	_	_
creators	_	_
making	_	_
a	_	_
living	_	_
solely	_	_
from	_	_
online	_	_
videos	_	_
[	_	_
26	_	_
]	_	_
.	_	_

#13
Moreover	_	_
,	_	_
as	_	_
of	_	_
today	_	_
,	_	_
YouTube	_	_
receives	_	_
video	_	_
content	_	_
at	_	_
a	_	_
rate	_	_
of	_	_
more	_	_
than	_	_
400	_	_
hours/min	_	_
[	_	_
22	_	_
]	_	_
.	_	_

#14
Additionally	_	_
,	_	_
this	_	_
brought	_	_
profit-oriented	_	_
organizations	_	_
into	_	_
YouTube	_	_
,	_	_
so-called	_	_
multi	_	_
channel	_	_
networks	_	_
(	_	_
MCN	_	_
)	_	_
formed	_	_
.	_	_

#15
MCNs	_	_
thereby	_	_
incorporate	_	_
up	_	_
to	_	_
hundred-thousand	_	_
channels	_	_
.	_	_

#16
Associated	_	_
channels	_	_
are	_	_
supported	_	_
by	_	_
the	_	_
production	_	_
of	_	_
video	_	_
content	_	_
,	_	_
for	_	_
which	_	_
in	_	_
return	_	_
the	_	_
MCN	_	_
obtains	_	_
a	_	_
share	_	_
of	_	_
the	_	_
channel’s	_	_
revenue	_	_
.	_	_

#17
To	_	_
increase	_	_
the	_	_
popularity	_	_
of	_	_
a	_	_
channel	_	_
,	_	_
measured	_	_
in	_	_
view	_	_
and	_	_
subscriber	_	_
counts	_	_
,	_	_
channels	_	_
established	_	_
strategies	_	_
like	_	_
collaboration	_	_
with	_	_
other	_	_
channels	_	_
.	_	_

#18
A	_	_
collaboration	_	_
occurs	_	_
when	_	_
two	_	_
or	_	_
more	_	_
channels	_	_
create	_	_
a	_	_
video	_	_
together	_	_
and	_	_
upload	_	_
this	_	_
to	_	_
one	_	_
or	_	_
multiple	_	_
of	_	_
their	_	_
channels	_	_
.	_	_

#19
This	_	_
interaction	_	_
aims	_	_
to	_	_
increase	_	_
the	_	_
popularity	_	_
of	_	_
the	_	_
channels	_	_
by	_	_
potentially	_	_
combining	_	_
their	_	_
audience	_	_
and	_	_
is	_	_
well	_	_
established	_	_
and	_	_
often	_	_
encouraged	_	_
by	_	_
MCNs	_	_
.	_	_

#20
However	_	_
,	_	_
no	_	_
reliable	_	_
information	_	_
stating	_	_
collaborations	_	_
is	_	_
available	_	_
from	_	_
YouTube	_	_
.	_	_

#21
To	_	_
determine	_	_
collaborations	_	_
,	_	_
it	_	_
is	_	_
necessary	_	_
to	_	_
detect	_	_
the	_	_
interaction	_	_
in	_	_
video-content	_	_
.	_	_

#22
Through	_	_
this	_	_
detection	_	_
,	_	_
the	_	_
effects	_	_
and	_	_
properties	_	_
of	_	_
the	_	_
collaborations	_	_
on	_	_
YouTube	_	_
popularity	_	_
can	_	_
be	_	_
analyzed	_	_
.	_	_

#23
This	_	_
knowledge	_	_
can	_	_
then	_	_
be	_	_
leveraged	_	_
for	_	_
improving	_	_
YouTube	_	_
strategies	_	_
,	_	_
as	_	_
well	_	_
as	_	_
popularity	_	_
predictions	_	_
,	_	_
e.g.	_	_
,	_	_
for	_	_
content	_	_
distribution	_	_
.	_	_

#24
II	_	_
.	_	_

#25
MOTIVATION	_	_
For	_	_
the	_	_
detection	_	_
of	_	_
collaborations	_	_
in	_	_
YouTube	_	_
,	_	_
the	_	_
existing	_	_
work	_	_
CATANA	_	_
[	_	_
13	_	_
]	_	_
leverages	_	_
occurring	_	_
faces	_	_
in	_	_
the	_	_
video	_	_
through	_	_
face	_	_
recognition	_	_
to	_	_
identify	_	_
the	_	_
collaborators	_	_
.	_	_

#26
While	_	_
CATANA	_	_
yields	_	_
good	_	_
results	_	_
on	_	_
video	_	_
content	_	_
with	_	_
a	_	_
high	_	_
number	_	_
of	_	_
appearing	_	_
faces	_	_
,	_	_
in	_	_
cases	_	_
with	_	_
less	_	_
or	_	_
no	_	_
appearing	_	_
faces	_	_
it	_	_
would	_	_
not	_	_
perform	_	_
well	_	_
resulting	_	_
in	_	_
no	_	_
detections	_	_
.	_	_

#27
One	_	_
of	_	_
these	_	_
cases	_	_
are	_	_
videos	_	_
in	_	_
the	_	_
popular	_	_
category	_	_
Gaming	_	_
,	_	_
in	_	_
which	_	_
primarily	_	_
the	_	_
game	_	_
content	_	_
is	_	_
visible	_	_
and	_	_
often	_	_
no	_	_
faces	_	_
appear	_	_
.	_	_

#28
In	_	_
this	_	_
prior	_	_
work	_	_
,	_	_
videos	_	_
of	_	_
the	_	_
category	_	_
Gaming	_	_
represented	_	_
a	_	_
significant	_	_
part	_	_
of	_	_
the	_	_
used	_	_
dataset	_	_
,	_	_
with	_	_
43	_	_
%	_	_
of	_	_
all	_	_
videos	_	_
.	_	_

#29
To	_	_
improve	_	_
the	_	_
overall	_	_
detection	_	_
results	_	_
and	_	_
cover	_	_
cases	_	_
with	_	_
no	_	_
visible	_	_
faces	_	_
,	_	_
we	_	_
propose	_	_
to	_	_
leverage	_	_
the	_	_
audio	_	_
content	_	_
as	_	_
well	_	_
.	_	_

#30
To	_	_
do	_	_
this	_	_
,	_	_
active	_	_
speaker	_	_
detection	_	_
and	_	_
speaker	_	_
recognition	_	_
are	_	_
applied	_	_
to	_	_
the	_	_
videos	_	_
,	_	_
additionally	_	_
to	_	_
the	_	_
face	_	_
recognition	_	_
approach	_	_
.	_	_

#31
For	_	_
this	_	_
,	_	_
an	_	_
extension	_	_
of	_	_
the	_	_
existing	_	_
framework	_	_
CATANA	_	_
is	_	_
presented	_	_
in	_	_
this	_	_
work	_	_
.	_	_

#32
III	_	_
.	_	_

#33
RELATED	_	_
WORK	_	_
In	_	_
the	_	_
following	_	_
,	_	_
we	_	_
introduce	_	_
existing	_	_
work	_	_
on	_	_
the	_	_
subject	_	_
of	_	_
collaboration	_	_
detection	_	_
,	_	_
specifically	_	_
the	_	_
CATANA	_	_
[	_	_
13	_	_
]	_	_
framework	_	_
.	_	_

#34
Further	_	_
related	_	_
work	_	_
on	_	_
the	_	_
applied	_	_
methods	_	_
of	_	_
speaker	_	_
recognition	_	_
as	_	_
well	_	_
as	_	_
face	_	_
tracking	_	_
and	_	_
active	_	_
speaker	_	_
detection	_	_
are	_	_
discussed	_	_
in	_	_
this	_	_
section	_	_
.	_	_

#35
A	_	_
.	_	_

#36
Collaboration	_	_
Detection	_	_
Concerning	_	_
the	_	_
analysis	_	_
and	_	_
detection	_	_
of	_	_
collaborations	_	_
in	_	_
YouTube	_	_
,	_	_
to	_	_
the	_	_
best	_	_
of	_	_
our	_	_
knowledge	_	_
,	_	_
not	_	_
much	_	_
existing	_	_
work	_	_
was	_	_
conducted	_	_
until	_	_
now	_	_
.	_	_

#37
Koch	_	_
et	_	_
al.	_	_
[	_	_
13	_	_
]	_	_
proposed	_	_
an	_	_
unsupervised	_	_
framework	_	_
for	_	_
collaboration	_	_
detection	_	_
in	_	_
YouTube	_	_
videos	_	_
based	_	_
on	_	_
face	_	_
recognition	_	_
named	_	_
CATANA	_	_
.	_	_

#38
In	_	_
addition	_	_
to	_	_
the	_	_
detection	_	_
,	_	_
the	_	_
framework	_	_
is	_	_
also	_	_
capable	_	_
of	_	_
collecting	_	_
and	_	_
analyzing	_	_
YouTube	_	_
statistics	_	_
concerning	_	_
collaborations	_	_
and	_	_
their	_	_
impact	_	_
on	_	_
YouTube	_	_
popularity	_	_
.	_	_

#39
The	_	_
system	_	_
architecture	_	_
is	_	_
illustrated	_	_
in	_	_
Figure	_	_
1a	_	_
.	_	_

#40
For	_	_
the	_	_
detection	_	_
of	_	_
collaborations	_	_
in	_	_
video	_	_
content	_	_
,	_	_
the	_	_
framework	_	_
detects	_	_
the	_	_
appearing	_	_
individuals	_	_
in	_	_
a	_	_
set	_	_
of	_	_
videos	_	_
,	_	_
and	_	_
creates	_	_
associations	_	_
between	_	_
them	_	_
.	_	_

#41
This	_	_
procedure	_	_
is	_	_
similar	_	_
to	_	_
a	_	_
multi-class	_	_
classification	_	_
problem	_	_
,	_	_
for	_	_
which	_	_
no	_	_
prior	_	_
knowledge	_	_
about	_	_
the	_	_
number	_	_
of	_	_
individuals	_	_
,	_	_
nor	_	_
training	_	_
data	_	_
is	_	_
available	_	_
.	_	_

#42
Individuals	_	_
are	_	_
thereby	_	_
detected	_	_
frame-wise	_	_
using	_	_
an	_	_
adaptive	_	_
frame	_	_
selection	_	_
method	_	_
.	_	_

#43
Detected	_	_
faces	_	_
are	_	_
then	_	_
further	_	_
processed	_	_
through	_	_
a	_	_
CNN-based	_	_
face	_	_
recognition	_	_
method	_	_
extracting	_	_
1,792-dimensional	_	_
face	_	_
embeddings	_	_
which	_	_
are	_	_
stored	_	_
for	_	_
clustering	_	_
in	_	_
a	_	_
later	_	_
step	_	_
.	_	_

#44
Global	_	_
clustering	_	_
on	_	_
all	_	_
found	_	_
face	_	_
embeddings	_	_
using	_	_
the	_	_
HDBSCAN	_	_
clustering	_	_
ar	_	_
X	_	_
iv	_	_
:1	_	_
7	_	_
.	_	_

#45
0v	_	_
1	_	_
[	_	_
cs	_	_
.C	_	_
V	_	_
]	_	_
5	_	_
J	_	_
ul	_	_
2	_	_
(	_	_
a	_	_
)	_	_
CATANA	_	_
system	_	_
architecture	_	_
[	_	_
13	_	_
]	_	_
.	_	_

#46
(	_	_
b	_	_
)	_	_
Video	_	_
views	_	_
growth	_	_
factor	_	_
for	_	_
collaborations	_	_
[	_	_
13	_	_
]	_	_
.	_	_

#47
Fig.	_	_
1	_	_
:	_	_
(	_	_
a	_	_
)	_	_
CATANA	_	_
architecture	_	_
.	_	_

#48
(	_	_
b	_	_
)	_	_
Impact	_	_
of	_	_
collaborations	_	_
on	_	_
the	_	_
growth	_	_
of	_	_
the	_	_
number	_	_
of	_	_
video	_	_
views	_	_
.	_	_

#49
algorithm	_	_
[	_	_
11	_	_
]	_	_
then	_	_
associates	_	_
the	_	_
appearing	_	_
individuals	_	_
across	_	_
videos	_	_
.	_	_

#50
These	_	_
associations	_	_
are	_	_
leveraged	_	_
for	_	_
the	_	_
assignment	_	_
of	_	_
channel	_	_
content-creator	_	_
and	_	_
the	_	_
collaboration	_	_
detection	_	_
based	_	_
on	_	_
the	_	_
number	_	_
of	_	_
appearances	_	_
in	_	_
a	_	_
channel	_	_
.	_	_

#51
The	_	_
found	_	_
collaborations	_	_
are	_	_
thereby	_	_
modeled	_	_
as	_	_
a	_	_
graph	_	_
,	_	_
with	_	_
channels	_	_
as	_	_
nodes	_	_
and	_	_
collaborations	_	_
as	_	_
directed	_	_
edges	_	_
between	_	_
channels	_	_
.	_	_

#52
Figure	_	_
2	_	_
shows	_	_
an	_	_
example	_	_
of	_	_
such	_	_
a	_	_
graph	_	_
for	_	_
the	_	_
channels	_	_
A	_	_
,	_	_
B	_	_
,	_	_
C	_	_
,	_	_
and	_	_
collaborations	_	_
concerning	_	_
the	_	_
persons	_	_
ID1	_	_
and	_	_
ID2	_	_
.	_	_

#53
A	_	_
collaboration	_	_
is	_	_
thereby	_	_
modeled	_	_
as	_	_
a	_	_
directed	_	_
edge	_	_
.	_	_

#54
The	_	_
edge	_	_
ID1	_	_
,	_	_
3	_	_
for	_	_
example	_	_
,	_	_
describes	_	_
the	_	_
appearing	_	_
of	_	_
ID1	_	_
from	_	_
channel	_	_
A	_	_
in	_	_
a	_	_
total	_	_
of	_	_
three	_	_
videos	_	_
of	_	_
channel	_	_
B	_	_
.	_	_

#55
In	_	_
the	_	_
related	_	_
work	_	_
[	_	_
13	_	_
]	_	_
,	_	_
data	_	_
for	_	_
a	_	_
total	_	_
of	_	_
7,492	_	_
channels	_	_
and	_	_
more	_	_
than	_	_
200k	_	_
videos	_	_
were	_	_
collected	_	_
in	_	_
a	_	_
timespan	_	_
of	_	_
3	_	_
months	_	_
.	_	_

#56
Due	_	_
to	_	_
difficulties	_	_
in	_	_
videos	_	_
without	_	_
any	_	_
appearing	_	_
faces	_	_
and	_	_
computation-constraints	_	_
,	_	_
only	_	_
a	_	_
subset	_	_
of	_	_
these	_	_
videos	_	_
were	_	_
analyzed	_	_
.	_	_

#57
In	_	_
total	_	_
3,925	_	_
collaborations	_	_
for	_	_
1,599	_	_
channels	_	_
were	_	_
found	_	_
in	_	_
this	_	_
time	_	_
,	_	_
on	_	_
average	_	_
2.8	_	_
collaboration	_	_
per	_	_
channel	_	_
.	_	_

#58
Further	_	_
different	_	_
aspects	_	_
of	_	_
the	_	_
found	_	_
collaborations	_	_
concerning	_	_
categories	_	_
,	_	_
popularity	_	_
and	_	_
MCNmemberships	_	_
were	_	_
analyzed	_	_
.	_	_

#59
Results	_	_
show	_	_
that	_	_
collaborations	_	_
occurred	_	_
mostly	_	_
in	_	_
the	_	_
category	_	_
Entertainment	_	_
.	_	_

#60
Concerning	_	_
MCNs	_	_
membership	_	_
,	_	_
collaborations	_	_
within	_	_
their	_	_
own	_	_
network	_	_
,	_	_
or	_	_
with	_	_
non-associated	_	_
channels	_	_
were	_	_
preeminent	_	_
.	_	_

#61
Concerning	_	_
the	_	_
popularity	_	_
impact	_	_
of	_	_
collaborations	_	_
,	_	_
a	_	_
positive	_	_
effect	_	_
in	_	_
both	_	_
channel	_	_
and	_	_
video	_	_
statistics	_	_
was	_	_
found	_	_
.	_	_

#62
One	_	_
of	_	_
them	_	_
is	_	_
the	_	_
average	_	_
growth	_	_
of	_	_
collaboration	_	_
video’s	_	_
view-counts	_	_
,	_	_
which	_	_
was	_	_
found	_	_
in	_	_
average	_	_
34	_	_
%	_	_
higher	_	_
than	_	_
these	_	_
of	_	_
noncollaboration	_	_
videos	_	_
of	_	_
the	_	_
same	_	_
channel	_	_
.	_	_

#63
Figure	_	_
1b	_	_
shows	_	_
the	_	_
mean	_	_
video	_	_
view-count	_	_
growth	_	_
factor	_	_
using	_	_
a	_	_
confidence	_	_
interval	_	_
of	_	_
95	_	_
%	_	_
.	_	_

#64
Difficulties	_	_
in	_	_
the	_	_
detection	_	_
of	_	_
collaborations	_	_
in	_	_
video	_	_
content	_	_
without	_	_
appearing	_	_
faces	_	_
were	_	_
found	_	_
,	_	_
especially	_	_
in	_	_
the	_	_
prominent	_	_
video	_	_
category	_	_
Gaming	_	_
,	_	_
which	_	_
constituted	_	_
43	_	_
%	_	_
of	_	_
the	_	_
total	_	_
number	_	_
of	_	_
videos	_	_
in	_	_
their	_	_
dataset	_	_
.	_	_

#65
Due	_	_
to	_	_
these	_	_
difficulties	_	_
with	_	_
nearly	_	_
half	_	_
of	_	_
their	_	_
video	_	_
data	_	_
resulting	_	_
in	_	_
incorrect	_	_
or	_	_
no	_	_
detections	_	_
,	_	_
a	_	_
more	_	_
sophisticated	_	_
approach	_	_
improving	_	_
the	_	_
detection	_	_
rate	_	_
is	_	_
necessary	_	_
.	_	_

#66
For	_	_
this	_	_
reason	_	_
,	_	_
we	_	_
will	_	_
build	_	_
on	_	_
the	_	_
existing	_	_
framework	_	_
and	_	_
extend	_	_
the	_	_
detection	_	_
by	_	_
using	_	_
active	_	_
speaker	_	_
detection	_	_
and	_	_
speaker	_	_
recognition	_	_
.	_	_

#67
B	_	_
.	_	_

#68
Speaker	_	_
Recognition	_	_
In	_	_
this	_	_
section	_	_
,	_	_
relevant	_	_
existing	_	_
approaches	_	_
on	_	_
speaker	_	_
recognition	_	_
are	_	_
presented	_	_
and	_	_
the	_	_
possible	_	_
application	_	_
in	_	_
this	_	_
Fig.	_	_
2	_	_
:	_	_
Collaboration	_	_
graph	_	_
model	_	_
[	_	_
13	_	_
]	_	_
.	_	_

#69
work	_	_
discussed	_	_
.	_	_

#70
Nagrani	_	_
et	_	_
al.	_	_
[	_	_
20	_	_
]	_	_
present	_	_
VoxCeleb	_	_
,	_	_
in	_	_
which	_	_
they	_	_
made	_	_
multiple	_	_
contributions	_	_
concerning	_	_
speaker	_	_
recognition	_	_
.	_	_

#71
First	_	_
,	_	_
a	_	_
fully	_	_
automated	_	_
pipeline	_	_
is	_	_
proposed	_	_
for	_	_
the	_	_
creation	_	_
of	_	_
a	_	_
speaker	_	_
recognition	_	_
dataset	_	_
from	_	_
online	_	_
videos	_	_
.	_	_

#72
The	_	_
pipeline	_	_
thereby	_	_
combines	_	_
active	_	_
speaker	_	_
detection	_	_
and	_	_
face	_	_
recognition	_	_
to	_	_
identify	_	_
a	_	_
speaker	_	_
in	_	_
the	_	_
video	_	_
content	_	_
and	_	_
is	_	_
illustrated	_	_
in	_	_
Figure	_	_
3	_	_
.	_	_

#73
For	_	_
a	_	_
predefined	_	_
list	_	_
of	_	_
2	_	_
,	_	_
622	_	_
people	_	_
,	_	_
videos	_	_
from	_	_
YouTube	_	_
are	_	_
extracted	_	_
and	_	_
analyzed	_	_
through	_	_
the	_	_
pipeline	_	_
.	_	_

#74
Finally	_	_
resulting	_	_
in	_	_
utterances	_	_
of	_	_
1	_	_
,	_	_
251	_	_
people	_	_
.	_	_

#75
Reason	_	_
for	_	_
the	_	_
difference	_	_
in	_	_
the	_	_
number	_	_
of	_	_
individuals	_	_
is	_	_
that	_	_
during	_	_
the	_	_
pipeline	_	_
process	_	_
videos	_	_
of	_	_
individuals	_	_
were	_	_
discarded	_	_
if	_	_
no	_	_
active	_	_
speaker	_	_
could	_	_
be	_	_
detected	_	_
or	_	_
the	_	_
speaker	_	_
not	_	_
identified	_	_
.	_	_

#76
Using	_	_
existing	_	_
work	_	_
of	_	_
Chung	_	_
et	_	_
al.	_	_
[	_	_
6	_	_
]	_	_
for	_	_
active	_	_
speaker	_	_
detection	_	_
and	_	_
Simonyan	_	_
et	_	_
al.	_	_
[	_	_
25	_	_
]	_	_
for	_	_
face	_	_
recognition	_	_
,	_	_
hundreds	_	_
of	_	_
thousands	_	_
of	_	_
video-audio	_	_
segments	_	_
were	_	_
automatically	_	_
extracted	_	_
with	_	_
a	_	_
high	_	_
precision	_	_
concerning	_	_
speaker	_	_
identity	_	_
.	_	_

#77
This	_	_
collected	_	_
speaker	_	_
dataset	_	_
called	_	_
VoxCeleb	_	_
[	_	_
27	_	_
]	_	_
is	_	_
made	_	_
publicly	_	_
available	_	_
and	_	_
consists	_	_
of	_	_
over	_	_
140k	_	_
utterances	_	_
of	_	_
1	_	_
,	_	_
251	_	_
individuals	_	_
.	_	_

#78
The	_	_
dataset	_	_
was	_	_
then	_	_
further	_	_
leveraged	_	_
in	_	_
their	_	_
second	_	_
contribution	_	_
,	_	_
a	_	_
CNN-based	_	_
architecture	_	_
for	_	_
speaker	_	_
identification	_	_
and	_	_
verification	_	_
.	_	_

#79
This	_	_
architecture	_	_
is	_	_
based	_	_
on	_	_
the	_	_
work	_	_
of	_	_
VGG-M	_	_
[	_	_
5	_	_
]	_	_
,	_	_
which	_	_
is	_	_
a	_	_
network	_	_
designed	_	_
for	_	_
image	_	_
classification	_	_
achieving	_	_
state	_	_
of	_	_
the	_	_
art	_	_
performance	_	_
in	_	_
this	_	_
task	_	_
.	_	_

#80
The	_	_
image	_	_
classification	_	_
architecture	_	_
is	_	_
thereby	_	_
leveraged	_	_
by	_	_
generating	_	_
spectrograms	_	_
in	_	_
a	_	_
sliding	_	_
window	_	_
fashion	_	_
,	_	_
each	_	_
representing	_	_
3	_	_
seconds	_	_
of	_	_
speech	_	_
,	_	_
and	_	_
uses	_	_
these	_	_
as	_	_
input	_	_
.	_	_

#81
The	_	_
proposed	_	_
network	_	_
was	_	_
then	_	_
trained	_	_
using	_	_
the	_	_
described	_	_
VoxCeleb	_	_
speaker	_	_
dataset	_	_
.	_	_

#82
For	_	_
the	_	_
speaker	_	_
identification	_	_
task	_	_
a	_	_
1	_	_
,	_	_
251-dim	_	_
.	_	_

#83
softmax	_	_
layer	_	_
is	_	_
used	_	_
as	_	_
the	_	_
Fig.	_	_
3	_	_
:	_	_
VoxCeleb	_	_
active	_	_
speaker	_	_
verification	_	_
pipeline	_	_
as	_	_
given	_	_
in	_	_
[	_	_
20	_	_
]	_	_
.	_	_

#84
output	_	_
to	_	_
produce	_	_
a	_	_
classification	_	_
over	_	_
the	_	_
1,251	_	_
individuals	_	_
in	_	_
the	_	_
dataset	_	_
.	_	_

#85
For	_	_
identification	_	_
,	_	_
an	_	_
accuracy	_	_
of	_	_
92.1	_	_
%	_	_
was	_	_
achieved	_	_
.	_	_

#86
Additionally	_	_
,	_	_
they	_	_
compared	_	_
their	_	_
approach	_	_
with	_	_
the	_	_
de	_	_
facto	_	_
state	_	_
of	_	_
the	_	_
art	_	_
in	_	_
the	_	_
recent	_	_
years	_	_
,	_	_
an	_	_
i-vector	_	_
based	_	_
[	_	_
8	_	_
]	_	_
approach	_	_
.	_	_

#87
This	_	_
approach	_	_
thereby	_	_
achieved	_	_
only	_	_
an	_	_
accuracy	_	_
of	_	_
75.6	_	_
%	_	_
on	_	_
the	_	_
dataset	_	_
.	_	_

#88
For	_	_
the	_	_
verification	_	_
task	_	_
,	_	_
feature	_	_
vectors	_	_
are	_	_
extracted	_	_
one	_	_
layer	_	_
before	_	_
the	_	_
softmax	_	_
output	_	_
,	_	_
and	_	_
leveraged	_	_
as	_	_
a	_	_
speaker	_	_
embedding	_	_
.	_	_

#89
This	_	_
1	_	_
,	_	_
024-dim	_	_
.	_	_

#90
embedding	_	_
can	_	_
be	_	_
directly	_	_
used	_	_
for	_	_
speaker	_	_
comparison	_	_
using	_	_
a	_	_
distance	_	_
metric	_	_
like	_	_
the	_	_
cosine	_	_
distance	_	_
.	_	_

#91
Verification	_	_
evaluation	_	_
on	_	_
the	_	_
dataset	_	_
using	_	_
Equal	_	_
Error	_	_
Rate	_	_
(	_	_
EER	_	_
)	_	_
resulted	_	_
in	_	_
7.8	_	_
%	_	_
for	_	_
the	_	_
CNN-based	_	_
approach	_	_
,	_	_
while	_	_
only	_	_
8.8	_	_
%	_	_
for	_	_
i-vectors	_	_
(	_	_
the	_	_
less	_	_
,	_	_
the	_	_
better	_	_
)	_	_
.	_	_

#92
The	_	_
speaker	_	_
recognition	_	_
network	_	_
is	_	_
made	_	_
available	_	_
in	_	_
the	_	_
form	_	_
of	_	_
pre-trained	_	_
models	_	_
and	_	_
thus	_	_
can	_	_
be	_	_
directly	_	_
used	_	_
in	_	_
this	_	_
work	_	_
.	_	_

#93
The	_	_
proposed	_	_
embeddings	_	_
for	_	_
speaker	_	_
verification	_	_
can	_	_
thereby	_	_
be	_	_
leveraged	_	_
in	_	_
classification	_	_
,	_	_
as	_	_
well	_	_
as	_	_
clustering	_	_
.	_	_

#94
Especially	_	_
clustering	_	_
is	_	_
of	_	_
importance	_	_
in	_	_
this	_	_
work	_	_
,	_	_
as	_	_
we	_	_
do	_	_
not	_	_
have	_	_
prior	_	_
training	_	_
data	_	_
for	_	_
classification	_	_
.	_	_

#95
C.	_	_
Speaker	_	_
Diarization	_	_
Speaker	_	_
diarization	_	_
is	_	_
the	_	_
task	_	_
of	_	_
dividing	_	_
an	_	_
audio	_	_
sample	_	_
into	_	_
segments	_	_
of	_	_
different	_	_
speakers	_	_
.	_	_

#96
The	_	_
task	_	_
thereby	_	_
consists	_	_
of	_	_
multiple	_	_
steps	_	_
,	_	_
voice	_	_
activity	_	_
detection	_	_
(	_	_
VAD	_	_
)	_	_
,	_	_
speaker	_	_
model	_	_
generation	_	_
,	_	_
and	_	_
clustering	_	_
.	_	_

#97
Different	_	_
existing	_	_
approaches	_	_
are	_	_
available	_	_
and	_	_
discussed	_	_
in	_	_
this	_	_
chapter	_	_
.	_	_

#98
Rouvier	_	_
et	_	_
al.	_	_
[	_	_
23	_	_
]	_	_
present	_	_
the	_	_
LIUM	_	_
(	_	_
Laboratoire	_	_
d’Informatique	_	_
de	_	_
l’Université	_	_
du	_	_
Maine	_	_
)	_	_
Speaker	_	_
Diarization	_	_
,	_	_
an	_	_
open-source	_	_
toolbox	_	_
for	_	_
speaker	_	_
diarization	_	_
in	_	_
news	_	_
broadcasts	_	_
.	_	_

#99
The	_	_
toolbox	_	_
is	_	_
developed	_	_
to	_	_
provide	_	_
a	_	_
tool	_	_
for	_	_
the	_	_
development	_	_
of	_	_
new	_	_
diarization	_	_
systems	_	_
,	_	_
or	_	_
the	_	_
direct	_	_
application	_	_
as	_	_
an	_	_
easy	_	_
to	_	_
use	_	_
speaker	_	_
diarization	_	_
tool	_	_
.	_	_

#100
The	_	_
tool	_	_
thereby	_	_
computes	_	_
the	_	_
Mel	_	_
Frequency	_	_
Cepstral	_	_
Coefficients	_	_
(	_	_
MFCC	_	_
)	_	_
parameter	_	_
from	_	_
the	_	_
audio	_	_
and	_	_
provides	_	_
pre-trained	_	_
universal	_	_
background	_	_
models	_	_
(	_	_
UBM	_	_
)	_	_
for	_	_
the	_	_
classification	_	_
of	_	_
speech	_	_
,	_	_
non-speech	_	_
segments	_	_
.	_	_

#101
In	_	_
the	_	_
following	_	_
either	_	_
hierarchical	_	_
agglomerative	_	_
clustering	_	_
using	_	_
cross-likelihood	_	_
ratio	_	_
(	_	_
CLR	_	_
)	_	_
or	_	_
integer	_	_
linear	_	_
programming	_	_
using	_	_
i-vector	_	_
[	_	_
8	_	_
]	_	_
clustering	_	_
is	_	_
available	_	_
for	_	_
separating	_	_
the	_	_
speaker	_	_
.	_	_

#102
The	_	_
proposed	_	_
system	_	_
is	_	_
evaluated	_	_
on	_	_
three	_	_
datasets	_	_
,	_	_
ESTER1	_	_
,	_	_
ETAPE2	_	_
,	_	_
and	_	_
REPERE3	_	_
.	_	_

#103
Evaluation	_	_
metric	_	_
is	_	_
the	_	_
diarization	_	_
error	_	_
rate	_	_
(	_	_
DER	_	_
)	_	_
to	_	_
measure	_	_
the	_	_
performance	_	_
.	_	_

#104
DER	_	_
thereby	_	_
measures	_	_
the	_	_
speaking	_	_
time	_	_
attributed	_	_
to	_	_
the	_	_
correct	_	_
speaker	_	_
and	_	_
was	_	_
introduced	_	_
by	_	_
NIST	_	_
[	_	_
21	_	_
]	_	_
.	_	_

#105
Results	_	_
show	_	_
a	_	_
DER	_	_
of	_	_
8.35	_	_
%	_	_
-	_	_
24.49	_	_
%	_	_
for	_	_
the	_	_
three	_	_
evaluated	_	_
datasets	_	_
.	_	_

#106
A	_	_
direct	_	_
comparison	_	_
with	_	_
other	_	_
existing	_	_
diarization	_	_
methods	_	_
was	_	_
however	_	_
not	_	_
conducted	_	_
.	_	_

#107
With	_	_
this	_	_
insights	_	_
,	_	_
the	_	_
decision	_	_
for	_	_
applying	_	_
this	_	_
toolbox	_	_
in	_	_
our	_	_
work	_	_
should	_	_
be	_	_
based	_	_
on	_	_
further	_	_
tests	_	_
on	_	_
YouTube	_	_
video	_	_
content	_	_
,	_	_
as	_	_
this	_	_
toolbox	_	_
is	_	_
mainly	_	_
dedicated	_	_
for	_	_
news	_	_
broadcasts	_	_
.	_	_

#108
An	_	_
additional	_	_
approach	_	_
concerning	_	_
speaker	_	_
diarization	_	_
in	_	_
this	_	_
work	_	_
can	_	_
be	_	_
achieved	_	_
by	_	_
combining	_	_
different	_	_
existing	_	_
components	_	_
to	_	_
a	_	_
diarization	_	_
pipeline	_	_
consisting	_	_
out	_	_
of	_	_
the	_	_
parts	_	_
of	_	_
voice	_	_
activity	_	_
detection	_	_
,	_	_
speaker	_	_
modeling	_	_
,	_	_
and	_	_
clustering	_	_
.	_	_

#109
For	_	_
speaker	_	_
modeling	_	_
,	_	_
the	_	_
already	_	_
discussed	_	_
VoxCeleb	_	_
speaker	_	_
embeddings	_	_
model	_	_
[	_	_
20	_	_
]	_	_
can	_	_
be	_	_
used	_	_
to	_	_
model	_	_
a	_	_
speaker	_	_
to	_	_
a	_	_
feature	_	_
embedding	_	_
,	_	_
which	_	_
then	_	_
can	_	_
be	_	_
directly	_	_
applied	_	_
in	_	_
clustering	_	_
.	_	_

#110
For	_	_
the	_	_
voice	_	_
activity	_	_
detection	_	_
task	_	_
multiple	_	_
existing	_	_
tools	_	_
are	_	_
available	_	_
.	_	_

#111
One	_	_
of	_	_
the	_	_
current	_	_
state	_	_
of	_	_
the	_	_
art	_	_
VAD	_	_
systems	_	_
is	_	_
developed	_	_
by	_	_
Google	_	_
for	_	_
the	_	_
WebRTC	_	_
[	_	_
28	_	_
]	_	_
project	_	_
,	_	_
which	_	_
is	_	_
freely	_	_
available	_	_
and	_	_
easy	_	_
to	_	_
use	_	_
.	_	_

#112
WebRTC	_	_
is	_	_
an	_	_
open-source	_	_
framework	_	_
for	_	_
Real-Time	_	_
Communications	_	_
(	_	_
RTC	_	_
)	_	_
on	_	_
the	_	_
web	_	_
,	_	_
consisting	_	_
of	_	_
high-quality	_	_
components	_	_
for	_	_
online	_	_
communication	_	_
such	_	_
as	_	_
voice	_	_
and	_	_
video	_	_
chat	_	_
[	_	_
28	_	_
]	_	_
.	_	_

#113
The	_	_
VAD	_	_
system	_	_
supports	_	_
segments	_	_
of	_	_
10	_	_
,	_	_
20	_	_
,	_	_
or	_	_
30ms	_	_
and	_	_
uses	_	_
multiple	_	_
frequency	_	_
band	_	_
features	_	_
with	_	_
a	_	_
pre-trained	_	_
Gaussian	_	_
mixture	_	_
model	_	_
(	_	_
GMM	_	_
)	_	_
for	_	_
classification	_	_
[	_	_
24	_	_
]	_	_
.	_	_

#114
By	_	_
applying	_	_
a	_	_
VAD	_	_
system	_	_
,	_	_
an	_	_
audio	_	_
sample	_	_
is	_	_
segmented	_	_
into	_	_
speech	_	_
,	_	_
non-speech	_	_
segments	_	_
.	_	_

#115
To	_	_
construct	_	_
a	_	_
speaker	_	_
diarization	_	_
system	_	_
from	_	_
these	_	_
components	_	_
,	_	_
an	_	_
audio	_	_
sample	_	_
is	_	_
first	_	_
divided	_	_
by	_	_
1http	_	_
:	_	_
//catalog.elra.info/product_info.php	_	_
?	_	_
products_id=999	_	_
[	_	_
July	_	_
6	_	_
,	_	_
2018	_	_
]	_	_
2http	_	_
:	_	_
//catalog.elra.info/product_info.php	_	_
?	_	_
products_id=1299	_	_
[	_	_
July	_	_
6	_	_
,	_	_
2018	_	_
]	_	_
3http	_	_
:	_	_
//catalog.elra.info/product_info.php	_	_
?	_	_
products_id=1241	_	_
[	_	_
July	_	_
6	_	_
,	_	_
2018	_	_
]	_	_
Fig.	_	_
4	_	_
:	_	_
Active	_	_
speaker	_	_
detection	_	_
sample	_	_
using	_	_
the	_	_
inter-frame	_	_
difference	_	_
of	_	_
the	_	_
mouth	_	_
region	_	_
.	_	_

#116
The	_	_
inter-frame	_	_
difference	_	_
(	_	_
a	_	_
)	_	_
is	_	_
bigger	_	_
than	_	_
the	_	_
threshold	_	_
while	_	_
the	_	_
person	_	_
is	_	_
talking	_	_
.	_	_

#117
At	_	_
frame	_	_
73	_	_
the	_	_
person	_	_
stops	_	_
talking	_	_
and	_	_
the	_	_
inter-frame	_	_
difference	_	_
is	_	_
below	_	_
the	_	_
threshold	_	_
[	_	_
9	_	_
]	_	_
.	_	_

#118
the	_	_
WebRTC	_	_
VAD	_	_
and	_	_
in	_	_
the	_	_
following	_	_
the	_	_
segments	_	_
applied	_	_
to	_	_
the	_	_
VoxCeleb	_	_
network	_	_
extracting	_	_
speaker	_	_
embeddings	_	_
.	_	_

#119
For	_	_
these	_	_
extracted	_	_
speaker	_	_
embeddings	_	_
a	_	_
clustering	_	_
algorithm	_	_
using	_	_
a	_	_
metric	_	_
,	_	_
for	_	_
example	_	_
,	_	_
the	_	_
cosine	_	_
distance	_	_
,	_	_
is	_	_
then	_	_
applied	_	_
to	_	_
differentiate	_	_
the	_	_
occurring	_	_
speakers	_	_
.	_	_

#120
D.	_	_
Face	_	_
tracking	_	_
In	_	_
order	_	_
to	_	_
incorporate	_	_
the	_	_
speaker	_	_
recognition	_	_
into	_	_
CATANA	_	_
,	_	_
it	_	_
is	_	_
necessary	_	_
to	_	_
switch	_	_
from	_	_
a	_	_
frame-based	_	_
face	_	_
detection	_	_
to	_	_
a	_	_
face	_	_
tracking	_	_
approach	_	_
.	_	_

#121
The	_	_
resulting	_	_
face	_	_
tracks	_	_
are	_	_
a	_	_
representation	_	_
of	_	_
a	_	_
person	_	_
occurring	_	_
in	_	_
the	_	_
video	_	_
in	_	_
several	_	_
sequential	_	_
frames	_	_
.	_	_

#122
This	_	_
representation	_	_
further	_	_
makes	_	_
it	_	_
possible	_	_
to	_	_
draw	_	_
inferences	_	_
about	_	_
the	_	_
relation	_	_
to	_	_
the	_	_
audio	_	_
track	_	_
,	_	_
which	_	_
is	_	_
analyzed	_	_
by	_	_
the	_	_
speaker	_	_
recognition	_	_
.	_	_

#123
Everingham	_	_
et	_	_
al.	_	_
[	_	_
9	_	_
]	_	_
discussed	_	_
the	_	_
differences	_	_
between	_	_
a	_	_
frontal	_	_
and	_	_
a	_	_
multi-view	_	_
face	_	_
detection	_	_
.	_	_

#124
Although	_	_
the	_	_
frontal	_	_
face	_	_
detector	_	_
[	_	_
19	_	_
]	_	_
allows	_	_
only	_	_
to	_	_
detect	_	_
frontal	_	_
faces	_	_
,	_	_
it	_	_
also	_	_
is	_	_
more	_	_
reliable	_	_
than	_	_
multi-view	_	_
face	_	_
detectors	_	_
such	_	_
as	_	_
[	_	_
15	_	_
]	_	_
.	_	_

#125
A	_	_
popular	_	_
algorithm	_	_
to	_	_
track	_	_
faces	_	_
is	_	_
the	_	_
KanadeLucasTomasi	_	_
(	_	_
KLT	_	_
)	_	_
tracker	_	_
.	_	_

#126
The	_	_
tracking	_	_
is	_	_
implemented	_	_
by	_	_
matching	_	_
interesting	_	_
points	_	_
of	_	_
the	_	_
detected	_	_
face	_	_
to	_	_
the	_	_
local	_	_
area	_	_
of	_	_
the	_	_
following	_	_
frames	_	_
.	_	_

#127
The	_	_
output	_	_
is	_	_
a	_	_
stream	_	_
set	_	_
of	_	_
interesting	_	_
points	_	_
for	_	_
each	_	_
frame	_	_
.	_	_

#128
This	_	_
method	_	_
is	_	_
visualized	_	_
in	_	_
figure	_	_
5a	_	_
.	_	_

#129
It	_	_
is	_	_
robust	_	_
against	_	_
camera	_	_
movement	_	_
and	_	_
is	_	_
also	_	_
capable	_	_
to	_	_
track	_	_
moving	_	_
persons	_	_
.	_	_

#130
Especially	_	_
compared	_	_
directly	_	_
to	_	_
frame-based	_	_
face	_	_
detection	_	_
,	_	_
this	_	_
method	_	_
can	_	_
detect	_	_
face	_	_
tracks	_	_
although	_	_
the	_	_
face	_	_
is	_	_
not	_	_
visible	_	_
continuously	_	_
.	_	_

#131
Also	_	_
,	_	_
the	_	_
computational	_	_
effort	_	_
of	_	_
the	_	_
KLT	_	_
is	_	_
less	_	_
than	_	_
applying	_	_
face	_	_
detection	_	_
on	_	_
every	_	_
frame	_	_
.	_	_

#132
The	_	_
VGG	_	_
(	_	_
Visual	_	_
Geometry	_	_
Group	_	_
)	_	_
Face	_	_
Tracker	_	_
[	_	_
3	_	_
]	_	_
is	_	_
a	_	_
MATLAB	_	_
toolbox	_	_
for	_	_
face	_	_
tracking	_	_
provided	_	_
by	_	_
the	_	_
University	_	_
of	_	_
Oxford	_	_
.	_	_

#133
It	_	_
comes	_	_
with	_	_
a	_	_
pre-trained	_	_
cascade	_	_
face	_	_
detection	_	_
model	_	_
,	_	_
which	_	_
makes	_	_
it	_	_
possible	_	_
to	_	_
start	_	_
right	_	_
away	_	_
without	_	_
the	_	_
need	_	_
to	_	_
train	_	_
a	_	_
model	_	_
yourself	_	_
.	_	_

#134
The	_	_
VGG	_	_
Face	_	_
Tracker	_	_
works	_	_
in	_	_
four	_	_
basic	_	_
steps	_	_
.	_	_

#135
First	_	_
,	_	_
the	_	_
frames	_	_
are	_	_
extracted	_	_
from	_	_
the	_	_
video	_	_
using	_	_
the	_	_
FFmpeg	_	_
software	_	_
[	_	_
10	_	_
]	_	_
.	_	_

#136
The	_	_
second	_	_
step	_	_
is	_	_
to	_	_
detect	_	_
the	_	_
shot	_	_
boundaries	_	_
by	_	_
color	_	_
thresholding	_	_
.	_	_

#137
For	_	_
the	_	_
third	_	_
part	_	_
,	_	_
the	_	_
face	_	_
detection	_	_
,	_	_
Face	_	_
Tracker	_	_
uses	_	_
the	_	_
pre-trained	_	_
model	_	_
.	_	_

#138
The	_	_
last	_	_
segment	_	_
of	_	_
the	_	_
toolbox	_	_
is	_	_
the	_	_
tracking	_	_
functionality	_	_
,	_	_
which	_	_
uses	_	_
the	_	_
KLT	_	_
algorithm	_	_
.	_	_

#139
The	_	_
big	_	_
advantage	_	_
of	_	_
this	_	_
toolkit	_	_
is	_	_
that	_	_
it	_	_
can	_	_
be	_	_
configured	_	_
and	_	_
adapted	_	_
for	_	_
every	_	_
use	_	_
case	_	_
.	_	_

#140
Either	_	_
fast	_	_
tracking	_	_
with	_	_
less	_	_
accuracy	_	_
or	_	_
highly	_	_
reliable	_	_
tracking	_	_
with	_	_
a	_	_
high	_	_
amount	_	_
of	_	_
computational	_	_
effort	_	_
,	_	_
both	_	_
is	_	_
possible	_	_
.	_	_

#141
We	_	_
try	_	_
to	_	_
make	_	_
use	_	_
of	_	_
both	_	_
worlds	_	_
.	_	_

#142
E.	_	_
Active	_	_
Speaker	_	_
Detection	_	_
There	_	_
are	_	_
several	_	_
methods	_	_
for	_	_
implementing	_	_
active	_	_
speaker	_	_
detection	_	_
.	_	_

#143
Prerequisite	_	_
is	_	_
a	_	_
preprocessed	_	_
video	_	_
labeled	_	_
with	_	_
face	_	_
tracks	_	_
.	_	_

#144
An	_	_
intuitive	_	_
method	_	_
for	_	_
speaker	_	_
identification	_	_
is	_	_
by	_	_
detecting	_	_
lip	_	_
movement	_	_
directly	_	_
in	_	_
the	_	_
face-images	_	_
of	_	_
the	_	_
track	_	_
.	_	_

#145
Everingham	_	_
et	_	_
al.	_	_
[	_	_
9	_	_
]	_	_
proposed	_	_
to	_	_
calculate	_	_
the	_	_
inter-frame	_	_
difference	_	_
of	_	_
the	_	_
corresponding	_	_
mouth	_	_
regions	_	_
of	_	_
the	_	_
detected	_	_
faces	_	_
.	_	_

#146
This	_	_
measurement	_	_
is	_	_
calculated	_	_
by	_	_
taking	_	_
the	_	_
sum	_	_
of	_	_
the	_	_
squared	_	_
difference	_	_
of	_	_
the	_	_
pixel	_	_
values	_	_
.	_	_

#147
As	_	_
shown	_	_
in	_	_
Figure	_	_
4	_	_
,	_	_
the	_	_
inter-frame	_	_
difference	_	_
of	_	_
the	_	_
mouth	_	_
region	_	_
is	_	_
higher	_	_
if	_	_
the	_	_
person	_	_
is	_	_
speaking	_	_
.	_	_

#148
However	_	_
,	_	_
this	_	_
method	_	_
may	_	_
not	_	_
be	_	_
correct	_	_
in	_	_
all	_	_
cases	_	_
,	_	_
for	_	_
example	_	_
,	_	_
if	_	_
the	_	_
person	_	_
moves	_	_
the	_	_
mouth	_	_
without	_	_
speaking	_	_
,	_	_
e.g.	_	_
,	_	_
while	_	_
eating	_	_
or	_	_
laughing	_	_
.	_	_

#149
Chung	_	_
et	_	_
al.	_	_
[	_	_
6	_	_
]	_	_
proposed	_	_
the	_	_
audio-to-video	_	_
synchronization	_	_
network	_	_
(	_	_
SyncNet	_	_
)	_	_
.	_	_

#150
It	_	_
is	_	_
a	_	_
two-stream	_	_
convolutional	_	_
neural	_	_
network	_	_
(	_	_
CNN	_	_
)	_	_
,	_	_
which	_	_
consists	_	_
of	_	_
two	_	_
CNNs	_	_
,	_	_
one	_	_
for	_	_
the	_	_
audio	_	_
and	_	_
one	_	_
for	_	_
the	_	_
video	_	_
track	_	_
.	_	_

#151
Initially	_	_
,	_	_
the	_	_
authors	_	_
created	_	_
the	_	_
SyncNet	_	_
for	_	_
audio-visual	_	_
synchronization	_	_
tasks	_	_
,	_	_
which	_	_
are	_	_
very	_	_
important	_	_
for	_	_
the	_	_
film	_	_
industry	_	_
,	_	_
for	_	_
example	_	_
,	_	_
when	_	_
the	_	_
audio	_	_
part	_	_
is	_	_
streamed	_	_
separately	_	_
from	_	_
the	_	_
video	_	_
part	_	_
.	_	_

#152
But	_	_
the	_	_
SyncNet	_	_
can	_	_
also	_	_
be	_	_
used	_	_
for	_	_
active	_	_
speaker	_	_
detection	_	_
because	_	_
it	_	_
calculates	_	_
how	_	_
well	_	_
the	_	_
audio	_	_
fits	_	_
to	_	_
the	_	_
mouth	_	_
region	_	_
of	_	_
a	_	_
person	_	_
.	_	_

#153
The	_	_
network	_	_
needs	_	_
two	_	_
inputs	_	_
.	_	_

#154
First	_	_
,	_	_
it	_	_
needs	_	_
0.2	_	_
seconds	_	_
of	_	_
the	_	_
audio	_	_
stream	_	_
,	_	_
which	_	_
needs	_	_
to	_	_
be	_	_
converted	_	_
to	_	_
a	_	_
heatmap	_	_
.	_	_

#155
The	_	_
heatmap	_	_
is	_	_
illustrated	_	_
in	_	_
Figure	_	_
5b	_	_
.	_	_

#156
The	_	_
x-axis	_	_
thereby	_	_
represents	_	_
the	_	_
MFCC	_	_
values	_	_
for	_	_
each	_	_
time	_	_
step	_	_
and	_	_
on	_	_
the	_	_
y-axis	_	_
the	_	_
color	_	_
indicates	_	_
the	_	_
power	_	_
if	_	_
the	_	_
frequency	_	_
bins	_	_
.	_	_

#157
The	_	_
video	_	_
needs	_	_
to	_	_
be	_	_
converted	_	_
to	_	_
a	_	_
25Hz	_	_
frame	_	_
rate	_	_
and	_	_
cropped	_	_
to	_	_
the	_	_
face	_	_
region	_	_
with	_	_
160x160	_	_
pixels	_	_
.	_	_

#158
SyncNet	_	_
can	_	_
be	_	_
used	_	_
with	_	_
the	_	_
MATLAB	_	_
toolbox	_	_
MatConvNet	_	_
[	_	_
17	_	_
]	_	_
.	_	_

#159
It	_	_
also	_	_
comes	_	_
with	_	_
a	_	_
pre-trained	_	_
model	_	_
,	_	_
which	_	_
was	_	_
trained	_	_
on	_	_
BBC	_	_
videos	_	_
with	_	_
several	_	_
hundreds	_	_
of	_	_
speakers	_	_
.	_	_

#160
The	_	_
network	_	_
calculates	_	_
a	_	_
confidence	_	_
of	_	_
how	_	_
likely	_	_
it	_	_
is	_	_
for	_	_
the	_	_
mouth	_	_
region	_	_
to	_	_
be	_	_
part	_	_
of	_	_
the	_	_
speaking	_	_
person	_	_
.	_	_

#161
So	_	_
the	_	_
speaker	_	_
will	_	_
most	_	_
likely	_	_
be	_	_
the	_	_
one	_	_
with	_	_
the	_	_
highest	_	_
confidence	_	_
value	_	_
.	_	_

#162
On	_	_
the	_	_
(	_	_
a	_	_
)	_	_
Visualization	_	_
of	_	_
the	_	_
interesting	_	_
face	_	_
points	_	_
and	_	_
how	_	_
they	_	_
move	_	_
in	_	_
60	_	_
frames	_	_
.	_	_

#163
Frame	_	_
0	_	_
and	_	_
60	_	_
are	_	_
represented	_	_
as	_	_
the	_	_
original	_	_
frame	_	_
.	_	_

#164
(	_	_
b	_	_
)	_	_
As	_	_
a	_	_
preprocessing	_	_
step	_	_
,	_	_
the	_	_
audio	_	_
layer	_	_
has	_	_
to	_	_
be	_	_
converted	_	_
to	_	_
a	_	_
heatmap	_	_
.	_	_

#165
Fig.	_	_
5	_	_
:	_	_
Face	_	_
tracking	_	_
in	_	_
frames	_	_
and	_	_
audio	_	_
input	_	_
converted	_	_
for	_	_
active	_	_
speaker	_	_
detection	_	_
.	_	_

#166
Columbia	_	_
dataset	_	_
[	_	_
4	_	_
]	_	_
,	_	_
the	_	_
work	_	_
achieved	_	_
an	_	_
accuracy	_	_
between	_	_
99.8	_	_
%	_	_
and	_	_
100	_	_
%	_	_
.	_	_

#167
IV	_	_
.	_	_

#168
DESIGN	_	_
We	_	_
propose	_	_
an	_	_
extension	_	_
of	_	_
the	_	_
existing	_	_
CATANA	_	_
framework	_	_
through	_	_
four	_	_
additional	_	_
methods	_	_
:	_	_
face	_	_
tracking	_	_
,	_	_
active	_	_
speaker	_	_
detection	_	_
,	_	_
speaker	_	_
diarization	_	_
,	_	_
and	_	_
speaker	_	_
recognition	_	_
.	_	_

#169
For	_	_
face	_	_
detection	_	_
,	_	_
a	_	_
frame-wise	_	_
approach	_	_
is	_	_
used	_	_
in	_	_
CATANA	_	_
.	_	_

#170
To	_	_
get	_	_
more	_	_
information	_	_
concerning	_	_
the	_	_
temporal	_	_
course	_	_
of	_	_
the	_	_
appearances	_	_
we	_	_
choose	_	_
to	_	_
apply	_	_
face	_	_
tracking	_	_
instead	_	_
.	_	_

#171
Face	_	_
tracking	_	_
leveraged	_	_
shot	_	_
boundary	_	_
detection	_	_
to	_	_
extract	_	_
a	_	_
sequence	_	_
of	_	_
subsequent	_	_
frames	_	_
of	_	_
appearing	_	_
faces	_	_
.	_	_

#172
Through	_	_
the	_	_
temporal	_	_
dimension	_	_
of	_	_
the	_	_
sequence	_	_
,	_	_
a	_	_
direct	_	_
correlation	_	_
between	_	_
the	_	_
frame-sequence	_	_
and	_	_
its	_	_
audio	_	_
can	_	_
be	_	_
made	_	_
.	_	_

#173
In	_	_
the	_	_
following	_	_
,	_	_
active	_	_
speaker	_	_
detection	_	_
is	_	_
applied	_	_
to	_	_
decide	_	_
wherever	_	_
the	_	_
detected	_	_
face	_	_
in	_	_
the	_	_
sequence	_	_
is	_	_
the	_	_
speaker	_	_
of	_	_
the	_	_
associated	_	_
audio	_	_
.	_	_

#174
If	_	_
the	_	_
active	_	_
speaker	_	_
is	_	_
visible	_	_
,	_	_
the	_	_
previous	_	_
steps	_	_
provide	_	_
both	_	_
face	_	_
and	_	_
speaker	_	_
information	_	_
,	_	_
which	_	_
can	_	_
then	_	_
be	_	_
later	_	_
used	_	_
combined	_	_
or	_	_
separately	_	_
to	_	_
identify	_	_
the	_	_
person	_	_
.	_	_

#175
If	_	_
none	_	_
of	_	_
the	_	_
visible	_	_
faces	_	_
is	_	_
associated	_	_
as	_	_
the	_	_
speaker	_	_
,	_	_
face	_	_
recognition	_	_
is	_	_
applied	_	_
on	_	_
the	_	_
detected	_	_
faces	_	_
like	_	_
in	_	_
the	_	_
existing	_	_
CATANA	_	_
approach	_	_
nonetheless	_	_
.	_	_

#176
If	_	_
no	_	_
visible	_	_
speaker	_	_
is	_	_
detected	_	_
,	_	_
speaker	_	_
diarization	_	_
is	_	_
applied	_	_
to	_	_
potential	_	_
detect	_	_
and	_	_
separate	_	_
the	_	_
non-visible	_	_
speaker	_	_
in	_	_
the	_	_
audio	_	_
.	_	_

#177
These	_	_
separated	_	_
speech	_	_
segments	_	_
are	_	_
applied	_	_
through	_	_
speaker	_	_
recognition	_	_
to	_	_
identify	_	_
a	_	_
speaker	_	_
without	_	_
face	_	_
information	_	_
.	_	_

#178
The	_	_
result	_	_
of	_	_
these	_	_
steps	_	_
is	_	_
either	_	_
a	_	_
combination	_	_
of	_	_
face	_	_
and	_	_
speaker	_	_
embeddings	_	_
,	_	_
describing	_	_
the	_	_
visible	_	_
active	_	_
speaker	_	_
,	_	_
only	_	_
face	_	_
embeddings	_	_
of	_	_
appearing	_	_
faces	_	_
,	_	_
or	_	_
only	_	_
speaker	_	_
embeddings	_	_
describing	_	_
a	_	_
non-visible	_	_
speaker	_	_
,	_	_
for	_	_
example	_	_
,	_	_
a	_	_
commentator	_	_
.	_	_

#179
Especially	_	_
the	_	_
first	_	_
case	_	_
,	_	_
for	_	_
which	_	_
both	_	_
types	_	_
of	_	_
embeddings	_	_
are	_	_
available	_	_
is	_	_
most	_	_
helpful	_	_
in	_	_
later	_	_
identifying	_	_
the	_	_
persons	_	_
appearing	_	_
.	_	_

#180
The	_	_
availability	_	_
of	_	_
both	_	_
embeddings	_	_
for	_	_
a	_	_
segment	_	_
of	_	_
speech	_	_
makes	_	_
it	_	_
possible	_	_
to	_	_
bridge	_	_
face	_	_
and	_	_
speaker	_	_
embeddings	_	_
and	_	_
thus	_	_
associate	_	_
a	_	_
face	_	_
with	_	_
a	_	_
voice	_	_
.	_	_

#181
The	_	_
goal	_	_
is	_	_
thereby	_	_
to	_	_
gain	_	_
information	_	_
by	_	_
associating	_	_
stand-alone	_	_
face	_	_
or	_	_
speaker	_	_
embeddings	_	_
with	_	_
the	_	_
found	_	_
pairs	_	_
of	_	_
embeddings	_	_
and	_	_
thus	_	_
be	_	_
able	_	_
to	_	_
identify	_	_
,	_	_
for	_	_
example	_	_
,	_	_
a	_	_
non-visible	_	_
speaker	_	_
in	_	_
videos	_	_
.	_	_

#182
We	_	_
achieve	_	_
this	_	_
by	_	_
first	_	_
clustering	_	_
the	_	_
found	_	_
face	_	_
and	_	_
speaker	_	_
embeddings	_	_
separately	_	_
,	_	_
which	_	_
results	_	_
in	_	_
associations	_	_
between	_	_
face-to-face	_	_
and	_	_
speaker-to-speaker	_	_
embeddings	_	_
.	_	_

#183
For	_	_
pairs	_	_
of	_	_
face	_	_
and	_	_
speaker	_	_
embeddings	_	_
found	_	_
for	_	_
an	_	_
active	_	_
speaker	_	_
,	_	_
an	_	_
additional	_	_
association	_	_
between	_	_
the	_	_
different	_	_
types	_	_
of	_	_
embeddings	_	_
exists	_	_
,	_	_
which	_	_
is	_	_
further	_	_
extended	_	_
to	_	_
embeddings	_	_
clustered	_	_
within	_	_
their	_	_
type	_	_
.	_	_

#184
Figure	_	_
6	_	_
shows	_	_
a	_	_
schematic	_	_
of	_	_
this	_	_
process	_	_
,	_	_
modeling	_	_
embeddings	_	_
as	_	_
circles	_	_
and	_	_
edges	_	_
as	_	_
an	_	_
association	_	_
between	_	_
them	_	_
.	_	_

#185
Displayed	_	_
at	_	_
the	_	_
top	_	_
are	_	_
face	_	_
embeddings	_	_
and	_	_
at	_	_
the	_	_
bottom	_	_
the	_	_
speaker	_	_
embeddings	_	_
.	_	_

#186
Face	_	_
embedding	_	_
D	_	_
thereby	_	_
has	_	_
an	_	_
association	_	_
with	_	_
speaker	_	_
embedding	_	_
4	_	_
,	_	_
describing	_	_
an	_	_
active	_	_
speaker	_	_
detection	_	_
.	_	_

#187
Through	_	_
the	_	_
separate	_	_
clustering	_	_
of	_	_
the	_	_
face	_	_
and	_	_
speaker	_	_
embeddings	_	_
,	_	_
associations	_	_
within	_	_
their	_	_
respective	_	_
types	_	_
were	_	_
created	_	_
.	_	_

#188
An	_	_
example	_	_
are	_	_
the	_	_
embeddings	_	_
C	_	_
,	_	_
D	_	_
,	_	_
and	_	_
F.	_	_
Through	_	_
this	_	_
,	_	_
implicit	_	_
associations	_	_
can	_	_
further	_	_
be	_	_
made	_	_
between	_	_
the	_	_
embeddings	_	_
C	_	_
,	_	_
F	_	_
and	_	_
4	_	_
,	_	_
as	_	_
C	_	_
,	_	_
D	_	_
,	_	_
F	_	_
model	_	_
the	_	_
same	_	_
face	_	_
and	_	_
thus	_	_
same	_	_
person	_	_
.	_	_

#189
V.	_	_
IMPLEMENTATION	_	_
Our	_	_
implementation	_	_
is	_	_
based	_	_
on	_	_
the	_	_
CATANA	_	_
framework	_	_
,	_	_
which	_	_
is	_	_
shown	_	_
in	_	_
Figure	_	_
1a	_	_
.	_	_

#190
Our	_	_
proposed	_	_
extension	_	_
is	_	_
illustrated	_	_
in	_	_
Figure	_	_
7	_	_
.	_	_

#191
The	_	_
changed	_	_
parts	_	_
of	_	_
the	_	_
system	_	_
are	_	_
highlighted	_	_
and	_	_
labeled	_	_
,	_	_
wherever	_	_
an	_	_
existing	_	_
CATANA	_	_
part	_	_
is	_	_
used	_	_
unchanged	_	_
,	_	_
or	_	_
replaced	_	_
with	_	_
a	_	_
new	_	_
implementation	_	_
.	_	_

#192
Color	_	_
blue	_	_
describes	_	_
parts	_	_
of	_	_
the	_	_
CATANA	_	_
framework	_	_
which	_	_
were	_	_
left	_	_
unchanged	_	_
like	_	_
data	_	_
storage	_	_
,	_	_
metadata	_	_
crawler	_	_
,	_	_
and	_	_
video	_	_
download	_	_
.	_	_

#193
Green	_	_
describes	_	_
updated	_	_
or	_	_
replaced	_	_
parts	_	_
.	_	_

#194
Prominently	_	_
the	_	_
former	_	_
face	_	_
recognition	_	_
and	_	_
clustering	_	_
part	_	_
,	_	_
in	_	_
which	_	_
the	_	_
video	_	_
is	_	_
processed	_	_
,	_	_
were	_	_
replaced	_	_
for	_	_
the	_	_
most	_	_
part	_	_
.	_	_

#195
Instead	_	_
of	_	_
only	_	_
applying	_	_
face	_	_
recognition	_	_
,	_	_
both	_	_
active	_	_
speaker	_	_
detection	_	_
and	_	_
speaker	_	_
diarization	_	_
are	_	_
executed	_	_
before	_	_
face	_	_
recognition	_	_
,	_	_
returning	_	_
potential	_	_
speaker-face	_	_
associations	_	_
.	_	_

#196
The	_	_
extension	_	_
is	_	_
divided	_	_
into	_	_
three	_	_
major	_	_
parts	_	_
:	_	_
face	_	_
tracking	_	_
,	_	_
Fig.	_	_
6	_	_
:	_	_
Face	_	_
and	_	_
speaker	_	_
embeddings	_	_
bridge	_	_
.	_	_

#197
speaker	_	_
recognition	_	_
,	_	_
and	_	_
clustering	_	_
.	_	_

#198
The	_	_
whole	_	_
CATANA	_	_
framework	_	_
is	_	_
implemented	_	_
using	_	_
Python	_	_
,	_	_
which	_	_
we	_	_
will	_	_
continue	_	_
using	_	_
to	_	_
extend	_	_
the	_	_
framework	_	_
.	_	_

#199
However	_	_
,	_	_
some	_	_
parts	_	_
of	_	_
the	_	_
proposed	_	_
extension	_	_
are	_	_
using	_	_
a	_	_
different	_	_
runtime	_	_
environment	_	_
and	_	_
therefore	_	_
require	_	_
an	_	_
interface	_	_
to	_	_
Python	_	_
.	_	_

#200
VGGVox	_	_
,	_	_
VGG	_	_
Face	_	_
Tracker	_	_
,	_	_
as	_	_
well	_	_
as	_	_
SyncNet	_	_
are	_	_
implemented	_	_
using	_	_
MATLAB	_	_
.	_	_

#201
Due	_	_
to	_	_
incompatibility	_	_
,	_	_
it	_	_
is	_	_
not	_	_
possible	_	_
to	_	_
use	_	_
the	_	_
pre-trained	_	_
models	_	_
directly	_	_
in	_	_
Python	_	_
,	_	_
making	_	_
the	_	_
interaction	_	_
between	_	_
Python	_	_
and	_	_
MATLAB	_	_
necessary	_	_
.	_	_

#202
To	_	_
accomplish	_	_
this	_	_
the	_	_
MATLAB	_	_
Engine	_	_
API	_	_
for	_	_
Python	_	_
[	_	_
18	_	_
]	_	_
is	_	_
used	_	_
.	_	_

#203
This	_	_
library	_	_
provides	_	_
an	_	_
official	_	_
interface	_	_
between	_	_
Python	_	_
and	_	_
MATLAB	_	_
.	_	_

#204
It	_	_
is	_	_
possible	_	_
to	_	_
call	_	_
MATLAB	_	_
functions	_	_
,	_	_
scripts	_	_
,	_	_
provide	_	_
parameters	_	_
,	_	_
and	_	_
receive	_	_
return	_	_
values	_	_
.	_	_

#205
In	_	_
practice	_	_
,	_	_
a	_	_
MATLAB	_	_
instance	_	_
is	_	_
started	_	_
as	_	_
a	_	_
background	_	_
process	_	_
and	_	_
executes	_	_
all	_	_
calls	_	_
from	_	_
Python	_	_
.	_	_

#206
Data	_	_
interaction	_	_
between	_	_
Python	_	_
and	_	_
MATLAB	_	_
thereby	_	_
only	_	_
supports	_	_
a	_	_
set	_	_
of	_	_
compatible	_	_
types	_	_
which	_	_
are	_	_
converted	_	_
between	_	_
equivalent	_	_
types	_	_
of	_	_
both	_	_
technologies	_	_
.	_	_

#207
For	_	_
this	_	_
reason	_	_
,	_	_
multiple	_	_
of	_	_
the	_	_
MATLAB	_	_
function’s	_	_
return	_	_
values	_	_
needed	_	_
an	_	_
additional	_	_
adjustment	_	_
in	_	_
terms	_	_
of	_	_
type	_	_
and	_	_
structure	_	_
,	_	_
i.e.	_	_
,	_	_
only	_	_
scalar	_	_
structures	_	_
with	_	_
size	_	_
1	_	_
can	_	_
be	_	_
returned	_	_
.	_	_

#208
A	_	_
.	_	_

#209
Face	_	_
Tracking	_	_
and	_	_
Active	_	_
Speaker	_	_
Detection	_	_
These	_	_
two	_	_
steps	_	_
are	_	_
implemented	_	_
with	_	_
MATLAB	_	_
.	_	_

#210
The	_	_
VGG	_	_
(	_	_
Visual	_	_
Geometry	_	_
Group	_	_
)	_	_
Face	_	_
Tracker	_	_
[	_	_
3	_	_
]	_	_
is	_	_
used	_	_
for	_	_
the	_	_
face	_	_
tracking	_	_
.	_	_

#211
It	_	_
is	_	_
required	_	_
to	_	_
install	_	_
FFmpeg	_	_
[	_	_
10	_	_
]	_	_
and	_	_
the	_	_
Matconvnet	_	_
[	_	_
17	_	_
]	_	_
toolbox	_	_
to	_	_
run	_	_
the	_	_
algorithm	_	_
.	_	_

#212
We	_	_
have	_	_
adapted	_	_
the	_	_
algorithm	_	_
to	_	_
our	_	_
needs	_	_
to	_	_
provide	_	_
a	_	_
faster	_	_
detection	_	_
,	_	_
but	_	_
it	_	_
remains	_	_
still	_	_
very	_	_
time	_	_
consuming	_	_
,	_	_
especially	_	_
if	_	_
the	_	_
video	_	_
is	_	_
long	_	_
.	_	_

#213
The	_	_
first	_	_
two	_	_
steps	_	_
are	_	_
frame	_	_
extraction	_	_
and	_	_
shot	_	_
detection	_	_
,	_	_
which	_	_
work	_	_
quite	_	_
fast	_	_
,	_	_
compared	_	_
to	_	_
the	_	_
third	_	_
and	_	_
fourth	_	_
step	_	_
,	_	_
face	_	_
detection	_	_
and	_	_
face	_	_
tracking	_	_
,	_	_
which	_	_
tend	_	_
to	_	_
take	_	_
a	_	_
while	_	_
,	_	_
because	_	_
a	_	_
large	_	_
number	_	_
of	_	_
frames	_	_
must	deontic	_
be	_	_
processed	_	_
.	_	_

#214
We	_	_
decided	_	_
to	_	_
apply	_	_
the	_	_
face	_	_
detection	_	_
only	_	_
on	_	_
every	_	_
25th	_	_
frame	_	_
,	_	_
which	_	_
is	_	_
equivalent	_	_
with	_	_
one	_	_
detection	_	_
per	_	_
second	_	_
.	_	_

#215
People	_	_
who	_	_
occur	_	_
only	_	_
inside	_	_
this	_	_
time	_	_
frame	_	_
will	_	_
not	_	_
be	_	_
considered	_	_
.	_	_

#216
We	_	_
assumed	_	_
that	_	_
if	_	_
a	_	_
person	_	_
appears	_	_
less	_	_
than	_	_
a	_	_
second	_	_
,	_	_
it	_	_
does	_	_
not	_	_
contribute	_	_
enough	_	_
to	_	_
the	_	_
video	_	_
to	_	_
be	_	_
considered	_	_
.	_	_

#217
This	_	_
speeds	_	_
the	_	_
process	_	_
up	_	_
and	_	_
in	_	_
advance	_	_
filters	_	_
the	_	_
faces	_	_
which	_	_
are	_	_
not	_	_
of	_	_
interest	_	_
.	_	_

#218
We	_	_
could	_	_
have	_	_
raised	_	_
the	_	_
frame	_	_
skip	_	_
,	_	_
but	_	_
then	_	_
the	_	_
probability	_	_
of	_	_
missing	_	_
a	_	_
face	_	_
is	_	_
higher	_	_
and	_	_
the	_	_
benefit	_	_
of	_	_
that	_	_
does	_	_
not	_	_
have	_	_
such	_	_
a	_	_
big	_	_
impact	_	_
.	_	_

#219
The	_	_
last	_	_
step	_	_
could	_	_
not	_	_
be	_	_
made	_	_
faster	_	_
,	_	_
because	_	_
the	_	_
face	_	_
tracking	_	_
of	_	_
the	_	_
face	_	_
has	_	_
to	_	_
be	_	_
computed	_	_
on	_	_
every	_	_
frame	_	_
.	_	_

#220
This	_	_
is	_	_
especially	_	_
necessary	_	_
if	_	_
the	_	_
observed	_	_
person	_	_
is	_	_
moving	_	_
.	_	_

#221
The	_	_
output	_	_
of	_	_
the	_	_
face	_	_
tracking	_	_
is	_	_
the	_	_
location	_	_
information	_	_
for	_	_
every	_	_
found	_	_
face	_	_
in	_	_
every	_	_
frame	_	_
.	_	_

#222
To	_	_
make	_	_
sure	_	_
the	_	_
face	_	_
tracks	_	_
will	_	_
not	_	_
get	_	_
too	_	_
long	_	_
,	_	_
they	_	_
are	_	_
cut	_	_
into	_	_
pieces	_	_
with	_	_
the	_	_
length	_	_
of	_	_
50	_	_
frames	_	_
.	_	_

#223
This	_	_
is	_	_
done	_	_
to	_	_
ensure	_	_
,	_	_
that	_	_
tracks	_	_
where	_	_
a	_	_
person	_	_
starts	_	_
and	_	_
stops	_	_
speaking	_	_
are	_	_
separated	_	_
,	_	_
so	_	_
that	_	_
the	_	_
evaluation	_	_
of	_	_
the	_	_
person	_	_
being	_	_
the	_	_
active	_	_
speaker	_	_
can	_	_
be	_	_
more	_	_
accurate	_	_
.	_	_

#224
We	_	_
made	_	_
the	_	_
decision	_	_
to	_	_
cut	_	_
the	_	_
tracks	_	_
down	_	_
to	_	_
50	_	_
frames	_	_
,	_	_
because	_	_
a	_	_
two-second	_	_
audio	_	_
stream	_	_
is	_	_
sufficient	_	_
to	_	_
extract	_	_
speaker	_	_
embeddings	_	_
.	_	_

#225
If	_	_
the	_	_
confidence	_	_
of	_	_
SyncNet	_	_
is	_	_
high	_	_
enough	_	_
we	_	_
calculate	_	_
the	_	_
embeddings	_	_
.	_	_

#226
We	_	_
also	_	_
defined	_	_
a	_	_
minimal	_	_
length	_	_
of	_	_
the	_	_
face	_	_
tracks	_	_
.	_	_

#227
This	_	_
is	_	_
important	_	_
,	_	_
because	_	_
the	_	_
input	_	_
for	_	_
the	_	_
speaker	_	_
embedding	_	_
needs	_	_
to	_	_
be	_	_
long	_	_
enough	_	_
to	_	_
provide	_	_
good	_	_
and	_	_
reliable	_	_
results	_	_
.	_	_

#228
Afterwards	_	_
,	_	_
every	_	_
face	_	_
track	_	_
is	_	_
stored	_	_
to	_	_
the	_	_
hard	_	_
drive	_	_
as	_	_
an	_	_
.avi	_	_
video	_	_
file	_	_
with	_	_
the	_	_
corresponding	_	_
audio	_	_
track	_	_
.	_	_

#229
We	_	_
decided	_	_
to	_	_
use	_	_
the	_	_
SyncNet	_	_
provided	_	_
by	_	_
Chung	_	_
et	_	_
al.	_	_
[	_	_
6	_	_
]	_	_
for	_	_
the	_	_
active	_	_
speaker	_	_
detection	_	_
,	_	_
because	_	_
of	_	_
their	_	_
good	_	_
results	_	_
and	_	_
high	_	_
accuracy	_	_
.	_	_

#230
On	_	_
the	_	_
Columbia	_	_
dataset	_	_
[	_	_
4	_	_
]	_	_
they	_	_
reported	_	_
F1-scores	_	_
between	_	_
83.4	_	_
%	_	_
and	_	_
97.7	_	_
%	_	_
for	_	_
a	_	_
frame	_	_
window	_	_
of	_	_
10	_	_
.	_	_

#231
By	_	_
raising	_	_
the	_	_
window	_	_
to	_	_
100	_	_
they	_	_
reported	_	_
F1-scores	_	_
between	_	_
99.8	_	_
%	_	_
and	_	_
100	_	_
%	_	_
.	_	_

#232
They	_	_
provide	_	_
a	_	_
neural	_	_
network	_	_
to	_	_
calculate	_	_
the	_	_
confidence	_	_
if	_	_
a	_	_
person	_	_
is	_	_
speaking	_	_
.	_	_

#233
The	_	_
network	_	_
thereby	_	_
needs	_	_
a	_	_
video	_	_
file	_	_
of	_	_
the	_	_
cropped	_	_
face	_	_
with	_	_
the	_	_
audio	_	_
track	_	_
as	_	_
input	_	_
.	_	_

#234
Before	_	_
the	_	_
video	_	_
can	_	_
be	_	_
further	_	_
processed	_	_
it	_	_
needs	_	_
to	_	_
be	_	_
converted	_	_
into	_	_
the	_	_
right	_	_
format	_	_
.	_	_

#235
The	_	_
algorithm	_	_
can	_	_
only	_	_
work	_	_
with	_	_
a	_	_
video	_	_
at	_	_
25	_	_
frames	_	_
per	_	_
second	_	_
(	_	_
fps	_	_
)	_	_
and	_	_
an	_	_
audio	_	_
sampling	_	_
rate	_	_
at	_	_
16	_	_
kHz	_	_
.	_	_

#236
We	_	_
made	_	_
sure	_	_
that	_	_
the	_	_
cropped	_	_
images	_	_
are	_	_
as	_	_
similar	_	_
as	_	_
possible	_	_
to	_	_
the	_	_
provided	_	_
examples	_	_
,	_	_
as	_	_
the	_	_
neural	_	_
network	_	_
performance	_	_
is	_	_
depended	_	_
on	_	_
the	_	_
similarity	_	_
of	_	_
the	_	_
input	_	_
and	_	_
its	_	_
training	_	_
data	_	_
.	_	_

#237
In	_	_
order	_	_
to	_	_
achieve	_	_
this	_	_
similarity	_	_
,	_	_
the	_	_
mouth	_	_
of	_	_
the	_	_
person	_	_
is	_	_
placed	_	_
in	_	_
the	_	_
center	_	_
of	_	_
the	_	_
picture	_	_
and	_	_
it	_	_
is	_	_
resized	_	_
to	_	_
a	_	_
size	_	_
of	_	_
160x160	_	_
pixels	_	_
.	_	_

#238
After	_	_
preparing	_	_
all	_	_
necessary	_	_
steps	_	_
and	_	_
preprocessing	_	_
the	_	_
data	_	_
we	_	_
determined	_	_
that	_	_
the	_	_
output	_	_
of	_	_
the	_	_
SyncNet	_	_
network	_	_
is	_	_
not	_	_
as	_	_
desired	_	_
and	_	_
seemed	_	_
to	_	_
be	_	_
highly	_	_
random	_	_
.	_	_

#239
Eventually	_	_
after	_	_
debugging	_	_
and	_	_
different	_	_
experiments	_	_
with	_	_
video	_	_
and	_	_
audio	_	_
codecs	_	_
we	_	_
found	_	_
that	_	_
it	_	_
is	_	_
not	_	_
enough	_	_
to	_	_
convert	_	_
the	_	_
video	_	_
to	_	_
an	_	_
.avi	_	_
file	_	_
with	_	_
25	_	_
fps	_	_
and	_	_
a	_	_
sampling	_	_
rate	_	_
of	_	_
16	_	_
kHz	_	_
,	_	_
the	_	_
audio	_	_
codec	_	_
needs	_	_
to	_	_
be	_	_
PCM	_	_
S16	_	_
LE	_	_
(	_	_
araw	_	_
)	_	_
and	_	_
the	_	_
video	_	_
codec	_	_
needs	_	_
to	_	_
be	_	_
in	_	_
24	_	_
bits	_	_
RGB	_	_
(	_	_
RV24	_	_
)	_	_
.	_	_

#240
After	_	_
this	_	_
insight	_	_
,	_	_
we	_	_
could	_	_
process	_	_
with	_	_
the	_	_
further	_	_
steps	_	_
.	_	_

#241
For	_	_
tracks	_	_
with	_	_
a	_	_
high	_	_
confidence	_	_
that	_	_
the	_	_
person	_	_
is	_	_
speaking	_	_
we	_	_
directly	_	_
calculate	_	_
a	_	_
speaker	_	_
embedding	_	_
.	_	_

#242
As	_	_
we	_	_
now	_	_
obtained	_	_
both	_	_
speaker	_	_
embedding	_	_
and	_	_
face	_	_
images	_	_
,	_	_
which	_	_
are	_	_
Fig.	_	_
7	_	_
:	_	_
The	_	_
proposed	_	_
extension	_	_
of	_	_
the	_	_
CATANA	_	_
architecture	_	_
.	_	_

#243
Blue	_	_
segments	_	_
are	_	_
reused	_	_
modules	_	_
from	_	_
CATANA	_	_
,	_	_
green	_	_
segments	_	_
show	_	_
added	_	_
or	_	_
updated	_	_
parts	_	_
.	_	_

#244
applied	_	_
to	_	_
face	_	_
recognition	_	_
,	_	_
we	_	_
can	_	_
now	_	_
identify	_	_
a	_	_
person	_	_
by	_	_
its	_	_
voice	_	_
and	_	_
its	_	_
face	_	_
separately	_	_
,	_	_
if	_	_
the	_	_
person	_	_
is	_	_
visible	_	_
and	_	_
speaks	_	_
at	_	_
the	_	_
same	_	_
time	_	_
at	_	_
least	_	_
once	_	_
,	_	_
and	_	_
if	_	_
the	_	_
active	_	_
speaker	_	_
recognition	_	_
calculates	_	_
a	_	_
high	_	_
confidence	_	_
.	_	_

#245
B	_	_
.	_	_

#246
Speaker	_	_
recognition	_	_
The	_	_
speaker	_	_
recognition	_	_
parts	_	_
of	_	_
our	_	_
pipeline	_	_
extension	_	_
consist	_	_
of	_	_
speaker	_	_
recognition	_	_
for	_	_
identifying	_	_
different	_	_
speakers	_	_
and	_	_
speaker	_	_
diarization	_	_
,	_	_
which	_	_
segments	_	_
audio	_	_
into	_	_
speech	_	_
and	_	_
non-speech	_	_
segments	_	_
.	_	_

#247
For	_	_
speaker	_	_
recognition	_	_
the	_	_
proposed	_	_
speaker	_	_
embedding	_	_
system	_	_
VGGVox	_	_
[	_	_
20	_	_
]	_	_
is	_	_
used	_	_
.	_	_

#248
The	_	_
system	_	_
is	_	_
developed	_	_
in	_	_
MATLAB	_	_
and	_	_
also	_	_
requires	_	_
the	_	_
additional	_	_
toolbox	_	_
Matconvnet	_	_
[	_	_
17	_	_
]	_	_
.	_	_

#249
The	_	_
system	_	_
expects	_	_
an	_	_
audio	_	_
sample	_	_
as	_	_
input	_	_
and	_	_
returns	_	_
a	_	_
1	_	_
,	_	_
024-dim	_	_
.	_	_

#250
float	_	_
vector	_	_
describing	_	_
the	_	_
speaker	_	_
present	_	_
.	_	_

#251
The	_	_
audio	_	_
sample	_	_
thereby	_	_
requires	_	_
to	_	_
have	_	_
a	_	_
sampling	_	_
rate	_	_
of	_	_
16	_	_
kHz	_	_
,	_	_
16	_	_
bit	_	_
depth	_	_
and	_	_
to	_	_
be	_	_
single	_	_
channel	_	_
(	_	_
mono	_	_
)	_	_
.	_	_

#252
While	_	_
testing	_	_
,	_	_
we	_	_
also	_	_
discovered	_	_
that	_	_
a	_	_
too	_	_
short	_	_
audio	_	_
sample	_	_
could	_	_
not	_	_
be	_	_
processed	_	_
through	_	_
the	_	_
model	_	_
,	_	_
a	_	_
minimum	_	_
length	_	_
of	_	_
1	_	_
sec	_	_
or	_	_
16	_	_
,	_	_
000	_	_
samples	_	_
were	_	_
required	_	_
to	_	_
extract	_	_
an	_	_
embedding	_	_
without	_	_
error	_	_
.	_	_

#253
Speaker	_	_
diarization	_	_
is	_	_
implemented	_	_
as	_	_
described	_	_
in	_	_
section	_	_
III	_	_
by	_	_
combining	_	_
multiple	_	_
available	_	_
systems	_	_
to	_	_
a	_	_
diarization	_	_
pipeline	_	_
.	_	_

#254
Before	_	_
implementing	_	_
this	_	_
pipeline	_	_
we	_	_
further	_	_
conducted	_	_
an	_	_
evaluation	_	_
regarding	_	_
the	_	_
used	_	_
parts	_	_
for	_	_
diarization	_	_
and	_	_
their	_	_
performance	_	_
on	_	_
a	_	_
set	_	_
of	_	_
YouTube	_	_
videos	_	_
.	_	_

#255
For	_	_
this	_	_
we	_	_
defined	_	_
three	_	_
classes	_	_
of	_	_
YouTube	_	_
videos	_	_
based	_	_
on	_	_
the	_	_
number	_	_
of	_	_
appearing	_	_
speakers	_	_
in	_	_
the	_	_
audio	_	_
.	_	_

#256
Classes	_	_
are	_	_
Single	_	_
,	_	_
if	_	_
they	_	_
consist	_	_
only	_	_
of	_	_
one	_	_
speaker	_	_
,	_	_
Two	_	_
with	_	_
two	_	_
speakers	_	_
,	_	_
or	_	_
Multi	_	_
consisting	_	_
of	_	_
4	_	_
to	_	_
8	_	_
speakers	_	_
.	_	_

#257
We	_	_
evaluated	_	_
on	_	_
the	_	_
systems	_	_
BIC	_	_
[	_	_
2	_	_
]	_	_
,	_	_
webrtcvad	_	_
[	_	_
29	_	_
]	_	_
,	_	_
voiceid	_	_
[	_	_
16	_	_
]	_	_
,	_	_
and	_	_
voiceid+VGGVox	_	_
.	_	_

#258
BIC	_	_
is	_	_
a	_	_
speaker	_	_
diarization	_	_
library	_	_
based	_	_
on	_	_
Python	_	_
performing	_	_
VAD	_	_
,	_	_
audio	_	_
segmentation	_	_
and	_	_
hierarchical	_	_
clustering	_	_
.	_	_

#259
Webrtcvad	_	_
is	_	_
the	_	_
already	_	_
described	_	_
VAD	_	_
system	_	_
developed	_	_
by	_	_
Google	_	_
for	_	_
the	_	_
WebRTC	_	_
standard	_	_
.	_	_

#260
As	_	_
webrtcvad	_	_
is	_	_
only	_	_
a	_	_
VAD	_	_
system	_	_
,	_	_
we	_	_
combined	_	_
it	_	_
with	_	_
the	_	_
VGGVox	_	_
[	_	_
20	_	_
]	_	_
speaker	_	_
recognition	_	_
and	_	_
HDBSCAN	_	_
[	_	_
11	_	_
]	_	_
clustering	_	_
to	_	_
a	_	_
complete	_	_
diarization	_	_
pipeline	_	_
.	_	_

#261
Voiceid	_	_
is	_	_
a	_	_
Python	_	_
based	_	_
speaker	_	_
identification	_	_
system	_	_
based	_	_
on	_	_
the	_	_
previously	_	_
described	_	_
LIUM	_	_
Speaker	_	_
Diarization	_	_
framework	_	_
[	_	_
16	_	_
]	_	_
.	_	_

#262
Additionally	_	_
to	_	_
the	_	_
full	_	_
speaker	_	_
diarization	_	_
system	_	_
of	_	_
voiceid	_	_
(	_	_
LIUM	_	_
)	_	_
,	_	_
we	_	_
also	_	_
combined	_	_
voiceids’s	_	_
speech	_	_
segmentation	_	_
with	_	_
state	_	_
of	_	_
the	_	_
art	_	_
speaker	_	_
recognition	_	_
and	_	_
clustering	_	_
approaches	_	_
using	_	_
VGGVox	_	_
and	_	_
HDBSCAN	_	_
[	_	_
11	_	_
]	_	_
forming	_	_
a	_	_
new	_	_
integrated	_	_
system	_	_
.	_	_

#263
Results	_	_
in	_	_
Figures	_	_
8	_	_
and	_	_
9	_	_
show	_	_
different	_	_
metrics	_	_
concerning	_	_
the	_	_
clustered	_	_
audio	_	_
segments	_	_
:	_	_
Number	_	_
of	_	_
cluster	_	_
error	_	_
is	_	_
describing	_	_
the	_	_
number	_	_
of	_	_
speech	_	_
segments	_	_
incorrectly	_	_
clustered	_	_
and	_	_
number	_	_
of	_	_
not	_	_
clustered	_	_
describes	_	_
the	_	_
segments	_	_
not	_	_
clustered	_	_
at	_	_
all	_	_
.	_	_

#264
Further	_	_
the	_	_
number	_	_
of	_	_
found	_	_
cluster	_	_
displays	_	_
the	_	_
number	_	_
of	_	_
found	_	_
speaker	_	_
cluster	_	_
,	_	_
additionally	_	_
showing	_	_
the	_	_
class’	_	_
respective	_	_
optimal	_	_
number	_	_
.	_	_

#265
The	_	_
average	_	_
segment	_	_
length	_	_
describes	_	_
the	_	_
average	_	_
length	_	_
in	_	_
seconds	_	_
of	_	_
the	_	_
extracted	_	_
segments	_	_
for	_	_
the	_	_
systems	_	_
.	_	_

#266
We	_	_
see	_	_
that	_	_
for	_	_
all	_	_
classes	_	_
voiceid	_	_
extracts	_	_
a	_	_
large	_	_
number	_	_
of	_	_
clusters	_	_
compared	_	_
to	_	_
the	_	_
optimal	_	_
number	_	_
.	_	_

#267
This	_	_
indicates	_	_
that	_	_
their	_	_
applied	_	_
clustering	_	_
algorithm	_	_
is	_	_
conservative	_	_
in	_	_
merging	_	_
found	_	_
speaker	_	_
and	_	_
thus	_	_
yields	_	_
a	_	_
lot	_	_
of	_	_
small	_	_
clusters	_	_
.	_	_

#268
In	_	_
general	_	_
,	_	_
voiceid+VGGVOX	_	_
yields	_	_
the	_	_
best	_	_
results	_	_
for	_	_
number	_	_
of	_	_
clusters	_	_
.	_	_

#269
However	_	_
,	_	_
a	_	_
special	_	_
case	_	_
is	_	_
the	_	_
Multi	_	_
class	_	_
,	_	_
for	_	_
which	_	_
we	_	_
discovered	_	_
that	_	_
each	_	_
of	_	_
the	_	_
tested	_	_
systems	_	_
seems	_	_
to	_	_
struggle	_	_
in	_	_
distinguishing	_	_
between	_	_
a	_	_
increased	_	_
number	_	_
of	_	_
people	_	_
.	_	_

#270
Particular	_	_
in	_	_
a	_	_
discussion	_	_
,	_	_
where	_	_
multiple	_	_
speakers	_	_
are	_	_
talking	_	_
into	_	_
one	_	_
another	_	_
.	_	_

#271
This	_	_
is	_	_
due	_	_
to	_	_
the	_	_
fact	_	_
that	_	_
the	_	_
VAD	_	_
system	_	_
uses	_	_
the	_	_
silence	_	_
between	_	_
speeches	_	_
to	_	_
determine	_	_
segment	_	_
boundaries	_	_
.	_	_

#272
In	_	_
a	_	_
discussion	_	_
,	_	_
often	_	_
no	_	_
pause	_	_
is	_	_
present	_	_
,	_	_
a	_	_
segment	_	_
can	_	_
therefore	_	_
contain	_	_
multiple	_	_
speakers	_	_
which	_	_
makes	_	_
it	_	_
hard	_	_
to	_	_
correctly	_	_
extract	_	_
an	_	_
embedding	_	_
and	_	_
cluster	_	_
.	_	_

#273
This	_	_
case	_	_
is	_	_
also	_	_
reflected	_	_
in	_	_
the	_	_
number	_	_
of	_	_
cluster	_	_
errors	_	_
for	_	_
the	_	_
Multi	_	_
class	_	_
.	_	_

#274
For	_	_
the	_	_
average	_	_
segment	_	_
length	_	_
in	_	_
seconds	_	_
,	_	_
all	_	_
systems	_	_
yield	_	_
similar	_	_
results	_	_
,	_	_
around	_	_
6	_	_
seconds	_	_
in	_	_
average	_	_
for	_	_
classes	_	_
with	_	_
more	_	_
than	_	_
one	_	_
speaker	_	_
,	_	_
and	_	_
nearly	_	_
10	_	_
seconds	_	_
for	_	_
the	_	_
Single	_	_
class	_	_
.	_	_

#275
This	_	_
shows	_	_
that	_	_
in	_	_
a	_	_
setting	_	_
of	_	_
only	_	_
a	_	_
single	_	_
speaker	_	_
,	_	_
speeches	_	_
seem	_	_
to	_	_
have	_	_
a	_	_
longer	_	_
duration	_	_
between	_	_
pauses	_	_
than	_	_
in	_	_
a	_	_
dialogue	_	_
between	_	_
multiple	_	_
speakers	_	_
.	_	_

#276
Noticeable	_	_
is	_	_
the	_	_
spike	_	_
for	_	_
webrtcvad	_	_
in	_	_
the	_	_
Multi	_	_
class	_	_
illustrating	_	_
the	_	_
described	_	_
behavior	_	_
of	_	_
detecting	_	_
no	_	_
pause	_	_
,	_	_
which	_	_
will	_	_
likely	_	_
contain	_	_
multiple	_	_
speakers	_	_
per	_	_
segment	_	_
.	_	_

#277
We	_	_
can	_	_
also	_	_
see	_	_
that	_	_
the	_	_
webrtcvad	_	_
system	_	_
seems	_	_
to	_	_
have	_	_
a	_	_
low	_	_
number	_	_
of	_	_
cluster	_	_
error	_	_
for	_	_
all	_	_
classes	_	_
,	_	_
even	_	_
Multi	_	_
.	_	_

#278
This	_	_
is	_	_
however	_	_
a	_	_
false	_	_
impression	_	_
,	_	_
as	_	_
studying	_	_
the	_	_
number	_	_
of	_	_
not	_	_
Fig.	_	_
8	_	_
:	_	_
Diarization	_	_
evaluation	_	_
for	_	_
number	_	_
of	_	_
incorrect	_	_
clustered	_	_
segments	_	_
and	_	_
not	_	_
clustered	_	_
segments	_	_
.	_	_

#279
Fig.	_	_
9	_	_
:	_	_
Diarization	_	_
evaluation	_	_
concerning	_	_
number	_	_
of	_	_
clusters	_	_
,	_	_
also	_	_
displaying	_	_
the	_	_
optimal	_	_
number	_	_
for	_	_
the	_	_
respective	_	_
class	_	_
.	_	_

#280
clustered	_	_
,	_	_
we	_	_
can	_	_
see	_	_
that	_	_
webrtcvad	_	_
in	_	_
fact	_	_
has	_	_
not	_	_
clustered	_	_
the	_	_
majority	_	_
of	_	_
the	_	_
segments	_	_
at	_	_
all	_	_
.	_	_

#281
Concerning	_	_
these	_	_
results	_	_
we	_	_
decided	_	_
to	_	_
further	_	_
leverage	_	_
the	_	_
voiceid+VGGVox	_	_
approach	_	_
as	_	_
our	_	_
speaker	_	_
diarization	_	_
system	_	_
,	_	_
as	_	_
it	_	_
yielded	_	_
comparable	_	_
performance	_	_
as	_	_
voiceid	_	_
but	_	_
also	_	_
clustered	_	_
the	_	_
segments	_	_
to	_	_
the	_	_
near	_	_
optimal	_	_
number	_	_
of	_	_
clusters	_	_
.	_	_

#282
C.	_	_
Clustering	_	_
Clustering	_	_
is	_	_
applied	_	_
in	_	_
several	_	_
parts	_	_
of	_	_
the	_	_
pipeline	_	_
.	_	_

#283
In	_	_
general	_	_
for	_	_
all	_	_
applications	_	_
of	_	_
clustering	_	_
the	_	_
HDBSCAN	_	_
algorithm	_	_
is	_	_
used	_	_
.	_	_

#284
Through	_	_
HDBSCAN’s	_	_
density	_	_
based	_	_
approach	_	_
,	_	_
no	_	_
parameter	_	_
for	_	_
the	_	_
number	_	_
of	_	_
clusters	_	_
or	_	_
distance	_	_
i.e.	_	_
epsilon	_	_
parameter	_	_
is	_	_
necessary	_	_
,	_	_
while	_	_
still	_	_
yielding	_	_
comparable	_	_
,	_	_
or	_	_
better	_	_
results	_	_
than	_	_
other	_	_
approaches	_	_
[	_	_
13	_	_
]	_	_
.	_	_

#285
As	_	_
described	_	_
in	_	_
the	_	_
prior	_	_
work	_	_
of	_	_
CATANA	_	_
,	_	_
HDBSCAN	_	_
has	_	_
problems	_	_
when	_	_
only	_	_
a	_	_
single	_	_
class	_	_
is	_	_
present	_	_
in	_	_
the	_	_
data	_	_
,	_	_
yielding	_	_
only	_	_
the	_	_
noise	_	_
label	_	_
.	_	_

#286
For	_	_
this	_	_
reason	_	_
,	_	_
we	_	_
establish	_	_
a	_	_
fallback	_	_
method	_	_
,	_	_
like	_	_
proposed	_	_
in	_	_
CATANA	_	_
,	_	_
using	_	_
DBSCAN	_	_
for	_	_
clustering	_	_
,	_	_
in	_	_
case	_	_
only	_	_
noise	_	_
was	_	_
found	_	_
.	_	_

#287
As	_	_
described	_	_
in	_	_
the	_	_
previous	_	_
sections	_	_
,	_	_
clustering	_	_
is	_	_
applied	_	_
in	_	_
multiple	_	_
parts	_	_
,	_	_
for	_	_
example	_	_
,	_	_
speaker	_	_
diarization	_	_
,	_	_
speaker	_	_
recognition	_	_
,	_	_
and	_	_
face	_	_
recognition	_	_
which	_	_
all	_	_
use	_	_
clustering	_	_
at	_	_
some	_	_
point	_	_
to	_	_
group	_	_
the	_	_
extracted	_	_
data	_	_
.	_	_

#288
Additionally	_	_
,	_	_
at	_	_
the	_	_
end	_	_
of	_	_
the	_	_
pipeline	_	_
,	_	_
for	_	_
the	_	_
actual	_	_
collaboration	_	_
detection	_	_
,	_	_
all	_	_
found	_	_
embeddings	_	_
are	_	_
clustered	_	_
again	_	_
globally	_	_
to	_	_
associate	_	_
face	_	_
or	_	_
speaker	_	_
across	_	_
videos	_	_
and	_	_
channels	_	_
.	_	_

#289
For	_	_
global	_	_
clustering	_	_
a	_	_
Cython4	_	_
based	_	_
implementation	_	_
of	_	_
the	_	_
distance	_	_
matrix	_	_
computation	_	_
is	_	_
adopted	_	_
from	_	_
CATANA	_	_
.	_	_

#290
The	_	_
embeddings	_	_
are	_	_
thereby	_	_
stored	_	_
using	_	_
the	_	_
existing	_	_
data	_	_
storage	_	_
backend	_	_
of	_	_
CATANA	_	_
,	_	_
consisting	_	_
of	_	_
a	_	_
MySQL	_	_
database	_	_
.	_	_

#291
To	_	_
accompany	_	_
the	_	_
extension	_	_
,	_	_
the	_	_
original	_	_
database	_	_
scheme	_	_
was	_	_
adapted	_	_
to	_	_
additionally	_	_
store	_	_
both	_	_
face	_	_
and	_	_
speaker	_	_
embeddings	_	_
.	_	_

#292
A	_	_
special	_	_
case	_	_
for	_	_
the	_	_
application	_	_
of	_	_
clustering	_	_
is	_	_
the	_	_
merging	_	_
of	_	_
face	_	_
tracks	_	_
.	_	_

#293
This	_	_
is	_	_
necessary	_	_
as	_	_
too	_	_
long	_	_
face	_	_
tracks	_	_
are	_	_
split	_	_
up	_	_
as	_	_
described	_	_
in	_	_
section	_	_
V-A	_	_
,	_	_
resulting	_	_
in	_	_
a	_	_
large	_	_
number	_	_
of	_	_
tracks	_	_
which	_	_
may	_	_
only	_	_
contain	_	_
one	_	_
individual	_	_
.	_	_

#294
To	_	_
simplify	_	_
the	_	_
later	_	_
storage	_	_
,	_	_
tracks	_	_
of	_	_
the	_	_
same	_	_
individual	_	_
should	_	_
be	_	_
merged	_	_
back	_	_
together	_	_
.	_	_

#295
This	_	_
is	_	_
accomplished	_	_
by	_	_
clustering	_	_
all	_	_
split-up	_	_
face	_	_
tracks	_	_
based	_	_
on	_	_
their	_	_
face	_	_
embeddings	_	_
and	_	_
merging	_	_
them	_	_
according	_	_
to	_	_
the	_	_
found	_	_
cluster	_	_
label	_	_
.	_	_

#296
For	_	_
tracks	_	_
also	_	_
containing	_	_
speaker	_	_
embeddings	_	_
,	_	_
this	_	_
pair	_	_
of	_	_
embeddings	_	_
is	_	_
treated	_	_
as	_	_
one	_	_
entity	_	_
and	_	_
not	_	_
separated	_	_
by	_	_
merging	_	_
.	_	_

#297
VI	_	_
.	_	_

#298
EVALUATION	_	_
Evaluation	_	_
on	_	_
the	_	_
analyzed	_	_
YouTube	_	_
dataset	_	_
of	_	_
CATANA	_	_
is	_	_
desirable	_	_
.	_	_

#299
It	_	_
would	_	_
be	_	_
possible	_	_
to	_	_
compare	_	_
the	_	_
created	_	_
collaboration	_	_
graphs	_	_
and	_	_
their	_	_
properties	_	_
like	_	_
number	_	_
of	_	_
edges	_	_
,	_	_
nodes	_	_
,	_	_
and	_	_
clustering	_	_
index	_	_
.	_	_

#300
However	_	_
,	_	_
no	_	_
labeled	_	_
data	_	_
is	_	_
available	_	_
to	_	_
evaluate	_	_
the	_	_
actual	_	_
accuracy	_	_
of	_	_
both	_	_
methods	_	_
,	_	_
thus	_	_
we	_	_
could	_	_
not	_	_
determine	_	_
if	_	_
the	_	_
new	_	_
proposed	_	_
method	_	_
is	_	_
performing	_	_
4http	_	_
:	_	_
//cython.org	_	_
[	_	_
July	_	_
6	_	_
,	_	_
2018	_	_
]	_	_
VoxCeleb	_	_
Test	_	_
Set	_	_
Correct	_	_
Incorrect	_	_
Homogeneity	_	_
Completeness	_	_
V-Measure	_	_
CATANA	_	_
86	_	_
%	_	_
14	_	_
%	_	_
0.87	_	_
0.89	_	_
0.88	_	_
Speaker	_	_
Recognition	_	_
37	_	_
%	_	_
63	_	_
%	_	_
0.43	_	_
0.65	_	_
0.51	_	_
Proposed	_	_
method	_	_
60	_	_
%	_	_
40	_	_
%	_	_
0.54	_	_
0.55	_	_
0.55	_	_
TABLE	_	_
I	_	_
:	_	_
The	_	_
results	_	_
on	_	_
the	_	_
VoxCeleb	_	_
set	_	_
for	_	_
CATANA	_	_
,	_	_
speaker	_	_
recognition	_	_
and	_	_
our	_	_
approach	_	_
.	_	_

#301
better	_	_
or	_	_
not	_	_
.	_	_

#302
For	_	_
this	_	_
reason	_	_
,	_	_
we	_	_
have	_	_
chosen	_	_
to	_	_
evaluate	_	_
on	_	_
two	_	_
different	_	_
datasets	_	_
.	_	_

#303
First	_	_
,	_	_
we	_	_
evaluate	_	_
the	_	_
previously	_	_
presented	_	_
VoxCeleb	_	_
speaker	_	_
dataset	_	_
.	_	_

#304
In	_	_
this	_	_
dataset	_	_
the	_	_
speaker	_	_
is	_	_
always	_	_
visible	_	_
and	_	_
labeled	_	_
data	_	_
is	_	_
available	_	_
.	_	_

#305
This	_	_
allows	_	_
us	_	_
to	_	_
apply	_	_
both	_	_
,	_	_
CATANA	_	_
and	_	_
our	_	_
proposed	_	_
extension	_	_
to	_	_
the	_	_
data	_	_
.	_	_

#306
CATANA	_	_
thereby	_	_
only	_	_
uses	_	_
appearing	_	_
faces	_	_
for	_	_
classification	_	_
,	_	_
while	_	_
our	_	_
approach	_	_
can	_	_
also	_	_
leverage	_	_
speech	_	_
data	_	_
.	_	_

#307
Through	_	_
this	_	_
we	_	_
can	_	_
determine	_	_
if	_	_
speaker	_	_
recognition	_	_
can	_	_
improve	_	_
the	_	_
classification	_	_
accuracy	_	_
.	_	_

#308
The	_	_
VoxCeleb	_	_
dataset	_	_
consists	_	_
of	_	_
over	_	_
20,000	_	_
videos	_	_
of	_	_
1,251	_	_
individuals	_	_
.	_	_

#309
Due	_	_
to	_	_
time	_	_
constraint	_	_
of	_	_
this	_	_
work	_	_
we	_	_
will	_	_
not	_	_
analyze	_	_
the	_	_
complete	_	_
dataset	_	_
but	_	_
only	_	_
a	_	_
small	_	_
test	_	_
set	_	_
of	_	_
40	_	_
speakers	_	_
and	_	_
700	_	_
videos	_	_
(	_	_
selected	_	_
randomly	_	_
)	_	_
.	_	_

#310
Evaluated	_	_
will	_	_
be	_	_
which	_	_
person	_	_
is	_	_
occurring	_	_
in	_	_
which	_	_
video	_	_
,	_	_
without	_	_
any	_	_
prior	_	_
training	_	_
,	_	_
or	_	_
knowledge	_	_
of	_	_
included	_	_
individuals	_	_
(	_	_
open-set	_	_
classification	_	_
scenario	_	_
)	_	_
.	_	_

#311
Evaluation	_	_
metrics	_	_
used	_	_
for	_	_
this	_	_
first	_	_
dataset	_	_
are	_	_
the	_	_
percentage	_	_
of	_	_
correct	_	_
and	_	_
incorrect	_	_
assigned	_	_
videos	_	_
,	_	_
as	_	_
well	_	_
as	_	_
the	_	_
clustering	_	_
metrics	_	_
homogeneity	_	_
,	_	_
completeness	_	_
and	_	_
v-measure	_	_
,	_	_
as	_	_
its	_	_
ultimately	_	_
a	_	_
clustering	_	_
task	_	_
.	_	_

#312
The	_	_
homogeneity	_	_
score	_	_
is	_	_
a	_	_
value	_	_
between	_	_
0.0	_	_
and	_	_
1.0	_	_
,	_	_
while	_	_
1.0	_	_
stands	_	_
for	_	_
a	_	_
perfect	_	_
homogeneous	_	_
result	_	_
.	_	_

#313
Homogeneity	_	_
is	_	_
satisfied	_	_
if	_	_
all	_	_
clusters	_	_
contain	_	_
only	_	_
data	_	_
points	_	_
of	_	_
a	_	_
single	_	_
class	_	_
[	_	_
7	_	_
]	_	_
.	_	_

#314
Completeness	_	_
,	_	_
also	_	_
a	_	_
score	_	_
between	_	_
0.0	_	_
and	_	_
1.0	_	_
,	_	_
describes	_	_
if	_	_
all	_	_
members	_	_
of	_	_
a	_	_
given	_	_
class	_	_
are	_	_
assigned	_	_
to	_	_
the	_	_
same	_	_
cluster	_	_
[	_	_
7	_	_
]	_	_
.	_	_

#315
V-Measure	_	_
is	_	_
a	_	_
combined	_	_
metric	_	_
of	_	_
these	_	_
two	_	_
and	_	_
formed	_	_
by	_	_
the	_	_
harmonic	_	_
mean	_	_
of	_	_
the	_	_
homogeneity	_	_
and	_	_
completeness	_	_
score	_	_
.	_	_

#316
The	_	_
second	_	_
dataset	_	_
is	_	_
a	_	_
set	_	_
of	_	_
YouTube	_	_
videos	_	_
collected	_	_
in	_	_
this	_	_
work	_	_
.	_	_

#317
Videos	_	_
were	_	_
thereby	_	_
selected	_	_
based	_	_
on	_	_
properties	_	_
prior	_	_
difficult	_	_
for	_	_
the	_	_
CATANA	_	_
framework	_	_
,	_	_
like	_	_
gaming	_	_
videos	_	_
with	_	_
no	_	_
visible	_	_
faces	_	_
.	_	_

#318
A	_	_
set	_	_
of	_	_
72	_	_
videos	_	_
of	_	_
9	_	_
channels	_	_
was	_	_
collected	_	_
.	_	_

#319
Both	_	_
videos	_	_
with	_	_
and	_	_
without	_	_
collaborations	_	_
are	_	_
present	_	_
.	_	_

#320
There	_	_
is	_	_
a	_	_
total	_	_
of	_	_
34	_	_
collaborations	_	_
between	_	_
these	_	_
channels	_	_
.	_	_

#321
Additionally	_	_
,	_	_
only	_	_
25	_	_
of	_	_
these	_	_
72	_	_
videos	_	_
have	_	_
appearing	_	_
faces	_	_
,	_	_
while	_	_
the	_	_
rest	_	_
only	_	_
consists	_	_
of	_	_
non-visible	_	_
speakers	_	_
.	_	_

#322
Goal	_	_
for	_	_
this	_	_
dataset	_	_
is	_	_
the	_	_
evaluation	_	_
of	_	_
collaboration	_	_
detection	_	_
results	_	_
for	_	_
both	_	_
systems	_	_
.	_	_

#323
With	_	_
particularly	_	_
attention	_	_
on	_	_
the	_	_
difficult	_	_
cases	_	_
of	_	_
CATANA	_	_
,	_	_
we	_	_
evaluate	_	_
if	_	_
our	_	_
proposed	_	_
extensions	_	_
improve	_	_
the	_	_
detection	_	_
results	_	_
.	_	_

#324
Evaluated	_	_
will	_	_
be	_	_
the	_	_
resulting	_	_
collaboration	_	_
graph	_	_
,	_	_
the	_	_
number	_	_
of	_	_
processed	_	_
videos	_	_
,	_	_
the	_	_
number	_	_
of	_	_
correctly	_	_
and	_	_
incorrectly	_	_
detected	_	_
collaborations	_	_
,	_	_
as	_	_
well	_	_
as	_	_
the	_	_
time	_	_
needed	_	_
for	_	_
the	_	_
calculations	_	_
.	_	_

#325
A	_	_
.	_	_

#326
Evaluation	_	_
on	_	_
the	_	_
VoxCeleb	_	_
dataset	_	_
This	_	_
part	_	_
of	_	_
the	_	_
evaluation	_	_
is	_	_
based	_	_
on	_	_
a	_	_
subset	_	_
of	_	_
the	_	_
previously	_	_
described	_	_
VoxCeleb	_	_
dataset	_	_
.	_	_

#327
Per	_	_
definition	_	_
by	_	_
VoxCeleb	_	_
[	_	_
20	_	_
]	_	_
,	_	_
the	_	_
videos	_	_
should	_	_
always	_	_
contain	_	_
the	_	_
labeled	_	_
person	_	_
with	_	_
a	_	_
visible	_	_
face	_	_
and	_	_
actively	_	_
speaking	_	_
.	_	_

#328
The	_	_
videos	_	_
thereby	_	_
consist	_	_
mostly	_	_
of	_	_
interviews	_	_
and	_	_
therefore	_	_
could	_	_
contain	_	_
other	_	_
people	_	_
as	_	_
well	_	_
.	_	_

#329
The	_	_
results	_	_
on	_	_
this	_	_
test	_	_
set	_	_
for	_	_
CATANA	_	_
are	_	_
86	_	_
%	_	_
correct	_	_
assigned	_	_
videos	_	_
and	_	_
14	_	_
%	_	_
of	_	_
incorrectly	_	_
assignments	_	_
.	_	_

#330
Results	_	_
have	_	_
a	_	_
homogeneity	_	_
of	_	_
0.87	_	_
,	_	_
a	_	_
completeness	_	_
of	_	_
0.89	_	_
and	_	_
a	_	_
v-measure	_	_
0.88	_	_
.	_	_

#331
The	_	_
results	_	_
are	_	_
as	_	_
expected	_	_
,	_	_
as	_	_
in	_	_
this	_	_
dataset	_	_
every	_	_
speaker	_	_
is	_	_
visible	_	_
in	_	_
the	_	_
video	_	_
.	_	_

#332
Discrepancies	_	_
can	_	_
result	_	_
through	_	_
other	_	_
individuals	_	_
appearing	_	_
in	_	_
the	_	_
videos	_	_
,	_	_
which	_	_
are	_	_
not	_	_
labeled	_	_
in	_	_
the	_	_
dataset	_	_
,	_	_
for	_	_
example	_	_
,	_	_
the	_	_
interviewer	_	_
or	_	_
reporter	_	_
.	_	_

#333
Homogeneity	_	_
and	_	_
completeness	_	_
score	_	_
are	_	_
both	_	_
positive	_	_
and	_	_
show	_	_
that	_	_
the	_	_
found	_	_
clusters	_	_
consist	_	_
mostly	_	_
of	_	_
data	_	_
from	_	_
a	_	_
single	_	_
class	_	_
and	_	_
further	_	_
that	_	_
the	_	_
classes	_	_
are	_	_
not	_	_
scattered	_	_
over	_	_
multiple	_	_
clusters	_	_
but	_	_
mainly	_	_
contained	_	_
in	_	_
a	_	_
single	_	_
cluster	_	_
each	_	_
.	_	_

#334
For	_	_
the	_	_
evaluation	_	_
using	_	_
our	_	_
proposed	_	_
extension	_	_
,	_	_
a	_	_
pruning	_	_
of	_	_
the	_	_
VoxCeleb	_	_
test	_	_
set	_	_
had	_	_
to	_	_
be	_	_
done	_	_
due	_	_
to	_	_
the	_	_
time	_	_
consumption	_	_
of	_	_
processing	_	_
all	_	_
700	_	_
videos	_	_
.	_	_

#335
The	_	_
test	_	_
set	_	_
was	_	_
thereby	_	_
shortened	_	_
to	_	_
8	_	_
speaker	_	_
and	_	_
40	_	_
videos	_	_
.	_	_

#336
Regarding	_	_
evaluation	_	_
comparison	_	_
this	_	_
is	_	_
not	_	_
ideal	_	_
,	_	_
but	_	_
otherwise	_	_
no	_	_
result	_	_
could	_	_
have	_	_
been	_	_
obtained	_	_
in	_	_
time	_	_
.	_	_

#337
Results	_	_
for	_	_
our	_	_
proposed	_	_
approach	_	_
came	_	_
out	_	_
worse	_	_
than	_	_
anticipated	_	_
and	_	_
actually	_	_
performed	_	_
poorer	_	_
on	_	_
this	_	_
test	_	_
set	_	_
than	_	_
CATANA	_	_
.	_	_

#338
We	_	_
can	_	_
report	_	_
,	_	_
that	_	_
60	_	_
%	_	_
have	_	_
been	_	_
assigned	_	_
correctly	_	_
and	_	_
40	_	_
%	_	_
incorrectly	_	_
.	_	_

#339
The	_	_
homogeneity	_	_
has	_	_
a	_	_
value	_	_
of	_	_
0.58	_	_
,	_	_
the	_	_
completeness	_	_
is	_	_
0.55	_	_
,	_	_
and	_	_
the	_	_
v-measure	_	_
is	_	_
0.55	_	_
.	_	_

#340
Homogeneity	_	_
and	_	_
completeness	_	_
signify	_	_
both	_	_
that	_	_
the	_	_
data	_	_
was	_	_
scattered	_	_
into	_	_
multiple	_	_
clusters	_	_
showing	_	_
that	_	_
the	_	_
contained	_	_
classes	_	_
could	_	_
not	_	_
be	_	_
identified	_	_
and	_	_
separated	_	_
correctly	_	_
.	_	_

#341
Possible	_	_
reasons	_	_
for	_	_
these	_	_
results	_	_
could	_	_
be	_	_
the	_	_
varying	_	_
video	_	_
and	_	_
audio	_	_
quality	_	_
of	_	_
the	_	_
set	_	_
.	_	_

#342
After	_	_
examining	_	_
parts	_	_
of	_	_
the	_	_
videos	_	_
,	_	_
we	_	_
found	_	_
strong	_	_
difference	_	_
in	_	_
quality	_	_
for	_	_
videos	_	_
of	_	_
the	_	_
same	_	_
individual	_	_
,	_	_
which	_	_
could	_	_
lead	_	_
to	_	_
no	_	_
,	_	_
or	_	_
incorrect	_	_
recognition	_	_
especially	_	_
for	_	_
speakers	_	_
.	_	_

#343
The	_	_
results	_	_
are	_	_
shown	_	_
in	_	_
Table	_	_
I	_	_
for	_	_
an	_	_
easy	_	_
comparison	_	_
of	_	_
the	_	_
evaluated	_	_
approaches	_	_
on	_	_
the	_	_
VoxCeleb	_	_
dataset	_	_
.	_	_

#344
B	_	_
.	_	_

#345
Evaluation	_	_
of	_	_
speaker	_	_
recognition	_	_
only	_	_
To	_	_
further	_	_
directly	_	_
compare	_	_
face	_	_
and	_	_
speaker	_	_
recognition	_	_
,	_	_
we	_	_
evaluated	_	_
our	_	_
proposed	_	_
speaker	_	_
recognition	_	_
and	_	_
diarization	_	_
pipeline	_	_
on	_	_
the	_	_
same	_	_
VoxCeleb	_	_
subset	_	_
as	_	_
previously	_	_
while	_	_
only	_	_
5	_	_
15	_	_
25	_	_
40	_	_
set	_	_
size	_	_
m	_	_
ea	_	_
n	_	_
(	_	_
%	_	_
)	_	_
Clustering	_	_
accuracy	_	_
for	_	_
different	_	_
set-sizes	_	_
Correct	_	_
Incorrect	_	_
Fig.	_	_
10	_	_
:	_	_
Speaker	_	_
clustering	_	_
results	_	_
for	_	_
different	_	_
set	_	_
sizes	_	_
from	_	_
the	_	_
VoxCeleb	_	_
dataset	_	_
.	_	_

#346
YouTube	_	_
Gaming	_	_
Collection	_	_
Videos	_	_
detected	_	_
Videos	_	_
not	_	_
detected	_	_
Collaborations	_	_
found	_	_
Correct	_	_
collaborations	_	_
Time	_	_
(	_	_
h	_	_
)	_	_
Desired	_	_
Values	_	_
72	_	_
0	_	_
34	_	_
34	_	_
CATANA	_	_
31	_	_
41	_	_
13	_	_
0	_	_
6	_	_
Proposed	_	_
method	_	_
63	_	_
9	_	_
29	_	_
8	_	_
55	_	_
TABLE	_	_
II	_	_
:	_	_
The	_	_
results	_	_
on	_	_
the	_	_
YouTube	_	_
gaming	_	_
video	_	_
set	_	_
for	_	_
CATANA	_	_
and	_	_
our	_	_
approach	_	_
.	_	_

#347
utilizing	_	_
the	_	_
audio	_	_
content	_	_
.	_	_

#348
The	_	_
found	_	_
results	_	_
are	_	_
37	_	_
%	_	_
correct	_	_
assigned	_	_
videos	_	_
and	_	_
63	_	_
%	_	_
incorrect	_	_
assignments	_	_
.	_	_

#349
The	_	_
results	_	_
have	_	_
a	_	_
homogeneity	_	_
of	_	_
0.43	_	_
,	_	_
a	_	_
completeness	_	_
of	_	_
0.65	_	_
and	_	_
a	_	_
v-measure	_	_
of	_	_
0.51	_	_
.	_	_

#350
We	_	_
can	_	_
see	_	_
that	_	_
the	_	_
speaker	_	_
recognition	_	_
alone	_	_
performs	_	_
significantly	_	_
worse	_	_
than	_	_
face	_	_
recognition	_	_
and	_	_
conclude	_	_
that	_	_
speaker	_	_
recognition	_	_
alone	_	_
could	_	_
not	_	_
be	_	_
a	_	_
replacement	_	_
for	_	_
face	_	_
recognition	_	_
in	_	_
this	_	_
task	_	_
.	_	_

#351
A	_	_
reason	_	_
for	_	_
this	_	_
result	_	_
could	_	_
also	_	_
be	_	_
the	_	_
described	_	_
difference	_	_
in	_	_
video	_	_
and	_	_
audio	_	_
quality	_	_
.	_	_

#352
A	_	_
direct	_	_
comparison	_	_
can	_	_
be	_	_
found	_	_
in	_	_
Table	_	_
I	_	_
.	_	_

#353
To	_	_
further	_	_
evaluate	_	_
the	_	_
explanation	_	_
for	_	_
the	_	_
worse	_	_
performance	_	_
of	_	_
the	_	_
speaker	_	_
recognition	_	_
,	_	_
especially	_	_
compared	_	_
to	_	_
their	_	_
identification	_	_
accuracy	_	_
reported	_	_
with	_	_
>	_	_
90	_	_
%	_	_
[	_	_
20	_	_
]	_	_
,	_	_
we	_	_
conducted	_	_
additionally	_	_
tests	_	_
on	_	_
parts	_	_
of	_	_
the	_	_
VoxCeleb	_	_
dataset	_	_
using	_	_
their	_	_
provided	_	_
segment	_	_
boundaries	_	_
.	_	_

#354
This	_	_
is	_	_
done	_	_
to	_	_
ensure	_	_
that	_	_
only	_	_
the	_	_
labeled	_	_
individual	_	_
of	_	_
the	_	_
video	_	_
is	_	_
speaking	_	_
in	_	_
the	_	_
audio	_	_
.	_	_

#355
We	_	_
therefore	_	_
skipped	_	_
speaker	_	_
diarization	_	_
which	_	_
produced	_	_
these	_	_
segments	_	_
instead	_	_
in	_	_
the	_	_
first	_	_
evaluation	_	_
.	_	_

#356
Tested	_	_
using	_	_
segments	_	_
for	_	_
5	_	_
,	_	_
15	_	_
,	_	_
25	_	_
,	_	_
and	_	_
40	_	_
speakers	_	_
we	_	_
found	_	_
that	_	_
the	_	_
accuracy	_	_
significantly	_	_
increased	_	_
,	_	_
nearing	_	_
the	_	_
reported	_	_
accuracy	_	_
in	_	_
[	_	_
20	_	_
]	_	_
with	_	_
>	_	_
90	_	_
%	_	_
.	_	_

#357
This	_	_
indicates	_	_
that	_	_
the	_	_
speaker	_	_
diarization	_	_
seems	_	_
to	_	_
have	_	_
a	_	_
big	_	_
stake	_	_
in	_	_
the	_	_
accuracy	_	_
decrease	_	_
of	_	_
the	_	_
first	_	_
evaluation	_	_
.	_	_

#358
Leading	_	_
to	_	_
the	_	_
conclusion	_	_
that	_	_
the	_	_
used	_	_
speaker	_	_
diarization	_	_
system	_	_
could	_	_
not	_	_
provide	_	_
as	_	_
good	_	_
segmentations	_	_
as	_	_
the	_	_
labeled	_	_
data	_	_
of	_	_
the	_	_
VoxCeleb	_	_
dataset	_	_
and	_	_
seems	_	_
to	_	_
be	_	_
a	_	_
weak	_	_
point	_	_
in	_	_
the	_	_
pipeline	_	_
.	_	_

#359
Figure	_	_
10	_	_
shows	_	_
the	_	_
mean	_	_
results	_	_
for	_	_
the	_	_
different	_	_
set	_	_
sizes	_	_
using	_	_
a	_	_
confidence	_	_
interval	_	_
of	_	_
95	_	_
%	_	_
.	_	_

#360
Evaluation	_	_
was	_	_
thereby	_	_
conducted	_	_
in	_	_
a	_	_
10-fold	_	_
fashion	_	_
,	_	_
selecting	_	_
random	_	_
individuals	_	_
from	_	_
a	_	_
set	_	_
of	_	_
40	_	_
speakers	_	_
for	_	_
ten	_	_
iterations	_	_
.	_	_

#361
The	_	_
narrow	_	_
confidence	_	_
interval	_	_
for	_	_
the	_	_
set	_	_
of	_	_
40	_	_
speaker	_	_
is	_	_
due	_	_
to	_	_
that	_	_
in	_	_
every	_	_
iteration	_	_
all	_	_
40	_	_
speakers	_	_
of	_	_
the	_	_
test	_	_
set	_	_
were	_	_
selected	_	_
.	_	_

#362
C.	_	_
Evaluation	_	_
on	_	_
gaming	_	_
videos	_	_
In	_	_
order	_	_
to	_	_
evaluate	_	_
our	_	_
proposed	_	_
extension	_	_
concerning	_	_
the	_	_
cases	_	_
which	_	_
CATANA	_	_
failed	_	_
to	_	_
detect	_	_
,	_	_
we	_	_
conducted	_	_
an	_	_
evaluation	_	_
on	_	_
a	_	_
dataset	_	_
consisting	_	_
mainly	_	_
of	_	_
videos	_	_
with	_	_
no	_	_
visible	_	_
faces	_	_
.	_	_

#363
The	_	_
dataset	_	_
contains	_	_
72	_	_
videos	_	_
from	_	_
nine	_	_
channels	_	_
,	_	_
of	_	_
which	_	_
47	_	_
videos	_	_
contain	_	_
only	_	_
speech	_	_
without	_	_
appearing	_	_
faces	_	_
.	_	_

#364
A	_	_
total	_	_
of	_	_
34	_	_
collaborations	_	_
occur	_	_
in	_	_
the	_	_
dataset	_	_
,	_	_
modeling	_	_
a	_	_
collaboration	_	_
graph	_	_
with	_	_
9	_	_
nodes	_	_
and	_	_
7	_	_
edges	_	_
displayed	_	_
in	_	_
Figure	_	_
11	_	_
.	_	_

#365
The	_	_
results	_	_
of	_	_
CATANA	_	_
are	_	_
,	_	_
not	_	_
surprisingly	_	_
,	_	_
very	_	_
poor	_	_
.	_	_

#366
CATANA	_	_
was	_	_
only	_	_
able	_	_
to	_	_
extract	_	_
and	_	_
cluster	_	_
embeddings	_	_
from	_	_
31	_	_
of	_	_
the	_	_
72	_	_
videos	_	_
.	_	_

#367
In	_	_
total	_	_
13	_	_
collaborations	_	_
were	_	_
detected	_	_
,	_	_
resulting	_	_
in	_	_
a	_	_
collaboration	_	_
graph	_	_
with	_	_
9	_	_
nodes	_	_
and	_	_
7	_	_
edges	_	_
.	_	_

#368
For	_	_
parts	_	_
of	_	_
the	_	_
found	_	_
collaboration-edges	_	_
between	_	_
the	_	_
channels	_	_
BeHaind	_	_
and	_	_
Battle	_	_
Bros	_	_
the	_	_
detections	_	_
were	_	_
correct	_	_
but	_	_
falsely	_	_
assigned	_	_
the	_	_
face	_	_
of	_	_
BeHaind	_	_
as	_	_
the	_	_
content	_	_
creator	_	_
of	_	_
Battle	_	_
Bros	_	_
.	_	_

#369
This	_	_
lead	_	_
to	_	_
no	_	_
edge	_	_
in	_	_
the	_	_
collaborations	_	_
graph	_	_
from	_	_
BeHaind	_	_
to	_	_
Battle	_	_
Bros	_	_
,	_	_
but	_	_
instead	_	_
an	_	_
edge	_	_
from	_	_
Battle	_	_
Bros	_	_
to	_	_
BeHaind	_	_
.	_	_

#370
The	_	_
Reason	_	_
for	_	_
this	_	_
false	_	_
assignment	_	_
was	_	_
the	_	_
number	_	_
of	_	_
videos	_	_
where	_	_
BeHaind	_	_
appeared	_	_
,	_	_
which	_	_
were	_	_
higher	_	_
in	_	_
Battle	_	_
Bros	_	_
than	_	_
on	_	_
his	_	_
own	_	_
channel	_	_
.	_	_

#371
We	_	_
suppose	_	_
a	_	_
larger	_	_
dataset	_	_
could	_	_
prevent	_	_
this	_	_
error	_	_
.	_	_

#372
Concerning	_	_
appearing	_	_
faces	_	_
in	_	_
the	_	_
dataset	_	_
,	_	_
in	_	_
82	_	_
%	_	_
of	_	_
the	_	_
videos	_	_
detected	_	_
through	_	_
CATANA	_	_
,	_	_
faces	_	_
actual	_	_
appeared	_	_
.	_	_

#373
In	_	_
the	_	_
remaining	_	_
17	_	_
%	_	_
of	_	_
the	_	_
videos	_	_
,	_	_
CATANA	_	_
detected	_	_
faces	_	_
where	_	_
no	_	_
faces	_	_
had	_	_
appeared	_	_
.	_	_

#374
Possible	_	_
false	_	_
detections	_	_
could	_	_
potentially	_	_
be	_	_
caused	_	_
through	_	_
appearing	_	_
game	_	_
characters	_	_
.	_	_

#375
The	_	_
evaluation	_	_
of	_	_
our	_	_
proposed	_	_
extension	_	_
results	_	_
has	_	_
improved	_	_
the	_	_
results	_	_
but	_	_
is	_	_
not	_	_
satisfying	_	_
regarding	_	_
accuracy	_	_
and	_	_
quantity	_	_
.	_	_

#376
Table	_	_
II	_	_
shows	_	_
the	_	_
results	_	_
of	_	_
the	_	_
evaluation	_	_
on	_	_
the	_	_
YouTube	_	_
dataset	_	_
.	_	_

#377
In	_	_
comparison	_	_
to	_	_
CATANA’s	_	_
results	_	_
,	_	_
more	_	_
videos	_	_
could	_	_
be	_	_
detected	_	_
and	_	_
embeddings	_	_
extracted	_	_
.	_	_

#378
In	_	_
total	_	_
,	_	_
we	_	_
found	_	_
896	_	_
embeddings	_	_
which	_	_
were	_	_
clustered	_	_
to	_	_
56	_	_
clusters	_	_
(	_	_
not	_	_
including	_	_
noise	_	_
)	_	_
.	_	_

#379
41	_	_
of	_	_
these	_	_
clusters	_	_
were	_	_
speaker	_	_
clusters	_	_
and	_	_
15	_	_
were	_	_
face	_	_
clusters	_	_
.	_	_

#380
The	_	_
resulting	_	_
collaboration	_	_
graph	_	_
contains	_	_
9	_	_
nodes	_	_
,	_	_
16	_	_
edges	_	_
and	_	_
a	_	_
total	_	_
of	_	_
29	_	_
detected	_	_
collaborations	_	_
.	_	_

#381
The	_	_
collaboration	_	_
graph	_	_
is	_	_
shown	_	_
in	_	_
Figure	_	_
12b	_	_
.	_	_

#382
In	_	_
comparisons	_	_
to	_	_
CATANA	_	_
,	_	_
more	_	_
collaborations	_	_
were	_	_
detected	_	_
including	_	_
an	_	_
improvement	_	_
in	_	_
the	_	_
number	_	_
of	_	_
correct	_	_
detected	_	_
collaborations	_	_
.	_	_

#383
We	_	_
could	_	_
notice	_	_
that	_	_
most	_	_
of	_	_
the	_	_
collaborations	_	_
including	_	_
only	_	_
two	_	_
content	_	_
creators	_	_
were	_	_
detected	_	_
correctly	_	_
.	_	_

#384
Other	_	_
collaborations	_	_
with	_	_
up	_	_
to	_	_
4	_	_
participating	_	_
content	_	_
creators	_	_
were	_	_
not	_	_
correctly	_	_
detected	_	_
.	_	_

#385
This	_	_
could	_	_
potentially	_	_
be	_	_
attributed	_	_
to	_	_
the	_	_
previous	_	_
results	_	_
on	_	_
speaker	_	_
diarization	_	_
concerning	_	_
discussions	_	_
with	_	_
multiple	_	_
people	_	_
.	_	_

#386
Another	_	_
point	_	_
is	_	_
an	_	_
implementation	_	_
detail	_	_
concerning	_	_
the	_	_
execution	_	_
of	_	_
speaker	_	_
diarization	_	_
.	_	_

#387
The	_	_
initial	_	_
design	_	_
decision	_	_
was	_	_
to	_	_
execute	_	_
speaker	_	_
diarization	_	_
only	_	_
after	_	_
face	_	_
tracking	_	_
and	_	_
active	_	_
speaker	_	_
detection	_	_
,	_	_
and	_	_
if	_	_
no	_	_
active	_	_
speaker	_	_
was	_	_
detected	_	_
.	_	_

#388
Due	_	_
to	_	_
emerging	_	_
cases	_	_
with	_	_
only	_	_
a	_	_
single	_	_
active	_	_
speaker	_	_
combined	_	_
with	_	_
multiple	_	_
non-visible	_	_
speakers	_	_
,	_	_
thus	_	_
decision	_	_
reveals	_	_
a	_	_
flaw	_	_
and	_	_
could	_	_
affect	_	_
accuracy	_	_
further	_	_
.	_	_

#389
Adapting	_	_
our	_	_
design	_	_
to	_	_
this	_	_
case	_	_
is	_	_
an	_	_
easy	_	_
task	_	_
,	_	_
however	_	_
re-evaluating	_	_
the	_	_
YouTube	_	_
dataset	_	_
is	_	_
not	_	_
possible	_	_
due	_	_
to	_	_
the	_	_
time	_	_
constraints	_	_
of	_	_
this	_	_
work	_	_
.	_	_

#390
Another	_	_
considerable	_	_
factor	_	_
is	_	_
the	_	_
time	_	_
.	_	_

#391
While	_	_
CATANA	_	_
needed	_	_
five	_	_
hours	_	_
to	_	_
calculate	_	_
the	_	_
results	_	_
,	_	_
our	_	_
proposed	_	_
algorithm	_	_
took	_	_
55	_	_
hours	_	_
,	_	_
mainly	_	_
attributable	_	_
to	_	_
the	_	_
face	_	_
tracking	_	_
.	_	_

#392
The	_	_
results	_	_
are	_	_
slightly	_	_
better	_	_
,	_	_
for	_	_
almost	_	_
ten	_	_
times	_	_
the	_	_
time	_	_
CATANA	_	_
needs	_	_
.	_	_

#393
VII	_	_
.	_	_

#394
DISCUSSION	_	_
During	_	_
the	_	_
evaluation	_	_
,	_	_
we	_	_
could	_	_
determine	_	_
that	_	_
the	_	_
implemented	_	_
pipeline	_	_
still	_	_
has	_	_
vast	_	_
room	_	_
for	_	_
improvements	_	_
.	_	_

#395
Due	_	_
to	_	_
significant	_	_
problems	_	_
in	_	_
development	_	_
and	_	_
acquiring	_	_
satisfying	_	_
results	_	_
of	_	_
individual	_	_
pipeline	_	_
parts	_	_
,	_	_
we	_	_
were	_	_
not	_	_
able	_	_
to	_	_
invest	_	_
a	_	_
lot	_	_
of	_	_
time	_	_
to	_	_
improve	_	_
the	_	_
accuracy	_	_
and	_	_
quality	_	_
of	_	_
the	_	_
overall	_	_
results	_	_
of	_	_
our	_	_
approach	_	_
.	_	_

#396
Especially	_	_
due	_	_
Fig.	_	_
11	_	_
:	_	_
Collaboration	_	_
graph	_	_
of	_	_
the	_	_
YouTube	_	_
video	_	_
test	_	_
set	_	_
.	_	_

#397
Showing	_	_
channels	_	_
as	_	_
nodes	_	_
,	_	_
including	_	_
channel	_	_
name	_	_
and	_	_
number	_	_
of	_	_
videos	_	_
in	_	_
the	_	_
set	_	_
.	_	_

#398
The	_	_
numbers	_	_
on	_	_
the	_	_
edges	_	_
represent	_	_
the	_	_
number	_	_
of	_	_
videos	_	_
and	_	_
collaborations	_	_
between	_	_
the	_	_
channels	_	_
.	_	_

#399
(	_	_
a	_	_
)	_	_
CATANA	_	_
detected	_	_
collaborations	_	_
.	_	_

#400
(	_	_
b	_	_
)	_	_
Proposed	_	_
system	_	_
detected	_	_
collaborations	_	_
.	_	_

#401
Fig.	_	_
12	_	_
:	_	_
Collaboration	_	_
results	_	_
for	_	_
CATANA	_	_
and	_	_
our	_	_
new	_	_
proposed	_	_
approach	_	_
.	_	_

#402
Correct	_	_
collaboration	_	_
edges	_	_
marked	_	_
green	_	_
.	_	_

#403
to	_	_
the	_	_
time-consuming	_	_
evaluation	_	_
,	_	_
as	_	_
parts	_	_
like	_	_
face	_	_
tracking	_	_
are	_	_
very	_	_
time	_	_
expensive	_	_
.	_	_

#404
We	_	_
suggest	_	_
that	_	_
CATANA	_	_
is	_	_
about	_	_
ten	_	_
times	_	_
faster	_	_
in	_	_
processing	_	_
videos	_	_
than	_	_
our	_	_
approach	_	_
.	_	_

#405
For	_	_
this	_	_
reason	_	_
,	_	_
the	_	_
approach	_	_
may	_	_
be	_	_
more	_	_
suited	_	_
to	_	_
investigate	_	_
small	_	_
sets	_	_
of	_	_
videos	_	_
rather	_	_
than	_	_
big	_	_
sets	_	_
,	_	_
at	_	_
least	_	_
at	_	_
this	_	_
stage	_	_
of	_	_
development	_	_
.	_	_

#406
Video	_	_
quality	_	_
is	_	_
also	_	_
a	_	_
major	_	_
criterion	_	_
for	_	_
the	_	_
output	_	_
.	_	_

#407
In	_	_
many	_	_
YouTube	_	_
formats	_	_
especially	_	_
Gaming	_	_
,	_	_
the	_	_
content	_	_
creator	_	_
is	_	_
visible	_	_
on	_	_
a	_	_
so-called	_	_
face	_	_
cam	_	_
,	_	_
a	_	_
small	_	_
video	_	_
stream	_	_
of	_	_
the	_	_
face	_	_
which	_	_
is	_	_
placed	_	_
in	_	_
one	_	_
of	_	_
the	_	_
corners	_	_
in	_	_
the	_	_
video	_	_
.	_	_

#408
We	_	_
determined	_	_
,	_	_
that	_	_
only	_	_
good	_	_
results	_	_
could	_	_
be	_	_
achieved	_	_
for	_	_
face	_	_
cams	_	_
and	_	_
other	_	_
small	_	_
faces	_	_
in	_	_
the	_	_
video	_	_
if	_	_
the	_	_
video	_	_
quality	_	_
is	_	_
at	_	_
least	_	_
720p	_	_
(	_	_
1280x720	_	_
pixel	_	_
)	_	_
.	_	_

#409
This	_	_
ensures	_	_
,	_	_
that	_	_
the	_	_
cropped	_	_
face	_	_
has	_	_
still	_	_
a	_	_
resolution	_	_
of	_	_
160x160	_	_
.	_	_

#410
If	_	_
the	_	_
cropped	_	_
face	_	_
should	_	_
be	_	_
smaller	_	_
,	_	_
the	_	_
image	_	_
will	_	_
be	_	_
scaled	_	_
up	_	_
to	_	_
the	_	_
size	_	_
of	_	_
160x160	_	_
.	_	_

#411
This	_	_
results	_	_
in	_	_
a	_	_
blurry	_	_
face	_	_
image	_	_
leading	_	_
to	_	_
bad	_	_
results	_	_
in	_	_
active	_	_
speaker	_	_
and	_	_
face	_	_
recognition	_	_
.	_	_

#412
Concerning	_	_
our	_	_
YouTube	_	_
test	_	_
set	_	_
,	_	_
videos	_	_
showing	_	_
game	_	_
content	_	_
had	_	_
surprisingly	_	_
no	_	_
noticeable	_	_
impact	_	_
on	_	_
the	_	_
results	_	_
.	_	_

#413
As	_	_
it	_	_
was	_	_
initially	_	_
thought	_	_
that	_	_
especially	_	_
game	_	_
characters	_	_
could	_	_
trigger	_	_
speaker	_	_
and	_	_
face	_	_
recognition	_	_
,	_	_
which	_	_
however	_	_
was	_	_
not	_	_
the	_	_
case	_	_
in	_	_
our	_	_
results	_	_
.	_	_

#414
VIII	_	_
.	_	_

#415
CONCLUSION	_	_
The	_	_
goal	_	_
of	_	_
this	_	_
work	_	_
was	_	_
to	_	_
design	_	_
and	_	_
implement	_	_
an	_	_
approach	_	_
for	_	_
the	_	_
detection	_	_
of	_	_
content	_	_
creator	_	_
collaborations	_	_
in	_	_
YouTube	_	_
videos	_	_
.	_	_

#416
We	_	_
based	_	_
our	_	_
approach	_	_
on	_	_
the	_	_
existing	_	_
work	_	_
of	_	_
CATANA	_	_
[	_	_
13	_	_
]	_	_
and	_	_
proposed	_	_
an	_	_
extension	_	_
,	_	_
which	_	_
makes	_	_
use	_	_
of	_	_
face	_	_
tracking	_	_
,	_	_
active	_	_
speaker	_	_
detection	_	_
and	_	_
speaker	_	_
recognition	_	_
.	_	_

#417
This	_	_
extension	_	_
was	_	_
designed	_	_
to	_	_
address	_	_
open	_	_
issues	_	_
with	_	_
CATANA’s	_	_
face	_	_
recognition	_	_
approach	_	_
concerning	_	_
videos	_	_
without	_	_
appearing	_	_
faces	_	_
.	_	_

#418
We	_	_
implemented	_	_
a	_	_
working	_	_
pipeline	_	_
which	_	_
extracts	_	_
face	_	_
tracks	_	_
from	_	_
videos	_	_
,	_	_
decides	_	_
whether	_	_
an	_	_
individual	_	_
is	_	_
currently	_	_
speaking	_	_
and	_	_
labels	_	_
active	_	_
speakers	_	_
.	_	_

#419
Speech	_	_
is	_	_
extracted	_	_
and	_	_
an	_	_
embedding	_	_
is	_	_
calculated	_	_
for	_	_
clustering	_	_
occurring	_	_
speakers	_	_
.	_	_

#420
Additionally	_	_
,	_	_
the	_	_
existing	_	_
face	_	_
recognition	_	_
method	_	_
is	_	_
applied	_	_
as	_	_
well	_	_
.	_	_

#421
In	_	_
the	_	_
best	_	_
case	_	_
,	_	_
face	_	_
and	_	_
speaker	_	_
embeddings	_	_
describing	_	_
the	_	_
same	_	_
individual	_	_
are	_	_
extracted	_	_
and	_	_
associated	_	_
,	_	_
allowing	_	_
us	_	_
to	_	_
recognize	_	_
this	_	_
individual	_	_
separate	_	_
through	_	_
either	_	_
speech	_	_
or	_	_
face	_	_
features	_	_
.	_	_

#422
Evaluation	_	_
of	_	_
the	_	_
implemented	_	_
system	_	_
was	_	_
conducted	_	_
on	_	_
two	_	_
datasets	_	_
and	_	_
compared	_	_
to	_	_
results	_	_
of	_	_
CATANA	_	_
.	_	_

#423
Results	_	_
for	_	_
the	_	_
collaboration	_	_
detection	_	_
in	_	_
gaming	_	_
videos	_	_
with	_	_
mainly	_	_
no	_	_
visible	_	_
faces	_	_
showed	_	_
an	_	_
improvement	_	_
in	_	_
accuracy	_	_
and	_	_
quantity	_	_
but	_	_
also	_	_
flaws	_	_
in	_	_
the	_	_
current	_	_
pipeline	_	_
.	_	_

#424
One	_	_
weak	_	_
point	_	_
of	_	_
the	_	_
pipeline	_	_
being	_	_
the	_	_
speaker	_	_
diarization	_	_
.	_	_

#425
Therefore	_	_
,	_	_
we	_	_
conclude	_	_
that	_	_
the	_	_
proposed	_	_
approach	_	_
has	_	_
potential	_	_
in	_	_
the	_	_
application	_	_
of	_	_
collaboration	_	_
detection	_	_
but	_	_
needs	_	_
further	_	_
refinement	_	_
to	_	_
make	_	_
it	_	_
a	_	_
viable	_	_
replacement	_	_
for	_	_
CATANA	_	_
and	_	_
beyond	_	_
.	_	_