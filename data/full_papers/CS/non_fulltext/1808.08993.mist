#0
Open	_	_
Set	_	_
Chinese	_	_
Character	_	_
Recognition	_	_
using	_	_
Multi-typed	_	_
Attributes	_	_
Sheng	_	_
He∗	_	_
,	_	_
Lambert	_	_
Schomaker	_	_
Institute	_	_
of	_	_
Artificial	_	_
Intelligence	_	_
and	_	_
Cognitive	_	_
Engineering	_	_
,	_	_
University	_	_
of	_	_
Groningen	_	_
,	_	_
PO	_	_
Box	_	_
407	_	_
,	_	_
9700	_	_
AK	_	_
,	_	_
Groningen	_	_
,	_	_
The	_	_
Netherlands	_	_

#1
Abstract	_	_

#2
Recognition	_	_
of	_	_
Off-line	_	_
Chinese	_	_
characters	_	_
is	_	_
still	_	_
a	_	_
challenging	_	_
problem	_	_
,	_	_
especially	_	_
in	_	_
historical	_	_
documents	_	_
,	_	_
not	_	_
only	_	_
in	_	_
the	_	_
number	_	_
of	_	_
classes	_	_
extremely	_	_
large	_	_
in	_	_
comparison	_	_
to	_	_
contemporary	_	_
image	_	_
retrieval	_	_
methods	_	_
,	_	_
but	_	_
also	_	_
new	_	_
unseen	_	_
classes	_	_
can	_	_
be	_	_
expected	_	_
under	_	_
open	_	_
learning	_	_
conditions	_	_
(	_	_
even	_	_
for	_	_
CNN	_	_
)	_	_
.	_	_

#3
Chinese	_	_
character	_	_
recognition	_	_
with	_	_
zero	_	_
or	_	_
a	_	_
few	_	_
training	_	_
samples	_	_
is	_	_
a	_	_
difficult	_	_
problem	_	_
and	_	_
has	_	_
not	_	_
been	_	_
studied	_	_
yet	_	_
.	_	_

#4
In	_	_
this	_	_
paper	_	_
,	_	_
we	_	_
propose	_	_
a	_	_
new	_	_
Chinese	_	_
character	_	_
recognition	_	_
method	_	_
by	_	_
multi-type	_	_
attributes	_	_
,	_	_
which	_	_
are	_	_
based	_	_
on	_	_
pronunciation	_	_
,	_	_
structure	_	_
and	_	_
radicals	_	_
of	_	_
Chinese	_	_
characters	_	_
,	_	_
applied	_	_
to	_	_
character	_	_
recognition	_	_
in	_	_
historical	_	_
books	_	_
.	_	_

#5
This	_	_
intermediate	_	_
attribute	_	_
code	_	_
has	_	_
a	_	_
strong	_	_
advantage	_	_
over	_	_
the	_	_
common	_	_
“one-hot”	_	_
class	_	_
representation	_	_
because	_	_
it	_	_
allows	_	_
for	_	_
understanding	_	_
complex	_	_
and	_	_
unseen	_	_
patterns	_	_
symbolically	_	_
using	_	_
attributes	_	_
.	_	_

#6
First	_	_
,	_	_
each	_	_
character	_	_
is	_	_
represented	_	_
by	_	_
four	_	_
groups	_	_
of	_	_
attribute	_	_
types	_	_
to	_	_
cover	_	_
a	_	_
wide	_	_
range	_	_
of	_	_
character	_	_
possibilities	_	_
:	_	_
Pinyin	_	_
label	_	_
,	_	_
layout	_	_
structure	_	_
,	_	_
number	_	_
of	_	_
strokes	_	_
,	_	_
three	_	_
different	_	_
input	_	_
methods	_	_
such	_	_
as	_	_
Cangjie	_	_
,	_	_
Zhengma	_	_
and	_	_
Wubi	_	_
,	_	_
as	_	_
well	_	_
as	_	_
a	_	_
fourcorner	_	_
encoding	_	_
method	_	_
.	_	_

#7
A	_	_
convolutional	_	_
neural	_	_
network	_	_
(	_	_
CNN	_	_
)	_	_
is	_	_
trained	_	_
to	_	_
learn	_	_
these	_	_
attributes	_	_
.	_	_

#8
Subsequently	_	_
,	_	_
characters	_	_
can	_	_
be	_	_
easily	_	_
recognized	_	_
by	_	_
these	_	_
attributes	_	_
using	_	_
a	_	_
distance	_	_
metric	_	_
and	_	_
a	_	_
complete	_	_
lexicon	_	_
that	_	_
is	_	_
encoded	_	_
in	_	_
attribute	_	_
space	_	_
.	_	_

#9
We	_	_
evaluate	_	_
the	_	_
proposed	_	_
method	_	_
on	_	_
two	_	_
open	_	_
data	_	_
sets	_	_
:	_	_
printed	_	_
Chinese	_	_
character	_	_
recognition	_	_
for	_	_
zero-shot	_	_
learning	_	_
,	_	_
historical	_	_
characters	_	_
for	_	_
few-shot	_	_
learning	_	_
and	_	_
a	_	_
closed	_	_
set	_	_
:	_	_
handwritten	_	_
Chinese	_	_
characters	_	_
.	_	_

#10
Experimental	_	_
results	_	_
show	_	_
a	_	_
good	_	_
general	_	_
classification	_	_
of	_	_
seen	_	_
classes	_	_
but	_	_
also	_	_
a	_	_
very	_	_
promising	_	_
generalization	_	_
ability	_	_
to	_	_
unseen	_	_
characters	_	_
.	_	_

#11
Keywords	_	_
:	_	_
Chinese	_	_
character	_	_
attributes	_	_
,	_	_
Chinese	_	_
character	_	_
recognition	_	_
,	_	_
zero-shot	_	_
and	_	_
few-shot	_	_
learning	_	_
,	_	_
convolutional	_	_
neural	_	_
network	_	_
.	_	_

#12
∗Corresponding	_	_
author	_	_
Email	_	_
addresses	_	_
:	_	_
heshengxgd	_	_
@	_	_
gmail.com	_	_
(	_	_
Sheng	_	_
He	_	_
)	_	_
,	_	_
L.Schomaker	_	_
@	_	_
ai.rug.nl	_	_
(	_	_
Lambert	_	_
Schomaker	_	_
)	_	_
Preprint	_	_
submitted	_	_
to	_	_
Elsevier	_	_
April	_	_
25	_	_
,	_	_
2021	_	_
ar	_	_
X	_	_
iv	_	_
:1	_	_
8	_	_
.	_	_

#13
3v	_	_
1	_	_
[	_	_
cs	_	_
.C	_	_
V	_	_
]	_	_
2	_	_
7	_	_
A	_	_
ug	_	_
2	_	_
1	_	_
.	_	_

#14
Introduction	_	_
Most	_	_
Chinese	_	_
character-recognition	_	_
methods	_	_
focus	_	_
on	_	_
handwritten	_	_
Chinese	_	_
characters	_	_
based	_	_
on	_	_
a	_	_
balanced	_	_
“closed”	_	_
data	_	_
set	_	_
,	_	_
which	_	_
contains	_	_
most	_	_
frequently-used	_	_
3,755	_	_
characters	_	_
(	_	_
classes	_	_
)	_	_
and	_	_
each	_	_
character	_	_
has	_	_
several	_	_
hundred	_	_
samples	_	_
[	_	_
1	_	_
]	_	_
.	_	_

#15
All	_	_
testing	_	_
characters	_	_
are	_	_
known	_	_
at	_	_
training	_	_
time	_	_
,	_	_
which	_	_
is	_	_
called	_	_
“closed	_	_
set”	_	_
recognition	_	_
[	_	_
2	_	_
]	_	_
.	_	_

#16
A	_	_
typical	_	_
traditional	_	_
recognition	_	_
model	_	_
has	_	_
two	_	_
parts	_	_
:	_	_
feature	_	_
extraction	_	_
and	_	_
classification	_	_
.	_	_

#17
The	_	_
most	_	_
popular	_	_
feature	_	_
extraction	_	_
method	_	_
is	_	_
proposed	_	_
in	_	_
[	_	_
3	_	_
]	_	_
,	_	_
which	_	_
computes	_	_
features	_	_
based	_	_
on	_	_
directional	_	_
feature	_	_
maps	_	_
.	_	_

#18
This	_	_
method	_	_
is	_	_
extended	_	_
to	_	_
a	_	_
quadratic	_	_
feature	_	_
learning	_	_
method	_	_
[	_	_
4	_	_
]	_	_
by	_	_
feature	_	_
dimensionality	_	_
promotion	_	_
and	_	_
reduction	_	_
.	_	_

#19
The	_	_
modified	_	_
quadratic	_	_
discriminant	_	_
function	_	_
(	_	_
MQDF	_	_
)	_	_
[	_	_
5	_	_
]	_	_
and	_	_
compact	_	_
MQDF	_	_
[	_	_
6	_	_
]	_	_
has	_	_
been	_	_
successfully	_	_
used	_	_
for	_	_
handwritten	_	_
Chinese	_	_
character	_	_
recognition	_	_
.	_	_

#20
Recently	_	_
,	_	_
convolutional	_	_
neural	_	_
networks	_	_
(	_	_
CNN	_	_
)	_	_
have	_	_
also	_	_
been	_	_
applied	_	_
to	_	_
Chinese	_	_
character	_	_
recognition	_	_
[	_	_
7	_	_
,	_	_
8	_	_
,	_	_
9	_	_
]	_	_
.	_	_

#21
Zhang	_	_
et	_	_
al.	_	_
[	_	_
10	_	_
]	_	_
use	_	_
neural	_	_
networks	_	_
for	_	_
recognition	_	_
of	_	_
Chinese	_	_
characters	_	_
,	_	_
with	_	_
directional	_	_
feature	_	_
maps	_	_
as	_	_
input	_	_
.	_	_

#22
Xiao	_	_
et	_	_
al.	_	_
[	_	_
11	_	_
]	_	_
propose	_	_
a	_	_
fast	_	_
and	_	_
compact	_	_
CNN	_	_
to	_	_
reduce	_	_
the	_	_
network’s	_	_
computational	_	_
cost	_	_
for	_	_
Chinese	_	_
character	_	_
recognition	_	_
.	_	_

#23
All	_	_
of	_	_
these	_	_
methods	_	_
mentioned	_	_
above	_	_
consider	_	_
each	_	_
character	_	_
as	_	_
a	_	_
single	_	_
class	_	_
[	_	_
4	_	_
,	_	_
10	_	_
,	_	_
11	_	_
]	_	_
.	_	_

#24
A	_	_
pool	_	_
of	_	_
training	_	_
and	_	_
testing	_	_
samples	_	_
is	_	_
available	_	_
for	_	_
training	_	_
a	_	_
model	_	_
to	_	_
recognize	_	_
Chinese	_	_
characters	_	_
.	_	_

#25
The	_	_
problems	_	_
of	_	_
these	_	_
approaches	_	_
are	_	_
that	_	_
(	_	_
1	_	_
)	_	_
the	_	_
number	_	_
of	_	_
characters	_	_
is	_	_
very	_	_
large	_	_
and	_	_
uncertain	_	_
in	_	_
real-world	_	_
applications	_	_
,	_	_
which	_	_
corresponding	_	_
to	_	_
the	_	_
“open	_	_
set”	_	_
recognition	_	_
problem	_	_
[	_	_
2	_	_
]	_	_
.	_	_

#26
For	_	_
modern	_	_
Chinese	_	_
texts	_	_
,	_	_
a	_	_
more	_	_
complete	_	_
set	_	_
would	_	_
contain	_	_
7,000	_	_
characters1	_	_
.	_	_

#27
However	_	_
,	_	_
for	_	_
historical	_	_
and	_	_
scholarly	_	_
collections	_	_
,	_	_
54,678	_	_
characters	_	_
would	_	_
be	_	_
needed2	_	_
to	_	_
cover	_	_
an	_	_
important	_	_
dictionary	_	_
.	_	_

#28
Therefore	_	_
,	_	_
only	_	_
a	_	_
limited	_	_
number	_	_
of	_	_
documents	_	_
can	_	_
be	_	_
handled	_	_
satisfactorily	_	_
with	_	_
current	_	_
approaches	_	_
.	_	_

#29
While	_	_
about	_	_
4,000	_	_
output	_	_
units	_	_
for	_	_
a	_	_
neural	_	_
network	_	_
appear	_	_
to	_	_
reasonable	_	_
,	_	_
this	_	_
is	_	_
not	_	_
the	_	_
case	_	_
for	_	_
more	_	_
than	_	_
50,000	_	_
output	_	_
units	_	_
.	_	_

#30
If	_	_
all	_	_
variants	_	_
are	_	_
considered	_	_
,	_	_
the	_	_
total	_	_
set	_	_
size	_	_
will	_	_
even	_	_
be	_	_
above	_	_
106,0003	_	_
;	_	_
(	_	_
2	_	_
)	_	_
the	_	_
learned	_	_
information	_	_
is	_	_
not	_	_
shared	_	_
between	_	_
similar	_	_
characters	_	_
thus	_	_
the	_	_
learned	_	_
model	_	_
can	_	_
not	_	_
be	_	_
generalized	_	_
to	_	_
learn	_	_
other	_	_
characters	_	_
which	_	_
are	_	_
not	_	_
known	_	_
at	_	_
training	_	_
time	_	_
and	_	_
(	_	_
3	_	_
)	_	_
training	_	_
samples	_	_
for	_	_
each	_	_
character	_	_
should	_	_
be	_	_
sufficient	_	_
to	_	_
obtain	_	_
a	_	_
satisfying	_	_
performance	_	_
.	_	_

#31
In	_	_
a	_	_
real-world	_	_
application	_	_
,	_	_
such	_	_
as	_	_
recognizing	_	_
Chinese	_	_
text	_	_
in	_	_
historical	_	_
book	_	_
collections	_	_
,	_	_
the	_	_
number	_	_
of	_	_
characters	_	_
is	_	_
huge	_	_
and	_	_
there	_	_
will	_	_
not	_	_
be	_	_
many	_	_
instances	_	_
of	_	_
the	_	_
rarely-used	_	_
characters	_	_
for	_	_
training	_	_
and	_	_
development	_	_
.	_	_

#32
Therefore	_	_
,	_	_
it	_	_
is	_	_
very	_	_
difficult	_	_
to	_	_
obtain	_	_
a	_	_
good	_	_
performance	_	_
when	_	_
considering	_	_
each	_	_
rarely-used	_	_
character	_	_
as	_	_
a	_	_
class	_	_
and	_	_
without	_	_
explicitly	_	_
using	_	_
the	_	_
shared	_	_
information	_	_
between	_	_
characters	_	_
.	_	_

#33
Attributes	_	_
are	_	_
abstract	_	_
(	_	_
‘semantic’	_	_
)	_	_
properties	_	_
that	_	_
can	_	_
be	_	_
used	_	_
to	_	_
describe	_	_
objects	_	_
[	_	_
12	_	_
]	_	_
symbolically	_	_
.	_	_

#34
Because	_	_
they	_	_
represent	_	_
general	_	_
aspects	_	_
of	_	_
patterns	_	_
,	_	_
attributes	_	_
can	_	_
be	_	_
very	_	_
effective	_	_
for	_	_
transferring	_	_
learned	_	_
information	_	_
in	_	_
a	_	_
zero1Chart	_	_
of	_	_
Generally	_	_
Used	_	_
Characters	_	_
of	_	_
Modern	_	_
Chinese	_	_
2Great	_	_
Compendium	_	_
of	_	_
Chinese	_	_
Characters	_	_
or	_	_
‘Hanyu	_	_
Da	_	_
Zidian’	_	_
3Dictionary	_	_
of	_	_
Chinese	_	_
Variant	_	_
Form	_	_
,	_	_
‘Zhonghua	_	_
zi	_	_
hai’	_	_
Training	_	_
SetOpen	_	_
Set	_	_
·	_	_
·	_	_
·	_	_
·	_	_
·	_	_
·	_	_
Figure	_	_
1	_	_
:	_	_
Illumination	_	_
of	_	_
the	_	_
radicals	_	_
shared	_	_
between	_	_
different	_	_
characters	_	_
.	_	_

#35
Radicals	_	_
of	_	_
the	_	_
character	_	_
in	_	_
the	_	_
open	_	_
set	_	_
(	_	_
left	_	_
character	_	_
)	_	_
can	_	_
be	_	_
recognized	_	_
by	_	_
classifiers	_	_
trained	_	_
with	_	_
different	_	_
characters	_	_
which	_	_
contain	_	_
the	_	_
same	_	_
radicals	_	_
in	_	_
the	_	_
training	_	_
set	_	_
.	_	_

#36
The	_	_
left	_	_
part	_	_
can	_	_
be	_	_
learned	_	_
from	_	_
characters	_	_
in	_	_
the	_	_
red	_	_
box	_	_
and	_	_
the	_	_
right	_	_
part	_	_
can	_	_
be	_	_
learned	_	_
from	_	_
characters	_	_
in	_	_
the	_	_
blue	_	_
box	_	_
.	_	_

#37
shot	_	_
training	_	_
context	_	_
[	_	_
13	_	_
,	_	_
14	_	_
]	_	_
.	_	_

#38
Therefore	_	_
,	_	_
learning	_	_
of	_	_
abstract	_	_
attributes	_	_
is	_	_
very	_	_
important	_	_
for	_	_
Chinese	_	_
character	_	_
recognition	_	_
:	_	_
It	_	_
would	_	_
allow	_	_
for	_	_
a	_	_
recognition	_	_
of	_	_
samples	_	_
that	_	_
are	_	_
unseen	_	_
in	_	_
an	_	_
original	_	_
training	_	_
set	_	_
.	_	_

#39
Fig.	_	_
1	_	_
presents	_	_
one	_	_
example	_	_
of	_	_
the	_	_
radicals	_	_
shared	_	_
between	_	_
different	_	_
characters	_	_
.	_	_

#40
The	_	_
challenge	_	_
then	_	_
is	_	_
to	_	_
identify	_	_
attributes	_	_
,	_	_
possibly	_	_
of	_	_
multiple	_	_
types	_	_
,	_	_
that	_	_
are	_	_
helpful	_	_
in	_	_
zero-shot	_	_
or	_	_
few-shot	_	_
conditions	_	_
.	_	_

#41
Chinese	_	_
characters	_	_
are	_	_
pictograms	_	_
and	_	_
most	_	_
of	_	_
them	_	_
are	_	_
compounds	_	_
of	_	_
two	_	_
or	_	_
more	_	_
pictographic	_	_
or	_	_
ideographic	_	_
characters	_	_
,	_	_
i.e.	_	_
,	_	_
components	_	_
which	_	_
are	_	_
usually	_	_
called	_	_
radicals	_	_
.	_	_

#42
There	_	_
are	_	_
only	_	_
several	_	_
hundreds	_	_
of	_	_
radicals	_	_
which	_	_
can	_	_
represent	_	_
all	_	_
Chinese	_	_
characters	_	_
.	_	_

#43
Therefore	_	_
,	_	_
radicals	_	_
are	_	_
very	_	_
important	_	_
attributes	_	_
of	_	_
Chinese	_	_
characters	_	_
.	_	_

#44
They	_	_
have	_	_
been	_	_
used	_	_
in	_	_
previous	_	_
work	_	_
[	_	_
15	_	_
,	_	_
16	_	_
,	_	_
17	_	_
]	_	_
.	_	_

#45
However	_	_
,	_	_
there	_	_
are	_	_
many	_	_
more	_	_
attribute	_	_
types	_	_
that	_	_
can	_	_
be	_	_
exploited	_	_
,	_	_
such	_	_
as	_	_
pronunciation	_	_
and	_	_
structure	_	_
codes	_	_
.	_	_

#46
These	_	_
attributes	_	_
are	_	_
also	_	_
often	_	_
shared	_	_
between	_	_
different	_	_
characters	_	_
,	_	_
which	_	_
allows	_	_
them	_	_
to	_	_
be	_	_
used	_	_
to	_	_
recognize	_	_
unseen	_	_
characters	_	_
,	_	_
as	_	_
well	_	_
.	_	_

#47
In	_	_
this	_	_
paper	_	_
,	_	_
we	_	_
propose	_	_
a	_	_
method	_	_
to	_	_
recognize	_	_
Chinese	_	_
characters	_	_
by	_	_
multi-typed	_	_
attributes	_	_
.	_	_

#48
The	_	_
advantages	_	_
of	_	_
using	_	_
attributes	_	_
to	_	_
represent	_	_
Chinese	_	_
characters	_	_
are	_	_
that	_	_
:	_	_
(	_	_
1	_	_
)	_	_
The	_	_
number	_	_
of	_	_
attributes	_	_
is	_	_
much	_	_
smaller	_	_
than	_	_
the	_	_
possible	_	_
number	_	_
of	_	_
characters	_	_
in	_	_
the	_	_
script	_	_
.	_	_

#49
Only	_	_
several	_	_
hundreds	_	_
of	_	_
attribute	_	_
classifiers	_	_
are	_	_
needed	_	_
to	_	_
learn	_	_
for	_	_
representing	_	_
the	_	_
complete	_	_
set	_	_
of	_	_
Chinese	_	_
characters	_	_
.	_	_

#50
Attributes	_	_
are	_	_
shared	_	_
between	_	_
different	_	_
characters	_	_
and	_	_
using	_	_
the	_	_
attribute	_	_
representation	_	_
can	_	_
alleviate	_	_
the	_	_
problem	_	_
of	_	_
unbalanced	_	_
statistical	_	_
distribution	_	_
of	_	_
Chinese	_	_
character	_	_
in	_	_
real-world	_	_
text	_	_
corpora	_	_
;	_	_
(	_	_
2	_	_
)	_	_
Attributes	_	_
reflect	_	_
the	_	_
structure	_	_
of	_	_
Chinese	_	_
characters	_	_
and	_	_
they	_	_
are	_	_
meaningful	_	_
in	_	_
Chinese	_	_
character	_	_
recognition	_	_
,	_	_
also	_	_
for	_	_
humans	_	_
.	_	_

#51
Therefore	_	_
,	_	_
characters	_	_
which	_	_
are	_	_
similar	_	_
in	_	_
attribute	_	_
representation	_	_
will	_	_
also	_	_
have	_	_
some	_	_
semantic	_	_
relationship	_	_
,	_	_
i.e.	_	_
,	_	_
at	_	_
the	_	_
level	_	_
of	_	_
their	_	_
meaning	_	_
.	_	_

#52
The	_	_
use	_	_
of	_	_
abstract	_	_
attribute	_	_
coding	_	_
also	_	_
allows	_	_
to	_	_
define	_	_
similarity	_	_
in	_	_
another	_	_
space	_	_
than	_	_
the	_	_
input	_	_
image	_	_
,	_	_
avoiding	_	_
complicated	_	_
pattern	_	_
recognition	_	_
of	_	_
individual	_	_
strokes	_	_
at	_	_
the	_	_
image	_	_
level	_	_
[	_	_
18	_	_
,	_	_
9	_	_
]	_	_
;	_	_
(	_	_
3	_	_
)	_	_
Attributes	_	_
can	_	_
be	_	_
used	_	_
to	_	_
recognize	_	_
the	_	_
characters	_	_
which	_	_
are	_	_
not	_	_
in	_	_
the	_	_
training	_	_
set	_	_
.	_	_

#53
This	_	_
is	_	_
well-known	_	_
as	_	_
‘zero-shot	_	_
learning’	_	_
[	_	_
19	_	_
]	_	_
)	_	_
or	_	_
,	_	_
in	_	_
case	_	_
only	_	_
a	_	_
few	_	_
samples	_	_
are	_	_
available	_	_
for	_	_
training	_	_
,	_	_
‘few-shot	_	_
learning’	_	_
[	_	_
20	_	_
]	_	_
)	_	_
.	_	_

#54
For	_	_
the	_	_
general	_	_
applicability	_	_
of	_	_
character	_	_
recognition	_	_
in	_	_
historical	_	_
documents	_	_
which	_	_
contains	_	_
a	_	_
open	_	_
set	_	_
of	_	_
characters	_	_
,	_	_
with	_	_
rare	_	_
characters	_	_
it	_	_
is	_	_
essential	_	_
that	_	_
a	_	_
system	_	_
is	_	_
able	_	_
to	_	_
recognize	_	_
also	_	_
this	_	_
infrequent	_	_
,	_	_
usually	_	_
interesting	_	_
,	_	_
material	_	_
.	_	_

#55
The	_	_
rest	_	_
of	_	_
the	_	_
paper	_	_
is	_	_
organized	_	_
as	_	_
follows	_	_
:	_	_
Section	_	_
2	_	_
introduces	_	_
the	_	_
data	_	_
set	_	_
used	_	_
in	_	_
this	_	_
paper	_	_
.	_	_

#56
Section	_	_
Appendix	_	_
A	_	_
introduces	_	_
the	_	_
character	_	_
segmentation	_	_
in	_	_
historical	_	_
books	_	_
and	_	_
Section	_	_
3	_	_
describes	_	_
the	_	_
attributes	_	_
of	_	_
Chinese	_	_
characters	_	_
used	_	_
in	_	_
this	_	_
paper	_	_
.	_	_

#57
The	_	_
experimental	_	_
results	_	_
are	_	_
present	_	_
in	_	_
Section	_	_
4	_	_
and	_	_
the	_	_
conclusion	_	_
is	_	_
provided	_	_
in	_	_
Section	_	_
5	_	_
.	_	_

#58
2	_	_
.	_	_

#59
Data	_	_
set	_	_
We	_	_
evaluate	_	_
the	_	_
proposed	_	_
method	_	_
based	_	_
on	_	_
different	_	_
data	_	_
sets	_	_
:	_	_
open	_	_
set	_	_
of	_	_
printed	_	_
and	_	_
historical	_	_
Chinese	_	_
characters	_	_
and	_	_
closed	_	_
set	_	_
of	_	_
handwritten	_	_
characters	_	_
.	_	_

#60
In	_	_
order	_	_
to	_	_
evaluate	_	_
the	_	_
performance	_	_
of	_	_
attribute	_	_
recognition	_	_
on	_	_
printed	_	_
characters	_	_
,	_	_
we	_	_
collect	_	_
isolated	_	_
character	_	_
images	_	_
with	_	_
17	_	_
different	_	_
fonts	_	_
,	_	_
which	_	_
are	_	_
XiMing	_	_
,	_	_
HeiTi	_	_
,	_	_
XinSong	_	_
,	_	_
CuoJin	_	_
,	_	_
TeHei	_	_
,	_	_
LiShu	_	_
,	_	_
WeiBei	_	_
,	_	_
MingTi	_	_
,	_	_
XiYuan	_	_
,	_	_
YuanKai	_	_
,	_	_
TeMingFan	_	_
,	_	_
FangSong	_	_
,	_	_
XinShu	_	_
,	_	_
CuoKai	_	_
,	_	_
TeYuan	_	_
,	_	_
ChaoMing	_	_
,	_	_
CuoMingFang	_	_
.	_	_

#61
We	_	_
try	_	_
to	_	_
generate	_	_
all	_	_
possible	_	_
Chinese	_	_
characters	_	_
(	_	_
including	_	_
traditioanl	_	_
and	_	_
simple	_	_
characters	_	_
)	_	_
and	_	_
there	_	_
is	_	_
only	_	_
one	_	_
image	_	_
for	_	_
each	_	_
character	_	_
.	_	_

#62
Finally	_	_
,	_	_
there	_	_
are	_	_
about	_	_
27k	_	_
character	_	_
images	_	_
for	_	_
XiMing	_	_
,	_	_
HeiTi	_	_
and	_	_
XinSong	_	_
and	_	_
13k	_	_
character	_	_
images	_	_
for	_	_
the	_	_
rest	_	_
of	_	_
fonts	_	_
.	_	_

#63
This	_	_
paper	_	_
also	_	_
uses	_	_
Chinese	_	_
characters	_	_
from	_	_
historical	_	_
books	_	_
on	_	_
the	_	_
Ming	_	_
Qing	_	_
Women’s	_	_
Writings	_	_
digital	_	_
archive	_	_
4	_	_
,	_	_
which	_	_
is	_	_
also	_	_
stored	_	_
in	_	_
the	_	_
Monk	_	_
system	_	_
[	_	_
21	_	_
]	_	_
.	_	_

#64
The	_	_
collection	_	_
of	_	_
books	_	_
are	_	_
written	_	_
by	_	_
women	_	_
before	_	_
the	_	_
year	_	_
1911	_	_
.	_	_

#65
There	_	_
are	_	_
287	_	_
books	_	_
in	_	_
the	_	_
Monk	_	_
system	_	_
.	_	_

#66
All	_	_
images	_	_
are	_	_
suffered	_	_
from	_	_
degradations	_	_
due	_	_
to	_	_
the	_	_
time	_	_
and	_	_
the	_	_
quality	_	_
of	_	_
scanning	_	_
processing	_	_
.	_	_

#67
Fig.	_	_
2	_	_
shows	_	_
images	_	_
of	_	_
four	_	_
example	_	_
pages	_	_
from	_	_
this	_	_
data	_	_
set	_	_
.	_	_

#68
These	_	_
books	_	_
are	_	_
written	_	_
from	_	_
top	_	_
to	_	_
down	_	_
and	_	_
from	_	_
right	_	_
to	_	_
left	_	_
and	_	_
each	_	_
text	_	_
line	_	_
is	_	_
bounded	_	_
by	_	_
table	_	_
lines	_	_
.	_	_

#69
A	_	_
small	_	_
skew	_	_
angle	_	_
is	_	_
introduced	_	_
during	_	_
scanning	_	_
,	_	_
which	_	_
is	_	_
also	_	_
shown	_	_
in	_	_
Fig.	_	_
2	_	_
.	_	_

#70
Since	_	_
no	_	_
character	_	_
box	_	_
existed	_	_
in	_	_
this	_	_
collection	_	_
,	_	_
we	_	_
propose	_	_
a	_	_
method	_	_
to	_	_
efficiently	_	_
segment	_	_
characters	_	_
.	_	_

#71
The	_	_
segmentation	_	_
method	_	_
is	_	_
described	_	_
in	_	_
Appendix	_	_
A	_	_
.	_	_

#72
Each	_	_
isolated	_	_
character	_	_
is	_	_
labeled	_	_
on	_	_
the	_	_
Monk	_	_
system	_	_
[	_	_
21	_	_
]	_	_
.	_	_

#73
Totally	_	_
,	_	_
there	_	_
are	_	_
about	_	_
856,000	_	_
characters	_	_
are	_	_
labeled	_	_
with	_	_
3,739	_	_
different	_	_
traditional	_	_
Chinese	_	_
characters	_	_
.	_	_

#74
Unlike	_	_
the	_	_
commonly	_	_
used	_	_
CASIA-HWDB1.1	_	_
data	_	_
set	_	_
[	_	_
1	_	_
]	_	_
which	_	_
consists	_	_
equal	_	_
number	_	_
of	_	_
samples	_	_
for	_	_
each	_	_
character	_	_
(	_	_
closed	_	_
set	_	_
)	_	_
,	_	_
the	_	_
distribution	_	_
of	_	_
the	_	_
number	_	_
of	_	_
characters	_	_
(	_	_
open	_	_
set	_	_
)	_	_
in	_	_
this	_	_
collection	_	_
has	_	_
a	_	_
long	_	_
tail	_	_
according	_	_
to	_	_
a	_	_
Zipf	_	_
distribution	_	_
[	_	_
22	_	_
]	_	_
,	_	_
which	_	_
is	_	_
shown	_	_
in	_	_
Fig.	_	_
3	_	_
.	_	_

#75
Characters	_	_
can	_	_
be	_	_
roughly	_	_
divided	_	_
into	_	_
two	_	_
groups	_	_
:	_	_
frequently-used	_	_
characters	_	_
which	_	_
have	_	_
4http	_	_
:	_	_
//digital.library.mcgill.ca/mingqing/english/index.php	_	_
Figure	_	_
2	_	_
:	_	_
Example	_	_
of	_	_
page	_	_
images	_	_
from	_	_
the	_	_
dataset	_	_
used	_	_
in	_	_
this	_	_
paper	_	_
.	_	_

#76
Dlofreq	_	_
Dhifreq	_	_
Character	_	_
N	_	_
u	_	_
m	_	_
b	_	_
er	_	_
Figure	_	_
3	_	_
:	_	_
The	_	_
number	_	_
of	_	_
character	_	_
instances	_	_
has	_	_
a	_	_
long	_	_
tail	_	_
according	_	_
to	_	_
a	_	_
Zipf	_	_
distribution	_	_
[	_	_
22	_	_
]	_	_
.	_	_

#77
The	_	_
cutting	_	_
line	_	_
represents	_	_
the	_	_
threshold	_	_
of	_	_
number	_	_
of	_	_
instances	_	_
we	_	_
used	_	_
to	_	_
construct	_	_
the	_	_
subsets	_	_
in	_	_
this	_	_
paper	_	_
.	_	_

#78
Dhifreq	_	_
denotes	_	_
the	_	_
data	_	_
set	_	_
with	_	_
high-frequent	_	_
characters	_	_
and	_	_
Dlofreq	_	_
denotes	_	_
the	_	_
data	_	_
set	_	_
with	_	_
low-frequent	_	_
characters	_	_
.	_	_

#79
many	_	_
instances	_	_
and	_	_
rarely-used	_	_
characters	_	_
which	_	_
have	_	_
only	_	_
few	_	_
samples	_	_
.	_	_

#80
In	_	_
this	_	_
paper	_	_
,	_	_
we	_	_
split	_	_
the	_	_
data	_	_
set	_	_
into	_	_
Dhifreq	_	_
and	_	_
Dlofreq	_	_
subsets	_	_
:	_	_
Dhifreq	_	_
contains	_	_
samples	_	_
of	_	_
characters	_	_
whose	_	_
number	_	_
is	_	_
greater	_	_
than	_	_
20	_	_
(	_	_
high-frequent	_	_
characters	_	_
)	_	_
and	_	_
Dlofreq	_	_
contains	_	_
the	_	_
rest	_	_
of	_	_
characters	_	_
(	_	_
low-frequent	_	_
characters	_	_
)	_	_
.	_	_

#81
For	_	_
the	_	_
Dhifreq	_	_
,	_	_
80	_	_
%	_	_
samples	_	_
of	_	_
each	_	_
character	_	_
are	_	_
randomly	_	_
selected	_	_
for	_	_
training	_	_
and	_	_
the	_	_
remainder	_	_
are	_	_
used	_	_
for	_	_
testing	_	_
.	_	_

#82
All	_	_
the	_	_
samples	_	_
in	_	_
the	_	_
Dlofreq	_	_
set	_	_
are	_	_
used	_	_
for	_	_
few-shot	_	_
testing	_	_
(	_	_
including	_	_
zero-shot	_	_
)	_	_
.	_	_

#83
Table	_	_
1	_	_
shows	_	_
the	_	_
number	_	_
of	_	_
characters	_	_
and	_	_
instances	_	_
in	_	_
different	_	_
subsets	_	_
.	_	_

#84
Finally	_	_
,	_	_
we	_	_
evaluate	_	_
the	_	_
proposed	_	_
method	_	_
on	_	_
the	_	_
CASIA-HWDB1.1	_	_
data	_	_
set	_	_
Table	_	_
1	_	_
:	_	_
The	_	_
number	_	_
of	_	_
characters	_	_
and	_	_
instances	_	_
in	_	_
the	_	_
proposed	_	_
historical	_	_
books	_	_
.	_	_

#85
Dhifreq	_	_
Dlofreq	_	_
Total	_	_
Train	_	_
Set	_	_
Test	_	_
Set	_	_
Few-shot	_	_
Set	_	_
Number	_	_
of	_	_
characters	_	_
1,975	_	_
1,975	_	_
1,764	_	_
3,739	_	_
Number	_	_
of	_	_
instances	_	_
676,535	_	_
170,108	_	_
10,102	_	_
856,745	_	_
Pinyin	_	_
:	_	_
ke4	_	_
Structure	_	_
:	_	_
top-down	_	_
Nstroke	_	_
:	_	_
9	_	_
Cangjie	_	_
:	_	_
GHER*	_	_
Zhengma	_	_
:	_	_
WDRG	_	_
Wubi	_	_
:	_	_
PTKF	_	_
Four-corner	_	_
:	_	_
30604	_	_
Pinyin	_	_
:	_	_
rong2	_	_
Structure	_	_
:	_	_
top-down	_	_
Nstroke	_	_
:	_	_
10	_	_
Cangjie	_	_
:	_	_
JCOR*	_	_
Zhengma	_	_
:	_	_
WOOJ	_	_
Wubi	_	_
:	_	_
PWWK	_	_
Four-corner	_	_
:	_	_
30608	_	_
Pinyin	_	_
:	_	_
hua4	_	_
Structure	_	_
:	_	_
left-right	_	_
Nstroke	_	_
:	_	_
13	_	_
Cangjie	_	_
:	_	_
YRHJR	_	_
Zhengma	_	_
:	_	_
SMI*	_	_
Wubi	_	_
:	_	_
YTDG	_	_
Four-corner	_	_
:	_	_
02664	_	_
Pinyin	_	_
:	_	_
shui2	_	_
Structure	_	_
:	_	_
left-right	_	_
Nstroke	_	_
:	_	_
15	_	_
Cangjie	_	_
:	_	_
YROG*	_	_
Zhengma	_	_
:	_	_
SNI*	_	_
Wubi	_	_
:	_	_
YWYG	_	_
Four-corner	_	_
:	_	_
00615	_	_
Pinyin	_	_
:	_	_
ci2	_	_
Structure	_	_
:	_	_
left-right	_	_
Nstroke	_	_
:	_	_
19	_	_
Cangjie	_	_
:	_	_
BBYTJ	_	_
Zhengma	_	_
:	_	_
PVLS	_	_
Wubi	_	_
:	_	_
ECMU	_	_
Four-corner	_	_
:	_	_
20241	_	_
Pinyin	_	_
:	_	_
ji2	_	_
Structure	_	_
:	_	_
top-down	_	_
Nstroke	_	_
:	_	_
12	_	_
Cangjie	_	_
:	_	_
OGD**	_	_
Zhengma	_	_
:	_	_
NIF*	_	_
Wubi	_	_
:	_	_
WYSU	_	_
Four-corner	_	_
:	_	_
20904	_	_
Pinyin	_	_
:	_	_
mo4	_	_
Structure	_	_
:	_	_
top-down	_	_
Nstroke	_	_
:	_	_
10	_	_
Cangjie	_	_
:	_	_
TAK**	_	_
Zhengma	_	_
:	_	_
EKGD	_	_
Wubi	_	_
:	_	_
AJDU	_	_
Four-corner	_	_
:	_	_
44804	_	_
Pinyin	_	_
:	_	_
he2	_	_
Structure	_	_
:	_	_
left-right	_	_
Nstroke	_	_
:	_	_
22	_	_
Cangjie	_	_
:	_	_
OBHD*	_	_
Zhengma	_	_
:	_	_
ODLM	_	_
Wubi	_	_
:	_	_
WGKT	_	_
Four-corner	_	_
:	_	_
82294	_	_
Figure	_	_
4	_	_
:	_	_
A	_	_
number	_	_
of	_	_
images	_	_
of	_	_
Chinese	_	_
characters	_	_
and	_	_
their	_	_
attributes	_	_
in	_	_
multiple	_	_
types	_	_
.	_	_

#86
Nstroke	_	_
denotes	_	_
the	_	_
number	_	_
of	_	_
strokes	_	_
.	_	_

#87
We	_	_
use	_	_
the	_	_
star	_	_
∗	_	_
as	_	_
a	_	_
filler	_	_
code	_	_
to	_	_
ensure	_	_
that	_	_
each	_	_
attribute	_	_
has	_	_
a	_	_
fixed	_	_
number	_	_
of	_	_
slots	_	_
,	_	_
e.g.	_	_
,	_	_
four	_	_
for	_	_
Zhengma	_	_
and	_	_
Wubi	_	_
and	_	_
five	_	_
for	_	_
Cangjie	_	_
.	_	_

#88
which	_	_
contains	_	_
3,755	_	_
characters	_	_
on	_	_
the	_	_
level-1	_	_
set	_	_
of	_	_
GB2312-80	_	_
.	_	_

#89
All	_	_
characters	_	_
are	_	_
wrote	_	_
by	_	_
300	_	_
writers	_	_
and	_	_
each	_	_
writer	_	_
produced	_	_
one	_	_
sample	_	_
for	_	_
each	_	_
character	_	_
.	_	_

#90
It	_	_
has	_	_
official	_	_
training	_	_
and	_	_
testing	_	_
sets	_	_
:	_	_
characters	_	_
from	_	_
240	_	_
writers	_	_
are	_	_
selected	_	_
for	_	_
training	_	_
and	_	_
the	_	_
remainder	_	_
are	_	_
used	_	_
for	_	_
testing	_	_
.	_	_

#91
This	_	_
is	_	_
a	_	_
closed	_	_
data	_	_
set	_	_
because	_	_
the	_	_
same	_	_
characters	_	_
in	_	_
the	_	_
test	_	_
are	_	_
also	_	_
appeared	_	_
in	_	_
the	_	_
training	_	_
set	_	_
,	_	_
wrote	_	_
by	_	_
different	_	_
writers	_	_
.	_	_

#92
3	_	_
.	_	_

#93
Chinese	_	_
Character	_	_
Attributes	_	_
In	_	_
this	_	_
section	_	_
,	_	_
we	_	_
describe	_	_
how	_	_
to	_	_
obtain	_	_
the	_	_
attributes	_	_
of	_	_
each	_	_
Chinese	_	_
character	_	_
efficiently	_	_
.	_	_

#94
The	_	_
attributes	_	_
are	_	_
based	_	_
on	_	_
radicals	_	_
,	_	_
pronunciation	_	_
and	_	_
structure	_	_
of	_	_
characters	_	_
.	_	_

#95
Fig.	_	_
4	_	_
gives	_	_
an	_	_
example	_	_
of	_	_
all	_	_
attributes	_	_
of	_	_
each	_	_
character	_	_
described	_	_
in	_	_
this	_	_
section	_	_
.	_	_

#96
All	_	_
the	_	_
attributes	_	_
are	_	_
extracted	_	_
from	_	_
online	_	_
dictionary	_	_
http	_	_
:	_	_
//www.zdic.net/	_	_
.	_	_

#97
3.1	_	_
.	_	_

#98
Attribute	_	_
:	_	_
Pronunciation	_	_
Pinyin	_	_
is	_	_
the	_	_
official	_	_
romanization	_	_
system	_	_
for	_	_
Standard	_	_
Chinese	_	_
,	_	_
which	_	_
uses	_	_
Roman	_	_
letters	_	_
to	_	_
indicate	_	_
the	_	_
pronunciation	_	_
of	_	_
each	_	_
character	_	_
.	_	_

#99
Most	_	_
characters	_	_
can	_	_
be	_	_
spelled	_	_
with	_	_
exactly	_	_
one	_	_
initial	_	_
followed	_	_
by	_	_
one	_	_
final	_	_
,	_	_
with	_	_
a	_	_
tone	_	_
which	_	_
is	_	_
used	_	_
to	_	_
distinguish	_	_
characters	_	_
from	_	_
each	_	_
other	_	_
.	_	_

#100
Therefore	_	_
,	_	_
the	_	_
Pinyin	_	_
system	_	_
contains	_	_
three	_	_
parts	_	_
:	_	_
initials	_	_
,	_	_
finals	_	_
and	_	_
tones	_	_
.	_	_

#101
Initials	_	_
are	_	_
initial	_	_
consonants	_	_
,	_	_
while	_	_
finals	_	_
are	_	_
all	_	_
possible	_	_
combinations	_	_
of	_	_
medials	_	_
,	_	_
the	_	_
nucleus	_	_
vowel	_	_
,	_	_
and	_	_
coda	_	_
(	_	_
more	_	_
detailed	_	_
information	_	_
can	_	_
be	_	_
found	_	_
in	_	_
wikipedia	_	_
5	_	_
)	_	_
.	_	_

#102
Tones	_	_
is	_	_
usually	_	_
denoted	_	_
by	_	_
number	_	_
from	_	_
0	_	_
to	_	_
4	_	_
,	_	_
which	_	_
are	_	_
named	_	_
as	_	_
neural	_	_
tone	_	_
(	_	_
0	_	_
)	_	_
,	_	_
high-level	_	_
tone	_	_
(	_	_
1	_	_
)	_	_
,	_	_
rising	_	_
tone	_	_
(	_	_
2	_	_
)	_	_
,	_	_
dipping	_	_
tone	_	_
(	_	_
3	_	_
)	_	_
and	_	_
high-falling	_	_
tone	_	_
(	_	_
4	_	_
)	_	_
.	_	_

#103
There	_	_
are	_	_
26	_	_
initials	_	_
,	_	_
38	_	_
finals	_	_
and	_	_
5	_	_
tones	_	_
collected	_	_
from	_	_
all	_	_
possible	_	_
27,000	_	_
Chinese	_	_
characters	_	_
.	_	_

#104
The	_	_
Pinyin	_	_
can	_	_
be	_	_
used	_	_
as	_	_
attributes	_	_
because	_	_
characters	_	_
which	_	_
share	_	_
similar	_	_
radicals	_	_
usually	_	_
have	_	_
similar	_	_
Pinyin	_	_
(	_	_
but	_	_
not	_	_
vice	_	_
versa	_	_
)	_	_
.	_	_

#105
In	_	_
this	_	_
paper	_	_
,	_	_
we	_	_
use	_	_
Apinyin	_	_
to	_	_
denote	_	_
the	_	_
set	_	_
of	_	_
Pinyin	_	_
attributes	_	_
of	_	_
each	_	_
character	_	_
.	_	_

#106
More	_	_
precisely	_	_
,	_	_
Ai	_	_
pinyin	_	_
denotes	_	_
the	_	_
initials	_	_
parts	_	_
,	_	_
Af	_	_
pinyin	_	_
denotes	_	_
the	_	_
finals	_	_
parts	_	_
and	_	_
At	_	_
pinyin	_	_
denotes	_	_
the	_	_
tones	_	_
.	_	_

#107
If	_	_
characters	_	_
have	_	_
more	_	_
than	_	_
one	_	_
pronunciation	_	_
,	_	_
we	_	_
choose	_	_
the	_	_
frequently-used	_	_
one	_	_
.	_	_

#108
Therefore	_	_
,	_	_
there	_	_
are	_	_
three	_	_
sets	_	_
of	_	_
attributes	_	_
based	_	_
on	_	_
the	_	_
Pinyin	_	_
system	_	_
.	_	_

#109
The	_	_
attributes	_	_
in	_	_
each	_	_
set	_	_
are	_	_
collected	_	_
from	_	_
all	_	_
possible	_	_
27,000	_	_
characters	_	_
.	_	_

#110
Usually	_	_
,	_	_
each	_	_
character	_	_
contains	_	_
these	_	_
attributes	_	_
and	_	_
we	_	_
use	_	_
one-hot	_	_
vector	_	_
for	_	_
each	_	_
set	_	_
of	_	_
attribute	_	_
to	_	_
represent	_	_
the	_	_
attribute	_	_
that	_	_
character	_	_
has	_	_
.	_	_

#111
For	_	_
example	_	_
,	_	_
there	_	_
are	_	_
only	_	_
five	_	_
tons	_	_
in	_	_
all	_	_
Chinese	_	_
characters	_	_
,	_	_
thus	_	_
the	_	_
attributes	_	_
in	_	_
the	_	_
At	_	_
pinyin	_	_
is	_	_
the	_	_
set	_	_
{	_	_
0	_	_
,	_	_
1	_	_
,	_	_
2	_	_
,	_	_
3	_	_
,	_	_
4	_	_
}	_	_
.	_	_

#112
If	_	_
the	_	_
character	_	_
has	_	_
the	_	_
tone	_	_
3	_	_
,	_	_
then	_	_
the	_	_
one-hot	_	_
vector	_	_
of	_	_
the	_	_
attribute	_	_
At	_	_
pinyin	_	_
is	_	_
:	_	_
[	_	_
0	_	_
,	_	_
0	_	_
,	_	_
0	_	_
,	_	_
1	_	_
,	_	_
0	_	_
]	_	_
.	_	_

#113
This	_	_
is	_	_
similar	_	_
for	_	_
other	_	_
sets	_	_
of	_	_
attributes	_	_
and	_	_
the	_	_
sizes	_	_
of	_	_
the	_	_
attribute	_	_
vector	_	_
of	_	_
Ai	_	_
pinyin	_	_
,	_	_
Af	_	_
pinyin	_	_
and	_	_
At	_	_
pinyin	_	_
for	_	_
each	_	_
character	_	_
are	_	_
26	_	_
,	_	_
38	_	_
and	_	_
5	_	_
,	_	_
respectively	_	_
.	_	_

#114
Note	_	_
that	_	_
the	_	_
Pinyin	_	_
attributes	_	_
are	_	_
not	_	_
unique	_	_
for	_	_
each	_	_
character	_	_
and	_	_
many	_	_
different	_	_
characters	_	_
share	_	_
similar	_	_
or	_	_
exactly	_	_
the	_	_
same	_	_
Pinyin	_	_
.	_	_

#115
Thus	_	_
,	_	_
using	_	_
Pinyin	_	_
attributes	_	_
alone	_	_
can	_	_
not	_	_
be	_	_
directly	_	_
used	_	_
for	_	_
character	_	_
recognition	_	_
.	_	_

#116
However	_	_
,	_	_
recognizing	_	_
Pinyin	_	_
is	_	_
important	_	_
for	_	_
the	_	_
character	_	_
understanding	_	_
or	_	_
teaching	_	_
,	_	_
especially	_	_
for	_	_
traditional	_	_
and	_	_
rarely-used	_	_
characters	_	_
whose	_	_
pronunciations	_	_
are	_	_
not	_	_
well-known	_	_
.	_	_

#117
This	_	_
observation	_	_
underscores	_	_
the	_	_
need	_	_
for	_	_
multiple	_	_
types	_	_
of	_	_
attributes	_	_
that	_	_
may	_	_
compensate	_	_
incompleteness	_	_
of	_	_
their	_	_
coding	_	_
.	_	_

#118
3.2	_	_
.	_	_

#119
Attribute	_	_
:	_	_
Structures	_	_
and	_	_
number	_	_
of	_	_
strokes	_	_
Chinese	_	_
characters	_	_
consist	_	_
of	_	_
different	_	_
components/radicals	_	_
with	_	_
certain	_	_
layout	_	_
[	_	_
17	_	_
]	_	_
.	_	_

#120
Recognizing	_	_
the	_	_
structure	_	_
of	_	_
characters	_	_
is	_	_
very	_	_
useful	_	_
for	_	_
recognition	_	_
since	_	_
it	_	_
carries	_	_
rich	_	_
information	_	_
for	_	_
discriminating	_	_
different	_	_
characters	_	_
[	_	_
23	_	_
]	_	_
.	_	_

#121
Several	_	_
most	_	_
common	_	_
structures	_	_
are	_	_
:	_	_
single-radical	_	_
,	_	_
left-right	_	_
,	_	_
top-down	_	_
,	_	_
half	_	_
-surrounded	_	_
and	_	_
enclosure	_	_
[	_	_
17	_	_
,	_	_
23	_	_
]	_	_
.	_	_

#122
In	_	_
this	_	_
paper	_	_
,	_	_
we	_	_
extract	_	_
15	_	_
different	_	_
structures	_	_
from	_	_
27,000	_	_
characters	_	_
which	_	_
can	_	_
represent	_	_
all	_	_
possible	_	_
Chinese	_	_
characters	_	_
.	_	_

#123
We	_	_
use	_	_
Astruct	_	_
to	_	_
denote	_	_
the	_	_
structure	_	_
attribution	_	_
of	_	_
characters	_	_
and	_	_
the	_	_
size	_	_
of	_	_
corresponding	_	_
attribute	_	_
representation	_	_
is	_	_
15	_	_
for	_	_
each	_	_
character	_	_
.	_	_

#124
Each	_	_
Chinese	_	_
character	_	_
has	_	_
a	_	_
certain	_	_
number	_	_
of	_	_
strokes	_	_
which	_	_
are	_	_
the	_	_
set	_	_
of	_	_
line	_	_
patterns	_	_
.	_	_

#125
A	_	_
stroke	_	_
is	_	_
a	_	_
single	_	_
calligraphic	_	_
mark	_	_
and	_	_
one	_	_
movement	_	_
of	_	_
the	_	_
writing	_	_
instrument	_	_
when	_	_
writing	_	_
the	_	_
whole	_	_
character	_	_
.	_	_

#126
The	_	_
number	_	_
of	_	_
strokes	_	_
of	_	_
each	_	_
character	_	_
is	_	_
also	_	_
an	_	_
important	_	_
attribute	_	_
for	_	_
identifying	_	_
fundamental	_	_
components	_	_
of	_	_
radicals	_	_
.	_	_

#127
For	_	_
all	_	_
27,000	_	_
Chinese	_	_
characters	_	_
,	_	_
the	_	_
range	_	_
of	_	_
stroke	_	_
5https	_	_
:	_	_
//en.wikipedia.org/wiki/Pinyin	_	_
Figure	_	_
5	_	_
:	_	_
An	_	_
example	_	_
of	_	_
Chinese	_	_
character	_	_
radical	_	_
decomposition	_	_
of	_	_
the	_	_
Cangjie	_	_
coding	_	_
method	_	_
.	_	_

#128
Note	_	_
that	_	_
the	_	_
figure	_	_
is	_	_
from	_	_
the	_	_
website	_	_
wikipedia6	_	_
.	_	_

#129
numbers	_	_
is	_	_
from	_	_
1	_	_
to	_	_
40	_	_
.	_	_

#130
However	_	_
,	_	_
very	_	_
few	_	_
characters	_	_
have	_	_
more	_	_
than	_	_
30	_	_
strokes	_	_
.	_	_

#131
Therefore	_	_
,	_	_
we	_	_
only	_	_
use	_	_
31	_	_
numbers	_	_
to	_	_
represent	_	_
the	_	_
number	_	_
of	_	_
strokes	_	_
and	_	_
the	_	_
number	_	_
of	_	_
strokes	_	_
of	_	_
characters	_	_
which	_	_
have	_	_
more	_	_
than	_	_
30	_	_
strokes	_	_
is	_	_
considered	_	_
as	_	_
one	_	_
attribute	_	_
.	_	_

#132
We	_	_
use	_	_
ANstroke	_	_
to	_	_
denote	_	_
the	_	_
structure	_	_
attribution	_	_
of	_	_
characters	_	_
and	_	_
the	_	_
size	_	_
of	_	_
the	_	_
corresponding	_	_
representation	_	_
is	_	_
31	_	_
.	_	_

#133
3.3	_	_
.	_	_

#134
Attribute	_	_
:	_	_
Cangjie	_	_
,	_	_
Zhengma	_	_
and	_	_
Wubi	_	_
coding	_	_
Chinese	_	_
is	_	_
a	_	_
logographic	_	_
script	_	_
[	_	_
24	_	_
]	_	_
and	_	_
each	_	_
character	_	_
consists	_	_
of	_	_
several	_	_
“compounds”	_	_
or	_	_
“radicals”	_	_
.	_	_

#135
A	_	_
Chinese	_	_
radical	_	_
is	_	_
a	_	_
graphical	_	_
component	_	_
of	_	_
a	_	_
character	_	_
and	_	_
it	_	_
is	_	_
always	_	_
shared	_	_
between	_	_
different	_	_
characters	_	_
.	_	_

#136
Each	_	_
Chinese	_	_
character	_	_
can	_	_
also	_	_
divided	_	_
into	_	_
several	_	_
radicals	_	_
[	_	_
25	_	_
]	_	_
.	_	_

#137
Therefore	_	_
,	_	_
it	_	_
is	_	_
very	_	_
useful	_	_
to	_	_
use	_	_
radicals	_	_
as	_	_
the	_	_
basic	_	_
allograph	_	_
to	_	_
represent	_	_
Chinese	_	_
characters	_	_
and	_	_
there	_	_
are	_	_
several	_	_
works	_	_
about	_	_
radical	_	_
extraction	_	_
and	_	_
recognition	_	_
[	_	_
26	_	_
,	_	_
17	_	_
]	_	_
.	_	_

#138
Although	_	_
radicals	_	_
are	_	_
very	_	_
important	_	_
for	_	_
Chinese	_	_
character	_	_
representation	_	_
,	_	_
no	_	_
standard	_	_
criteria	_	_
exists	_	_
for	_	_
radical	_	_
decomposition	_	_
.	_	_

#139
Wang	_	_
et	_	_
al.	_	_
[	_	_
17	_	_
]	_	_
proposed	_	_
several	_	_
rules	_	_
to	_	_
decompose	_	_
each	_	_
character	_	_
into	_	_
radical	_	_
parts	_	_
.	_	_

#140
However	_	_
,	_	_
a	_	_
lot	_	_
of	_	_
(	_	_
expensive	_	_
)	_	_
human	_	_
efforts	_	_
is	_	_
needed	_	_
to	_	_
label	_	_
all	_	_
the	_	_
radicals	_	_
in	_	_
the	_	_
complete	_	_
Chinese	_	_
character	_	_
set	_	_
.	_	_

#141
There	_	_
are	_	_
some	_	_
methods	_	_
of	_	_
Chinese	_	_
radical	_	_
decomposition	_	_
for	_	_
typing	_	_
Chinese	_	_
into	_	_
computers	_	_
using	_	_
a	_	_
standard	_	_
keyboard	_	_
.	_	_

#142
The	_	_
input	_	_
methods	_	_
use	_	_
different	_	_
codes	_	_
for	_	_
different	_	_
characters	_	_
and	_	_
the	_	_
codes	_	_
are	_	_
based	_	_
on	_	_
the	_	_
graphological	_	_
aspect	_	_
of	_	_
the	_	_
characters	_	_
:	_	_
each	_	_
basic	_	_
,	_	_
graphical	_	_
unit	_	_
is	_	_
represented	_	_
by	_	_
a	_	_
basic	_	_
character	_	_
component	_	_
and	_	_
each	_	_
mapped	_	_
to	_	_
a	_	_
particular	_	_
letter	_	_
key	_	_
on	_	_
a	_	_
standard	_	_
keyboard	_	_
.	_	_

#143
For	_	_
example	_	_
,	_	_
the	_	_
Cangjie	_	_
input	_	_
method	_	_
6	_	_
,	_	_
which	_	_
represents	_	_
each	_	_
Chinese	_	_
character	_	_
based	_	_
on	_	_
the	_	_
graphological	_	_
aspect	_	_
(	_	_
radicals	_	_
)	_	_
of	_	_
the	_	_
characters	_	_
.	_	_

#144
In	_	_
Cangjie	_	_
,	_	_
each	_	_
key	_	_
in	_	_
the	_	_
keyboard	_	_
corresponds	_	_
to	_	_
a	_	_
basic	_	_
radical	_	_
and	_	_
it	_	_
might	options	_
be	_	_
associated	_	_
with	_	_
other	_	_
auxiliary	_	_
shapes	_	_
which	_	_
might	options	_
be	_	_
either	_	_
rotated	_	_
or	_	_
transposed	_	_
versions	_	_
of	_	_
components	_	_
of	_	_
the	_	_
basic	_	_
radicals	_	_
.	_	_

#145
Fig.	_	_
5	_	_
gives	_	_
an	_	_
example	_	_
of	_	_
character	_	_
decomposition	_	_
and	_	_
encoding	_	_
using	_	_
alphabets	_	_
.	_	_

#146
Similar	_	_
input	_	_
methods	_	_
have	_	_
also	_	_
been	_	_
used	_	_
for	_	_
typing	_	_
Chinese	_	_
,	_	_
such	_	_
as	_	_
the	_	_
Zhengma	_	_
7	_	_
and	_	_
Wubi	_	_
8	_	_
methods	_	_
.	_	_

#147
These	_	_
three	_	_
methods	_	_
decompose	_	_
Chinese	_	_
characters	_	_
in	_	_
different	_	_
ways	_	_
based	_	_
on	_	_
character	_	_
structures	_	_
,	_	_
which	_	_
represent	_	_
each	_	_
character	_	_
with	_	_
several	_	_
keys	_	_
on	_	_
the	_	_
keyboard	_	_
.	_	_

#148
Each	_	_
character	_	_
is	_	_
encoded	_	_
with	_	_
different	_	_
number	_	_
of	_	_
letters	_	_
,	_	_
depending	_	_
on	_	_
the	_	_
structure	_	_
of	_	_
characters	_	_
.	_	_

#149
Generally	_	_
,	_	_
simple	_	_
characters	_	_
have	_	_
less	_	_
letters	_	_
and	_	_
complex	_	_
ones	_	_
have	_	_
more	_	_
letters	_	_
to	_	_
represent	_	_
.	_	_

#150
The	_	_
maximum	_	_
length	_	_
of	_	_
Cangjie	_	_
,	_	_
Zhengma	_	_
and	_	_
Wubi	_	_
codes	_	_
are	_	_
5	_	_
,	_	_
4	_	_
and	_	_
4	_	_
,	_	_
respectively	_	_
.	_	_

#151
The	_	_
code	_	_
of	_	_
each	_	_
character	_	_
is	_	_
made	_	_
fixed	_	_
length	_	_
by	_	_
adding	_	_
an	_	_
extra	_	_
key	_	_
∗	_	_
at	_	_
the	_	_
end	_	_
it	_	_
has	_	_
less	_	_
code	_	_
.	_	_

#152
The	_	_
advantage	_	_
of	_	_
using	_	_
codes	_	_
of	_	_
each	_	_
input	_	_
method	_	_
as	_	_
attributes	_	_
is	_	_
that	_	_
the	_	_
decomposition	_	_
rules	_	_
that	_	_
define	_	_
how	_	_
to	_	_
analyse	_	_
a	_	_
character	_	_
are	_	_
well-designed	_	_
and	_	_
fixed	_	_
for	_	_
all	_	_
users	_	_
and	_	_
they	_	_
are	_	_
easily	_	_
obtained	_	_
from	_	_
online	_	_
dictionary	_	_
.	_	_

#153
The	_	_
code	_	_
for	_	_
each	_	_
character	_	_
is	_	_
almost	_	_
unique	_	_
and	_	_
thus	_	_
they	_	_
can	_	_
be	_	_
directly	_	_
used	_	_
for	_	_
character	_	_
recognition	_	_
based	_	_
on	_	_
a	_	_
given	_	_
lexicon	_	_
.	_	_

#154
In	_	_
this	_	_
paper	_	_
,	_	_
we	_	_
use	_	_
Acj	_	_
,	_	_
Azm	_	_
and	_	_
Awb	_	_
to	_	_
denote	_	_
the	_	_
Cangjie	_	_
,	_	_
Zhengma	_	_
and	_	_
Wubi	_	_
attributes	_	_
of	_	_
characters	_	_
,	_	_
respectively	_	_
.	_	_

#155
For	_	_
Cangjie	_	_
code	_	_
,	_	_
we	_	_
use	_	_
Ai	_	_
cj	_	_
to	_	_
present	_	_
the	_	_
code	_	_
in	_	_
i-th	_	_
position	_	_
,	_	_
where	_	_
i	_	_
∈	_	_
{	_	_
1	_	_
,	_	_
2	_	_
,	_	_
3	_	_
,	_	_
4	_	_
,	_	_
5	_	_
}	_	_
.	_	_

#156
Since	_	_
each	_	_
character	_	_
has	_	_
at	_	_
least	_	_
one	_	_
Cangjie	_	_
code	_	_
,	_	_
there	_	_
are	_	_
26	_	_
letters	_	_
on	_	_
the	_	_
first	_	_
code	_	_
A1	_	_
cj	_	_
and	_	_
27	_	_
letters	_	_
(	_	_
with	_	_
the	_	_
extra	_	_
∗	_	_
)	_	_
from	_	_
second	_	_
to	_	_
fifth	_	_
code	_	_
Ai	_	_
cj	_	_
when	_	_
2	_	_
≤	_	_
i	_	_
≤	_	_
5	_	_
.	_	_

#157
Therefore	_	_
,	_	_
the	_	_
corresponding	_	_
representation	_	_
size	_	_
of	_	_
each	_	_
code	_	_
is	_	_
26	_	_
or	_	_
27	_	_
,	_	_
depends	_	_
on	_	_
whether	_	_
there	_	_
is	_	_
the	_	_
extra	_	_
∗	_	_
existed	_	_
or	_	_
not	_	_
.	_	_

#158
This	_	_
is	_	_
the	_	_
same	_	_
for	_	_
the	_	_
Azm	_	_
and	_	_
Awb	_	_
,	_	_
which	_	_
have	_	_
four	_	_
codes	_	_
for	_	_
each	_	_
character	_	_
.	_	_

#159
3.4	_	_
.	_	_

#160
Attribute	_	_
:	_	_
Four-Corner	_	_
coding	_	_
The	_	_
Four-Corner	_	_
method	_	_
9	_	_
is	_	_
another	_	_
Chinese	_	_
character-encoding	_	_
method	_	_
,	_	_
which	_	_
uses	_	_
four	_	_
digits	_	_
to	_	_
encode	_	_
the	_	_
shape	_	_
found	_	_
in	_	_
the	_	_
four	_	_
corners	_	_
of	_	_
character	_	_
,	_	_
top-left	_	_
to	_	_
bottom-right	_	_
.	_	_

#161
A	_	_
fifth	_	_
digit	_	_
is	_	_
added	_	_
to	_	_
describe	_	_
an	_	_
extra	_	_
part	_	_
above	_	_
the	_	_
bottom-right	_	_
if	_	_
necessary	_	_
.	_	_

#162
Therefor	_	_
,	_	_
each	_	_
character	_	_
is	_	_
encoded	_	_
with	_	_
five	_	_
digits	_	_
.	_	_

#163
Fig.	_	_
6	_	_
shows	_	_
an	_	_
example	_	_
of	_	_
the	_	_
Four-Corner	_	_
coding	_	_
method	_	_
.	_	_

#164
The	_	_
Four-Corner	_	_
method	_	_
is	_	_
used	_	_
to	_	_
index	_	_
Chinese	_	_
characters	_	_
in	_	_
dictionary	_	_
and	_	_
there	_	_
are	_	_
only	_	_
five	_	_
digits	_	_
to	_	_
represent	_	_
each	_	_
character	_	_
.	_	_

#165
Therefore	_	_
,	_	_
many	_	_
characters	_	_
share	_	_
the	_	_
same	_	_
code	_	_
,	_	_
similar	_	_
as	_	_
the	_	_
Pinyin	_	_
system	_	_
.	_	_

#166
This	_	_
is	_	_
an	_	_
additional	_	_
argument	_	_
to	_	_
use	_	_
several	_	_
,	_	_
multi-typed	_	_
attributes	_	_
for	_	_
character-class	_	_
description	_	_
.	_	_

#167
6https	_	_
:	_	_
//en.wikipedia.org/wiki/Cangjie_input_method	_	_
7https	_	_
:	_	_
//en.wikipedia.org/wiki/Zhengma_method	_	_
8https	_	_
:	_	_
//en.wikipedia.org/wiki/Wubi_method	_	_
9https	_	_
:	_	_
//en.wikipedia.org/wiki/Four-Corner_Method	_	_
Figure	_	_
6	_	_
:	_	_
An	_	_
example	_	_
of	_	_
Chinese	_	_
character	_	_
radical	_	_
decomposition	_	_
of	_	_
the	_	_
Four-Corner	_	_
coding	_	_
method	_	_
.	_	_

#168
Note	_	_
that	_	_
the	_	_
figure	_	_
is	_	_
from	_	_
the	_	_
website	_	_
wikipedia9	_	_
.	_	_

#169
In	_	_
this	_	_
paper	_	_
,	_	_
we	_	_
use	_	_
Afc	_	_
to	_	_
denote	_	_
the	_	_
Four-Corner	_	_
attributes	_	_
and	_	_
Ai	_	_
fc	_	_
represents	_	_
the	_	_
digit	_	_
on	_	_
i-th	_	_
position	_	_
(	_	_
1	_	_
≤	_	_
i	_	_
≤	_	_
5	_	_
)	_	_
.	_	_

#170
The	_	_
size	_	_
of	_	_
each	_	_
Four-Corner	_	_
attribute	_	_
representation	_	_
is	_	_
10	_	_
bins	_	_
,	_	_
yielding	_	_
50	_	_
attribute	_	_
values	_	_
.	_	_

#171
3.5	_	_
.	_	_

#172
Attribute	_	_
classifier	_	_
We	_	_
describe	_	_
different	_	_
attributes	_	_
of	_	_
Chinese	_	_
characters	_	_
in	_	_
the	_	_
above	_	_
sections	_	_
and	_	_
there	_	_
are	_	_
totally	_	_
23	_	_
attribute	_	_
sets	_	_
:	_	_
3	_	_
attribute	_	_
sets	_	_
of	_	_
Pinyin	_	_
,	_	_
1	_	_
attribute	_	_
set	_	_
of	_	_
structure	_	_
,	_	_
1	_	_
attribute	_	_
set	_	_
of	_	_
the	_	_
number	_	_
of	_	_
strokes	_	_
,	_	_
5	_	_
attribute	_	_
sets	_	_
of	_	_
Cangjie	_	_
codes	_	_
in	_	_
five	_	_
different	_	_
positions	_	_
(	_	_
the	_	_
length	_	_
of	_	_
the	_	_
Cangjie	_	_
code	_	_
for	_	_
each	_	_
character	_	_
is	_	_
five	_	_
)	_	_
,	_	_
4	_	_
attribute	_	_
sets	_	_
of	_	_
Zhengma	_	_
and	_	_
Wubi	_	_
and	_	_
5	_	_
attribute	_	_
sets	_	_
of	_	_
the	_	_
Four-Corner	_	_
method	_	_
.	_	_

#173
For	_	_
each	_	_
character	_	_
,	_	_
the	_	_
attribute	_	_
histogram	_	_
is	_	_
a	_	_
one-hot	_	_
vector	_	_
per	_	_
attribute	_	_
set	_	_
.	_	_

#174
Therefore	_	_
,	_	_
a	_	_
classifier	_	_
can	_	_
be	_	_
learned	_	_
to	_	_
predict	_	_
each	_	_
attribute	_	_
set	_	_
and	_	_
totally	_	_
23	_	_
classifiers	_	_
are	_	_
needed	_	_
to	_	_
learn	_	_
the	_	_
described	_	_
23	_	_
attribute	_	_
sets	_	_
.	_	_

#175
The	_	_
basic	_	_
framework	_	_
of	_	_
attribute	_	_
classifiers	_	_
is	_	_
shown	_	_
in	_	_
Fig.	_	_
7	_	_
.	_	_

#176
Compared	_	_
with	_	_
traditional	_	_
methods	_	_
,	_	_
the	_	_
convolutional	_	_
neural	_	_
network	_	_
[	_	_
27	_	_
]	_	_
provides	_	_
the	_	_
state-of-the-art	_	_
performance	_	_
in	_	_
nearly	_	_
every	_	_
field	_	_
of	_	_
pattern	_	_
recognition	_	_
.	_	_

#177
Therefore	_	_
,	_	_
we	_	_
also	_	_
appy	_	_
the	_	_
CNN	_	_
method	_	_
for	_	_
attribute	_	_
recognition	_	_
.	_	_

#178
In	_	_
this	_	_
paper	_	_
,	_	_
we	_	_
use	_	_
the	_	_
residual	_	_
neural	_	_
network	_	_
(	_	_
resNet	_	_
)	_	_
[	_	_
28	_	_
]	_	_
,	_	_
which	_	_
is	_	_
widely	_	_
used	_	_
in	_	_
different	_	_
applications	_	_
.	_	_

#179
The	_	_
network	_	_
contains	_	_
one	_	_
input	_	_
layer	_	_
with	_	_
16	_	_
feature	_	_
maps	_	_
,	_	_
following	_	_
fifteen	_	_
residual	_	_
blocks	_	_
and	_	_
23	_	_
global	_	_
average	_	_
pooling	_	_
layers	_	_
as	_	_
output	_	_
(	_	_
each	_	_
layer	_	_
corresponds	_	_
to	_	_
an	_	_
attribute	_	_
set	_	_
classifier	_	_
)	_	_
.	_	_

#180
Fig.	_	_
8	_	_
shows	_	_
the	_	_
structure	_	_
of	_	_
the	_	_
resNet	_	_
used	_	_
in	_	_
this	_	_
paper	_	_
.	_	_

#181
On	_	_
each	_	_
residual	_	_
block	_	_
,	_	_
there	_	_
are	_	_
two	_	_
convolutional	_	_
layers	_	_
followed	_	_
by	_	_
the	_	_
batch	_	_
normalization	_	_
[	_	_
29	_	_
]	_	_
.	_	_

#182
Images	_	_
with	_	_
attributes	_	_
Attribute	_	_
classifiersConvolutional	_	_
layers	_	_
ResNet	_	_
av	_	_
er	_	_
ag	_	_
e	_	_
p	_	_
o	_	_
ol	_	_
Ai	_	_
pingyin	_	_
Af	_	_
pingyin	_	_
At	_	_
pingyin	_	_
Astruct	_	_
ANstroke	_	_
A1	_	_
cj	_	_
··	_	_
·	_	_
··	_	_
·	_	_
A4	_	_
fc	_	_
A5	_	_
fc	_	_
Figure	_	_
7	_	_
:	_	_
The	_	_
structure	_	_
of	_	_
the	_	_
neural	_	_
network	_	_
used	_	_
for	_	_
Chinese	_	_
attribute	_	_
recognition	_	_
.	_	_

#183
The	_	_
detail	_	_
structure	_	_
of	_	_
the	_	_
ResNet	_	_
is	_	_
show	_	_
in	_	_
Fig.	_	_
8	_	_
.	_	_

#184
All	_	_
attributes	_	_
classifiers	_	_
share	_	_
the	_	_
basic	_	_
convolutional	_	_
layers	_	_
.	_	_

#185
layer	_	_
name	_	_
size	_	_
layer	_	_
conv1	_	_
64×64	_	_
3×3	_	_
,	_	_
16	_	_
conv2	_	_
x	_	_
64×64	_	_
3×3	_	_
,	_	_
16	_	_
3×3	_	_
,	_	_
16	_	_
×3	_	_
conv3	_	_
x	_	_
32×32	_	_
3×3	_	_
,	_	_
32	_	_
3×3	_	_
,	_	_
32	_	_
×3	_	_
conv4	_	_
x	_	_
16×16	_	_
3×3	_	_
,	_	_
64	_	_
3×3	_	_
,	_	_
64	_	_
×3	_	_
conv5	_	_
x	_	_
8×8	_	_
3×3	_	_
,	_	_
128	_	_
3×3	_	_
,	_	_
128	_	_
×3	_	_
conv6	_	_
x	_	_
4×4	_	_
3×3	_	_
,	_	_
256	_	_
3×3	_	_
,	_	_
256	_	_
×3	_	_
fc	_	_
1×1	_	_
average	_	_
pool	_	_
Figure	_	_
8	_	_
:	_	_
The	_	_
structure	_	_
of	_	_
the	_	_
residual	_	_
neural	_	_
network	_	_
used	_	_
in	_	_
this	_	_
paper	_	_
.	_	_

#186
Building	_	_
blocks	_	_
are	_	_
shown	_	_
in	_	_
brackets	_	_
with	_	_
the	_	_
numbers	_	_
of	_	_
blocks	_	_
stacked	_	_
.	_	_

#187
Average	_	_
pooling	_	_
is	_	_
used	_	_
by	_	_
conv2	_	_
x	_	_
,	_	_
conv3	_	_
x	_	_
,	_	_
conv4	_	_
x	_	_
,	_	_
conv5	_	_
x	_	_
with	_	_
a	_	_
stride	_	_
of	_	_
2	_	_
.	_	_

#188
The	_	_
input	_	_
of	_	_
the	_	_
network	_	_
is	_	_
the	_	_
gray-scale	_	_
image	_	_
,	_	_
with	_	_
the	_	_
fixed	_	_
size	_	_
64×64	_	_
.	_	_

#189
The	_	_
initialization	_	_
of	_	_
the	_	_
network	_	_
is	_	_
also	_	_
very	_	_
important	_	_
and	_	_
we	_	_
use	_	_
the	_	_
widely	_	_
used	_	_
Xavier	_	_
initialization	_	_
method	_	_
[	_	_
30	_	_
]	_	_
.	_	_

#190
For	_	_
each	_	_
attribute	_	_
classifier	_	_
,	_	_
the	_	_
entropy	_	_
softmax	_	_
loss	_	_
is	_	_
used	_	_
.	_	_

#191
Finally	_	_
,	_	_
the	_	_
training	_	_
loss	_	_
of	_	_
the	_	_
model	_	_
is	_	_
defined	_	_
as	_	_
the	_	_
sum	_	_
of	_	_
all	_	_
23	_	_
attribute	_	_
set	_	_
classifiers	_	_
:	_	_
loss	_	_
=	_	_
23∑	_	_
i=1	_	_
entropy	_	_
softmax	_	_
loss	_	_
(	_	_
Ai	_	_
)	_	_
(	_	_
1	_	_
)	_	_
The	_	_
network	_	_
is	_	_
trained	_	_
with	_	_
an	_	_
initial	_	_
learning	_	_
rate	_	_
of	_	_
10−4	_	_
.	_	_

#192
The	_	_
learning	_	_
rate	_	_
reduces	_	_
by	_	_
half	_	_
every	_	_
10k	_	_
iterations	_	_
.	_	_

#193
The	_	_
batch	_	_
size	_	_
is	_	_
set	_	_
to	_	_
200	_	_
and	_	_
the	_	_
training	_	_
is	_	_
run	_	_
on	_	_
a	_	_
single	_	_
Nvidia	_	_
GTX	_	_
960	_	_
GPU	_	_
using	_	_
the	_	_
Tensorflow	_	_
framework	_	_
[	_	_
31	_	_
]	_	_
.	_	_

#194
3.6	_	_
.	_	_

#195
Chinese	_	_
character	_	_
recognition	_	_
by	_	_
attributes	_	_
Once	_	_
the	_	_
attribute	_	_
classifiers	_	_
are	_	_
trained	_	_
,	_	_
they	_	_
can	_	_
be	_	_
used	_	_
for	_	_
attribute	_	_
estimation	_	_
of	_	_
characters	_	_
in	_	_
the	_	_
test	_	_
set	_	_
.	_	_

#196
Given	_	_
the	_	_
estimated	_	_
attribute	_	_
,	_	_
the	_	_
character	_	_
can	_	_
be	_	_
recognized	_	_
with	_	_
a	_	_
lexicon	_	_
,	_	_
which	_	_
stores	_	_
the	_	_
character	_	_
labels	_	_
as	_	_
well	_	_
as	_	_
the	_	_
corresponding	_	_
attributes	_	_
.	_	_

#197
Due	_	_
to	_	_
the	_	_
quality	_	_
and	_	_
style	_	_
of	_	_
the	_	_
input	_	_
image	_	_
,	_	_
some	_	_
attribute	_	_
classifiers	_	_
may	_	_
produce	_	_
the	_	_
wrong	_	_
results	_	_
.	_	_

#198
In	_	_
addition	_	_
,	_	_
we	_	_
use	_	_
different	_	_
set	_	_
of	_	_
attributes	_	_
and	_	_
it	_	_
is	_	_
very	_	_
hard	_	_
to	_	_
know	_	_
which	_	_
set	_	_
of	_	_
attribute	_	_
classifiers	_	_
are	_	_
completely	_	_
correct	_	_
for	_	_
recognition	_	_
.	_	_

#199
In	_	_
order	_	_
to	_	_
solve	_	_
this	_	_
problem	_	_
,	_	_
we	_	_
assign	_	_
the	_	_
label	_	_
of	_	_
the	_	_
test	_	_
character	_	_
with	_	_
the	_	_
most	_	_
similar	_	_
character	_	_
in	_	_
the	_	_
given	_	_
lexicon	_	_
by	_	_
the	_	_
Hamming	_	_
distance	_	_
between	_	_
the	_	_
estimated	_	_
attribute	_	_
vector	_	_
and	_	_
the	_	_
attribute	_	_
vector	_	_
stored	_	_
in	_	_
the	_	_
lexicon	_	_
,	_	_
which	_	_
is	_	_
similar	_	_
as	_	_
the	_	_
nearest	_	_
neighbor	_	_
classification	_	_
method	_	_
.	_	_

#200
We	_	_
use	_	_
the	_	_
Hamming	_	_
distance	_	_
because	_	_
the	_	_
attribute	_	_
representation	_	_
of	_	_
all	_	_
23	_	_
attribute	_	_
sets	_	_
is	_	_
the	_	_
binary	_	_
vector	_	_
if	_	_
we	_	_
combine	_	_
them	_	_
together	_	_
as	_	_
one	_	_
feature	_	_
vector	_	_
.	_	_

#201
Fig.	_	_
9	_	_
shows	_	_
the	_	_
framework	_	_
of	_	_
Chinese	_	_
character	_	_
recognition	_	_
with	_	_
the	_	_
Cangjie	_	_
attribute	_	_
as	_	_
an	_	_
example	_	_
.	_	_

#202
4	_	_
.	_	_

#203
Experimental	_	_
results	_	_
In	_	_
this	_	_
section	_	_
,	_	_
we	_	_
evaluate	_	_
the	_	_
attribute	_	_
recognition	_	_
of	_	_
Chinese	_	_
characters	_	_
on	_	_
different	_	_
data	_	_
sets	_	_
.	_	_

#204
First	_	_
,	_	_
we	_	_
evaluate	_	_
the	_	_
performance	_	_
of	_	_
zero-shot	_	_
learning	_	_
on	_	_
a	_	_
machine-printed	_	_
Chinese	_	_
characters	_	_
with	_	_
different	_	_
fonts	_	_
.	_	_

#205
Second	_	_
,	_	_
the	_	_
performance	_	_
on	_	_
the	_	_
unbalanced	_	_
data	_	_
set	_	_
from	_	_
the	_	_
historical	_	_
books	_	_
that	_	_
are	_	_
introduced	_	_
earlier	_	_
is	_	_
reported	_	_
.	_	_

#206
Finally	_	_
,	_	_
we	_	_
present	_	_
the	_	_
results	_	_
of	_	_
attribute	_	_
recognition	_	_
on	_	_
the	_	_
balanced	_	_
and	_	_
“closed”	_	_
handwritten	_	_
isolated	_	_
Chinese	_	_
characters	_	_
.	_	_

#207
4.1	_	_
.	_	_

#208
Performance	_	_
on	_	_
a	_	_
machine-printed	_	_
data	_	_
set	_	_
The	_	_
commonly	_	_
used	_	_
3,755	_	_
Chinese	_	_
characters	_	_
with	_	_
different	_	_
fonts	_	_
in	_	_
the	_	_
GB2312-80	_	_
level-1	_	_
set	_	_
are	_	_
used	_	_
for	_	_
testing	_	_
and	_	_
the	_	_
rest	_	_
of	_	_
characters	_	_
are	_	_
used	_	_
for	_	_
training	_	_
,	_	_
which	_	_
means	_	_
the	_	_
characters	_	_
in	_	_
the	_	_
test	_	_
set	_	_
are	_	_
not	_	_
present	_	_
in	_	_
the	_	_
training	_	_
set	_	_
(	_	_
zero-shot	_	_
learning	_	_
)	_	_
.	_	_

#209
This	_	_
experiment	_	_
aims	_	_
to	_	_
demonstrate	_	_
the	_	_
generalization	_	_
of	_	_
the	_	_
proposed	_	_
attribute	_	_
representation	_	_
to	_	_
the	_	_
unseen	_	_
characters	_	_
in	_	_
a	_	_
clean	_	_
data	_	_
set	_	_
.	_	_

#210
4.1.1	_	_
.	_	_

#211
Performance	_	_
of	_	_
attribute	_	_
recognition	_	_
on	_	_
unseen	_	_
characters	_	_
Table	_	_
2	_	_
shows	_	_
the	_	_
performance	_	_
of	_	_
attribute	_	_
recognition	_	_
on	_	_
the	_	_
test	_	_
set	_	_
with	_	_
different	_	_
fonts	_	_
where	_	_
characters	_	_
are	_	_
not	_	_
in	_	_
the	_	_
training	_	_
set	_	_
.	_	_

#212
It	_	_
should	_	_
be	_	_
noted	_	_
that	_	_
there	_	_
will	_	_
not	_	_
be	_	_
a	_	_
direct	_	_
relation	_	_
between	_	_
this	_	_
performance	_	_
and	_	_
final	_	_
character	_	_
recognition	_	_
scores	_	_
shown	_	_
later	_	_
.	_	_

#213
This	_	_
is	_	_
due	_	_
to	_	_
several	_	_
factors	_	_
,	_	_
including	_	_
the	_	_
dimensionality	_	_
of	_	_
the	_	_
attribute	_	_
.	_	_

#214
A	_	_
mediocre	_	_
attribute	_	_
may	_	_
be	_	_
helpful	_	_
in	_	_
the	_	_
end	_	_
.	_	_

#215
The	_	_
lowest	_	_
accuracy	_	_
is	_	_
found	_	_
in	_	_
Nstroke	_	_
(	_	_
the	_	_
attribute	_	_
:	_	_
number	_	_
of	_	_
strokes	_	_
)	_	_
,	_	_
whereas	_	_
the	_	_
performance	_	_
of	_	_
the	_	_
“Four-Corner”	_	_
attribute	_	_
sets	_	_
is	_	_
over	_	_
90	_	_
%	_	_
but	_	_
the	_	_
each	_	_
“Four-Corner”	_	_
code	_	_
is	_	_
shared	_	_
by	_	_
many	_	_
characters	_	_
.	_	_

#216
For	_	_
almost-unique	_	_
code	_	_
Training	_	_
Samples	_	_
A1	_	_
cj	_	_
Classifier	_	_
(	_	_
A1	_	_
cj	_	_
)	_	_
Training	_	_
Testing	_	_
·	_	_
·	_	_
·	_	_
A	_	_
·	_	_
·	_	_
·	_	_
B	_	_
·	_	_
·	_	_
·	_	_
C	_	_
·	_	_
·	_	_
·	_	_
·	_	_
·	_	_
·	_	_
A2	_	_
cj	_	_
Classifier	_	_
(	_	_
A2	_	_
cj	_	_
)	_	_
·	_	_
·	_	_
·	_	_
A3	_	_
cj	_	_
Classifier	_	_
(	_	_
A3	_	_
cj	_	_
)	_	_
·	_	_
·	_	_
·	_	_
A4	_	_
cj	_	_
Classifier	_	_
(	_	_
A4	_	_
cj	_	_
)	_	_
·	_	_
·	_	_
·	_	_
A5	_	_
cj	_	_
Classifier	_	_
(	_	_
A5	_	_
cj	_	_
)	_	_
·	_	_
·	_	_
·	_	_
B	_	_
U	_	_
C	_	_
S	_	_
H	_	_
Lexicon	_	_
BUCSH	_	_
U+76fc	_	_
OPFBO	_	_
U+9501	_	_
LSCWJ	_	_
U+9610	_	_
KHFMU	_	_
U+3e70	_	_
NLFBG	_	_
U+969a	_	_
·	_	_
·	_	_
·	_	_
U+76fc	_	_
O	_	_
P	_	_
F	_	_
B	_	_
O	_	_
U+9501	_	_
L	_	_
S	_	_
C	_	_
W	_	_
J	_	_
U+9610	_	_
K	_	_
H	_	_
F	_	_
M	_	_
U	_	_
U+3e70	_	_
Figure	_	_
9	_	_
:	_	_
The	_	_
framework	_	_
of	_	_
Chinese	_	_
character	_	_
recognition	_	_
by	_	_
attributes	_	_
using	_	_
Cangjie	_	_
attributes	_	_
.	_	_

#217
The	_	_
attribute	_	_
classifiers	_	_
are	_	_
trained	_	_
using	_	_
samples	_	_
in	_	_
the	_	_
training	_	_
data	_	_
set	_	_
.	_	_

#218
For	_	_
characters	_	_
in	_	_
the	_	_
test	_	_
set	_	_
,	_	_
their	_	_
attributes	_	_
are	_	_
predicted	_	_
by	_	_
the	_	_
attribute	_	_
classifiers	_	_
and	_	_
they	_	_
can	_	_
be	_	_
recognized	_	_
with	_	_
a	_	_
lexicon	_	_
which	_	_
stores	_	_
the	_	_
attributes	_	_
and	_	_
the	_	_
corresponding	_	_
label	_	_
(	_	_
the	_	_
Unicode	_	_
in	_	_
this	_	_
figure	_	_
)	_	_
.	_	_

#219
encoding	_	_
methods	_	_
,	_	_
such	_	_
as	_	_
Cangjie	_	_
,	_	_
Zhengma	_	_
and	_	_
Wubi	_	_
,	_	_
the	_	_
performance	_	_
is	_	_
around	_	_
70	_	_
%	_	_
,	_	_
but	_	_
they	_	_
convey	_	_
more	_	_
information	_	_
concerning	_	_
the	_	_
character	_	_
class	_	_
.	_	_

#220
One	_	_
interesting	_	_
observation	_	_
is	_	_
that	_	_
the	_	_
performance	_	_
of	_	_
the	_	_
first	_	_
code	_	_
of	_	_
these	_	_
three	_	_
attributes	_	_
is	_	_
better	_	_
than	_	_
others	_	_
(	_	_
88.8	_	_
%	_	_
for	_	_
Cangjie	_	_
,	_	_
87.6	_	_
%	_	_
for	_	_
Zhengma	_	_
and	_	_
85.7	_	_
%	_	_
for	_	_
Wubi	_	_
)	_	_
,	_	_
which	_	_
shows	_	_
the	_	_
first	_	_
code	_	_
is	_	_
more	_	_
informative	_	_
than	_	_
others	_	_
.	_	_

#221
Although	_	_
the	_	_
results	_	_
of	_	_
attribute	_	_
classification	_	_
in	_	_
Pinyin	_	_
are	_	_
mediocre	_	_
(	_	_
46	_	_
%	_	_
)	_	_
,	_	_
the	_	_
attribute	_	_
may	_	_
still	_	_
be	_	_
helpful	_	_
on	_	_
the	_	_
basis	_	_
of	_	_
uniqueness	_	_
of	_	_
codes	_	_
in	_	_
the	_	_
total	_	_
character	_	_
set	_	_
.	_	_

#222
From	_	_
Table	_	_
2	_	_
we	_	_
can	_	_
obtain	_	_
the	_	_
conclusion	_	_
that	_	_
attributes	_	_
learned	_	_
on	_	_
the	_	_
training	_	_
set	_	_
has	_	_
the	_	_
potential	_	_
to	_	_
transfer	_	_
to	_	_
unseen	_	_
characters	_	_
.	_	_

#223
Therefore	_	_
,	_	_
from	_	_
attribution	_	_
recognition	_	_
,	_	_
we	_	_
predict	_	_
that	_	_
it	_	_
is	_	_
possible	_	_
to	_	_
recognize	_	_
Chinese	_	_
character	_	_
that	_	_
are	_	_
not	_	_
part	_	_
of	_	_
the	_	_
training	_	_
set	_	_
.	_	_

#224
Since	_	_
the	_	_
unseen	_	_
characters	_	_
occurred	_	_
exactly	_	_
once	_	_
,	_	_
this	_	_
can	_	_
not	_	_
be	_	_
tested	_	_
directly	_	_
in	_	_
this	_	_
data	_	_
set	_	_
.	_	_

#225
In	_	_
the	_	_
next	_	_
section	_	_
,	_	_
the	_	_
actual	_	_
character	_	_
recognition	_	_
performance	_	_
will	_	_
be	_	_
presented	_	_
on	_	_
characters	_	_
that	_	_
occurred	_	_
at	_	_
least	_	_
17	_	_
times	_	_
.	_	_

#226
It	_	_
should	_	_
be	_	_
noted	_	_
that	_	_
the	_	_
more	_	_
common	_	_
characters	_	_
in	_	_
the	_	_
test	_	_
set	_	_
also	_	_
have	_	_
a	_	_
more	_	_
simple	_	_
structure	_	_
.	_	_

#227
This	_	_
will	_	_
be	_	_
addressed	_	_
in	_	_
a	_	_
later	_	_
section	_	_
.	_	_

#228
Table	_	_
2	_	_
:	_	_
Performance	_	_
of	_	_
character	_	_
attribute	_	_
recognition	_	_
on	_	_
the	_	_
unseen	_	_
characters	_	_
in	_	_
the	_	_
machine-printed	_	_
data	_	_
set	_	_
.	_	_

#229
Attributes	_	_
Dims	_	_
Accuracy	_	_
(	_	_
%	_	_
)	_	_
Attributes	_	_
Dims	_	_
Accuracy	_	_
(	_	_
%	_	_
)	_	_
Cangjie	_	_
A1	_	_
cj	_	_
26	_	_
88.8	_	_
Four-Corner	_	_
A1	_	_
fc	_	_
10	_	_
93.5	_	_
A2	_	_
cj	_	_
27	_	_
71.9	_	_
A2	_	_
fc	_	_
10	_	_
94.1	_	_
A3	_	_
cj	_	_
27	_	_
69.2	_	_
A3	_	_
fc	_	_
10	_	_
93.1	_	_
A4	_	_
cj	_	_
27	_	_
94.6	_	_
A4	_	_
fc	_	_
10	_	_
95.3	_	_
A5	_	_
cj	_	_
27	_	_
87.6	_	_
A5	_	_
fc	_	_
10	_	_
90.2	_	_
Zhengma	_	_
A1	_	_
zm	_	_
26	_	_
87.6	_	_
Wubi	_	_
A1	_	_
wb	_	_
26	_	_
85.7	_	_
A2	_	_
zm	_	_
26	_	_
75.5	_	_
A2	_	_
wb	_	_
26	_	_
70.8	_	_
A3	_	_
zm	_	_
26	_	_
67.2	_	_
A3	_	_
wb	_	_
26	_	_
62.9	_	_
A4	_	_
zm	_	_
27	_	_
72.9	_	_
A4	_	_
wb	_	_
27	_	_
72.9	_	_
Pinyin	_	_
Ai	_	_
pinyin	_	_
26	_	_
41.4	_	_
Structure	_	_
Astruct	_	_
15	_	_
81.8	_	_
Af	_	_
pinyin	_	_
38	_	_
49.1	_	_
At	_	_
pinyin	_	_
5	_	_
47.5	_	_
Stroke	_	_
ANstroke	_	_
31	_	_
38.7	_	_
4.1.2	_	_
.	_	_

#230
Performance	_	_
of	_	_
character	_	_
recognition	_	_
by	_	_
attributes	_	_
Once	_	_
attributes	_	_
of	_	_
each	_	_
character	_	_
are	_	_
recognized	_	_
,	_	_
they	_	_
can	_	_
be	_	_
used	_	_
for	_	_
character	_	_
recolonization	_	_
by	_	_
directly	_	_
comparing	_	_
them	_	_
with	_	_
the	_	_
attributes	_	_
of	_	_
the	_	_
lexicon	_	_
characters	_	_
.	_	_

#231
In	_	_
this	_	_
section	_	_
,	_	_
the	_	_
lexicon	_	_
is	_	_
the	_	_
set	_	_
of	_	_
characters	_	_
in	_	_
the	_	_
test	_	_
set	_	_
,	_	_
which	_	_
has	_	_
the	_	_
size	_	_
of	_	_
3,755	_	_
.	_	_

#232
Table	_	_
3	_	_
shows	_	_
the	_	_
accuracy	_	_
of	_	_
character	_	_
recognition	_	_
on	_	_
the	_	_
machine-printed	_	_
data	_	_
set	_	_
with	_	_
different	_	_
sets	_	_
of	_	_
attribute	_	_
vectors	_	_
.	_	_

#233
From	_	_
table	_	_
we	_	_
can	_	_
see	_	_
that	_	_
the	_	_
combination	_	_
of	_	_
Pinyin	_	_
,	_	_
Structure	_	_
and	_	_
Number	_	_
of	_	_
strokes	_	_
attributes	_	_
provides	_	_
a	_	_
low	_	_
performance	_	_
.	_	_

#234
The	_	_
performance	_	_
of	_	_
other	_	_
embedding	_	_
methods	_	_
,	_	_
such	_	_
as	_	_
Cangjie	_	_
,	_	_
Zhengma	_	_
,	_	_
Wubi	_	_
and	_	_
Four-Corner	_	_
,	_	_
is	_	_
similar	_	_
.	_	_

#235
However	_	_
,	_	_
combining	_	_
all	_	_
of	_	_
attributes	_	_
gives	_	_
much	_	_
better	_	_
result	_	_
and	_	_
85.2	_	_
%	_	_
is	_	_
achieved	_	_
on	_	_
the	_	_
unseen	_	_
character	_	_
sets	_	_
,	_	_
which	_	_
is	_	_
higher	_	_
than	_	_
the	_	_
combination	_	_
of	_	_
different	_	_
coding	_	_
methods	_	_
.	_	_

#236
The	_	_
reason	_	_
is	_	_
that	_	_
the	_	_
Pinyin	_	_
,	_	_
Structure	_	_
and	_	_
Number	_	_
of	_	_
strokes	_	_
are	_	_
different	_	_
types	_	_
of	_	_
attributes	_	_
and	_	_
combine	_	_
them	_	_
with	_	_
coding	_	_
methods	_	_
can	_	_
provide	_	_
a	_	_
slightly	_	_
better	_	_
performance	_	_
.	_	_

#237
Since	_	_
the	_	_
numbers	_	_
of	_	_
training	_	_
samples	_	_
of	_	_
different	_	_
fonts	_	_
are	_	_
not	_	_
same	_	_
,	_	_
it	_	_
is	_	_
interesting	_	_
to	_	_
know	_	_
the	_	_
performance	_	_
of	_	_
different	_	_
fonts	_	_
with	_	_
respect	_	_
to	_	_
the	_	_
number	_	_
of	_	_
training	_	_
samples	_	_
.	_	_

#238
Fig.	_	_
10	_	_
shows	_	_
the	_	_
performance	_	_
of	_	_
character	_	_
recognition	_	_
with	_	_
different	_	_
fonts	_	_
.	_	_

#239
From	_	_
the	_	_
figure	_	_
we	_	_
can	_	_
see	_	_
that	_	_
when	_	_
the	_	_
number	_	_
of	_	_
training	_	_
characters	_	_
is	_	_
large	_	_
(	_	_
such	_	_
as	_	_
20k	_	_
characters	_	_
of	_	_
XiMing	_	_
,	_	_
HeiTi	_	_
and	_	_
XinSong	_	_
fonts	_	_
)	_	_
,	_	_
the	_	_
performance	_	_
is	_	_
high	_	_
(	_	_
the	_	_
accuracy	_	_
is	_	_
about	_	_
90	_	_
%	_	_
)	_	_
.	_	_

#240
The	_	_
performance	_	_
of	_	_
WeiBei	_	_
and	_	_
XinShu	_	_
is	_	_
lower	_	_
than	_	_
other	_	_
fonts	_	_
.	_	_

#241
We	_	_
conduct	_	_
another	_	_
experiment	_	_
on	_	_
character	_	_
recognition	_	_
on	_	_
images	_	_
with	_	_
the	_	_
HeiTi	_	_
font	_	_
.	_	_

#242
We	_	_
randomly	_	_
divide	_	_
the	_	_
total	_	_
27k	_	_
character	_	_
images	_	_
(	_	_
each	_	_
character	_	_
has	_	_
only	_	_
one	_	_
example	_	_
)	_	_
into	_	_
five	_	_
parts	_	_
and	_	_
the	_	_
experiment	_	_
is	_	_
performed	_	_
with	_	_
five	_	_
cross-validation	_	_
:	_	_
each	_	_
time	_	_
,	_	_
four	_	_
parts	_	_
are	_	_
used	_	_
for	_	_
training	_	_
and	_	_
one	_	_
part	_	_
is	_	_
used	_	_
for	_	_
testing	_	_
.	_	_

#243
Table	_	_
4	_	_
shows	_	_
the	_	_
average	_	_
performance	_	_
of	_	_
character	_	_
recognition	_	_
with	_	_
different	_	_
attributes	_	_
.	_	_

#244
Cangjie	_	_
provides	_	_
the	_	_
best	_	_
performance	_	_
since	_	_
it	_	_
Table	_	_
3	_	_
:	_	_
Performance	_	_
of	_	_
character	_	_
recognition	_	_
by	_	_
attributes	_	_
on	_	_
the	_	_
printed	_	_
data	_	_
set	_	_
.	_	_

#245
Classifiers	_	_
Dims	_	_
Accuracy	_	_
(	_	_
%	_	_
)	_	_
Apinyin+struct+Nstroke	_	_
115	_	_
9.1	_	_
Acj	_	_
134	_	_
57.7	_	_
Azm	_	_
105	_	_
55.4	_	_
Awb	_	_
107	_	_
53.2	_	_
Afc	_	_
50	_	_
54.7	_	_
Acj+zm+wb	_	_
346	_	_
76.5	_	_
Acj+zm+wb+fc	_	_
396	_	_
84.3	_	_
Combined	_	_
all	_	_
A	_	_
511	_	_
85.2	_	_
X	_	_
in	_	_
S	_	_
on	_	_
g	_	_
H	_	_
ei	_	_
T	_	_
i	_	_
X	_	_
iM	_	_
in	_	_
g	_	_
T	_	_
eH	_	_
ei	_	_
M	_	_
in	_	_
gT	_	_
i	_	_
C	_	_
u	_	_
oM	_	_
in	_	_
gF	_	_
an	_	_
T	_	_
eM	_	_
in	_	_
gF	_	_
an	_	_
C	_	_
h	_	_
ao	_	_
M	_	_
in	_	_
g	_	_
X	_	_
iY	_	_
u	_	_
an	_	_
T	_	_
eY	_	_
u	_	_
an	_	_
F	_	_
an	_	_
gS	_	_
on	_	_
g	_	_
L	_	_
iS	_	_
h	_	_
u	_	_
Y	_	_
u	_	_
an	_	_
K	_	_
ai	_	_
C	_	_
u	_	_
oJ	_	_
in	_	_
C	_	_
u	_	_
oK	_	_
ai	_	_
W	_	_
ei	_	_
B	_	_
ei	_	_
X	_	_
in	_	_
S	_	_
h	_	_
u	_	_
0.5	_	_
1.5	_	_
·104	_	_
N	_	_
u	_	_
m	_	_
b	_	_
er	_	_
o	_	_
f	_	_
T	_	_
ra	_	_
in	_	_
in	_	_
g	_	_
S	_	_
am	_	_
p	_	_
le	_	_
s	_	_
P	_	_
er	_	_
fo	_	_
rm	_	_
an	_	_
ce	_	_
(	_	_
%	_	_
)	_	_
Figure	_	_
10	_	_
:	_	_
Performance	_	_
of	_	_
character	_	_
recognition	_	_
(	_	_
red	_	_
line	_	_
)	_	_
with	_	_
different	_	_
number	_	_
of	_	_
training	_	_
samples	_	_
per	_	_
character	_	_
class	_	_
(	_	_
blue	_	_
bar	_	_
)	_	_
on	_	_
printed	_	_
character	_	_
images	_	_
with	_	_
different	_	_
fonts	_	_
.	_	_

#246
The	_	_
font	_	_
is	_	_
sorted	_	_
by	_	_
the	_	_
performance	_	_
of	_	_
character	_	_
recognition	_	_
.	_	_

#247
has	_	_
five	_	_
codes	_	_
.	_	_

#248
Combining	_	_
all	_	_
of	_	_
23	_	_
attribute	_	_
sets	_	_
reaches	_	_
99.90	_	_
%	_	_
on	_	_
zero-shot	_	_
learning	_	_
,	_	_
which	_	_
is	_	_
higher	_	_
than	_	_
the	_	_
performance	_	_
on	_	_
the	_	_
test	_	_
set	_	_
of	_	_
commonly-used	_	_
3,755	_	_
characters	_	_
(	_	_
90.0	_	_
%	_	_
reported	_	_
in	_	_
Fig.	_	_
10	_	_
)	_	_
.	_	_

#249
This	_	_
high	_	_
performance	_	_
is	_	_
possible	_	_
because	_	_
most	_	_
radicals	_	_
of	_	_
the	_	_
complicated-shape	_	_
traditional	_	_
characters	_	_
are	_	_
highly	_	_
informative	_	_
phonetic	_	_
components	_	_
while	_	_
radicals	_	_
of	_	_
simple	_	_
characters	_	_
(	_	_
especially	_	_
in	_	_
the	_	_
commonly-used	_	_
GB2312-80	_	_
level-1	_	_
set	_	_
)	_	_
are	_	_
artificially	_	_
designed	_	_
or	_	_
simplified	_	_
by	_	_
reducing	_	_
the	_	_
number	_	_
of	_	_
strokes	_	_
.	_	_

#250
From	_	_
Tables	_	_
3	_	_
,	_	_
4	_	_
and	_	_
Fig.	_	_
10	_	_
,	_	_
we	_	_
can	_	_
see	_	_
that	_	_
characters	_	_
which	_	_
are	_	_
not	_	_
in	_	_
the	_	_
Table	_	_
4	_	_
:	_	_
Performance	_	_
of	_	_
character	_	_
recognition	_	_
by	_	_
attributes	_	_
on	_	_
character	_	_
images	_	_
with	_	_
the	_	_
HeiTi	_	_
font	_	_
.	_	_

#251
Classifiers	_	_
Dims	_	_
Accuracy	_	_
(	_	_
%	_	_
)	_	_
Acj	_	_
134	_	_
92.20	_	_
Azm	_	_
105	_	_
80.11	_	_
Awb	_	_
107	_	_
79.95	_	_
Combined	_	_
all	_	_
A	_	_
511	_	_
99.90	_	_
training	_	_
set	_	_
can	_	_
be	_	_
recognized	_	_
by	_	_
attributes	_	_
,	_	_
which	_	_
demonstrates	_	_
a	_	_
very	_	_
good	_	_
generalization	_	_
of	_	_
the	_	_
Chinese	_	_
attributes	_	_
to	_	_
the	_	_
unseen	_	_
character	_	_
sets	_	_
.	_	_

#252
However	_	_
,	_	_
these	_	_
unseen	_	_
characters	_	_
can	_	_
not	_	_
be	_	_
recognized	_	_
by	_	_
the	_	_
traditional	_	_
classification	_	_
methods	_	_
which	_	_
consider	_	_
each	_	_
character	_	_
as	_	_
a	_	_
class	_	_
.	_	_

#253
4.2	_	_
.	_	_

#254
Performance	_	_
on	_	_
historical	_	_
documents	_	_
with	_	_
unbalanced	_	_
distribution	_	_
of	_	_
characters	_	_
In	_	_
this	_	_
section	_	_
,	_	_
we	_	_
conduct	_	_
experiments	_	_
on	_	_
the	_	_
historical	_	_
books	_	_
that	_	_
were	_	_
introduced	_	_
earlier	_	_
.	_	_

#255
The	_	_
number	_	_
of	_	_
characters	_	_
and	_	_
instances	_	_
is	_	_
shown	_	_
in	_	_
Table	_	_
1	_	_
.	_	_

#256
As	_	_
mentioned	_	_
in	_	_
Section	_	_
2	_	_
,	_	_
the	_	_
distribution	_	_
of	_	_
characters	_	_
has	_	_
a	_	_
long	_	_
tail	_	_
.	_	_

#257
Therefore	_	_
,	_	_
we	_	_
evaluate	_	_
the	_	_
proposed	_	_
method	_	_
based	_	_
on	_	_
two	_	_
sub-sets	_	_
:	_	_
Dhifreq	_	_
and	_	_
Dlofreq	_	_
sets	_	_
.	_	_

#258
Dhifreq	_	_
consists	_	_
characters	_	_
which	_	_
have	_	_
more	_	_
than	_	_
20	_	_
samples	_	_
and	_	_
it	_	_
divided	_	_
into	_	_
training	_	_
(	_	_
80	_	_
%	_	_
)	_	_
and	_	_
testing	_	_
sets	_	_
(	_	_
20	_	_
%	_	_
)	_	_
.	_	_

#259
All	_	_
character	_	_
images	_	_
in	_	_
Dlofreq	_	_
which	_	_
are	_	_
not	_	_
in	_	_
the	_	_
training	_	_
set	_	_
are	_	_
used	_	_
for	_	_
zero-shot	_	_
testing	_	_
.	_	_

#260
During	_	_
training	_	_
,	_	_
we	_	_
use	_	_
the	_	_
translation	_	_
augmentation	_	_
because	_	_
character	_	_
images	_	_
in	_	_
the	_	_
training	_	_
and	_	_
testing	_	_
sets	_	_
suffer	_	_
from	_	_
this	_	_
degradation	_	_
which	_	_
is	_	_
introduced	_	_
in	_	_
the	_	_
character	_	_
segmentation	_	_
processing	_	_
.	_	_

#261
Since	_	_
the	_	_
number	_	_
of	_	_
characters	_	_
in	_	_
this	_	_
data	_	_
set	_	_
is	_	_
small	_	_
and	_	_
only	_	_
1,975	_	_
characters	_	_
are	_	_
present	_	_
in	_	_
the	_	_
training	_	_
set	_	_
(	_	_
see	_	_
Table	_	_
1	_	_
)	_	_
,	_	_
the	_	_
corresponding	_	_
attribute	_	_
vectors	_	_
are	_	_
sparse	_	_
and	_	_
most	_	_
of	_	_
them	_	_
do	_	_
not	_	_
have	_	_
any	_	_
training	_	_
samples	_	_
.	_	_

#262
Therefore	_	_
,	_	_
during	_	_
training	_	_
,	_	_
we	_	_
also	_	_
use	_	_
all	_	_
the	_	_
27,000	_	_
machine-printed	_	_
HeiTi	_	_
characters	_	_
which	_	_
is	_	_
similar	_	_
to	_	_
the	_	_
font	_	_
in	_	_
the	_	_
proposed	_	_
historical	_	_
document	_	_
collections	_	_
to	_	_
mitigate	_	_
the	_	_
sparse	_	_
distribution	_	_
of	_	_
the	_	_
attributes	_	_
.	_	_

#263
This	_	_
can	_	_
be	_	_
considered	_	_
as	_	_
a	_	_
form	_	_
of	_	_
‘attribute	_	_
augmentation’	_	_
.	_	_

#264
In	_	_
this	_	_
section	_	_
,	_	_
the	_	_
model	_	_
trained	_	_
without	_	_
HeiTi	_	_
printed	_	_
characters	_	_
is	_	_
named	_	_
as	_	_
Model	_	_
while	_	_
the	_	_
augmented	_	_
model	_	_
trained	_	_
with	_	_
HeiTi	_	_
printed	_	_
characters	_	_
is	_	_
named	_	_
as	_	_
Model+	_	_
in	_	_
this	_	_
paper	_	_
.	_	_

#265
4.2.1	_	_
.	_	_

#266
Performance	_	_
of	_	_
attribute	_	_
recognition	_	_
Table	_	_
5	_	_
shows	_	_
the	_	_
results	_	_
of	_	_
attribute	_	_
recognition	_	_
on	_	_
the	_	_
test	_	_
set	_	_
(	_	_
20	_	_
%	_	_
)	_	_
of	_	_
Dhifreq	_	_
and	_	_
Dlofreq	_	_
where	_	_
no	_	_
character	_	_
is	_	_
present	_	_
in	_	_
the	_	_
training	_	_
set	_	_
.	_	_

#267
From	_	_
the	_	_
table	_	_
we	_	_
can	_	_
obtain	_	_
the	_	_
conclusions	_	_
that	_	_
:	_	_
(	_	_
1	_	_
)	_	_
there	_	_
is	_	_
no	_	_
obvious	_	_
difference	_	_
between	_	_
the	_	_
performance	_	_
of	_	_
the	_	_
Model	_	_
and	_	_
Model+	_	_
on	_	_
the	_	_
test	_	_
set	_	_
of	_	_
Dhifreq	_	_
,	_	_
which	_	_
means	_	_
when	_	_
characters	_	_
are	_	_
in	_	_
the	_	_
training	_	_
set	_	_
,	_	_
the	_	_
network	_	_
can	_	_
learn	_	_
their	_	_
attributes	_	_
and	_	_
the	_	_
performance	_	_
of	_	_
all	_	_
attributes	_	_
is	_	_
around	_	_
99	_	_
%	_	_
;	_	_
(	_	_
2	_	_
)	_	_
the	_	_
performance	_	_
of	_	_
Model+	_	_
is	_	_
better	_	_
than	_	_
Model	_	_
on	_	_
the	_	_
Dlofreq	_	_
set	_	_
,	_	_
in	_	_
which	_	_
the	_	_
characters	_	_
are	_	_
not	_	_
present	_	_
during	_	_
training	_	_
.	_	_

#268
The	_	_
most	_	_
likely	_	_
reason	_	_
is	_	_
that	_	_
the	_	_
number	_	_
of	_	_
training	_	_
characters	_	_
(	_	_
1,975	_	_
)	_	_
is	_	_
limited	_	_
and	_	_
not	_	_
every	_	_
attribute	_	_
is	_	_
present	_	_
in	_	_
the	_	_
training	_	_
characters	_	_
.	_	_

#269
Thus	_	_
some	_	_
attribute	_	_
vectors	_	_
in	_	_
the	_	_
neural	_	_
network	_	_
of	_	_
Model	_	_
are	_	_
not	_	_
trained	_	_
,	_	_
resulting	_	_
in	_	_
a	_	_
worse	_	_
performance	_	_
on	_	_
the	_	_
unseen	_	_
character	_	_
set	_	_
.	_	_

#270
Table	_	_
5	_	_
:	_	_
Accuracy	_	_
(	_	_
%	_	_
)	_	_
of	_	_
character	_	_
attribute	_	_
recognition	_	_
on	_	_
Dhifreq	_	_
and	_	_
Dlofreq	_	_
.	_	_

#271
Model+	_	_
indicates	_	_
the	_	_
model	_	_
is	_	_
trained	_	_
with	_	_
the	_	_
machine-printed	_	_
characters	_	_
using	_	_
‘attribute	_	_
augmentation’	_	_
.	_	_

#272
Please	_	_
note	_	_
the	_	_
beneficial	_	_
effect	_	_
of	_	_
this	_	_
font-based	_	_
augmentation	_	_
for	_	_
the	_	_
case	_	_
of	_	_
infrequent	_	_
characters	_	_
(	_	_
last	_	_
column	_	_
)	_	_
.	_	_

#273
Attributes	_	_
Dims	_	_
Dhifreq	_	_
Dlofreq	_	_
Model	_	_
Model+	_	_
Model	_	_
Model+	_	_
Pinyin	_	_
Ai	_	_
pinyin	_	_
26	_	_
99.3	_	_
98.9	_	_
18.9	_	_
34.7	_	_
Af	_	_
pinyin	_	_
38	_	_
98.9	_	_
98.5	_	_
26.2	_	_
43.7	_	_
At	_	_
pinyin	_	_
5	_	_
98.9	_	_
98.6	_	_
33.9	_	_
46.8	_	_
Structure	_	_
Astruct	_	_
15	_	_
99.7	_	_
99.6	_	_
86.1	_	_
88.9	_	_
Stroke	_	_
ANstroke	_	_
31	_	_
99.2	_	_
98.9	_	_
18.5	_	_
33.1	_	_
Cangjie	_	_
A1	_	_
cj	_	_
26	_	_
99.6	_	_
99.3	_	_
73.4	_	_
84.6	_	_
A2	_	_
cj	_	_
27	_	_
99.1	_	_
98.7	_	_
45.1	_	_
62.6	_	_
A3	_	_
cj	_	_
27	_	_
99.4	_	_
99.1	_	_
34.8	_	_
52.6	_	_
A4	_	_
cj	_	_
27	_	_
99.7	_	_
99.5	_	_
48.1	_	_
63.4	_	_
A5	_	_
cj	_	_
27	_	_
99.9	_	_
99.8	_	_
79.2	_	_
86.5	_	_
Zhengma	_	_
A1	_	_
zm	_	_
26	_	_
99.6	_	_
99.3	_	_
74.1	_	_
82.1	_	_
A2	_	_
zm	_	_
26	_	_
99.5	_	_
99.2	_	_
46.9	_	_
64.5	_	_
A3	_	_
zm	_	_
26	_	_
98.9	_	_
98.7	_	_
34.2	_	_
54.4	_	_
A4	_	_
zm	_	_
27	_	_
99.5	_	_
99.3	_	_
47.2	_	_
63.5	_	_
Wubi	_	_
A1	_	_
wb	_	_
26	_	_
99.2	_	_
99.0	_	_
72.1	_	_
80.7	_	_
A2	_	_
wb	_	_
26	_	_
99.0	_	_
98.7	_	_
39.6	_	_
58.2	_	_
A3	_	_
wb	_	_
26	_	_
98.8	_	_
98.4	_	_
32.5	_	_
49.6	_	_
A4	_	_
wb	_	_
27	_	_
99.1	_	_
98.8	_	_
50.8	_	_
66.6	_	_
Four-Corner	_	_
A1	_	_
fc	_	_
10	_	_
99.7	_	_
99.4	_	_
83.5	_	_
88.3	_	_
A2	_	_
fc	_	_
10	_	_
99.6	_	_
99.4	_	_
71.7	_	_
81.0	_	_
A3	_	_
fc	_	_
10	_	_
99.6	_	_
99.4	_	_
81.6	_	_
87.2	_	_
A4	_	_
fc	_	_
10	_	_
99.7	_	_
99.6	_	_
82.9	_	_
88.6	_	_
A5	_	_
fc	_	_
10	_	_
99.6	_	_
99.4	_	_
70.8	_	_
80.0	_	_
4.2.2	_	_
.	_	_

#274
Performance	_	_
of	_	_
character	_	_
recognition	_	_
In	_	_
this	_	_
section	_	_
,	_	_
we	_	_
also	_	_
conduct	_	_
the	_	_
character	_	_
recognition	_	_
using	_	_
the	_	_
nearest	_	_
neighborhood	_	_
method	_	_
on	_	_
the	_	_
historical	_	_
books	_	_
,	_	_
given	_	_
the	_	_
attributes	_	_
recognized	_	_
by	_	_
the	_	_
trained	_	_
model	_	_
.	_	_

#275
The	_	_
lexicon	_	_
size	_	_
is	_	_
3,739	_	_
which	_	_
contains	_	_
all	_	_
characters	_	_
present	_	_
in	_	_
the	_	_
data	_	_
set	_	_
and	_	_
the	_	_
Hamming	_	_
distance	_	_
is	_	_
applied	_	_
,	_	_
which	_	_
is	_	_
the	_	_
same	_	_
to	_	_
the	_	_
character	_	_
recognition	_	_
in	_	_
the	_	_
machine-printed	_	_
characters	_	_
in	_	_
Section	_	_
4.1.2	_	_
.	_	_

#276
The	_	_
results	_	_
are	_	_
shown	_	_
in	_	_
Table	_	_
6	_	_
.	_	_

#277
The	_	_
similar	_	_
conclusions	_	_
are	_	_
obtained	_	_
with	_	_
the	_	_
attribute	_	_
recognition	_	_
on	_	_
the	_	_
Table	_	_
6	_	_
:	_	_
Accuracy	_	_
(	_	_
%	_	_
)	_	_
of	_	_
character	_	_
recognition	_	_
by	_	_
attributes	_	_
in	_	_
the	_	_
historical	_	_
books	_	_
.	_	_

#278
Classifiers	_	_
Dims	_	_
Dhifreq	_	_
Dlofreq	_	_
Model	_	_
Model+	_	_
Model	_	_
Model+	_	_
Apinyin+struct+Nstroke	_	_
115	_	_
90.8	_	_
90.1	_	_
1.1	_	_
5.5	_	_
Acj	_	_
134	_	_
97.1	_	_
96.4	_	_
10.1	_	_
32.8	_	_
Azm	_	_
105	_	_
94.1	_	_
93.4	_	_
11.4	_	_
31.8	_	_
Awb	_	_
107	_	_
94.4	_	_
93.7	_	_
10.7	_	_
30.3	_	_
Afc	_	_
50	_	_
65.6	_	_
65.2	_	_
22.7	_	_
35.0	_	_
Acj+zm+wb	_	_
346	_	_
98.5	_	_
98.3	_	_
17.0	_	_
50.5	_	_
Acj+zm+wb+fc	_	_
396	_	_
98.5	_	_
98.3	_	_
24.8	_	_
57.8	_	_
Combined	_	_
all	_	_
A	_	_
511	_	_
98.6	_	_
98.4	_	_
20.7	_	_
56.8	_	_
machine-printed	_	_
data	_	_
set	_	_
.	_	_

#279
Over	_	_
98	_	_
%	_	_
accuracies	_	_
are	_	_
achieved	_	_
on	_	_
both	_	_
models	_	_
(	_	_
with	_	_
and	_	_
without	_	_
the	_	_
machine-printed	_	_
characters	_	_
)	_	_
on	_	_
the	_	_
test	_	_
set	_	_
of	_	_
Dhifreq	_	_
.	_	_

#280
However	_	_
,	_	_
on	_	_
the	_	_
Dlofreq	_	_
data	_	_
set	_	_
,	_	_
model	_	_
trained	_	_
with	_	_
attribute	_	_
augmentation	_	_
improves	_	_
the	_	_
accuracy	_	_
from	_	_
20.7	_	_
%	_	_
to	_	_
56.8	_	_
%	_	_
.	_	_

#281
4.2.3	_	_
.	_	_

#282
Comparison	_	_
with	_	_
traditional	_	_
character	_	_
recognition	_	_
method	_	_
In	_	_
the	_	_
traditional	_	_
Chinese	_	_
character	_	_
recognition	_	_
,	_	_
each	_	_
character	_	_
is	_	_
considered	_	_
as	_	_
a	_	_
class	_	_
and	_	_
the	_	_
number	_	_
of	_	_
classes	_	_
is	_	_
same	_	_
as	_	_
the	_	_
number	_	_
of	_	_
characters	_	_
.	_	_

#283
In	_	_
order	_	_
to	_	_
compare	_	_
the	_	_
proposed	_	_
attribute	_	_
representation	_	_
with	_	_
the	_	_
traditional	_	_
one	_	_
,	_	_
we	_	_
train	_	_
a	_	_
network	_	_
which	_	_
considers	_	_
each	_	_
character	_	_
as	_	_
a	_	_
class	_	_
.	_	_

#284
This	_	_
is	_	_
named	_	_
as	_	_
Character-based	_	_
classifier	_	_
in	_	_
this	_	_
section	_	_
,	_	_
following	_	_
the	_	_
traditional	_	_
character	_	_
recognition	_	_
protocol	_	_
[	_	_
10	_	_
]	_	_
.	_	_

#285
For	_	_
fair	_	_
comparison	_	_
,	_	_
we	_	_
use	_	_
the	_	_
same	_	_
network	_	_
structure	_	_
,	_	_
except	_	_
the	_	_
last	_	_
layer	_	_
which	_	_
corresponds	_	_
to	_	_
the	_	_
number	_	_
of	_	_
characters	_	_
.	_	_

#286
The	_	_
network	_	_
is	_	_
trained	_	_
with	_	_
the	_	_
same	_	_
configuration	_	_
with	_	_
the	_	_
attribute	_	_
classifiers	_	_
.	_	_

#287
Table	_	_
7	_	_
shows	_	_
the	_	_
performance	_	_
of	_	_
the	_	_
Character-based	_	_
classifier	_	_
and	_	_
the	_	_
proposed	_	_
Attribute-based	_	_
classifier	_	_
.	_	_

#288
Since	_	_
there	_	_
is	_	_
no	_	_
example	_	_
on	_	_
Dlofreq	_	_
in	_	_
the	_	_
training	_	_
set	_	_
,	_	_
the	_	_
traditional	_	_
Character-based	_	_
classifier	_	_
can	_	_
not	_	_
be	_	_
used	_	_
to	_	_
recognize	_	_
the	_	_
character	_	_
in	_	_
Dlofreq	_	_
.	_	_

#289
On	_	_
the	_	_
Dhifreq	_	_
set	_	_
,	_	_
the	_	_
performance	_	_
of	_	_
Character-based	_	_
classifier	_	_
and	_	_
Attribute-based	_	_
classifier	_	_
is	_	_
similar	_	_
.	_	_

#290
But	_	_
the	_	_
proposed	_	_
attribute-based	_	_
classifier	_	_
can	_	_
recognize	_	_
the	_	_
characters	_	_
on	_	_
the	_	_
unseen	_	_
data	_	_
set	_	_
.	_	_

#291
Traditionally	_	_
,	_	_
when	_	_
there	_	_
is	_	_
no	_	_
sufficient	_	_
sample	_	_
for	_	_
training	_	_
,	_	_
the	_	_
nearest-neighbor	_	_
method	_	_
is	_	_
usually	_	_
used	_	_
for	_	_
recognition	_	_
,	_	_
using	_	_
features	_	_
extracted	_	_
on	_	_
the	_	_
last	_	_
layer	_	_
of	_	_
the	_	_
trained	_	_
network	_	_
on	_	_
the	_	_
large	_	_
data	_	_
set	_	_
.	_	_

#292
In	_	_
this	_	_
section	_	_
,	_	_
we	_	_
also	_	_
evaluate	_	_
the	_	_
powerful	_	_
of	_	_
features	_	_
extracted	_	_
on	_	_
the	_	_
Character-based	_	_
classifier	_	_
and	_	_
Attribute-based	_	_
classifier	_	_
on	_	_
the	_	_
Dlofreq	_	_
set	_	_
using	_	_
the	_	_
nearest	_	_
neighbor	_	_
method	_	_
.	_	_

#293
More	_	_
precisely	_	_
,	_	_
we	_	_
use	_	_
the	_	_
word	_	_
spotting	_	_
protocol	_	_
[	_	_
32	_	_
,	_	_
33	_	_
]	_	_
to	_	_
evaluate	_	_
the	_	_
efficient	_	_
of	_	_
features	_	_
extracted	_	_
from	_	_
different	_	_
classifiers	_	_
.	_	_

#294
The	_	_
word	_	_
spotting	_	_
is	_	_
similar	_	_
as	_	_
image	_	_
retrieval	_	_
,	_	_
which	_	_
retrieve	_	_
all	_	_
relevant	_	_
instances	_	_
of	_	_
user	_	_
queries	_	_
in	_	_
a	_	_
data	_	_
set	_	_
.	_	_

#295
Given	_	_
a	_	_
query	_	_
character	_	_
,	_	_
the	_	_
rest	_	_
of	_	_
characters	_	_
in	_	_
the	_	_
data	_	_
set	_	_
are	_	_
sorted	_	_
according	_	_
the	_	_
distance	_	_
(	_	_
Euclidean	_	_
distance	_	_
used	_	_
in	_	_
this	_	_
section	_	_
)	_	_
computed	_	_
between	_	_
their	_	_
features	_	_
and	_	_
the	_	_
same	_	_
characters	_	_
should	_	_
be	_	_
ranked	_	_
on	_	_
the	_	_
top	_	_
.	_	_

#296
Table	_	_
7	_	_
:	_	_
Comparison	_	_
of	_	_
accuracy	_	_
(	_	_
%	_	_
)	_	_
of	_	_
character	_	_
recognition	_	_
using	_	_
different	_	_
classifiers	_	_
.	_	_

#297
n/a	_	_
indicates	_	_
that	_	_
the	_	_
test	_	_
is	_	_
not	_	_
possible	_	_
for	_	_
this	_	_
method	_	_
.	_	_

#298
Classifier	_	_
Dhifreq	_	_
Dlofreq	_	_
Model	_	_
Model+	_	_
Character-based	_	_
classifier	_	_
[	_	_
10	_	_
]	_	_
98.3	_	_
n/a	_	_
n/a	_	_
Attribute-based	_	_
classifier	_	_
98.6	_	_
20.7	_	_
56.8	_	_
Table	_	_
8	_	_
:	_	_
The	_	_
mean	_	_
Average	_	_
Precision	_	_
(	_	_
as	_	_
a	_	_
proportion	_	_
)	_	_
of	_	_
word	_	_
spotting	_	_
with	_	_
different	_	_
features	_	_
on	_	_
the	_	_
Dlofreq	_	_
set	_	_
.	_	_

#299
Features	_	_
Model	_	_
Model+	_	_
Character-based	_	_
classifier	_	_
0.481	_	_
Apinyin+struct+Nstroke	_	_
0.607	_	_
0.547	_	_
Acj	_	_
0.753	_	_
0.768	_	_
Azm	_	_
0.739	_	_
0.740	_	_
Awb	_	_
0.749	_	_
0.744	_	_
Afc	_	_
0.720	_	_
0.725	_	_
Acj+zm+wb	_	_
0.883	_	_
0.896	_	_
Acj+zm+wb+fc	_	_
0.903	_	_
0.916	_	_
Combine	_	_
All	_	_
A	_	_
0.913	_	_
0.926	_	_
The	_	_
mean	_	_
Average	_	_
Precision	_	_
(	_	_
mAP	_	_
)	_	_
is	_	_
used	_	_
to	_	_
measure	_	_
the	_	_
performance	_	_
.	_	_

#300
Table	_	_
8	_	_
shows	_	_
the	_	_
performance	_	_
of	_	_
different	_	_
features	_	_
extracted	_	_
on	_	_
Character-based	_	_
classifier	_	_
and	_	_
Attribute-based	_	_
classifier	_	_
on	_	_
the	_	_
Dlofreq	_	_
data	_	_
set	_	_
for	_	_
word	_	_
spotting	_	_
.	_	_

#301
All	_	_
attribute-based	_	_
features	_	_
provides	_	_
better	_	_
results	_	_
than	_	_
the	_	_
feature	_	_
extracted	_	_
on	_	_
the	_	_
Character-based	_	_
classifier	_	_
since	_	_
the	_	_
Attribute-based	_	_
classifier	_	_
can	_	_
learn	_	_
information	_	_
shared	_	_
between	_	_
different	_	_
characters	_	_
and	_	_
these	_	_
learned	_	_
information	_	_
can	_	_
be	_	_
generalized	_	_
to	_	_
the	_	_
novel	_	_
character	_	_
sets	_	_
.	_	_

#302
4.2.4	_	_
.	_	_

#303
Performance	_	_
of	_	_
few-shot	_	_
learning	_	_
Since	_	_
the	_	_
performance	_	_
of	_	_
the	_	_
proposed	_	_
attribute	_	_
learning	_	_
is	_	_
not	_	_
satisfactory	_	_
and	_	_
only	_	_
56.8	_	_
%	_	_
is	_	_
achieved	_	_
on	_	_
the	_	_
Dlofreq	_	_
data	_	_
set	_	_
.	_	_

#304
we	_	_
conduct	_	_
other	_	_
experiments	_	_
with	_	_
few-shot	_	_
learning	_	_
protocol	_	_
[	_	_
34	_	_
]	_	_
:	_	_
only	_	_
k	_	_
samples	_	_
of	_	_
each	_	_
character	_	_
from	_	_
Dlofreq	_	_
are	_	_
present	_	_
in	_	_
the	_	_
training	_	_
set	_	_
,	_	_
which	_	_
is	_	_
called	_	_
k-shot	_	_
learning	_	_
.	_	_

#305
Few-shot	_	_
learning	_	_
aims	_	_
to	_	_
adapt	_	_
the	_	_
learned	_	_
information	_	_
from	_	_
a	_	_
support	_	_
data	_	_
set	_	_
which	_	_
has	_	_
sufficient	_	_
training	_	_
samples	_	_
to	_	_
new	_	_
classes	_	_
given	_	_
only	_	_
a	_	_
few	_	_
examples	_	_
.	_	_

#306
In	_	_
this	_	_
section	_	_
,	_	_
we	_	_
evaluate	_	_
the	_	_
performance	_	_
with	_	_
different	_	_
k	_	_
,	_	_
from	_	_
1	_	_
to	_	_
5	_	_
.	_	_

#307
Table	_	_
9	_	_
and	_	_
Table	_	_
10	_	_
show	_	_
the	_	_
performance	_	_
of	_	_
character	_	_
attribute	_	_
recognition	_	_
and	_	_
character	_	_
recognition	_	_
by	_	_
attributes	_	_
with	_	_
few-shot	_	_
learning	_	_
,	_	_
respectively	_	_
.	_	_

#308
From	_	_
these	_	_
two	_	_
tables	_	_
we	_	_
can	_	_
see	_	_
that	_	_
the	_	_
performance	_	_
of	_	_
both	_	_
attribute	_	_
and	_	_
character	_	_
recognition	_	_
increases	_	_
significantly	_	_
when	_	_
more	_	_
samples	_	_
are	_	_
present	_	_
in	_	_
the	_	_
training	_	_
set	_	_
.	_	_

#309
For	_	_
character	_	_
recognition	_	_
by	_	_
attributes	_	_
,	_	_
training	_	_
with	_	_
only	_	_
one	_	_
sample	_	_
on	_	_
the	_	_
Dlofreq	_	_
set	_	_
improves	_	_
the	_	_
accuracy	_	_
from	_	_
20.7	_	_
%	_	_
to	_	_
70.6	_	_
%	_	_
.	_	_

#310
If	_	_
five	_	_
samples	_	_
are	_	_
available	_	_
for	_	_
each	_	_
character	_	_
,	_	_
accuracy	_	_
is	_	_
95.1	_	_
%	_	_
.	_	_

#311
Generally	_	_
,	_	_
the	_	_
model	_	_
Table	_	_
9	_	_
:	_	_
Accuracy	_	_
(	_	_
%	_	_
)	_	_
of	_	_
character	_	_
attribute	_	_
recognition	_	_
with	_	_
few-shot	_	_
learning	_	_
on	_	_
the	_	_
Dlofreq	_	_
set	_	_
.	_	_

#312
Attributes	_	_
Dims	_	_
0-shot	_	_
1-shot	_	_
2-shot	_	_
3-shot	_	_
4-shot	_	_
5-shot	_	_
Model	_	_
Model+	_	_
Model	_	_
Model+	_	_
Model	_	_
Model+	_	_
Model	_	_
Model+	_	_
Model	_	_
Model+	_	_
Model	_	_
Model+	_	_
Pinyin	_	_
Ai	_	_
pinyin	_	_
26	_	_
17.1	_	_
33.8	_	_
44.2	_	_
70.8	_	_
60.8	_	_
78.6	_	_
70.3	_	_
82.7	_	_
76.8	_	_
86.5	_	_
82.8	_	_
88.1	_	_
Af	_	_
pinyin	_	_
38	_	_
26.9	_	_
44.6	_	_
50.2	_	_
75.5	_	_
61.5	_	_
81.7	_	_
70.8	_	_
84.4	_	_
78.4	_	_
88.4	_	_
85.3	_	_
89.9	_	_
At	_	_
pinyin	_	_
5	_	_
32.3	_	_
45.9	_	_
57.7	_	_
74.8	_	_
69.4	_	_
80.8	_	_
76.7	_	_
85.3	_	_
82.1	_	_
87.7	_	_
86.8	_	_
89.8	_	_
Structure	_	_
Astruct	_	_
15	_	_
85.6	_	_
88.7	_	_
88.4	_	_
93.3	_	_
91.7	_	_
94.9	_	_
92.7	_	_
95.3	_	_
94.2	_	_
96.2	_	_
95.4	_	_
96.9	_	_
Stroke	_	_
ANstroke	_	_
31	_	_
18.5	_	_
32.5	_	_
45.0	_	_
64.6	_	_
58.8	_	_
75.4	_	_
66.5	_	_
80.7	_	_
76.5	_	_
84.4	_	_
83.3	_	_
87.2	_	_
Cangjie	_	_
A1	_	_
cj	_	_
26	_	_
76.8	_	_
84.5	_	_
86.2	_	_
92.2	_	_
89.7	_	_
93.2	_	_
91.9	_	_
94.0	_	_
93.4	_	_
95.1	_	_
95.1	_	_
96.2	_	_
A2	_	_
cj	_	_
27	_	_
44.2	_	_
62.5	_	_
63.3	_	_
81.9	_	_
73.4	_	_
85.9	_	_
79.8	_	_
87.9	_	_
83.7	_	_
89.9	_	_
87.6	_	_
91.3	_	_
A3	_	_
cj	_	_
27	_	_
36.4	_	_
53.1	_	_
59.0	_	_
77.4	_	_
69.7	_	_
81.7	_	_
77.1	_	_
85.7	_	_
81.5	_	_
87.6	_	_
85.1	_	_
89.9	_	_
A4	_	_
cj	_	_
27	_	_
49.9	_	_
64.9	_	_
65.4	_	_
83.3	_	_
73.2	_	_
87.3	_	_
78.6	_	_
90.4	_	_
83.6	_	_
91.8	_	_
87.5	_	_
92.8	_	_
A5	_	_
cj	_	_
27	_	_
80.9	_	_
87.3	_	_
87.1	_	_
94.4	_	_
90.8	_	_
95.5	_	_
92.1	_	_
95.8	_	_
94.1	_	_
96.2	_	_
94.9	_	_
96.5	_	_
Zhengma	_	_
A1	_	_
zm	_	_
26	_	_
73.7	_	_
81.0	_	_
85.5	_	_
92.2	_	_
89.4	_	_
93.3	_	_
91.5	_	_
94.6	_	_
94.3	_	_
95.4	_	_
95.5	_	_
95.9	_	_
A2	_	_
zm	_	_
26	_	_
47.3	_	_
64.4	_	_
68.6	_	_
83.4	_	_
76.0	_	_
86.9	_	_
82.5	_	_
88.3	_	_
86.2	_	_
90.6	_	_
89.7	_	_
91.9	_	_
A3	_	_
zm	_	_
26	_	_
33.9	_	_
54.8	_	_
58.7	_	_
80.8	_	_
69.6	_	_
85.3	_	_
75.2	_	_
87.5	_	_
82.5	_	_
90.0	_	_
86.8	_	_
91.5	_	_
A4	_	_
zm	_	_
27	_	_
47.2	_	_
63.4	_	_
69.1	_	_
83.4	_	_
76.3	_	_
87.1	_	_
82.1	_	_
89.6	_	_
86.1	_	_
90.5	_	_
88.9	_	_
91.9	_	_
Wubi	_	_
A1	_	_
wb	_	_
26	_	_
71.9	_	_
80.2	_	_
83.2	_	_
91.1	_	_
87.3	_	_
92.5	_	_
90.5	_	_
93.7	_	_
92.9	_	_
94.8	_	_
94.9	_	_
95.4	_	_
A2	_	_
wb	_	_
26	_	_
39.5	_	_
58.4	_	_
62.8	_	_
80.6	_	_
72.7	_	_
84.7	_	_
79.5	_	_
87.3	_	_
83.9	_	_
89.4	_	_
87.5	_	_
91.2	_	_
A3	_	_
wb	_	_
26	_	_
34.1	_	_
51.1	_	_
56.8	_	_
77.2	_	_
68.1	_	_
82.6	_	_
76.0	_	_
85.2	_	_
82.0	_	_
88.5	_	_
85.7	_	_
90.4	_	_
A4	_	_
wb	_	_
27	_	_
51.1	_	_
67.0	_	_
71.3	_	_
84.5	_	_
78.6	_	_
88.5	_	_
83.3	_	_
91.2	_	_
87.4	_	_
92.6	_	_
90.2	_	_
93.3	_	_
Four-Corner	_	_
A1	_	_
fc	_	_
10	_	_
83.7	_	_
87.9	_	_
90.3	_	_
93.2	_	_
92.9	_	_
94.5	_	_
94.3	_	_
95.5	_	_
95.5	_	_
95.8	_	_
96.1	_	_
96.1	_	_
A2	_	_
fc	_	_
10	_	_
70.7	_	_
80.6	_	_
84.0	_	_
91.1	_	_
88.2	_	_
92.5	_	_
91.1	_	_
93.5	_	_
93.1	_	_
94.2	_	_
94.1	_	_
95.3	_	_
A3	_	_
fc	_	_
10	_	_
82.2	_	_
87.3	_	_
87.5	_	_
93.1	_	_
89.8	_	_
94.0	_	_
92.7	_	_
94.6	_	_
93.6	_	_
95.7	_	_
95.1	_	_
95.8	_	_
A4	_	_
fc	_	_
10	_	_
82.6	_	_
88.4	_	_
89.7	_	_
93.9	_	_
91.9	_	_
94.9	_	_
93.9	_	_
95.4	_	_
94.7	_	_
95.7	_	_
95.7	_	_
96.3	_	_
A5	_	_
fc	_	_
10	_	_
71.4	_	_
79.9	_	_
82.6	_	_
91.2	_	_
87.1	_	_
92.5	_	_
89.0	_	_
94.0	_	_
91.4	_	_
94.5	_	_
93.2	_	_
95.3	_	_
Table	_	_
10	_	_
:	_	_
Accuracy	_	_
(	_	_
%	_	_
)	_	_
of	_	_
character	_	_
recognition	_	_
by	_	_
attributes	_	_
with	_	_
few-shot	_	_
learning	_	_
on	_	_
the	_	_
Dlofreq	_	_
set	_	_
.	_	_

#313
Classifier	_	_
Dims	_	_
0-shot	_	_
1-shot	_	_
2-shot	_	_
3-shot	_	_
4-shot	_	_
5-shot	_	_
Model	_	_
Model+	_	_
Model	_	_
Model+	_	_
Model	_	_
Model+	_	_
Model	_	_
Model+	_	_
Model	_	_
Model+	_	_
Model	_	_
Model+	_	_
Apinyin+struct+Nstroke	_	_
115	_	_
0.9	_	_
4.8	_	_
10.9	_	_
36.4	_	_
24.1	_	_
48.3	_	_
34.5	_	_
55	_	_
.	_	_

#314
8	_	_
46.4	_	_
61.1	_	_
56.8	_	_
65.7	_	_
Acj	_	_
134	_	_
10.6	_	_
33.2	_	_
36.2	_	_
66.7	_	_
49.9	_	_
72.6	_	_
62.2	_	_
77.7	_	_
68.9	_	_
80.5	_	_
76.3	_	_
83.6	_	_
Azm	_	_
105	_	_
11.5	_	_
31.0	_	_
38.5	_	_
64.4	_	_
50.7	_	_
70.9	_	_
60.2	_	_
75.5	_	_
69.3	_	_
78.8	_	_
75.5	_	_
81.3	_	_
Awb	_	_
107	_	_
9.9	_	_
30.2	_	_
35.6	_	_
62.7	_	_
50.1	_	_
70.1	_	_
60.6	_	_
74.0	_	_
68.4	_	_
77.3	_	_
73.9	_	_
80.0	_	_
Afc	_	_
50	_	_
21.9	_	_
33.6	_	_
38.9	_	_
49.4	_	_
44.4	_	_
52.5	_	_
49.0	_	_
55.1	_	_
52.4	_	_
56.2	_	_
55.1	_	_
57.6	_	_
Acj+zm+wb	_	_
346	_	_
16.7	_	_
49.9	_	_
61.3	_	_
83.7	_	_
77.2	_	_
87.8	_	_
85.1	_	_
90.9	_	_
89.8	_	_
92.6	_	_
92.9	_	_
93.7	_	_
Acj+zm+wb+fc	_	_
396	_	_
25.7	_	_
58.2	_	_
69.8	_	_
85.4	_	_
81.9	_	_
89.6	_	_
88.3	_	_
92.1	_	_
91.7	_	_
93.3	_	_
93.8	_	_
94.5	_	_
Combined	_	_
all	_	_
A	_	_
511	_	_
20.7	_	_
56.6	_	_
70.6	_	_
86.4	_	_
83.7	_	_
90.3	_	_
89.5	_	_
92.7	_	_
93.1	_	_
94.2	_	_
95.1	_	_
94.9	_	_
trained	_	_
with	_	_
attribute	_	_
augmentation	_	_
provides	_	_
better	_	_
results	_	_
for	_	_
both	_	_
attribute	_	_
and	_	_
character	_	_
recognition	_	_
.	_	_

#315
We	_	_
found	_	_
that	_	_
fine	_	_
tuning	_	_
a	_	_
traditional	_	_
character-based	_	_
neural	_	_
classifier	_	_
on	_	_
the	_	_
Dlofreq	_	_
set	_	_
by	_	_
adding	_	_
output	_	_
units	_	_
and	_	_
training	_	_
on	_	_
such	_	_
a	_	_
small	_	_
number	_	_
of	_	_
samples	_	_
will	_	_
not	_	_
help	_	_
:	_	_
There	_	_
is	_	_
a	_	_
severe	_	_
underfit	_	_
and	_	_
the	_	_
performance	_	_
is	_	_
close	_	_
to	_	_
zero	_	_
.	_	_

#316
In	_	_
contrast	_	_
,	_	_
attribute-based	_	_
classifiers	_	_
have	_	_
a	_	_
good	_	_
generalization	_	_
to	_	_
new	_	_
characters	_	_
,	_	_
if	_	_
just	_	_
a	_	_
few	_	_
samples	_	_
are	_	_
available	_	_
for	_	_
training	_	_
.	_	_

#317
4.3	_	_
.	_	_

#318
Performance	_	_
on	_	_
the	_	_
closed	_	_
handwritten	_	_
Chinese	_	_
data	_	_
set	_	_
In	_	_
this	_	_
section	_	_
,	_	_
we	_	_
also	_	_
conduct	_	_
experiments	_	_
on	_	_
offline	_	_
handwritten	_	_
HWDB1.1	_	_
data	_	_
set	_	_
[	_	_
1	_	_
]	_	_
.	_	_

#319
Table	_	_
11	_	_
shows	_	_
the	_	_
performance	_	_
of	_	_
attribute	_	_
recognition	_	_
on	_	_
the	_	_
test	_	_
set	_	_
of	_	_
the	_	_
HWDB1.1	_	_
data	_	_
set	_	_
.	_	_

#320
Generally	_	_
,	_	_
the	_	_
performance	_	_
of	_	_
attribute	_	_
recognition	_	_
is	_	_
around	_	_
95	_	_
%	_	_
,	_	_
which	_	_
indicates	_	_
that	_	_
the	_	_
deep	_	_
network	_	_
can	_	_
also	_	_
learn	_	_
attributes	_	_
on	_	_
the	_	_
handwritten	_	_
Chinese	_	_
characters	_	_
.	_	_

#321
Table	_	_
12	_	_
provides	_	_
the	_	_
accuracy	_	_
of	_	_
character	_	_
recognition	_	_
and	_	_
the	_	_
best	_	_
result	_	_
is	_	_
achieved	_	_
by	_	_
using	_	_
all	_	_
attributes	_	_
.	_	_

#322
Our	_	_
proposed	_	_
attribute-based	_	_
classifier	_	_
provides	_	_
lower	_	_
than	_	_
the	_	_
human	_	_
performance	_	_
and	_	_
state-of-the-art	_	_
because	_	_
attribute-based	_	_
neural	_	_
network	_	_
learns	_	_
the	_	_
detailed	_	_
information	_	_
on	_	_
the	_	_
characters	_	_
,	_	_
which	_	_
is	_	_
very	_	_
difficult	_	_
on	_	_
the	_	_
handwritten	_	_
characters	_	_
,	_	_
especially	_	_
on	_	_
the	_	_
similar	_	_
characters	_	_
which	_	_
might	options	_
have	_	_
only	_	_
one	_	_
stroke	_	_
difference	_	_
.	_	_

#323
Fig.	_	_
11	_	_
shows	_	_
some	_	_
failure	_	_
predictions	_	_
of	_	_
our	_	_
approach	_	_
.	_	_

#324
As	_	_
can	_	_
be	_	_
seen	_	_
,	_	_
the	_	_
recognized	_	_
characters	_	_
by	_	_
the	_	_
proposed	_	_
method	_	_
are	_	_
very	_	_
similar	_	_
to	_	_
the	_	_
ground	_	_
truth	_	_
.	_	_

#325
In	_	_
fact	_	_
,	_	_
most	_	_
of	_	_
them	_	_
are	_	_
of	_	_
similar	_	_
appearance	_	_
and	_	_
they	_	_
share	_	_
common	_	_
radicals	_	_
,	_	_
which	_	_
corresponds	_	_
to	_	_
the	_	_
similar-handwritten	_	_
Chinese	_	_
character	_	_
recognition	_	_
problem	_	_
[	_	_
18	_	_
,	_	_
9	_	_
]	_	_
.	_	_

#326
Therefore	_	_
,	_	_
our	_	_
proposed	_	_
method	_	_
can	_	_
find	_	_
the	_	_
similar	_	_
characters	_	_
and	_	_
they	_	_
may	_	_
be	_	_
recognized	_	_
correctly	_	_
by	_	_
applying	_	_
a	_	_
post-hoc	_	_
language	_	_
model	_	_
[	_	_
35	_	_
]	_	_
.	_	_

#327
5	_	_
.	_	_

#328
Conclusion	_	_
In	_	_
this	_	_
paper	_	_
,	_	_
we	_	_
propose	_	_
a	_	_
novel	_	_
method	_	_
for	_	_
Chinese	_	_
character	_	_
recognition	_	_
by	_	_
multi-typed	_	_
attributes	_	_
.	_	_

#329
The	_	_
attributes	_	_
are	_	_
collected	_	_
based	_	_
on	_	_
the	_	_
pronunciation	_	_
,	_	_
character	_	_
structures	_	_
and	_	_
strokes	_	_
,	_	_
three	_	_
typing	_	_
methods	_	_
which	_	_
decompose	_	_
Chinese	_	_
characters	_	_
based	_	_
on	_	_
their	_	_
radicals	_	_
.	_	_

#330
We	_	_
evaluated	_	_
our	_	_
attribute-based	_	_
recognition	_	_
on	_	_
the	_	_
machine-printed	_	_
Chinese	_	_
characters	_	_
with	_	_
zero-shot	_	_
learning	_	_
:	_	_
Attributes	_	_
of	_	_
characters	_	_
are	_	_
learned	_	_
on	_	_
the	_	_
training	_	_
set	_	_
and	_	_
evaluated	_	_
on	_	_
an	_	_
unseen	_	_
character	_	_
set	_	_
.	_	_

#331
The	_	_
results	_	_
show	_	_
that	_	_
our	_	_
proposed	_	_
method	_	_
can	_	_
recognize	_	_
Figure	_	_
11	_	_
:	_	_
Failure	_	_
examples	_	_
of	_	_
character	_	_
recognition	_	_
on	_	_
the	_	_
HDBW1.1	_	_
data	_	_
set	_	_
.	_	_

#332
The	_	_
characters	_	_
in	_	_
the	_	_
green	_	_
boxes	_	_
are	_	_
the	_	_
ground-truth	_	_
while	_	_
characters	_	_
in	_	_
the	_	_
red	_	_
boxes	_	_
are	_	_
the	_	_
corresponding	_	_
recognized	_	_
characters	_	_
.	_	_

#333
characters	_	_
which	_	_
are	_	_
not	_	_
in	_	_
the	_	_
training	_	_
set	_	_
.	_	_

#334
In	_	_
addition	_	_
,	_	_
we	_	_
also	_	_
tested	_	_
the	_	_
proposed	_	_
method	_	_
on	_	_
the	_	_
unbalanced	_	_
historical	_	_
books	_	_
,	_	_
using	_	_
zero-shot	_	_
and	_	_
few-shot	_	_
learning	_	_
.	_	_

#335
Results	_	_
show	_	_
that	_	_
in	_	_
this	_	_
real-world	_	_
application	_	_
with	_	_
a	_	_
limited	_	_
number	_	_
of	_	_
characters	_	_
,	_	_
the	_	_
few-shot	_	_
learning	_	_
provides	_	_
quite	_	_
a	_	_
good	_	_
performance	_	_
up	_	_
to	_	_
≈95	_	_
%	_	_
accuracy	_	_
for	_	_
5-shot	_	_
training	_	_
.	_	_

#336
This	_	_
compares	_	_
well	_	_
with	_	_
the	_	_
98	_	_
%	_	_
accuracy	_	_
obtained	_	_
for	_	_
high-frequent	_	_
characters	_	_
.	_	_

#337
Finally	_	_
,	_	_
the	_	_
results	_	_
on	_	_
hand-written	_	_
Chinese	_	_
characters	_	_
have	_	_
been	_	_
reported	_	_
.	_	_

#338
Our	_	_
proposed	_	_
method	_	_
can	_	_
find	_	_
the	_	_
similar	_	_
and	_	_
confused	_	_
characters	_	_
,	_	_
at	_	_
a	_	_
performance	_	_
level	_	_
that	_	_
is	_	_
only	_	_
3.7	_	_
%	_	_
lower	_	_
than	_	_
dedicated	_	_
state	_	_
of	_	_
the	_	_
art	_	_
methods	_	_
but	_	_
does	_	_
not	_	_
impose	_	_
any	_	_
strict	_	_
limitation	_	_
on	_	_
the	_	_
size	_	_
of	_	_
the	_	_
character	_	_
set	_	_
.	_	_

#339
Our	_	_
proposed	_	_
method	_	_
is	_	_
very	_	_
useful	_	_
for	_	_
bootstrapping	_	_
a	_	_
system	_	_
,	_	_
such	_	_
as	_	_
the	_	_
Monk	_	_
[	_	_
21	_	_
,	_	_
36	_	_
]	_	_
,	_	_
for	_	_
word	_	_
recognition	_	_
in	_	_
Chinese	_	_
historical	_	_
documents	_	_
.	_	_

#340
The	_	_
attribute	_	_
classifiers	_	_
can	_	_
be	_	_
trained	_	_
on	_	_
a	_	_
rich	_	_
data	_	_
set	_	_
and	_	_
then	_	_
generalize	_	_
to	_	_
the	_	_
unseen	_	_
set	_	_
which	_	_
might	_	_
have	_	_
zero	_	_
or	_	_
a	_	_
few	_	_
samples	_	_
.	_	_

#341
Acknowledgments	_	_
This	_	_
work	_	_
has	_	_
been	_	_
supported	_	_
by	_	_
the	_	_
Dutch	_	_
Organization	_	_
for	_	_
Scientific	_	_
Research	_	_
NWO	_	_
and	_	_
DiD	_	_
Global	_	_
Currents	_	_
(	_	_
Project	_	_
no.	_	_
640.006.015	_	_
)	_	_
.	_	_

#342
Appendix	_	_
A	_	_
.	_	_

#343
Character	_	_
Segmentation	_	_
The	_	_
segmentation	_	_
method	_	_
used	_	_
in	_	_
this	_	_
paper	_	_
for	_	_
Chinese	_	_
character	_	_
segmentation	_	_
in	_	_
historical	_	_
books	_	_
consists	_	_
of	_	_
three	_	_
main	_	_
steps	_	_
:	_	_
Text	_	_
line	_	_
detection	_	_
which	_	_
aims	_	_
to	_	_
extract	_	_
vertical	_	_
text	_	_
lines	_	_
and	_	_
remove	_	_
table	_	_
lines	_	_
in	_	_
the	_	_
document	_	_
images	_	_
,	_	_
skew	_	_
correction	_	_
which	_	_
can	_	_
detect	_	_
and	_	_
correct	_	_
the	_	_
small	_	_
skew	_	_
angle	_	_
and	_	_
character	_	_
boxes	_	_
detection	_	_
based	_	_
on	_	_
the	_	_
detected	_	_
text	_	_
lines	_	_
.	_	_

#344
The	_	_
detailed	_	_
description	_	_
of	_	_
these	_	_
three	_	_
steps	_	_
is	_	_
provided	_	_
in	_	_
the	_	_
following	_	_
sections	_	_
.	_	_

#345
Appendix	_	_
A.1	_	_
.	_	_

#346
Text	_	_
line	_	_
detection	_	_
in	_	_
historical	_	_
document	_	_
images	_	_
Most	_	_
line-extraction	_	_
methods	_	_
use	_	_
a	_	_
projection	_	_
profile	_	_
of	_	_
pixels	_	_
or	_	_
edges	_	_
to	_	_
detect	_	_
text	_	_
components	_	_
along	_	_
line	_	_
text	_	_
[	_	_
37	_	_
,	_	_
38	_	_
]	_	_
.	_	_

#347
This	_	_
method	_	_
does	_	_
not	_	_
work	_	_
properly	_	_
in	_	_
our	_	_
data	_	_
set	_	_
.	_	_

#348
As	_	_
shown	_	_
in	_	_
Fig.	_	_
2	_	_
,	_	_
most	_	_
documents	_	_
in	_	_
our	_	_
dataset	_	_
have	_	_
table	_	_
lines	_	_
and	_	_
a	_	_
small	_	_
skew	_	_
angle	_	_
,	_	_
which	_	_
brings	_	_
a	_	_
large	_	_
noise	_	_
to	_	_
text	_	_
line	_	_
detection	_	_
based	_	_
on	_	_
project	_	_
profiles	_	_
.	_	_

#349
Instead	_	_
of	_	_
using	_	_
the	_	_
ink-pixel	_	_
project	_	_
profiles	_	_
,	_	_
we	_	_
use	_	_
the	_	_
run-length	_	_
based	_	_
method	_	_
to	_	_
detection	_	_
text	_	_
lines	_	_
due	_	_
to	_	_
the	_	_
fact	_	_
that	_	_
on	_	_
the	_	_
text	_	_
line	_	_
the	_	_
average	_	_
run-length	_	_
of	_	_
the	_	_
white	_	_
pixel	_	_
is	_	_
usually	_	_
small	_	_
[	_	_
39	_	_
]	_	_
and	_	_
there	_	_
is	_	_
only	_	_
several	_	_
white	_	_
run-length	_	_
on	_	_
background	_	_
and	_	_
no	_	_
white	_	_
run-length	_	_
on	_	_
table	_	_
lines	_	_
.	_	_

#350
The	_	_
input	_	_
is	_	_
a	_	_
binarized	_	_
image	_	_
with	_	_
the	_	_
size	_	_
(	_	_
w	_	_
,	_	_
h	_	_
)	_	_
where	_	_
w	_	_
is	_	_
the	_	_
width	_	_
and	_	_
h	_	_
is	_	_
the	_	_
height	_	_
.	_	_

#351
For	_	_
each	_	_
vertical	_	_
line	_	_
y	_	_
,	_	_
the	_	_
mean	_	_
run-length	_	_
of	_	_
the	_	_
white	_	_
pixel	_	_
m	_	_
(	_	_
x	_	_
)	_	_
is	_	_
computed	_	_
by	_	_
:	_	_
m	_	_
(	_	_
y	_	_
)	_	_
=	_	_
{	_	_
∑	_	_
i	_	_
rl	_	_
(	_	_
y	_	_
)	_	_
/N	_	_
if	_	_
N	_	_
≥	_	_
t	_	_
h	_	_
if	_	_
N	_	_
≤	_	_
t	_	_
(	_	_
A.1	_	_
)	_	_
where	_	_
rl	_	_
(	_	_
y	_	_
)	_	_
is	_	_
the	_	_
run-length	_	_
of	_	_
the	_	_
white	_	_
pixel	_	_
on	_	_
the	_	_
vertical	_	_
line	_	_
y	_	_
and	_	_
N	_	_
is	_	_
the	_	_
number	_	_
of	_	_
the	_	_
run-length	_	_
.	_	_

#352
In	_	_
order	_	_
to	_	_
remove	_	_
the	_	_
noise	_	_
,	_	_
the	_	_
mean	_	_
run-length	_	_
is	_	_
set	_	_
to	_	_
the	_	_
height	_	_
of	_	_
image	_	_
h	_	_
if	_	_
the	_	_
number	_	_
of	_	_
run-length	_	_
is	_	_
less	_	_
than	_	_
a	_	_
threshold	_	_
t.	_	_
In	_	_
practice	_	_
,	_	_
we	_	_
found	_	_
that	_	_
t	_	_
=	_	_
7	_	_
works	_	_
best	_	_
in	_	_
our	_	_
data	_	_
set	_	_
.	_	_

#353
Fig.	_	_
A.12	_	_
(	_	_
b	_	_
)	_	_
shows	_	_
an	_	_
example	_	_
of	_	_
the	_	_
mean	_	_
run-length	_	_
distribution	_	_
,	_	_
from	_	_
which	_	_
we	_	_
can	_	_
find	_	_
that	_	_
on	_	_
text	_	_
lines	_	_
the	_	_
value	_	_
of	_	_
m	_	_
(	_	_
y	_	_
)	_	_
is	_	_
very	_	_
small	_	_
and	_	_
on	_	_
the	_	_
background	_	_
the	_	_
value	_	_
of	_	_
m	_	_
(	_	_
y	_	_
)	_	_
is	_	_
very	_	_
large	_	_
.	_	_

#354
Therefore	_	_
,	_	_
text	_	_
lines	_	_
can	_	_
be	_	_
found	_	_
when	_	_
the	_	_
m	_	_
(	_	_
y	_	_
)	_	_
is	_	_
less	_	_
than	_	_
a	_	_
threshold	_	_
which	_	_
can	_	_
be	_	_
roughly	_	_
set	_	_
to	_	_
h/4	_	_
and	_	_
the	_	_
rest	_	_
of	_	_
lines	_	_
are	_	_
set	_	_
to	_	_
background	_	_
lines	_	_
(	_	_
which	_	_
are	_	_
shown	_	_
as	_	_
red	_	_
lines	_	_
in	_	_
Fig.	_	_
A.12	_	_
(	_	_
c	_	_
)	_	_
)	_	_
.	_	_

#355
After	_	_
that	_	_
,	_	_
due	_	_
to	_	_
table	_	_
lines	_	_
and	_	_
noise	_	_
on	_	_
the	_	_
input	_	_
image	_	_
,	_	_
there	_	_
are	_	_
some	_	_
small	_	_
gaps	_	_
between	_	_
the	_	_
background	_	_
lines	_	_
and	_	_
they	_	_
are	_	_
removed	_	_
.	_	_

#356
Fig.	_	_
A.12	_	_
(	_	_
c	_	_
)	_	_
shows	_	_
the	_	_
detected	_	_
text	_	_
lines	_	_
and	_	_
background	_	_
lines	_	_
.	_	_

#357
Appendix	_	_
A.2	_	_
.	_	_

#358
Skew	_	_
correction	_	_
As	_	_
mentioned	_	_
before	_	_
,	_	_
most	_	_
images	_	_
in	_	_
our	_	_
data	_	_
set	_	_
have	_	_
a	_	_
small	_	_
skew	_	_
angle	_	_
and	_	_
the	_	_
skew	_	_
angles	_	_
are	_	_
variable	_	_
between	_	_
different	_	_
pages	_	_
.	_	_

#359
Our	_	_
text	_	_
line	_	_
detection	_	_
method	_	_
proposed	_	_
on	_	_
the	_	_
above	_	_
section	_	_
works	_	_
very	_	_
well	_	_
on	_	_
images	_	_
without	_	_
skew	_	_
angles	_	_
,	_	_
which	_	_
provides	_	_
the	_	_
smallest	_	_
sum	_	_
of	_	_
all	_	_
text	_	_
line	_	_
width	_	_
or	_	_
largest	_	_
sum	_	_
of	_	_
background	_	_
line	_	_
width	_	_
.	_	_

#360
However	_	_
,	_	_
when	_	_
a	_	_
skew	_	_
angle	_	_
is	_	_
introduced	_	_
,	_	_
the	_	_
width	_	_
of	_	_
each	_	_
text	_	_
line	_	_
is	_	_
increasing	_	_
and	_	_
the	_	_
width	_	_
of	_	_
the	_	_
background	_	_
lines	_	_
is	_	_
decreasing	_	_
.	_	_

#361
(	_	_
a	_	_
)	_	_
(	_	_
b	_	_
)	_	_
(	_	_
c	_	_
)	_	_
Figure	_	_
A.12	_	_
:	_	_
Examples	_	_
of	_	_
the	_	_
proposed	_	_
text	_	_
line	_	_
detection	_	_
.	_	_

#362
(	_	_
a	_	_
)	_	_
the	_	_
input	_	_
image	_	_
;	_	_
(	_	_
b	_	_
)	_	_
the	_	_
red	_	_
lines	_	_
are	_	_
the	_	_
mean	_	_
run-length	_	_
of	_	_
white	_	_
pixel	_	_
computed	_	_
by	_	_
Eq.	_	_
A.1	_	_
;	_	_
(	_	_
c	_	_
)	_	_
text	_	_
lines	_	_
and	_	_
background	_	_
lines	_	_
(	_	_
red	_	_
lines	_	_
)	_	_
.	_	_

#363
In	_	_
this	_	_
paper	_	_
,	_	_
we	_	_
compute	_	_
the	_	_
sum	_	_
width	_	_
of	_	_
background	_	_
lines	_	_
in	_	_
five	_	_
different	_	_
angles	_	_
:	_	_
{	_	_
−1	_	_
,	_	_
−0.5	_	_
,	_	_
0	_	_
,	_	_
0.5	_	_
,	_	_
1	_	_
}	_	_
to	_	_
estimate	_	_
the	_	_
skew	_	_
angle	_	_
leading	_	_
to	_	_
the	_	_
largest	_	_
width	_	_
of	_	_
background	_	_
lines	_	_
and	_	_
the	_	_
image	_	_
is	_	_
subsequently	_	_
rotated	_	_
to	_	_
correct	_	_
the	_	_
skew	_	_
angle	_	_
.	_	_

#364
Appendix	_	_
A.3	_	_
.	_	_

#365
Character	_	_
segmentation	_	_
Given	_	_
each	_	_
text	_	_
line	_	_
,	_	_
we	_	_
first	_	_
remove	_	_
these	_	_
rows	_	_
where	_	_
all	_	_
pixels	_	_
are	_	_
white	_	_
or	_	_
black	_	_
pixels	_	_
.	_	_

#366
Then	_	_
the	_	_
candidate	_	_
boxes	_	_
are	_	_
obtained	_	_
based	_	_
on	_	_
ink	_	_
connected	_	_
components	_	_
and	_	_
an	_	_
example	_	_
is	_	_
shown	_	_
in	_	_
Fig.	_	_
A.13	_	_
(	_	_
a	_	_
)	_	_
.	_	_

#367
From	_	_
the	_	_
figure	_	_
we	_	_
can	_	_
see	_	_
that	_	_
some	_	_
boxes	_	_
contain	_	_
the	_	_
whole	_	_
character	_	_
,	_	_
some	_	_
boxes	_	_
are	_	_
small	_	_
,	_	_
containing	_	_
only	_	_
a	_	_
part	_	_
of	_	_
characters	_	_
and	_	_
some	_	_
are	_	_
large	_	_
,	_	_
covering	_	_
several	_	_
characters	_	_
.	_	_

#368
Based	_	_
on	_	_
the	_	_
fact	_	_
that	_	_
the	_	_
region	_	_
of	_	_
an	_	_
entire	_	_
Chinese	_	_
character	_	_
is	_	_
approximately	_	_
rectangular	_	_
,	_	_
we	_	_
use	_	_
the	_	_
ratio	_	_
between	_	_
the	_	_
width	_	_
and	_	_
height	_	_
of	_	_
a	_	_
box	_	_
to	_	_
detect	_	_
exceptions	_	_
.	_	_

#369
The	_	_
ratio	_	_
r	_	_
(	_	_
b	_	_
)	_	_
of	_	_
each	_	_
candidated	_	_
box	_	_
b	_	_
between	_	_
the	_	_
width	_	_
and	_	_
height	_	_
is	_	_
computed	_	_
by	_	_
:	_	_
r	_	_
(	_	_
b	_	_
)	_	_
=	_	_
min	_	_
(	_	_
wb	_	_
,	_	_
hb	_	_
)	_	_
max	_	_
(	_	_
wb	_	_
,	_	_
hb	_	_
)	_	_
(	_	_
A.2	_	_
)	_	_
where	_	_
wb	_	_
,	_	_
hb	_	_
are	_	_
the	_	_
width	_	_
and	_	_
height	_	_
of	_	_
the	_	_
box	_	_
b	_	_
,	_	_
respectively	_	_
.	_	_

#370
We	_	_
use	_	_
two	_	_
sets	_	_
:	_	_
the	_	_
set	_	_
C	_	_
which	_	_
is	_	_
used	_	_
to	_	_
keep	_	_
all	_	_
the	_	_
segmented	_	_
character	_	_
boxes	_	_
and	_	_
it	_	_
is	_	_
empty	_	_
at	_	_
the	_	_
beginning	_	_
and	_	_
the	_	_
set	_	_
R	_	_
which	_	_
contains	_	_
all	_	_
the	_	_
candidated	_	_
boxes	_	_
.	_	_

#371
Our	_	_
goal	_	_
is	_	_
to	_	_
select	_	_
the	_	_
boxes	_	_
which	_	_
contain	_	_
the	_	_
entire	_	_
characters	_	_
from	_	_
the	_	_
candidated	_	_
set	_	_
R	_	_
to	_	_
the	_	_
set	_	_
C.	_	_
The	_	_
box	_	_
of	_	_
each	_	_
Chinese	_	_
character	_	_
is	_	_
approximately	_	_
to	_	_
a	_	_
rectangle	_	_
,	_	_
whose	_	_
ratio	_	_
r	_	_
(	_	_
b	_	_
)	_	_
is	_	_
approximately	_	_
equal	_	_
to	_	_
1	_	_
.	_	_

#372
Based	_	_
on	_	_
this	_	_
fact	_	_
,	_	_
our	_	_
proposed	_	_
character	_	_
segmentation	_	_
method	_	_
mainly	_	_
contains	_	_
several	_	_
steps	_	_
as	_	_
following	_	_
:	_	_

#373
Step	_	_
1	_	_
:	_	_
boxes	_	_
in	_	_
the	_	_
set	_	_
R	_	_
whose	_	_
ratio	_	_
r	_	_
(	_	_
b	_	_
)	_	_
is	_	_
greater	_	_
than	_	_
0.8	_	_
contains	_	_
the	_	_
entire	_	_
Chinese	_	_
characters	_	_
and	_	_
they	_	_
are	_	_
directly	_	_
moved	_	_
from	_	_
R	_	_
to	_	_
C	_	_
;	_	_
Step	_	_
2	_	_
:	_	_
the	_	_
average	_	_
height	_	_
mh	_	_
of	_	_
the	_	_
character	_	_
in	_	_
the	_	_
whole	_	_
page	_	_
can	_	_
be	_	_
estimated	_	_
by	_	_
all	_	_
boxes	_	_
in	_	_
the	_	_
set	_	_
C	_	_
and	_	_
it	_	_
is	_	_
used	_	_
as	_	_
the	_	_
prior	_	_
knowledge	_	_
of	_	_
characters	_	_
;	_	_
Step	_	_
3	_	_
:	_	_
the	_	_
large	_	_
boxes	_	_
in	_	_
the	_	_
set	_	_
R	_	_
whose	_	_
height	_	_
can	_	_
be	_	_
roughly	_	_
divided	_	_
by	_	_
the	_	_
average	_	_
height	_	_
mh	_	_
contains	_	_
several	_	_
entire	_	_
characters	_	_
and	_	_
they	_	_
are	_	_
split	_	_
equally	_	_
into	_	_
small	_	_
boxes	_	_
(	_	_
whose	_	_
ratio	_	_
r	_	_
(	_	_
b	_	_
)	_	_
is	_	_
greater	_	_
than	_	_
0.8	_	_
)	_	_
and	_	_
moved	_	_
to	_	_
the	_	_
set	_	_
C	_	_
;	_	_
Step	_	_
4	_	_
:	_	_
merging	_	_
neighbor	_	_
boxes	_	_
in	_	_
the	_	_
set	_	_
R	_	_
,	_	_
which	_	_
yields	_	_
large	_	_
boxes	_	_
;	_	_
Step	_	_
5	_	_
:	_	_
repeating	_	_
the	_	_
Step	_	_
3	_	_
,	_	_
which	_	_
split	_	_
the	_	_
large	_	_
boxes	_	_
into	_	_
small	_	_
boxes	_	_
which	_	_
might	_	_
contain	_	_
the	_	_
entire	_	_
characters	_	_
;	_	_
Step	_	_
6	_	_
:	_	_
each	_	_
box	_	_
in	_	_
the	_	_
set	_	_
C	_	_
contains	_	_
one	_	_
whole	_	_
character	_	_
and	_	_
all	_	_
of	_	_
them	_	_
are	_	_
aligned	_	_
based	_	_
on	_	_
other	_	_
characters	_	_
on	_	_
the	_	_
same	_	_
row	_	_
in	_	_
the	_	_
image	_	_
to	_	_
make	_	_
sure	_	_
that	_	_
all	_	_
characters	_	_
in	_	_
the	_	_
same	_	_
row	_	_
have	_	_
the	_	_
same	_	_
height	_	_
.	_	_

#374
After	_	_
these	_	_
six	_	_
steps	_	_
,	_	_
each	_	_
box	_	_
in	_	_
the	_	_
set	_	_
C	_	_
contains	_	_
an	_	_
entire	_	_
Chinese	_	_
character	_	_
and	_	_
boxes	_	_
in	_	_
the	_	_
set	_	_
R	_	_
are	_	_
discarded	_	_
.	_	_

#375
Fig.	_	_
A.13	_	_
(	_	_
b	_	_
)	_	_
shows	_	_
the	_	_
result	_	_
boxes	_	_
,	_	_
from	_	_
which	_	_
we	_	_
can	_	_
find	_	_
that	_	_
our	_	_
method	_	_
can	_	_
segment	_	_
the	_	_
Chinese	_	_
characters	_	_
properly	_	_
even	_	_
there	_	_
are	_	_
noise	_	_
or	_	_
intra-space	_	_
inside	_	_
the	_	_
characters	_	_
.	_	_

#376
Fig.	_	_
A.14	_	_
gives	_	_
more	_	_
examples	_	_
of	_	_
the	_	_
segmented	_	_
boxes	_	_
in	_	_
one	_	_
image	_	_
by	_	_
the	_	_
proposed	_	_
method	_	_
.	_	_

#377
Appendix	_	_
A.4	_	_
.	_	_

#378
Discussion	_	_
Our	_	_
proposed	_	_
segmentation	_	_
method	_	_
uses	_	_
the	_	_
run-length	_	_
distribution	_	_
to	_	_
detect	_	_
text	_	_
lines	_	_
in	_	_
Chinese	_	_
historical	_	_
documents	_	_
,	_	_
which	_	_
can	_	_
capture	_	_
the	_	_
structure	_	_
information	_	_
in	_	_
text	_	_
line	_	_
while	_	_
projection-based	_	_
methods	_	_
only	_	_
compute	_	_
the	_	_
density	_	_
of	_	_
the	_	_
ink	_	_
pixels	_	_
on	_	_
each	_	_
line	_	_
,	_	_
which	_	_
is	_	_
sensitive	_	_
to	_	_
noise	_	_
or	_	_
table	_	_
lines	_	_
.	_	_

#379
Skew	_	_
correction	_	_
is	_	_
very	_	_
important	_	_
for	_	_
character	_	_
segmentation	_	_
and	_	_
recognition	_	_
and	_	_
usually	_	_
the	_	_
Hough	_	_
transform	_	_
is	_	_
used	_	_
[	_	_
40	_	_
]	_	_
in	_	_
historical	_	_
documents	_	_
.	_	_

#380
Our	_	_
proposed	_	_
method	_	_
is	_	_
easy	_	_
to	_	_
estimate	_	_
the	_	_
small	_	_
skew	_	_
angle	_	_
in	_	_
the	_	_
proposed	_	_
Chinese	_	_
historical	_	_
documents	_	_
.	_	_

#381
In	_	_
addition	_	_
,	_	_
our	_	_
character	_	_
segmentation	_	_
method	_	_
is	_	_
also	_	_
very	_	_
efficient	_	_
and	_	_
all	_	_
characters	_	_
in	_	_
the	_	_
same	_	_
column	_	_
have	_	_
the	_	_
same	_	_
width	_	_
and	_	_
characters	_	_
in	_	_
the	_	_
same	_	_
row	_	_
have	_	_
the	_	_
same	_	_
height	_	_
.	_	_

#382
Therefore	_	_
,	_	_
our	_	_
segmentation	_	_
can	_	_
handle	_	_
the	_	_
problems	_	_
of	_	_
character	_	_
touching	_	_
and	_	_
intra-space	_	_
inside	_	_
the	_	_
character	_	_
,	_	_
as	_	_
shown	_	_
in	_	_
Fig.	_	_
A.14	_	_
.	_	_