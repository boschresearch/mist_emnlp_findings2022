#0
In	_	_
Defense	_	_
of	_	_
Classical	_	_
Image	_	_
Processing	_	_
:	_	_
Fast	_	_
Depth	_	_
Completion	_	_
on	_	_
the	_	_
CPU	_	_
Jason	_	_
Ku	_	_
,	_	_
Ali	_	_
Harakeh	_	_
,	_	_
and	_	_
Steven	_	_
L.	_	_
Waslander	_	_
Mechanical	_	_
and	_	_
Mechatronics	_	_
Engineering	_	_
Department	_	_
University	_	_
Of	_	_
Waterloo	_	_
Waterloo	_	_
,	_	_
ON	_	_
,	_	_
Canada	_	_
jason.ku	_	_
@	_	_
uwaterloo.ca	_	_
,	_	_
www.aharakeh.com	_	_
,	_	_
stevenw	_	_
@	_	_
uwaterloo.ca	_	_
Abstract—With	_	_
the	_	_
rise	_	_
of	_	_
data	_	_
driven	_	_
deep	_	_
neural	_	_
networks	_	_
as	_	_
a	_	_
realization	_	_
of	_	_
universal	_	_
function	_	_
approximators	_	_
,	_	_
most	_	_
research	_	_
on	_	_
computer	_	_
vision	_	_
problems	_	_
has	_	_
moved	_	_
away	_	_
from	_	_
hand	_	_
crafted	_	_
classical	_	_
image	_	_
processing	_	_
algorithms	_	_
.	_	_

#1
This	_	_
paper	_	_
shows	_	_
that	_	_
with	_	_
a	_	_
well	_	_
designed	_	_
algorithm	_	_
,	_	_
we	_	_
are	_	_
capable	_	_
of	_	_
outperforming	_	_
neural	_	_
network	_	_
based	_	_
methods	_	_
on	_	_
the	_	_
task	_	_
of	_	_
depth	_	_
completion	_	_
.	_	_

#2
The	_	_
proposed	_	_
algorithm	_	_
is	_	_
simple	_	_
and	_	_
fast	_	_
,	_	_
runs	_	_
on	_	_
the	_	_
CPU	_	_
,	_	_
and	_	_
relies	_	_
only	_	_
on	_	_
basic	_	_
image	_	_
processing	_	_
operations	_	_
to	_	_
perform	_	_
depth	_	_
completion	_	_
of	_	_
sparse	_	_
LIDAR	_	_
depth	_	_
data	_	_
.	_	_

#3
We	_	_
evaluate	_	_
our	_	_
algorithm	_	_
on	_	_
the	_	_
challenging	_	_
KITTI	_	_
depth	_	_
completion	_	_
benchmark	_	_
[	_	_
1	_	_
]	_	_
,	_	_
and	_	_
at	_	_
the	_	_
time	_	_
of	_	_
submission	_	_
,	_	_
our	_	_
method	_	_
ranks	_	_
first	_	_
on	_	_
the	_	_
KITTI	_	_
test	_	_
server	_	_
among	_	_
all	_	_
published	_	_
methods	_	_
.	_	_

#4
Furthermore	_	_
,	_	_
our	_	_
algorithm	_	_
is	_	_
data	_	_
independent	_	_
,	_	_
requiring	_	_
no	_	_
training	_	_
data	_	_
to	_	_
perform	_	_
the	_	_
task	_	_
at	_	_
hand	_	_
.	_	_

#5
The	_	_
code	_	_
written	_	_
in	_	_
Python	_	_
will	_	_
be	_	_
made	_	_
publicly	_	_
available	_	_
at	_	_
https	_	_
:	_	_
//github.com/kujason/ip	_	_
basic	_	_
.	_	_

#6
Keywords-image	_	_
processing	_	_
;	_	_
depth	_	_
completion	_	_
.	_	_

#7
I	_	_
.	_	_

#8
INTRODUCTION	_	_
The	_	_
realization	_	_
of	_	_
universal	_	_
function	_	_
approximators	_	_
via	_	_
deep	_	_
neural	_	_
networks	_	_
has	_	_
revolutionized	_	_
computer	_	_
vision	_	_
and	_	_
image	_	_
processing	_	_
.	_	_

#9
Deep	_	_
neural	_	_
networks	_	_
have	_	_
been	_	_
used	_	_
to	_	_
approximate	_	_
difficult	_	_
high	_	_
dimensional	_	_
functions	_	_
involved	_	_
in	_	_
object	_	_
detection	_	_
[	_	_
2	_	_
]	_	_
,	_	_
semantic	_	_
and	_	_
instance	_	_
level	_	_
segmentation	_	_
[	_	_
3	_	_
]	_	_
,	_	_
and	_	_
even	_	_
the	_	_
decision	_	_
making	_	_
process	_	_
for	_	_
driving	_	_
a	_	_
car	_	_
[	_	_
4	_	_
]	_	_
.	_	_

#10
The	_	_
success	_	_
of	_	_
these	_	_
function	_	_
approximators	_	_
on	_	_
AI-complete	_	_
[	_	_
5	_	_
]	_	_
tasks	_	_
has	_	_
lead	_	_
the	_	_
research	_	_
community	_	_
to	_	_
stray	_	_
away	_	_
from	_	_
classical	_	_
non-learning	_	_
based	_	_
methods	_	_
to	_	_
solve	_	_
almost	_	_
all	_	_
problems	_	_
.	_	_

#11
This	_	_
paper	_	_
aims	_	_
to	_	_
show	_	_
that	_	_
well-designed	_	_
classical	_	_
image	_	_
processing	_	_
algorithms	_	_
can	_	_
still	_	_
provide	_	_
very	_	_
competitive	_	_
results	_	_
compared	_	_
to	_	_
deep	_	_
learning	_	_
based	_	_
methods	_	_
.	_	_

#12
We	_	_
specifically	_	_
tackle	_	_
the	_	_
problem	_	_
of	_	_
depth	_	_
completion	_	_
,	_	_
that	_	_
is	_	_
,	_	_
inferring	_	_
a	_	_
dense	_	_
depth	_	_
map	_	_
from	_	_
image	_	_
and	_	_
sparse	_	_
depth	_	_
map	_	_
inputs	_	_
.	_	_

#13
Depth	_	_
completion	_	_
is	_	_
an	_	_
important	_	_
task	_	_
for	_	_
machine	_	_
vision	_	_
and	_	_
robotics	_	_
.	_	_

#14
Current	_	_
state-of-the-art	_	_
LIDAR	_	_
sensors	_	_
can	_	_
only	_	_
provide	_	_
sparse	_	_
depth	_	_
maps	_	_
when	_	_
projected	_	_
back	_	_
to	_	_
image	_	_
space	_	_
.	_	_

#15
This	_	_
limits	_	_
both	_	_
the	_	_
performance	_	_
and	_	_
the	_	_
operational	_	_
range	_	_
of	_	_
many	_	_
perception	_	_
algorithms	_	_
that	_	_
rely	_	_
on	_	_
the	_	_
depth	_	_
as	_	_
input	_	_
.	_	_

#16
For	_	_
example	_	_
,	_	_
3D	_	_
object	_	_
detection	_	_
algorithms	_	_
[	_	_
2	_	_
]	_	_
,	_	_
[	_	_
6	_	_
]	_	_
,	_	_
[	_	_
7	_	_
]	_	_
can	_	_
regress	_	_
bounding	_	_
boxes	_	_
only	_	_
if	_	_
there	_	_
are	_	_
enough	_	_
points	_	_
belonging	_	_
to	_	_
the	_	_
object	_	_
.	_	_

#17
Many	_	_
different	_	_
approaches	_	_
have	_	_
been	_	_
proposed	_	_
for	_	_
depth	_	_
completion	_	_
.	_	_

#18
These	_	_
approaches	_	_
range	_	_
from	_	_
simple	_	_
bilateral	_	_
upsampling	_	_
based	_	_
algorithms	_	_
[	_	_
8	_	_
]	_	_
to	_	_
end-to-end	_	_
deep	_	_
learning	_	_
based	_	_
ones	_	_
[	_	_
9	_	_
]	_	_
.	_	_

#19
The	_	_
latter	_	_
are	_	_
very	_	_
attractive	_	_
as	_	_
they	_	_
require	_	_
minimal	_	_
human	_	_
design	_	_
decisions	_	_
due	_	_
to	_	_
their	_	_
data	_	_
driven	_	_
nature	_	_
.	_	_

#20
However	_	_
,	_	_
using	_	_
deep	_	_
learning	_	_
approaches	_	_
results	_	_
in	_	_
multiple	_	_
consequences	_	_
.	_	_

#21
First	_	_
,	_	_
there	_	_
is	_	_
finite	_	_
compute	_	_
power	_	_
on	_	_
embedded	_	_
systems	_	_
.	_	_

#22
GPUs	_	_
are	_	_
very	_	_
power	_	_
hungry	_	_
,	_	_
and	_	_
deploying	_	_
a	_	_
GPU	_	_
for	_	_
each	_	_
module	_	_
to	_	_
run	_	_
is	_	_
prohibitive	_	_
.	_	_

#23
Second	_	_
,	_	_
the	_	_
creation	_	_
of	_	_
deep	_	_
learning	_	_
models	_	_
without	_	_
proper	_	_
understanding	_	_
of	_	_
the	_	_
problem	_	_
can	_	_
lead	_	_
to	_	_
sub-optimal	_	_
network	_	_
designs	_	_
.	_	_

#24
In	_	_
fact	_	_
,	_	_
we	_	_
believe	_	_
that	_	_
solving	_	_
this	_	_
problem	_	_
with	_	_
high	_	_
capacity	_	_
models	_	_
can	_	_
only	_	_
provide	_	_
good	_	_
results	_	_
after	_	_
developing	_	_
sufficient	_	_
understanding	_	_
of	_	_
its	_	_
underlying	_	_
intricacies	_	_
through	_	_
trying	_	_
to	_	_
solve	_	_
it	_	_
with	_	_
classical	_	_
image	_	_
processing	_	_
methods	_	_
.	_	_

#25
This	_	_
paper	_	_
aims	_	_
to	_	_
show	_	_
that	_	_
on	_	_
certain	_	_
problems	_	_
,	_	_
deep	_	_
learning	_	_
based	_	_
approaches	_	_
can	_	_
still	_	_
be	_	_
outperformed	_	_
by	_	_
well	_	_
designed	_	_
classical	_	_
image	_	_
processing	_	_
based	_	_
algorithms	_	_
.	_	_

#26
To	_	_
validate	_	_
this	_	_
,	_	_
we	_	_
design	_	_
a	_	_
simple	_	_
algorithm	_	_
for	_	_
depth	_	_
completion	_	_
that	_	_
relies	_	_
on	_	_
image	_	_
processing	_	_
operations	_	_
only	_	_
.	_	_

#27
The	_	_
algorithm	_	_
is	_	_
non-guided	_	_
and	_	_
relies	_	_
on	_	_
LIDAR	_	_
data	_	_
only	_	_
,	_	_
making	_	_
it	_	_
independent	_	_
of	_	_
changes	_	_
in	_	_
image	_	_
quality	_	_
.	_	_

#28
Furthermore	_	_
,	_	_
our	_	_
algorithm	_	_
is	_	_
not	_	_
deep	_	_
learning	_	_
based	_	_
,	_	_
requiring	_	_
no	_	_
training	_	_
data	_	_
,	_	_
making	_	_
it	_	_
robust	_	_
against	_	_
overfitting	_	_
.	_	_

#29
The	_	_
algorithm	_	_
runs	_	_
as	_	_
fast	_	_
as	_	_
deep	_	_
learning	_	_
based	_	_
approaches	_	_
but	_	_
on	_	_
the	_	_
CPU	_	_
,	_	_
while	_	_
performing	_	_
better	_	_
than	_	_
the	_	_
custom	_	_
designed	_	_
sparsity	_	_
invariant	_	_
convolutional	_	_
neural	_	_
network	_	_
of	_	_
[	_	_
9	_	_
]	_	_
.	_	_

#30
To	_	_
summarize	_	_
,	_	_
our	_	_
contributions	_	_
are	_	_
as	_	_
follows	_	_
:	_	_
•	_	_
We	_	_
provide	_	_
a	_	_
fast	_	_
depth	_	_
completion	_	_
algorithm	_	_
that	_	_
runs	_	_
at	_	_
90	_	_
Hz	_	_
on	_	_
the	_	_
CPU	_	_
and	_	_
ranks	_	_
first	_	_
among	_	_
all	_	_
published	_	_
methods	_	_
on	_	_
the	_	_
KITTI	_	_
depth	_	_
completion	_	_
benchmark	_	_
[	_	_
10	_	_
]	_	_
.	_	_

#31
•	_	_
We	_	_
show	_	_
that	_	_
our	_	_
algorithm	_	_
outperforms	_	_
CNN	_	_
based	_	_
approaches	_	_
that	_	_
have	_	_
been	_	_
designed	_	_
to	_	_
tackle	_	_
sparse	_	_
input	_	_
representations	_	_
by	_	_
a	_	_
wide	_	_
margin	_	_
.	_	_

#32
The	_	_
rest	_	_
of	_	_
this	_	_
paper	_	_
is	_	_
structured	_	_
as	_	_
follows	_	_
:	_	_
Section	_	_
II	_	_
provides	_	_
a	_	_
brief	_	_
overview	_	_
of	_	_
state-of-the-art	_	_
depth	_	_
completion	_	_
algorithms	_	_
.	_	_

#33
Section	_	_
IV	_	_
describes	_	_
the	_	_
problem	_	_
of	_	_
depth	_	_
completion	_	_
from	_	_
a	_	_
mathematical	_	_
perspective	_	_
and	_	_
then	_	_
ar	_	_
X	_	_
iv	_	_
:1	_	_
2	_	_
.	_	_

#34
6v	_	_
1	_	_
[	_	_
cs	_	_
.C	_	_
V	_	_
]	_	_
3	_	_
1	_	_
Ja	_	_
n	_	_
Figure	_	_
1	_	_
:	_	_
A	_	_
flowchart	_	_
of	_	_
the	_	_
proposed	_	_
algorithm	_	_
.	_	_

#35
Clockwise	_	_
starting	_	_
at	_	_
top	_	_
left	_	_
:	_	_
Input	_	_
LIDAR	_	_
depth	_	_
map	_	_
(	_	_
enhanced	_	_
for	_	_
visibility	_	_
)	_	_
,	_	_
inversion	_	_
and	_	_
dilation	_	_
,	_	_
small	_	_
hole	_	_
closure	_	_
,	_	_
small	_	_
hole	_	_
fill	_	_
,	_	_
extension	_	_
to	_	_
top	_	_
of	_	_
frame	_	_
,	_	_
large	_	_
hole	_	_
fill	_	_
and	_	_
blur	_	_
,	_	_
inversion	_	_
for	_	_
output	_	_
,	_	_
image	_	_
of	_	_
scene	_	_
(	_	_
not	_	_
used	_	_
,	_	_
only	_	_
for	_	_
reference	_	_
)	_	_
.	_	_

#36
introduces	_	_
our	_	_
proposed	_	_
algorithm	_	_
.	_	_

#37
Section	_	_
V	_	_
provides	_	_
a	_	_
qualitative	_	_
and	_	_
quantitative	_	_
comparison	_	_
with	_	_
the	_	_
state-of-the-art	_	_
methods	_	_
on	_	_
the	_	_
KITTI	_	_
depth	_	_
completion	_	_
benchmark	_	_
.	_	_

#38
Finally	_	_
,	_	_
we	_	_
conclude	_	_
the	_	_
paper	_	_
with	_	_
Section	_	_
VI	_	_
.	_	_

#39
II	_	_
.	_	_

#40
RELATED	_	_
WORK	_	_
Depth	_	_
completion	_	_
or	_	_
upsampling	_	_
is	_	_
an	_	_
active	_	_
area	_	_
of	_	_
research	_	_
with	_	_
applications	_	_
in	_	_
stereo	_	_
vision	_	_
,	_	_
optical	_	_
flow	_	_
,	_	_
and	_	_
3D	_	_
reconstruction	_	_
from	_	_
sparse	_	_
LIDAR	_	_
data	_	_
.	_	_

#41
This	_	_
section	_	_
discusses	_	_
state-of-the-art	_	_
depth	_	_
completion	_	_
algorithms	_	_
while	_	_
categorizing	_	_
them	_	_
into	_	_
two	_	_
main	_	_
classes	_	_
:	_	_
guided	_	_
depth	_	_
completion	_	_
and	_	_
non-guided	_	_
depth	_	_
completion	_	_
.	_	_

#42
Guided	_	_
Depth	_	_
Completion	_	_
:	_	_
Methods	_	_
belonging	_	_
to	_	_
this	_	_
category	_	_
rely	_	_
on	_	_
colour	_	_
images	_	_
for	_	_
guidance	_	_
to	_	_
perform	_	_
depth	_	_
map	_	_
completion	_	_
.	_	_

#43
A	_	_
variety	_	_
of	_	_
previous	_	_
algorithms	_	_
have	_	_
proposed	_	_
joint	_	_
bilateral	_	_
filtering	_	_
to	_	_
perform	_	_
“hole	_	_
filling”	_	_
on	_	_
the	_	_
target	_	_
depth	_	_
map	_	_
[	_	_
11	_	_
]	_	_
,	_	_
[	_	_
12	_	_
]	_	_
,	_	_
[	_	_
13	_	_
]	_	_
.	_	_

#44
Median	_	_
filters	_	_
have	_	_
also	_	_
been	_	_
extended	_	_
to	_	_
perform	_	_
depth	_	_
completion	_	_
from	_	_
colour	_	_
image	_	_
guidance	_	_
[	_	_
14	_	_
]	_	_
.	_	_

#45
Recently	_	_
,	_	_
deep	_	_
learning	_	_
approaches	_	_
have	_	_
emerged	_	_
to	_	_
tackle	_	_
the	_	_
guided	_	_
depth	_	_
completion	_	_
problem	_	_
[	_	_
15	_	_
]	_	_
,	_	_
[	_	_
16	_	_
]	_	_
.	_	_

#46
These	_	_
methods	_	_
have	_	_
been	_	_
demonstrated	_	_
to	_	_
produce	_	_
higher	_	_
quality	_	_
depth	_	_
maps	_	_
,	_	_
but	_	_
are	_	_
data-driven	_	_
,	_	_
requiring	_	_
large	_	_
amounts	_	_
of	_	_
training	_	_
data	_	_
to	_	_
generalize	_	_
well	_	_
.	_	_

#47
Furthermore	_	_
,	_	_
these	_	_
algorithms	_	_
assume	_	_
operation	_	_
on	_	_
a	_	_
regular	_	_
grid	_	_
and	_	_
fail	_	_
when	_	_
applied	_	_
to	_	_
very	_	_
sparse	_	_
input	_	_
such	_	_
as	_	_
the	_	_
depth	_	_
map	_	_
output	_	_
of	_	_
a	_	_
LIDAR	_	_
sensor	_	_
.	_	_

#48
All	_	_
of	_	_
the	_	_
above	_	_
guided	_	_
depth	_	_
completion	_	_
models	_	_
suffer	_	_
from	_	_
a	_	_
dependency	_	_
on	_	_
the	_	_
quality	_	_
of	_	_
the	_	_
guiding	_	_
colour	_	_
images	_	_
.	_	_

#49
The	_	_
performance	_	_
on	_	_
the	_	_
depth	_	_
completion	_	_
task	_	_
deteriorates	_	_
as	_	_
the	_	_
quality	_	_
of	_	_
the	_	_
associated	_	_
colour	_	_
image	_	_
becomes	_	_
worse	_	_
.	_	_

#50
Furthermore	_	_
,	_	_
the	_	_
quality	_	_
of	_	_
the	_	_
depth	_	_
map	_	_
output	_	_
is	_	_
highly	_	_
correlated	_	_
to	_	_
the	_	_
quality	_	_
of	_	_
calibration	_	_
and	_	_
synchronization	_	_
between	_	_
the	_	_
depth	_	_
sensor	_	_
and	_	_
the	_	_
camera	_	_
.	_	_

#51
Our	_	_
proposed	_	_
algorithm	_	_
is	_	_
non-guided	_	_
and	_	_
requires	_	_
no	_	_
training	_	_
data	_	_
,	_	_
resolving	_	_
most	_	_
of	_	_
the	_	_
problems	_	_
faced	_	_
with	_	_
the	_	_
guided	_	_
depth	_	_
completion	_	_
approach	_	_
.	_	_

#52
Non-Guided	_	_
Depth	_	_
Completion	_	_
:	_	_
Methods	_	_
belonging	_	_
to	_	_
this	_	_
category	_	_
use	_	_
only	_	_
a	_	_
sparse	_	_
depth	_	_
map	_	_
to	_	_
produce	_	_
a	_	_
dense	_	_
one	_	_
.	_	_

#53
[	_	_
17	_	_
]	_	_
uses	_	_
repetitive	_	_
structures	_	_
to	_	_
identify	_	_
similar	_	_
patches	_	_
in	_	_
3D	_	_
across	_	_
different	_	_
scales	_	_
to	_	_
perform	_	_
depth	_	_
completion	_	_
.	_	_

#54
[	_	_
9	_	_
]	_	_
provides	_	_
a	_	_
baseline	_	_
using	_	_
Nadaraya-Watson	_	_
kernel	_	_
regression	_	_
[	_	_
18	_	_
]	_	_
to	_	_
estimate	_	_
missing	_	_
values	_	_
for	_	_
depth	_	_
completion	_	_
of	_	_
sparse	_	_
LIDAR	_	_
scans	_	_
.	_	_

#55
Missing	_	_
values	_	_
do	_	_
not	_	_
contribute	_	_
to	_	_
the	_	_
Gaussian	_	_
filter	_	_
and	_	_
therefore	_	_
sparsity	_	_
is	_	_
implicitly	_	_
handled	_	_
in	_	_
the	_	_
algorithm	_	_
.	_	_

#56
[	_	_
9	_	_
]	_	_
recently	_	_
proposed	_	_
a	_	_
sparsity	_	_
invariant	_	_
CNN	_	_
architecture	_	_
for	_	_
depth	_	_
completion	_	_
.	_	_

#57
The	_	_
proposed	_	_
sparsity	_	_
invariant	_	_
convolutional	_	_
layer	_	_
only	_	_
considers	_	_
“valid”	_	_
values	_	_
in	_	_
the	_	_
output	_	_
computation	_	_
providing	_	_
better	_	_
results	_	_
than	_	_
normal	_	_
convolutional	_	_
kernels	_	_
.	_	_

#58
However	_	_
,	_	_
[	_	_
9	_	_
]	_	_
also	_	_
provided	_	_
results	_	_
for	_	_
CNNs	_	_
trained	_	_
on	_	_
nearest	_	_
neighbour	_	_
interpolated	_	_
depth	_	_
maps	_	_
that	_	_
outperformed	_	_
these	_	_
sparsity	_	_
invariant	_	_
CNNs	_	_
,	_	_
diminishing	_	_
the	_	_
practical	_	_
value	_	_
of	_	_
pursuing	_	_
this	_	_
direction	_	_
of	_	_
research	_	_
for	_	_
depth	_	_
completion	_	_
.	_	_

#59
As	_	_
discussed	_	_
in	_	_
the	_	_
previous	_	_
sections	_	_
,	_	_
deep	_	_
learning	_	_
based	_	_
approaches	_	_
are	_	_
still	_	_
too	_	_
computationally	_	_
taxing	_	_
,	_	_
requiring	_	_
systems	_	_
to	_	_
deploy	_	_
power	_	_
hungry	_	_
GPUs	_	_
to	_	_
run	_	_
instances	_	_
of	_	_
the	_	_
neural	_	_
network	_	_
.	_	_

#60
In	_	_
the	_	_
next	_	_
sections	_	_
,	_	_
we	_	_
aim	_	_
to	_	_
show	_	_
that	_	_
our	_	_
classical	_	_
image	_	_
processing	_	_
algorithm	_	_
can	_	_
perform	_	_
as	_	_
well	_	_
as	_	_
deep	_	_
neural	_	_
networks	_	_
and	_	_
at	_	_
a	_	_
similar	_	_
frame	_	_
rate	_	_
without	_	_
incurring	_	_
additional	_	_
restrictions	_	_
on	_	_
the	_	_
deployment	_	_
hardware	_	_
.	_	_

#61
Figure	_	_
2	_	_
:	_	_
A	_	_
toy	_	_
example	_	_
summarizing	_	_
the	_	_
problem	_	_
formulation	_	_
described	_	_
in	_	_
equation	_	_
1	_	_
.	_	_

#62
Empty	_	_
values	_	_
are	_	_
coloured	_	_
in	_	_
red	_	_
,	_	_
and	_	_
filled	_	_
by	_	_
applying	_	_
the	_	_
function	_	_
f	_	_
to	_	_
Dsparse	_	_
.	_	_

#63
Figure	_	_
3	_	_
:	_	_
Different	_	_
kernels	_	_
used	_	_
for	_	_
comparison	_	_
.	_	_

#64
III	_	_
.	_	_

#65
PROBLEM	_	_
FORMULATION	_	_
The	_	_
problem	_	_
of	_	_
depth	_	_
completion	_	_
can	_	_
be	_	_
described	_	_
as	_	_
follows	_	_
:	_	_
Given	_	_
an	_	_
image	_	_
I	_	_
∈	_	_
RM×N	_	_
,	_	_
and	_	_
a	_	_
sparse	_	_
depth	_	_
map	_	_
Dsparse	_	_
∈	_	_
RM×N	_	_
find	_	_
f̂	_	_
that	_	_
approximates	_	_
a	_	_
true	_	_
function	_	_
f	_	_
:	_	_
RM×N	_	_
×	_	_
RM×N	_	_
→	_	_
RM×N	_	_
where	_	_
f	_	_
(	_	_
I	_	_
,	_	_
Dsparse	_	_
)	_	_
=	_	_
Ddense	_	_
.	_	_

#66
The	_	_
problem	_	_
can	_	_
be	_	_
formulated	_	_
as	_	_
:	_	_
min	_	_
.	_	_

#67
||f̂	_	_
(	_	_
I	_	_
,	_	_
Dsparse	_	_
)	_	_
−	_	_
f	_	_
(	_	_
I	_	_
,	_	_
Dsparse	_	_
)	_	_
||2F	_	_
=	_	_
0	_	_
(	_	_
1	_	_
)	_	_
Here	_	_
,	_	_
Ddense	_	_
is	_	_
the	_	_
output	_	_
dense	_	_
depth	_	_
map	_	_
,	_	_
and	_	_
has	_	_
the	_	_
same	_	_
size	_	_
as	_	_
I	_	_
and	_	_
Dsparse	_	_
with	_	_
empty	_	_
values	_	_
replaced	_	_
by	_	_
their	_	_
depth	_	_
estimate	_	_
.	_	_

#68
In	_	_
the	_	_
case	_	_
of	_	_
non-guided	_	_
depth	_	_
completion	_	_
,	_	_
the	_	_
above	_	_
formulation	_	_
becomes	_	_
independent	_	_
of	_	_
the	_	_
image	_	_
I	_	_
as	_	_
shown	_	_
in	_	_
Fig.	_	_
2	_	_
.	_	_

#69
We	_	_
realize	_	_
f̂	_	_
via	_	_
a	_	_
series	_	_
of	_	_
image	_	_
processing	_	_
operations	_	_
described	_	_
below	_	_
.	_	_

#70
IV	_	_
.	_	_

#71
PROPOSED	_	_
ALGORITHM	_	_
The	_	_
proposed	_	_
method	_	_
,	_	_
as	_	_
shown	_	_
in	_	_
Fig.	_	_
1	_	_
is	_	_
implemented	_	_
in	_	_
Python	_	_
and	_	_
uses	_	_
a	_	_
series	_	_
of	_	_
OpenCV	_	_
[	_	_
19	_	_
]	_	_
and	_	_
NumPy	_	_
[	_	_
20	_	_
]	_	_
operations	_	_
to	_	_
perform	_	_
depth	_	_
completion	_	_
.	_	_

#72
We	_	_
leverage	_	_
the	_	_
implementation	_	_
of	_	_
standard	_	_
OpenCV	_	_
operations	_	_
,	_	_
which	_	_
use	_	_
larger	_	_
pixel	_	_
values	_	_
to	_	_
overwrite	_	_
lower	_	_
pixel	_	_
values	_	_
.	_	_

#73
This	_	_
way	_	_
,	_	_
the	_	_
issue	_	_
of	_	_
sparsity	_	_
can	_	_
be	_	_
addressed	_	_
by	_	_
selecting	_	_
appropriate	_	_
operations	_	_
to	_	_
fill	_	_
in	_	_
empty	_	_
pixels	_	_
.	_	_

#74
By	_	_
exploiting	_	_
this	_	_
property	_	_
of	_	_
OpenCV	_	_
operations	_	_
,	_	_
we	_	_
realize	_	_
depth	_	_
completion	_	_
via	_	_
the	_	_
eight	_	_
step	_	_
algorithm	_	_
described	_	_
below	_	_
.	_	_

#75
The	_	_
final	_	_
result	_	_
of	_	_
the	_	_
algorithm	_	_
is	_	_
a	_	_
dense	_	_
depth	_	_
map	_	_
Ddense	_	_
that	_	_
can	_	_
be	_	_
used	_	_
as	_	_
input	_	_
for	_	_
3D	_	_
object	_	_
detection	_	_
,	_	_
occupancy	_	_
grid	_	_
generation	_	_
,	_	_
and	_	_
even	_	_
simultaneous	_	_
localization	_	_
and	_	_
mapping	_	_
(	_	_
SLAM	_	_
)	_	_
.	_	_

#76
1	_	_
)	_	_
Depth	_	_
Inversion	_	_
:	_	_
The	_	_
main	_	_
sparsity	_	_
handling	_	_
mechanisms	_	_
employed	_	_
are	_	_
OpenCV	_	_
morphological	_	_
transformation	_	_
operations	_	_
,	_	_
which	_	_
overwrite	_	_
smaller	_	_
pixel	_	_
values	_	_
with	_	_
larger	_	_
ones	_	_
.	_	_

#77
When	_	_
considering	_	_
the	_	_
raw	_	_
KITTI	_	_
depth	_	_
map	_	_
data	_	_
,	_	_
closer	_	_
pixels	_	_
take	_	_
values	_	_
close	_	_
to	_	_
0	_	_
m	_	_
while	_	_
further	_	_
ones	_	_
take	_	_
values	_	_
up	_	_
to	_	_
a	_	_
maximum	_	_
of	_	_
80	_	_
m.	_	_
However	_	_
,	_	_
empty	_	_
pixels	_	_
take	_	_
the	_	_
value	_	_
0	_	_
m	_	_
too	_	_
,	_	_
which	_	_
prevents	_	_
using	_	_
native	_	_
OpenCV	_	_
operations	_	_
without	_	_
modification	_	_
.	_	_

#78
Applying	_	_
a	_	_
dilation	_	_
operation	_	_
on	_	_
the	_	_
original	_	_
depth	_	_
map	_	_
would	_	_
result	_	_
in	_	_
larger	_	_
distances	_	_
overwriting	_	_
smaller	_	_
distances	_	_
,	_	_
resulting	_	_
in	_	_
the	_	_
loss	_	_
of	_	_
edge	_	_
information	_	_
for	_	_
closer	_	_
objects	_	_
.	_	_

#79
To	_	_
resolve	_	_
this	_	_
problem	_	_
,	_	_
valid	_	_
(	_	_
non-empty	_	_
)	_	_
pixel	_	_
depths	_	_
are	_	_
inverted	_	_
according	_	_
to	_	_
Dinverted	_	_
=	_	_
100.0−Dinput	_	_
,	_	_
which	_	_
also	_	_
creates	_	_
a	_	_
20	_	_
m	_	_
buffer	_	_
between	_	_
valid	_	_
and	_	_
empty	_	_
pixel	_	_
values	_	_
.	_	_

#80
This	_	_
inversion	_	_
allows	_	_
the	_	_
algorithm	_	_
to	_	_
preserve	_	_
closer	_	_
edges	_	_
when	_	_
applying	_	_
dilation	_	_
operations	_	_
.	_	_

#81
The	_	_
20	_	_
m	_	_
buffer	_	_
is	_	_
used	_	_
to	_	_
offset	_	_
the	_	_
valid	_	_
depths	_	_
in	_	_
order	_	_
to	_	_
allow	_	_
the	_	_
masking	_	_
of	_	_
invalid	_	_
pixels	_	_
during	_	_
subsequent	_	_
operations	_	_
.	_	_

#82
2	_	_
)	_	_
Custom	_	_
Kernel	_	_
Dilation	_	_
:	_	_
We	_	_
start	_	_
by	_	_
filling	_	_
empty	_	_
pixels	_	_
nearest	_	_
to	_	_
valid	_	_
pixels	_	_
,	_	_
as	_	_
these	_	_
are	_	_
most	_	_
likely	_	_
to	_	_
share	_	_
close	_	_
depth	_	_
values	_	_
with	_	_
valid	_	_
depths	_	_
.	_	_

#83
Considering	_	_
both	_	_
the	_	_
sparsity	_	_
of	_	_
projected	_	_
points	_	_
and	_	_
the	_	_
structure	_	_
of	_	_
the	_	_
LIDAR	_	_
scan	_	_
lines	_	_
,	_	_
we	_	_
design	_	_
a	_	_
custom	_	_
kernel	_	_
for	_	_
an	_	_
initial	_	_
dilation	_	_
of	_	_
each	_	_
valid	_	_
depth	_	_
pixel	_	_
.	_	_

#84
The	_	_
kernel	_	_
shape	_	_
is	_	_
designed	_	_
such	_	_
that	_	_
the	_	_
most	_	_
likely	_	_
pixels	_	_
with	_	_
the	_	_
same	_	_
values	_	_
are	_	_
dilated	_	_
to	_	_
the	_	_
same	_	_
value	_	_
.	_	_

#85
We	_	_
implement	_	_
and	_	_
evaluate	_	_
four	_	_
kernel	_	_
shapes	_	_
shown	_	_
in	_	_
Fig.	_	_
3	_	_
.	_	_

#86
From	_	_
the	_	_
results	_	_
of	_	_
the	_	_
experiments	_	_
performed	_	_
in	_	_
Section	_	_
V	_	_
,	_	_
a	_	_
5×	_	_
5	_	_
diamond	_	_
kernel	_	_
is	_	_
used	_	_
to	_	_
dilate	_	_
all	_	_
valid	_	_
pixels	_	_
.	_	_

#87
3	_	_
)	_	_
Small	_	_
Hole	_	_
Closure	_	_
:	_	_
After	_	_
the	_	_
initial	_	_
dilation	_	_
step	_	_
,	_	_
many	_	_
holes	_	_
still	_	_
exist	_	_
in	_	_
the	_	_
depth	_	_
map	_	_
.	_	_

#88
Since	_	_
these	_	_
areas	_	_
contain	_	_
no	_	_
depth	_	_
values	_	_
,	_	_
we	_	_
consider	_	_
the	_	_
structure	_	_
of	_	_
objects	_	_
in	_	_
the	_	_
environment	_	_
and	_	_
note	_	_
that	_	_
nearby	_	_
patches	_	_
of	_	_
dilated	_	_
depths	_	_
can	_	_
be	_	_
connected	_	_
to	_	_
form	_	_
the	_	_
edges	_	_
of	_	_
objects	_	_
.	_	_

#89
A	_	_
morphological	_	_
close	_	_
operation	_	_
,	_	_
with	_	_
a	_	_
5	_	_
×	_	_
5	_	_
full	_	_
kernel	_	_
,	_	_
is	_	_
used	_	_
to	_	_
close	_	_
small	_	_
holes	_	_
in	_	_
the	_	_
depth	_	_
map	_	_
.	_	_

#90
This	_	_
operation	_	_
uses	_	_
a	_	_
binary	_	_
kernel	_	_
,	_	_
which	_	_
preserves	_	_
object	_	_
edges	_	_
.	_	_

#91
This	_	_
step	_	_
acts	_	_
to	_	_
connect	_	_
nearby	_	_
depth	_	_
values	_	_
,	_	_
and	_	_
can	_	_
be	_	_
seen	_	_
as	_	_
a	_	_
set	_	_
of	_	_
5×	_	_
5	_	_
pixel	_	_
planes	_	_
stacked	_	_
from	_	_
farthest	_	_
to	_	_
nearest	_	_
.	_	_

#92
4	_	_
)	_	_
Small	_	_
Hole	_	_
Fill	_	_
:	_	_
Some	_	_
small	_	_
to	_	_
medium	_	_
sized	_	_
holes	_	_
in	_	_
the	_	_
depth	_	_
map	_	_
are	_	_
not	_	_
filled	_	_
by	_	_
the	_	_
first	_	_
two	_	_
dilation	_	_
operations	_	_
.	_	_

#93
To	_	_
fill	_	_
these	_	_
holes	_	_
,	_	_
a	_	_
mask	_	_
of	_	_
empty	_	_
pixels	_	_
is	_	_
first	_	_
calculated	_	_
,	_	_
followed	_	_
by	_	_
a	_	_
7	_	_
×	_	_
7	_	_
full	_	_
kernel	_	_
dilation	_	_
operation	_	_
.	_	_

#94
This	_	_
operation	_	_
results	_	_
in	_	_
only	_	_
the	_	_
empty	_	_
pixels	_	_
being	_	_
filled	_	_
,	_	_
while	_	_
keeping	_	_
valid	_	_
pixels	_	_
that	_	_
have	_	_
been	_	_
previously	_	_
computed	_	_
unchanged	_	_
.	_	_

#95
5	_	_
)	_	_
Extension	_	_
to	_	_
Top	_	_
of	_	_
Frame	_	_
:	_	_
To	_	_
account	_	_
for	_	_
tall	_	_
objects	_	_
such	_	_
as	_	_
trees	_	_
,	_	_
poles	_	_
,	_	_
and	_	_
buildings	_	_
that	_	_
extend	_	_
above	_	_
the	_	_
top	_	_
of	_	_
LIDAR	_	_
points	_	_
,	_	_
the	_	_
top	_	_
value	_	_
along	_	_
each	_	_
column	_	_
is	_	_
extrapolated	_	_
to	_	_
the	_	_
top	_	_
of	_	_
the	_	_
image	_	_
,	_	_
providing	_	_
a	_	_
denser	_	_
depth	_	_
map	_	_
output	_	_
.	_	_

#96
6	_	_
)	_	_
Large	_	_
Hole	_	_
Fill	_	_
:	_	_
The	_	_
final	_	_
fill	_	_
step	_	_
takes	_	_
care	_	_
of	_	_
larger	_	_
holes	_	_
in	_	_
the	_	_
depth	_	_
map	_	_
that	_	_
are	_	_
not	_	_
fully	_	_
filled	_	_
from	_	_
previous	_	_
steps	_	_
.	_	_

#97
Since	_	_
these	_	_
areas	_	_
contain	_	_
no	_	_
points	_	_
,	_	_
and	_	_
no	_	_
image	_	_
data	_	_
is	_	_
used	_	_
,	_	_
the	_	_
depth	_	_
values	_	_
for	_	_
these	_	_
pixels	_	_
are	_	_
extrapolated	_	_
from	_	_
nearby	_	_
values	_	_
.	_	_

#98
A	_	_
dilation	_	_
operation	_	_
with	_	_
a	_	_
31x31	_	_
full	_	_
kernel	_	_
is	_	_
used	_	_
to	_	_
fill	_	_
in	_	_
any	_	_
remaining	_	_
empty	_	_
pixels	_	_
,	_	_
while	_	_
leaving	_	_
valid	_	_
pixels	_	_
unchanged	_	_
.	_	_

#99
Sparse	_	_
CNN	_	_
Nearest	_	_
Neighbor	_	_
Interpolation	_	_
+	_	_
CNN	_	_
Ours	_	_
Figure	_	_
4	_	_
:	_	_
The	_	_
qualitative	_	_
results	_	_
of	_	_
our	_	_
proposed	_	_
algorithm	_	_
on	_	_
three	_	_
samples	_	_
in	_	_
the	_	_
KITTI	_	_
test	_	_
set	_	_
in	_	_
comparison	_	_
to	_	_
Sparse	_	_
CNN	_	_
and	_	_
Nearest	_	_
Neighbour	_	_
Interpolation	_	_
with	_	_
CNN	_	_
,	_	_
both	_	_
of	_	_
which	_	_
were	_	_
proposed	_	_
in	_	_
[	_	_
9	_	_
]	_	_
.	_	_

#100
Top	_	_
:	_	_
Output	_	_
dense	_	_
depth	_	_
map	_	_
.	_	_

#101
Bottom	_	_
:	_	_
Visualization	_	_
of	_	_
the	_	_
pixel-wise	_	_
error	_	_
in	_	_
estimation	_	_
ranging	_	_
from	_	_
blue	_	_
for	_	_
a	_	_
low	_	_
error	_	_
to	_	_
red	_	_
for	_	_
a	_	_
high	_	_
error	_	_
.	_	_

#102
It	_	_
can	_	_
be	_	_
seen	_	_
that	_	_
our	_	_
method	_	_
has	_	_
a	_	_
lower	_	_
error	_	_
in	_	_
estimation	_	_
especially	_	_
for	_	_
further	_	_
away	_	_
pixels	_	_
.	_	_

#103
7	_	_
)	_	_
Median	_	_
and	_	_
Gaussian	_	_
Blur	_	_
:	_	_
After	_	_
applying	_	_
the	_	_
previous	_	_
steps	_	_
,	_	_
we	_	_
end	_	_
up	_	_
with	_	_
a	_	_
dense	_	_
depth	_	_
map	_	_
.	_	_

#104
However	_	_
,	_	_
outliers	_	_
exist	_	_
in	_	_
this	_	_
depth	_	_
map	_	_
as	_	_
a	_	_
by-product	_	_
of	_	_
the	_	_
dilation	_	_
operations	_	_
.	_	_

#105
To	_	_
remove	_	_
these	_	_
outliers	_	_
,	_	_
we	_	_
use	_	_
a	_	_
5×	_	_
5	_	_
kernel	_	_
median	_	_
blur	_	_
.	_	_

#106
This	_	_
denoising	_	_
step	_	_
is	_	_
very	_	_
important	_	_
as	_	_
it	_	_
removes	_	_
outliers	_	_
while	_	_
maintaining	_	_
local	_	_
edges	_	_
.	_	_

#107
Finally	_	_
,	_	_
a	_	_
5×5	_	_
Gaussian	_	_
blur	_	_
is	_	_
applied	_	_
in	_	_
order	_	_
to	_	_
smooth	_	_
local	_	_
planes	_	_
and	_	_
round	_	_
off	_	_
sharp	_	_
object	_	_
edges	_	_
.	_	_

#108
8	_	_
)	_	_
Depth	_	_
Inversion	_	_
:	_	_
The	_	_
final	_	_
step	_	_
of	_	_
our	_	_
algorithm	_	_
is	_	_
to	_	_
revert	_	_
back	_	_
to	_	_
the	_	_
original	_	_
depth	_	_
encoding	_	_
from	_	_
the	_	_
inverted	_	_
depth	_	_
values	_	_
used	_	_
by	_	_
the	_	_
previous	_	_
steps	_	_
of	_	_
the	_	_
algorithm	_	_
.	_	_

#109
This	_	_
is	_	_
simply	_	_
calculated	_	_
as	_	_
Doutput	_	_
=	_	_
100.0−Dinverted	_	_
.	_	_

#110
V.	_	_
EXPERIMENTS	_	_
AND	_	_
RESULTS	_	_
We	_	_
test	_	_
our	_	_
algorithm’s	_	_
performance	_	_
on	_	_
the	_	_
depth	_	_
completion	_	_
task	_	_
in	_	_
the	_	_
KITTI	_	_
depth	_	_
completion	_	_
benchmark	_	_
.	_	_

#111
The	_	_
recently	_	_
released	_	_
depth	_	_
completion	_	_
benchmark	_	_
contains	_	_
a	_	_
large	_	_
set	_	_
of	_	_
LIDAR	_	_
scans	_	_
projected	_	_
into	_	_
image	_	_
coordinates	_	_
to	_	_
form	_	_
depth	_	_
maps	_	_
.	_	_

#112
The	_	_
LIDAR	_	_
points	_	_
are	_	_
projected	_	_
to	_	_
the	_	_
image	_	_
coordinates	_	_
using	_	_
the	_	_
front	_	_
camera	_	_
calibration	_	_
matrices	_	_
,	_	_
resulting	_	_
in	_	_
a	_	_
sparse	_	_
depth	_	_
map	_	_
with	_	_
the	_	_
same	_	_
size	_	_
as	_	_
the	_	_
RGB	_	_
image	_	_
.	_	_

#113
The	_	_
sparsity	_	_
is	_	_
induced	_	_
by	_	_
the	_	_
fact	_	_
that	_	_
LIDAR	_	_
data	_	_
has	_	_
a	_	_
much	_	_
lower	_	_
resolution	_	_
than	_	_
the	_	_
image	_	_
space	_	_
it	_	_
is	_	_
being	_	_
projected	_	_
to	_	_
.	_	_

#114
Due	_	_
to	_	_
the	_	_
angles	_	_
of	_	_
LIDAR	_	_
scan	_	_
lines	_	_
,	_	_
only	_	_
the	_	_
bottom	_	_
two-thirds	_	_
of	_	_
the	_	_
depth	_	_
map	_	_
contain	_	_
points	_	_
.	_	_

#115
The	_	_
sparsity	_	_
of	_	_
the	_	_
points	_	_
in	_	_
the	_	_
bottom	_	_
region	_	_
of	_	_
the	_	_
depth	_	_
maps	_	_
is	_	_
found	_	_
to	_	_
range	_	_
between	_	_
5	_	_
−	_	_
7	_	_
%	_	_
.	_	_

#116
The	_	_
corresponding	_	_
RGB	_	_
image	_	_
is	_	_
also	_	_
provided	_	_
for	_	_
each	_	_
depth	_	_
map	_	_
,	_	_
but	_	_
is	_	_
not	_	_
used	_	_
by	_	_
our	_	_
unguided	_	_
depth	_	_
completion	_	_
algorithm	_	_
.	_	_

#117
The	_	_
provided	_	_
validation	_	_
set	_	_
of	_	_
1000	_	_
images	_	_
is	_	_
used	_	_
for	_	_
evaluation	_	_
for	_	_
all	_	_
experiments	_	_
,	_	_
and	_	_
the	_	_
final	_	_
results	_	_
on	_	_
the	_	_
1000	_	_
image	_	_
test	_	_
set	_	_
are	_	_
submitted	_	_
and	_	_
evaluated	_	_
by	_	_
KITTI’s	_	_
test	_	_
server	_	_
.	_	_

#118
The	_	_
performance	_	_
of	_	_
the	_	_
algorithm	_	_
and	_	_
the	_	_
baselines	_	_
are	_	_
evaluated	_	_
using	_	_
the	_	_
inverse	_	_
Root	_	_
Mean	_	_
Squared	_	_
Error	_	_
(	_	_
iRMSE	_	_
)	_	_
,	_	_
inverse	_	_
Mean	_	_
Average	_	_
Error	_	_
(	_	_
iMAE	_	_
)	_	_
,	_	_
Root	_	_
Mean	_	_
Squared	_	_
Error	_	_
(	_	_
RMSE	_	_
)	_	_
,	_	_
and	_	_
Mean	_	_
Average	_	_
Error	_	_
(	_	_
MAE	_	_
)	_	_
metrics	_	_
.	_	_

#119
We	_	_
refer	_	_
the	_	_
reader	_	_
to	_	_
[	_	_
9	_	_
]	_	_
for	_	_
a	_	_
deeper	_	_
insight	_	_
on	_	_
each	_	_
of	_	_
these	_	_
metrics	_	_
.	_	_

#120
Since	_	_
methods	_	_
are	_	_
ranked	_	_
based	_	_
on	_	_
RMSE	_	_
on	_	_
KITTI’s	_	_
test	_	_
server	_	_
,	_	_
the	_	_
RMSE	_	_
metric	_	_
is	_	_
used	_	_
as	_	_
the	_	_
criterion	_	_
for	_	_
selecting	_	_
the	_	_
best	_	_
design	_	_
.	_	_

#121
A	_	_
.	_	_

#122
Performance	_	_
on	_	_
the	_	_
Depth	_	_
Completion	_	_
Task	_	_
At	_	_
the	_	_
time	_	_
of	_	_
submission	_	_
,	_	_
the	_	_
proposed	_	_
algorithm	_	_
ranks	_	_
first	_	_
among	_	_
all	_	_
published	_	_
methods	_	_
in	_	_
both	_	_
RMSE	_	_
and	_	_
MAE	_	_
metrics	_	_
.	_	_

#123
Table	_	_
I	_	_
provides	_	_
the	_	_
results	_	_
of	_	_
comparison	_	_
against	_	_
the	_	_
baseline	_	_
Nadaraya-Watson	_	_
kernel	_	_
method	_	_
(	_	_
NadarayaW	_	_
)	_	_
,	_	_
as	_	_
well	_	_
as	_	_
the	_	_
learning	_	_
based	_	_
approaches	_	_
Sparsity	_	_
Invariant	_	_
CNNs	_	_
(	_	_
SparseConvs	_	_
)	_	_
and	_	_
Nearest	_	_
Neighbour	_	_
Interpolation	_	_
with	_	_
CNN	_	_
(	_	_
NN+CNN	_	_
)	_	_
[	_	_
9	_	_
]	_	_
,	_	_
all	_	_
of	_	_
which	_	_
are	_	_
specifically	_	_
tailored	_	_
for	_	_
processing	_	_
sparse	_	_
input	_	_
.	_	_

#124
Our	_	_
algorithm	_	_
outperforms	_	_
the	_	_
NN+CNN	_	_
,	_	_
the	_	_
runner	_	_
up	_	_
on	_	_
the	_	_
KITTI	_	_
data	_	_
set	_	_
,	_	_
by	_	_
131.29	_	_
mm	_	_
in	_	_
RMSE	_	_
and	_	_
113.54	_	_
mm	_	_
in	_	_
MAE	_	_
.	_	_

#125
That	_	_
is	_	_
equivalent	_	_
to	_	_
a	_	_
difference	_	_
of	_	_
11	_	_
cm	_	_
mean	_	_
error	_	_
in	_	_
the	_	_
final	_	_
point	_	_
cloud	_	_
results	_	_
,	_	_
which	_	_
is	_	_
important	_	_
for	_	_
accurate	_	_
3D	_	_
object	_	_
localization	_	_
,	_	_
obstacle	_	_
avoidance	_	_
,	_	_
and	_	_
SLAM	_	_
.	_	_

#126
Furthermore	_	_
,	_	_
Method	_	_
iRMSE	_	_
(	_	_
1/km	_	_
)	_	_
iMAE	_	_
(	_	_
1/km	_	_
)	_	_
RMSE	_	_
(	_	_
mm	_	_
)	_	_
MAE	_	_
(	_	_
mm	_	_
)	_	_
Runtime	_	_
(	_	_
s	_	_
)	_	_
NadarayaW	_	_
6.34	_	_
1.84	_	_
1852.60	_	_
416.77	_	_
0.05	_	_
SparseConvs	_	_
4.94	_	_
1.78	_	_
1601.33	_	_
481.27	_	_
0.01	_	_
NN+CNN	_	_
3.25	_	_
1.29	_	_
1419.75	_	_
416.14	_	_
0.02	_	_
Ours	_	_
(	_	_
IP-Basic	_	_
)	_	_
3.78	_	_
1.29	_	_
1288.46	_	_
302.60	_	_
0.011	_	_
Table	_	_
I	_	_
:	_	_
A	_	_
comparison	_	_
of	_	_
the	_	_
performance	_	_
of	_	_
Nadaraya-Watson	_	_
kernel	_	_
baseline	_	_
,	_	_
Sparse	_	_
CNN	_	_
,	_	_
Nearest	_	_
Neighbour	_	_
Interpolation	_	_
with	_	_
CNN	_	_
,	_	_
and	_	_
our	_	_
method	_	_
,	_	_
evaluated	_	_
on	_	_
the	_	_
KITTI	_	_
depth	_	_
completion	_	_
test	_	_
set	_	_
.	_	_

#127
Results	_	_
are	_	_
generated	_	_
by	_	_
KITTI’s	_	_
evaluation	_	_
server	_	_
[	_	_
10	_	_
]	_	_
.	_	_

#128
our	_	_
proposed	_	_
algorithm	_	_
runs	_	_
at	_	_
90	_	_
Hz	_	_
on	_	_
an	_	_
Intel	_	_
Core	_	_
i77700K	_	_
Processor	_	_
,	_	_
while	_	_
both	_	_
the	_	_
second	_	_
and	_	_
third	_	_
ranking	_	_
methods	_	_
require	_	_
an	_	_
additional	_	_
GPU	_	_
to	_	_
run	_	_
at	_	_
50	_	_
and	_	_
100	_	_
Hz	_	_
respectively	_	_
.	_	_

#129
B	_	_
.	_	_

#130
Experimental	_	_
Design	_	_
To	_	_
design	_	_
the	_	_
algorithm	_	_
,	_	_
a	_	_
greedy	_	_
design	_	_
procedure	_	_
is	_	_
followed	_	_
.	_	_

#131
Since	_	_
empty	_	_
pixels	_	_
nearby	_	_
valid	_	_
pixels	_	_
are	_	_
likely	_	_
to	_	_
share	_	_
similar	_	_
values	_	_
,	_	_
we	_	_
structure	_	_
the	_	_
order	_	_
of	_	_
the	_	_
algorithm	_	_
with	_	_
smaller	_	_
to	_	_
larger	_	_
hole	_	_
fills	_	_
.	_	_

#132
This	_	_
allows	_	_
the	_	_
area	_	_
of	_	_
effect	_	_
for	_	_
each	_	_
valid	_	_
pixel	_	_
to	_	_
increase	_	_
slowly	_	_
while	_	_
still	_	_
preserving	_	_
local	_	_
structure	_	_
.	_	_

#133
The	_	_
remaining	_	_
empty	_	_
areas	_	_
are	_	_
then	_	_
extrapolated	_	_
,	_	_
but	_	_
have	_	_
become	_	_
much	_	_
smaller	_	_
than	_	_
before	_	_
.	_	_

#134
A	_	_
final	_	_
blurring	_	_
step	_	_
is	_	_
used	_	_
to	_	_
reduce	_	_
output	_	_
noise	_	_
and	_	_
smooth	_	_
out	_	_
local	_	_
planes	_	_
.	_	_

#135
The	_	_
effect	_	_
of	_	_
design	_	_
choices	_	_
for	_	_
the	_	_
dilation	_	_
kernel	_	_
sizes	_	_
are	_	_
first	_	_
explored	_	_
,	_	_
followed	_	_
by	_	_
those	_	_
of	_	_
that	_	_
kernel’s	_	_
shape	_	_
,	_	_
and	_	_
finally	_	_
the	_	_
blurring	_	_
kernels	_	_
employed	_	_
after	_	_
dilation	_	_
.	_	_

#136
We	_	_
choose	_	_
the	_	_
best	_	_
result	_	_
of	_	_
each	_	_
experiment	_	_
to	_	_
continue	_	_
with	_	_
the	_	_
next	_	_
design	_	_
step	_	_
.	_	_

#137
Due	_	_
to	_	_
this	_	_
greedy	_	_
design	_	_
approach	_	_
,	_	_
the	_	_
first	_	_
two	_	_
experiments	_	_
on	_	_
kernel	_	_
size	_	_
and	_	_
shape	_	_
do	_	_
not	_	_
include	_	_
the	_	_
blurring	_	_
of	_	_
Step	_	_
7	_	_
.	_	_

#138
The	_	_
final	_	_
algorithm	_	_
design	_	_
uses	_	_
the	_	_
top	_	_
performing	_	_
designs	_	_
from	_	_
each	_	_
experiment	_	_
to	_	_
achieve	_	_
the	_	_
best	_	_
result	_	_
.	_	_

#139
Custom	_	_
Kernel	_	_
Design	_	_
:	_	_
The	_	_
design	_	_
of	_	_
the	_	_
initial	_	_
dilation	_	_
kernel	_	_
is	_	_
found	_	_
to	_	_
greatly	_	_
affect	_	_
the	_	_
performance	_	_
of	_	_
the	_	_
algorithm	_	_
.	_	_

#140
To	_	_
find	_	_
an	_	_
optimal	_	_
dilation	_	_
kernel	_	_
,	_	_
a	_	_
full	_	_
kernel	_	_
is	_	_
varied	_	_
between	_	_
3	_	_
×	_	_
3	_	_
,	_	_
5	_	_
×	_	_
5	_	_
,	_	_
and	_	_
7	_	_
×	_	_
7	_	_
sizes	_	_
.	_	_

#141
A	_	_
7	_	_
×	_	_
7	_	_
kernel	_	_
is	_	_
found	_	_
to	_	_
dilate	_	_
depth	_	_
values	_	_
past	_	_
their	_	_
actual	_	_
area	_	_
of	_	_
effect	_	_
,	_	_
while	_	_
a	_	_
3×3	_	_
kernel	_	_
dilation	_	_
does	_	_
not	_	_
expand	_	_
pixels	_	_
enough	_	_
to	_	_
allow	_	_
edges	_	_
to	_	_
be	_	_
connected	_	_
by	_	_
later	_	_
hole	_	_
closing	_	_
operations	_	_
.	_	_

#142
Table	_	_
II	_	_
shows	_	_
that	_	_
a	_	_
5	_	_
×	_	_
5	_	_
kernel	_	_
provides	_	_
the	_	_
lowest	_	_
RMSE	_	_
.	_	_

#143
Using	_	_
the	_	_
results	_	_
of	_	_
the	_	_
kernel	_	_
size	_	_
experiment	_	_
,	_	_
the	_	_
design	_	_
space	_	_
of	_	_
5	_	_
×	_	_
5	_	_
binary	_	_
kernel	_	_
shapes	_	_
is	_	_
explored	_	_
.	_	_

#144
A	_	_
full	_	_
kernel	_	_
is	_	_
used	_	_
as	_	_
a	_	_
baseline	_	_
,	_	_
and	_	_
compared	_	_
with	_	_
circular	_	_
,	_	_
cross	_	_
,	_	_
and	_	_
diamond	_	_
kernel	_	_
shapes	_	_
.	_	_

#145
The	_	_
shape	_	_
of	_	_
the	_	_
dilation	_	_
kernel	_	_
defines	_	_
the	_	_
initial	_	_
area	_	_
of	_	_
effect	_	_
for	_	_
each	_	_
pixel	_	_
.	_	_

#146
Table	_	_
II	_	_
shows	_	_
that	_	_
a	_	_
diamond	_	_
kernel	_	_
provides	_	_
the	_	_
lowest	_	_
RMSE	_	_
.	_	_

#147
The	_	_
diamond	_	_
kernel	_	_
shape	_	_
preserves	_	_
the	_	_
rough	_	_
outline	_	_
of	_	_
rounded	_	_
edges	_	_
,	_	_
while	_	_
being	_	_
large	_	_
enough	_	_
to	_	_
allow	_	_
edges	_	_
to	_	_
become	_	_
connected	_	_
by	_	_
the	_	_
next	_	_
hole	_	_
closing	_	_
operation	_	_
.	_	_

#148
It	_	_
should	deontic-rhetorical	_
be	_	_
noted	_	_
that	_	_
the	_	_
size	_	_
and	_	_
shape	_	_
of	_	_
the	_	_
dilation	_	_
kernel	_	_
is	_	_
not	_	_
found	_	_
to	_	_
have	_	_
a	_	_
significant	_	_
impact	_	_
on	_	_
runtime	_	_
.	_	_

#149
Noise	_	_
Reduction	_	_
through	_	_
Blurring	_	_
:	_	_
The	_	_
depth	_	_
map	_	_
output	_	_
contains	_	_
many	_	_
small	_	_
flat	_	_
planes	_	_
and	_	_
sharp	_	_
edges	_	_
due	_	_
to	_	_
the	_	_
Manhattan	_	_
[	_	_
21	_	_
]	_	_
nature	_	_
of	_	_
the	_	_
environment	_	_
,	_	_
and	_	_
the	_	_
series	_	_
of	_	_
binary	_	_
image	_	_
processing	_	_
operations	_	_
applied	_	_
during	_	_
the	_	_
previous	_	_
steps	_	_
.	_	_

#150
Furthermore	_	_
,	_	_
small	_	_
areas	_	_
of	_	_
outliers	_	_
may	options	_
be	_	_
dilated	_	_
,	_	_
providing	_	_
erroneous	_	_
patches	_	_
of	_	_
depth	_	_
values	_	_
.	_	_

#151
To	_	_
apply	_	_
smoothing	_	_
to	_	_
local	_	_
planes	_	_
,	_	_
round	_	_
off	_	_
object	_	_
edges	_	_
,	_	_
and	_	_
remove	_	_
outlier	_	_
depth	_	_
pixels	_	_
,	_	_
we	_	_
study	_	_
the	_	_
effect	_	_
of	_	_
median	_	_
,	_	_
bilateral	_	_
,	_	_
and	_	_
Gaussian	_	_
blurring	_	_
on	_	_
the	_	_
algorithm’s	_	_
performance	_	_
.	_	_

#152
Table	_	_
III	_	_
shows	_	_
the	_	_
effect	_	_
of	_	_
different	_	_
blur	_	_
methods	_	_
on	_	_
the	_	_
final	_	_
performance	_	_
of	_	_
the	_	_
algorithm	_	_
and	_	_
on	_	_
its	_	_
runtime	_	_
.	_	_

#153
A	_	_
median	_	_
blur	_	_
is	_	_
designed	_	_
to	_	_
remove	_	_
salt-and-pepper	_	_
noise	_	_
,	_	_
making	_	_
it	_	_
effective	_	_
in	_	_
removing	_	_
outlier	_	_
depth	_	_
values	_	_
.	_	_

#154
This	_	_
operation	_	_
adds	_	_
2	_	_
ms	_	_
to	_	_
the	_	_
runtime	_	_
,	_	_
but	_	_
the	_	_
improvement	_	_
Kernel	_	_
RMSE	_	_
(	_	_
mm	_	_
)	_	_
MAE	_	_
(	_	_
mm	_	_
)	_	_
Runtime	_	_
(	_	_
s	_	_
)	_	_
No	_	_
Blur	_	_
1512.18	_	_
333.67	_	_
0.007	_	_
Bilateral	_	_
Blur	_	_
1511.80	_	_
334.12	_	_
0.011	_	_
Median	_	_
Blur	_	_
1461.54	_	_
323.34	_	_
0.009	_	_
Median	_	_
+	_	_
Bilateral	_	_
Blur	_	_
1456.69	_	_
328.02	_	_
0.014	_	_
Gaussian	_	_
Blur	_	_
1360.06	_	_
310.39	_	_
0.008	_	_
Median	_	_
+	_	_
Gaussian	_	_
Blur	_	_
1350.93	_	_
305.35	_	_
0.011	_	_
Table	_	_
III	_	_
:	_	_
Effect	_	_
of	_	_
blurring	_	_
.	_	_

#155
Original	_	_
LIDAR	_	_
Sparse	_	_
Point	_	_
Cloud	_	_
Our	_	_
Algorithm	_	_
s	_	_
Dense	_	_
Point	_	_
Cloud	_	_
Output	_	_
(	_	_
Bilateral	_	_
Blur	_	_
)	_	_
Our	_	_
Algorithm	_	_
s	_	_
Dense	_	_
Point	_	_
Cloud	_	_
Output	_	_
(	_	_
Gaussian	_	_
Blur	_	_
)	_	_
Figure	_	_
5	_	_
:	_	_
Qualitative	_	_
results	_	_
of	_	_
the	_	_
application	_	_
of	_	_
our	_	_
algorithm	_	_
on	_	_
LIDAR	_	_
point	_	_
clouds	_	_
using	_	_
both	_	_
bilateral	_	_
and	_	_
Gaussian	_	_
blur	_	_
kernels	_	_
.	_	_

#156
Points	_	_
have	_	_
been	_	_
colourized	_	_
using	_	_
the	_	_
RGB	_	_
image	_	_
for	_	_
easier	_	_
visualization	_	_
.	_	_

#157
It	_	_
can	_	_
be	_	_
seen	_	_
that	_	_
ground	_	_
truth	_	_
object	_	_
detection	_	_
bounding	_	_
boxes	_	_
in	_	_
red	_	_
have	_	_
much	_	_
more	_	_
points	_	_
in	_	_
the	_	_
dense	_	_
point	_	_
cloud	_	_
.	_	_

#158
can	_	_
be	_	_
seen	_	_
through	_	_
a	_	_
decrease	_	_
in	_	_
both	_	_
RMSE	_	_
and	_	_
MAE	_	_
.	_	_

#159
A	_	_
bilateral	_	_
blur	_	_
preserves	_	_
local	_	_
structure	_	_
by	_	_
only	_	_
blurring	_	_
pixels	_	_
with	_	_
other	_	_
nearby	_	_
pixels	_	_
having	_	_
similar	_	_
values	_	_
,	_	_
and	_	_
has	_	_
minimal	_	_
effect	_	_
on	_	_
the	_	_
evaluated	_	_
RMSE	_	_
and	_	_
MAE	_	_
metrics	_	_
,	_	_
while	_	_
adding	_	_
4	_	_
ms	_	_
to	_	_
the	_	_
runtime	_	_
.	_	_

#160
Due	_	_
to	_	_
the	_	_
Euclidean	_	_
calculation	_	_
of	_	_
the	_	_
RMSE	_	_
metric	_	_
,	_	_
a	_	_
Gaussian	_	_
blur	_	_
reduces	_	_
RMS	_	_
errors	_	_
significantly	_	_
by	_	_
minimizing	_	_
the	_	_
effect	_	_
of	_	_
outlier	_	_
pixel	_	_
depths	_	_
.	_	_

#161
The	_	_
Gaussian	_	_
blur	_	_
also	_	_
runs	_	_
fastest	_	_
,	_	_
adding	_	_
only	_	_
1	_	_
ms	_	_
to	_	_
the	_	_
average	_	_
runtime	_	_
.	_	_

#162
The	_	_
final	_	_
algorithm	_	_
employs	_	_
a	_	_
combined	_	_
median	_	_
and	_	_
Gaussian	_	_
blur	_	_
as	_	_
this	_	_
combination	_	_
is	_	_
shown	_	_
to	_	_
provide	_	_
the	_	_
lowest	_	_
RMSE	_	_
.	_	_

#163
Figure	_	_
5	_	_
shows	_	_
the	_	_
results	_	_
of	_	_
running	_	_
the	_	_
algorithm	_	_
with	_	_
two	_	_
different	_	_
blurring	_	_
kernels	_	_
on	_	_
a	_	_
projected	_	_
point	_	_
cloud	_	_
from	_	_
a	_	_
sample	_	_
in	_	_
the	_	_
KITTI	_	_
object	_	_
detection	_	_
benchmark	_	_
.	_	_

#164
The	_	_
steps	_	_
of	_	_
extending	_	_
depth	_	_
values	_	_
to	_	_
the	_	_
top	_	_
of	_	_
frame	_	_
and	_	_
large	_	_
hole	_	_
filling	_	_
are	_	_
skipped	_	_
since	_	_
they	_	_
introduce	_	_
a	_	_
large	_	_
number	_	_
of	_	_
extrapolated	_	_
depth	_	_
values	_	_
.	_	_

#165
For	_	_
applications	_	_
where	_	_
a	_	_
fully	_	_
dense	_	_
depth	_	_
map	_	_
is	_	_
not	_	_
required	_	_
,	_	_
it	_	_
is	_	_
recommended	_	_
to	_	_
limit	_	_
both	_	_
the	_	_
upward	_	_
extension	_	_
per	_	_
column	_	_
and	_	_
dilation	_	_
kernel	_	_
size	_	_
.	_	_

#166
While	_	_
the	_	_
Gaussian	_	_
blur	_	_
version	_	_
provides	_	_
the	_	_
lowest	_	_
RMSE	_	_
,	_	_
it	_	_
also	_	_
introduces	_	_
many	_	_
additional	_	_
3D	_	_
points	_	_
to	_	_
the	_	_
scene	_	_
.	_	_

#167
The	_	_
bilateral	_	_
blur	_	_
version	_	_
preserves	_	_
the	_	_
local	_	_
structure	_	_
of	_	_
objects	_	_
and	_	_
is	_	_
recommended	_	_
for	_	_
practical	_	_
applications	_	_
.	_	_

#168
It	_	_
should	deontic-rhetorical	_
be	_	_
noted	_	_
that	_	_
the	_	_
points	_	_
are	_	_
colourized	_	_
using	_	_
the	_	_
RGB	_	_
image	_	_
,	_	_
but	_	_
image	_	_
data	_	_
is	_	_
not	_	_
used	_	_
in	_	_
our	_	_
unguided	_	_
approach	_	_
.	_	_

#169
An	_	_
accurate	_	_
,	_	_
denser	_	_
point	_	_
cloud	_	_
can	_	_
be	_	_
helpful	_	_
for	_	_
3D	_	_
object	_	_
detection	_	_
methods	_	_
[	_	_
2	_	_
]	_	_
,	_	_
[	_	_
6	_	_
]	_	_
,	_	_
[	_	_
22	_	_
]	_	_
which	_	_
rely	_	_
on	_	_
point	_	_
cloud	_	_
data	_	_
for	_	_
both	_	_
object	_	_
classification	_	_
and	_	_
localization	_	_
.	_	_

#170
After	_	_
depth	_	_
completion	_	_
,	_	_
it	_	_
can	_	_
be	_	_
seen	_	_
that	_	_
ground	_	_
truth	_	_
labelled	_	_
objects	_	_
contain	_	_
many	_	_
more	_	_
points	_	_
.	_	_

#171
The	_	_
structure	_	_
of	_	_
the	_	_
cars	_	_
and	_	_
road	_	_
scene	_	_
become	_	_
much	_	_
clearer	_	_
,	_	_
and	_	_
this	_	_
is	_	_
especially	_	_
noticeable	_	_
for	_	_
the	_	_
objects	_	_
farther	_	_
away	_	_
.	_	_

#172
More	_	_
qualitative	_	_
results	_	_
are	_	_
available	_	_
in	_	_
video	_	_
format	_	_
at	_	_
https	_	_
:	_	_
//youtu.be/t	_	_
CGGUE2kEM	_	_
.	_	_

#173
VI	_	_
.	_	_

#174
CONCLUSION	_	_
In	_	_
this	_	_
work	_	_
,	_	_
we	_	_
propose	_	_
a	_	_
depth	_	_
completion	_	_
algorithm	_	_
that	_	_
takes	_	_
as	_	_
an	_	_
input	_	_
a	_	_
sparse	_	_
depth	_	_
map	_	_
to	_	_
output	_	_
a	_	_
dense	_	_
depth	_	_
map	_	_
.	_	_

#175
Our	_	_
proposed	_	_
algorithm	_	_
uses	_	_
only	_	_
traditional	_	_
image	_	_
processing	_	_
techniques	_	_
and	_	_
requires	_	_
no	_	_
training	_	_
,	_	_
making	_	_
it	_	_
robust	_	_
to	_	_
overfitting	_	_
.	_	_

#176
We	_	_
show	_	_
that	_	_
our	_	_
image	_	_
processing	_	_
based	_	_
algorithm	_	_
provides	_	_
state	_	_
of	_	_
the	_	_
art	_	_
results	_	_
on	_	_
the	_	_
KITTI	_	_
depth	_	_
completion	_	_
benchmark	_	_
,	_	_
outperforming	_	_
several	_	_
learning-based	_	_
methods	_	_
.	_	_

#177
Our	_	_
algorithm	_	_
also	_	_
runs	_	_
in	_	_
real	_	_
time	_	_
at	_	_
90	_	_
Hz	_	_
and	_	_
does	_	_
not	_	_
require	_	_
any	_	_
additional	_	_
GPU	_	_
hardware	_	_
,	_	_
making	_	_
it	_	_
a	_	_
competitive	_	_
candidate	_	_
to	_	_
be	_	_
deployed	_	_
on	_	_
embedded	_	_
systems	_	_
as	_	_
a	_	_
preprocessing	_	_
step	_	_
for	_	_
more	_	_
complex	_	_
tasks	_	_
such	_	_
as	_	_
SLAM	_	_
or	_	_
3D	_	_
object	_	_
detection	_	_
.	_	_

#178
Finally	_	_
,	_	_
this	_	_
work	_	_
is	_	_
not	_	_
meant	_	_
to	_	_
undermine	_	_
the	_	_
power	_	_
of	_	_
deep	_	_
learning	_	_
systems	_	_
,	_	_
but	_	_
rather	_	_
to	_	_
shed	_	_
light	_	_
on	_	_
the	_	_
current	_	_
trend	_	_
in	_	_
literature	_	_
,	_	_
where	_	_
classical	_	_
methods	_	_
are	_	_
not	_	_
carefully	_	_
considered	_	_
for	_	_
comparison	_	_
although	_	_
they	_	_
can	_	_
become	_	_
powerful	_	_
baselines	_	_
if	_	_
designed	_	_
properly	_	_
.	_	_