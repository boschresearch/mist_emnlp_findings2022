#0
CLOUD	_	_
DETECTION	_	_
FROM	_	_
RGB	_	_
COLOR	_	_
REMOTE	_	_
SENSING	_	_
IMAGES	_	_
WITH	_	_
DEEP	_	_
PYRAMID	_	_
NETWORKS	_	_
Savas	_	_
Ozkan	_	_
,	_	_
Mehmet	_	_
Efendioglu	_	_
,	_	_
Caner	_	_
Demirpolat	_	_
TUBITAK	_	_
Space	_	_
Technologies	_	_
Research	_	_
Institute	_	_
Remote	_	_
Sensing	_	_
Group	_	_
Ankara	_	_
,	_	_
Turkey	_	_
{	_	_
savas.ozkan	_	_
,	_	_
mehmet.efendioglu	_	_
,	_	_
caner.demirpolat	_	_
}	_	_
@	_	_
tubitak.gov.tr	_	_
ABSTRACT	_	_
Cloud	_	_
detection	_	_
from	_	_
remotely	_	_
observed	_	_
data	_	_
is	_	_
a	_	_
critical	_	_
pre-processing	_	_
step	_	_
for	_	_
various	_	_
remote	_	_
sensing	_	_
applications	_	_
.	_	_

#1
In	_	_
particular	_	_
,	_	_
this	_	_
problem	_	_
becomes	_	_
even	_	_
harder	_	_
for	_	_
RGB	_	_
color	_	_
images	_	_
,	_	_
since	_	_
there	_	_
is	_	_
no	_	_
distinct	_	_
spectral	_	_
pattern	_	_
for	_	_
clouds	_	_
,	_	_
which	_	_
is	_	_
directly	_	_
separable	_	_
from	_	_
the	_	_
Earth	_	_
surface	_	_
.	_	_

#2
In	_	_
this	_	_
paper	_	_
,	_	_
we	_	_
adapt	_	_
a	_	_
deep	_	_
pyramid	_	_
network	_	_
(	_	_
DPN	_	_
)	_	_
to	_	_
tackle	_	_
this	_	_
problem	_	_
.	_	_

#3
For	_	_
this	_	_
purpose	_	_
,	_	_
the	_	_
network	_	_
is	_	_
enhanced	_	_
with	_	_
a	_	_
pre-trained	_	_
parameter	_	_
model	_	_
at	_	_
the	_	_
encoder	_	_
layer	_	_
.	_	_

#4
Moreover	_	_
,	_	_
the	_	_
method	_	_
is	_	_
able	_	_
to	_	_
obtain	_	_
accurate	_	_
pixel-level	_	_
segmentation	_	_
and	_	_
classification	_	_
results	_	_
from	_	_
a	_	_
set	_	_
of	_	_
noisy	_	_
labeled	_	_
RGB	_	_
color	_	_
images	_	_
.	_	_

#5
In	_	_
order	_	_
to	_	_
demonstrate	_	_
the	_	_
superiority	_	_
of	_	_
the	_	_
method	_	_
,	_	_
we	_	_
collect	_	_
and	_	_
label	_	_
data	_	_
with	_	_
the	_	_
corresponding	_	_
cloud/non-cloudy	_	_
masks	_	_
acquired	_	_
from	_	_
low-orbit	_	_
Gokturk-2	_	_
and	_	_
RASAT	_	_
satellites	_	_
.	_	_

#6
The	_	_
experimental	_	_
results	_	_
validates	_	_
that	_	_
the	_	_
proposed	_	_
method	_	_
outperforms	_	_
several	_	_
baselines	_	_
even	_	_
for	_	_
hard	_	_
cases	_	_
(	_	_
e.g.	_	_
snowy	_	_
mountains	_	_
)	_	_
that	_	_
are	_	_
perceptually	_	_
difficult	_	_
to	_	_
distinguish	_	_
by	_	_
human	_	_
eyes	_	_
.	_	_

#7
Index	_	_
Terms—	_	_
Cloud	_	_
Detection	_	_
,	_	_
Deep	_	_
Pyramid	_	_
Networks	_	_
1	_	_
.	_	_

#8
INTRODUCTION	_	_
The	_	_
presence	_	_
of	_	_
clouds	_	_
due	_	_
to	_	_
climate	_	_
factors	_	_
limits	_	_
the	_	_
clear	_	_
acquisition	_	_
of	_	_
content	_	_
information	_	_
from	_	_
the	_	_
Earth	_	_
surface	_	_
for	_	_
almost	_	_
all	_	_
optical	_	_
sensors	_	_
.	_	_

#9
Ultimately	_	_
,	_	_
this	_	_
reduces	_	_
the	_	_
visibility	_	_
and	_	_
affects	_	_
adversely	_	_
the	_	_
processing	_	_
of	_	_
data	_	_
for	_	_
many	_	_
remote	_	_
sensing	_	_
applications	_	_
such	_	_
as	_	_
classification	_	_
,	_	_
segmentation	_	_
and	_	_
change	_	_
detection	_	_
etc	_	_
.	_	_

#10
Hence	_	_
,	_	_
detection/elimination	_	_
of	_	_
cloudy	_	_
coverages	_	_
constitutes	_	_
an	_	_
important	_	_
pre-processing	_	_
step	_	_
for	_	_
remote	_	_
sensing	_	_
.	_	_

#11
In	_	_
particular	_	_
,	_	_
RGB	_	_
color	_	_
bands	_	_
are	_	_
more	_	_
sensitive	_	_
to	_	_
these	_	_
atmospheric	_	_
scattering	_	_
conditions	_	_
compared	_	_
to	_	_
the	_	_
high	_	_
wavelength	_	_
sensors	_	_
(	_	_
i.e.	_	_
infrared/multi-spectral	_	_
)	_	_
[	_	_
1	_	_
]	_	_
.	_	_

#12
Thus	_	_
,	_	_
this	_	_
problem	_	_
becomes	_	_
even	_	_
harder	_	_
and	_	_
the	_	_
spatial	_	_
content	_	_
of	_	_
the	_	_
image	_	_
needs	_	_
to	_	_
be	_	_
leveraged	_	_
rather	_	_
than	_	_
singly	_	_
spectral	_	_
properties	_	_
of	_	_
clouds	_	_
as	_	_
in	_	_
multi-spectral/infrared	_	_
sensors	_	_
.	_	_

#13
For	_	_
this	_	_
Project	_	_
Website	_	_
:	_	_
https	_	_
:	_	_
//github.com/savasozkan/cloud_	_	_
detection	_	_
reason	_	_
,	_	_
addressing	_	_
the	_	_
problem	_	_
from	_	_
the	_	_
perspective	_	_
of	_	_
object	_	_
segmentation	_	_
and	_	_
classification	_	_
can	_	_
yield	_	_
more	_	_
intuitive	_	_
results	_	_
.	_	_

#14
Moreover	_	_
,	_	_
more	_	_
generalized	_	_
solutions	_	_
,	_	_
i.e.	_	_
instead	_	_
of	_	_
sensor-specific	_	_
rules/thresholds	_	_
,	_	_
can	_	_
be	_	_
presented	_	_
[	_	_
2	_	_
,	_	_
3	_	_
]	_	_
.	_	_

#15
In	_	_
this	_	_
paper	_	_
,	_	_
we	_	_
tackle	_	_
the	_	_
cloud	_	_
detection	_	_
problem	_	_
by	_	_
presenting	_	_
a	_	_
framework	_	_
based	_	_
on	_	_
deep	_	_
pyramid	_	_
network	_	_
architecture	_	_
(	_	_
DPN	_	_
)	_	_
[	_	_
4	_	_
,	_	_
5	_	_
]	_	_
.	_	_

#16
Compared	_	_
to	_	_
the	_	_
existing	_	_
rule-based	_	_
methods	_	_
[	_	_
6	_	_
,	_	_
7	_	_
,	_	_
8	_	_
,	_	_
9	_	_
]	_	_
,	_	_
the	_	_
proposed	_	_
method	_	_
exploits	_	_
texture	_	_
information	_	_
exhibited	_	_
from	_	_
cloudy/non-cloudy	_	_
pixels	_	_
with	_	_
high-level	_	_
features	_	_
.	_	_

#17
This	_	_
improves	_	_
classification	_	_
decisions	_	_
without	_	_
the	_	_
need	_	_
of	_	_
any	_	_
specific	_	_
spectral	_	_
information	_	_
,	_	_
since	_	_
a	_	_
pre-trained	_	_
encoder	_	_
network	_	_
is	_	_
capable	_	_
of	_	_
extracting	_	_
rich	_	_
and	_	_
distinct	_	_
high-level	_	_
representations	_	_
for	_	_
visual	_	_
objects	_	_
in	_	_
the	_	_
images	_	_
.	_	_

#18
Moreover	_	_
,	_	_
due	_	_
to	_	_
the	_	_
architecture	_	_
,	_	_
the	_	_
network	_	_
is	_	_
concurrently	_	_
optimized	_	_
for	_	_
both	_	_
segmentation	_	_
and	_	_
classification	_	_
phases	_	_
.	_	_

#19
Lastly	_	_
,	_	_
since	_	_
the	_	_
ground	_	_
truth	_	_
cloud	_	_
masks	_	_
are	_	_
quite	_	_
noisy	_	_
(	_	_
i.e.	_	_
achieving	_	_
perfect	_	_
pixel-level	_	_
annotations	_	_
is	_	_
quite	_	_
difficult	_	_
[	_	_
10	_	_
]	_	_
)	_	_
,	_	_
use	_	_
of	_	_
a	_	_
pre-trained	_	_
model	_	_
for	_	_
the	_	_
abstract	_	_
representation	_	_
of	_	_
an	_	_
input	_	_
provides	_	_
robustness	_	_
to	_	_
the	_	_
overall	_	_
segmentation	_	_
and	_	_
classification	_	_
phases	_	_
.	_	_

#20
Rest	_	_
of	_	_
the	_	_
paper	_	_
is	_	_
organized	_	_
as	_	_
follows	_	_
:	_	_
related	_	_
works	_	_
are	_	_
reviewed	_	_
in	_	_
Section	_	_
2	_	_
.	_	_

#21
Section	_	_
3	_	_
is	_	_
reserved	_	_
for	_	_
the	_	_
detail	_	_
of	_	_
the	_	_
proposed	_	_
method	_	_
and	_	_
the	_	_
problem	_	_
statement	_	_
.	_	_

#22
Experimental	_	_
results	_	_
,	_	_
dataset	_	_
and	_	_
baseline	_	_
methods	_	_
are	_	_
explained	_	_
in	_	_
Section	_	_
4	_	_
and	_	_
the	_	_
paper	_	_
is	_	_
concluded	_	_
in	_	_
Section	_	_
5	_	_
.	_	_

#23
2	_	_
.	_	_

#24
RELATED	_	_
WORK	_	_
In	_	_
this	_	_
section	_	_
,	_	_
we	_	_
review	_	_
the	_	_
literature	_	_
for	_	_
RGB	_	_
color	_	_
satellite	_	_
images	_	_
as	_	_
well	_	_
as	_	_
other	_	_
optical	_	_
sensors	_	_
such	_	_
as	_	_
multispectral/infrared	_	_
to	_	_
demonstrate	_	_
the	_	_
complexity	_	_
of	_	_
the	_	_
problem	_	_
for	_	_
visible	_	_
domain	_	_
.	_	_

#25
The	_	_
methods	_	_
used	_	_
for	_	_
multi/infrared	_	_
bands	_	_
are	_	_
frequently	_	_
based	_	_
on	_	_
radiometric	_	_
properties	_	_
of	_	_
clouds/surface	_	_
as	_	_
reflectance	_	_
and	_	_
temperature	_	_
.	_	_

#26
[	_	_
6	_	_
,	_	_
7	_	_
]	_	_
exploit	_	_
the	_	_
variations	_	_
of	_	_
reflectance	_	_
in	_	_
thermal	_	_
bands	_	_
to	_	_
distinguish	_	_
clouds	_	_
from	_	_
the	_	_
surface	_	_
.	_	_

#27
Harb	_	_
et	_	_
.	_	_

#28
al	_	_
.	_	_

#29
[	_	_
8	_	_
]	_	_
propose	_	_
a	_	_
processing	_	_
chain	_	_
based	_	_
on	_	_
the	_	_
thermal	_	_
pattern	_	_
of	_	_
clouds	_	_
with	_	_
morphological	_	_
filtrations	_	_
.	_	_

#30
Similarly	_	_
,	_	_
Braaten	_	_
et	_	_
.	_	_

#31
al	_	_
.	_	_

#32
[	_	_
9	_	_
]	_	_
extend	_	_
the	_	_
assumption	_	_
to	_	_
multi-spectral	_	_
data	_	_
.	_	_

#33
However	_	_
,	_	_
these	_	_
methods	_	_
highly	_	_
depend	_	_
on	_	_
sensor	_	_
models	_	_
(	_	_
i.e.	_	_
since	_	_
they	_	_
are	_	_
rule-based	_	_
methods	_	_
)	_	_
and	_	_
ar	_	_
X	_	_
iv	_	_
:1	_	_
1	_	_
.	_	_

#34
6v	_	_
1	_	_
[	_	_
cs	_	_
.C	_	_
V	_	_
]	_	_
2	_	_
6	_	_
Ja	_	_
n	_	_
Fig.	_	_
1	_	_
.	_	_

#35
Deep	_	_
Pyramid	_	_
Network	_	_
with	_	_
Encoder	_	_
and	_	_
Generator	_	_
filter	_	_
blocks	_	_
.	_	_

#36
the	_	_
derived	_	_
solution	_	_
can	_	_
not	_	_
be	_	_
generalized	_	_
to	_	_
different	_	_
sensors	_	_
by	_	_
using	_	_
similar	_	_
assumptions	_	_
for	_	_
band	_	_
information	_	_
.	_	_

#37
Differently	_	_
,	_	_
multi-temporal	_	_
methods	_	_
aim	_	_
to	_	_
detect	_	_
clouds	_	_
based	_	_
on	_	_
background	_	_
changes	_	_
in	_	_
time	_	_
by	_	_
which	_	_
data	_	_
is	_	_
acquired	_	_
in	_	_
different	_	_
time-instances	_	_
.	_	_

#38
Zhu	_	_
et	_	_
.	_	_

#39
al	_	_
.	_	_

#40
[	_	_
11	_	_
]	_	_
combine	_	_
the	_	_
thermal	_	_
cloud	_	_
patterns	_	_
with	_	_
time-series	_	_
data	_	_
to	_	_
detect	_	_
more	_	_
accurate	_	_
cloud	_	_
masks	_	_
.	_	_

#41
Moreover	_	_
,	_	_
the	_	_
method	_	_
[	_	_
12	_	_
]	_	_
uses	_	_
temporal	_	_
data	_	_
to	_	_
estimate	_	_
clouds	_	_
with	_	_
a	_	_
non-linear	_	_
regression	_	_
algorithm	_	_
.	_	_

#42
However	_	_
,	_	_
the	_	_
main	_	_
limitation	_	_
of	_	_
the	_	_
methods	_	_
is	_	_
that	_	_
the	_	_
time	_	_
series	_	_
of	_	_
data	_	_
are	_	_
assumed	_	_
to	_	_
possess	_	_
smooth	_	_
variations	_	_
on	_	_
ground	_	_
surfaces	_	_
while	_	_
abrupt	_	_
changes	_	_
for	_	_
clouds	_	_
.	_	_

#43
Furthermore	_	_
,	_	_
recording	_	_
such	_	_
dense	_	_
data	_	_
practically	_	_
increase	_	_
the	_	_
operational	_	_
cost	_	_
.	_	_

#44
In	_	_
order	_	_
to	_	_
generalize	_	_
the	_	_
solution	_	_
,	_	_
classification-based	_	_
approaches	_	_
learn	_	_
a	_	_
set	_	_
of	_	_
parameters	_	_
from	_	_
training	_	_
samples	_	_
to	_	_
distinguish	_	_
clouds	_	_
from	_	_
the	_	_
surface	_	_
.	_	_

#45
Hu	_	_
et	_	_
.	_	_

#46
al	_	_
.	_	_

#47
[	_	_
2	_	_
]	_	_
extract	_	_
several	_	_
low-level	_	_
features	_	_
such	_	_
as	_	_
color	_	_
,	_	_
texture	_	_
features	_	_
etc	_	_
.	_	_

#48
to	_	_
estimate	_	_
pixel-level	_	_
masks	_	_
.	_	_

#49
Recently	_	_
,	_	_
[	_	_
3	_	_
]	_	_
classifies	_	_
locally	_	_
sampled	_	_
patches	_	_
(	_	_
i.e.	_	_
by	_	_
a	_	_
Super-Pixel	_	_
(	_	_
SP	_	_
)	_	_
algorithm	_	_
)	_	_
with	_	_
a	_	_
Convolutional	_	_
Neural	_	_
Network	_	_
(	_	_
CNN	_	_
)	_	_
as	_	_
cloud	_	_
or	_	_
non-cloud	_	_
.	_	_

#50
3	_	_
.	_	_

#51
CLOUD	_	_
DETECTION	_	_
WITH	_	_
PYRAMID	_	_
NETWORKS	_	_
As	_	_
mentioned	_	_
,	_	_
since	_	_
there	_	_
is	_	_
no	_	_
explicit	_	_
spectral/physical	_	_
pattern	_	_
for	_	_
clouds	_	_
in	_	_
RGB	_	_
color	_	_
satellite	_	_
images	_	_
,	_	_
we	_	_
treat	_	_
the	_	_
problem	_	_
as	_	_
an	_	_
object	_	_
segmentation	_	_
and	_	_
classification	_	_
problem	_	_
in	_	_
order	_	_
to	_	_
make	_	_
a	_	_
realistic	_	_
problem	_	_
formulation	_	_
.	_	_

#52
In	_	_
particular	_	_
,	_	_
the	_	_
texture	_	_
details	_	_
around	_	_
cloudy	_	_
regions	_	_
indicate	_	_
distinct	_	_
visual	_	_
patterns	_	_
for	_	_
detection/segmentation	_	_
phases	_	_
.	_	_

#53
Our	_	_
aim	_	_
is	_	_
to	_	_
extract	_	_
high-level	_	_
abstract	_	_
representations	_	_
from	_	_
data	_	_
and	_	_
iteratively	_	_
merge	_	_
them	_	_
to	_	_
make	_	_
pixel-level	_	_
classification	_	_
decisions	_	_
.	_	_

#54
Moreover	_	_
,	_	_
the	_	_
proposed	_	_
method	_	_
is	_	_
able	_	_
to	_	_
compute	_	_
segmentation	_	_
and	_	_
classification	_	_
phases	_	_
concurrently	_	_
to	_	_
optimize	_	_
the	_	_
network	_	_
in	_	_
an	_	_
end-to-end	_	_
learning	_	_
manner	_	_
,	_	_
thus	_	_
there	_	_
is	_	_
no	_	_
need	_	_
to	_	_
employ	_	_
these	_	_
layers	_	_
separately	_	_
as	_	_
in	_	_
[	_	_
3	_	_
]	_	_
.	_	_

#55
3.1.	_	_
Formulation	_	_

#56
Suppose	_	_
we	_	_
are	_	_
given	_	_
a	_	_
RGB	_	_
color	_	_
satellite	_	_
image	_	_
x	_	_
∈	_	_
RW×H×3	_	_
and	_	_
the	_	_
method	_	_
aims	_	_
to	_	_
generate	_	_
an	_	_
image	_	_
mask	_	_
y	_	_
∈	_	_
RW×H×2	_	_
that	_	_
implicitly	_	_
corresponds	_	_
to	_	_
two	_	_
channel	_	_
classification	_	_
decisions	_	_
for	_	_
ground	_	_
surface	_	_
and	_	_
cloud/haze	_	_
coverages	_	_
.	_	_

#57
Therefore	_	_
,	_	_
the	_	_
main	_	_
objective	_	_
is	_	_
to	_	_
learn	_	_
a	_	_
set	_	_
of	_	_
parameters	_	_
θc	_	_
and	_	_
θg	_	_
for	_	_
encoder	_	_
and	_	_
generator	_	_
functions	_	_
C	_	_
(	_	_
.	_	_
)	_	_
and	_	_
G	_	_
(	_	_
.	_	_
)	_	_
such	_	_
that	_	_
the	_	_
input-target	_	_
error	_	_
should	deontic-rhetorical	_
be	_	_
minimized	_	_
for	_	_
a	_	_
set	_	_
of	_	_
training	_	_
pairs	_	_
{	_	_
xi	_	_
,	_	_
yi	_	_
}	_	_
based	_	_
on	_	_
a	_	_
loss	_	_
function	_	_
:	_	_
L	_	_
=	_	_
−	_	_
1	_	_
N	_	_
∑	_	_
i	_	_
yi	_	_
log	_	_
(	_	_
pi	_	_
)	_	_
(	_	_
1	_	_
)	_	_
where	_	_
pi	_	_
=	_	_
G	_	_
(	_	_
C	_	_
(	_	_
xi	_	_
,	_	_
θc	_	_
)	_	_
,	_	_
θg	_	_
)	_	_
is	_	_
the	_	_
mask	_	_
prediction	_	_
of	_	_
the	_	_
network	_	_
for	_	_
the	_	_
input	_	_
xi	_	_
.	_	_

#58
The	_	_
softmax	_	_
cross-entropy	_	_
loss	_	_
in	_	_
Eq.	_	_
1	_	_
maximizes	_	_
the	_	_
similarity	_	_
of	_	_
optimum	_	_
input-target	_	_
transformation	_	_
.	_	_

#59
Moreover	_	_
,	_	_
N	_	_
corresponds	_	_
to	_	_
the	_	_
mini-batch	_	_
size	_	_
.	_	_

#60
In	_	_
the	_	_
inference	_	_
stage	_	_
,	_	_
the	_	_
decisions	_	_
of	_	_
cloudy/non-cloudy	_	_
coverages	_	_
are	_	_
computed	_	_
based	_	_
on	_	_
the	_	_
outputs	_	_
of	_	_
these	_	_
learned	_	_
functions	_	_
.	_	_

#61
3.2	_	_
.	_	_

#62
Architecture	_	_
Our	_	_
deep	_	_
network	_	_
architecture	_	_
consists	_	_
of	_	_
two	_	_
main	_	_
filter	_	_
blocks	_	_
[	_	_
4	_	_
,	_	_
5	_	_
]	_	_
.	_	_

#63
First	_	_
,	_	_
encoder	_	_
block	_	_
C	_	_
(	_	_
.	_	_
)	_	_

#64
extracts	_	_
robust	_	_
abstract	_	_
representations	_	_
from	_	_
a	_	_
RGB	_	_
color	_	_
image	_	_
.	_	_

#65
Then	_	_
,	_	_
generator	_	_
block	_	_
G	_	_
(	_	_
.	_	_
)	_	_

#66
computes	_	_
pixel-level	_	_
segmentation	_	_
and	_	_
classification	_	_
masks	_	_
according	_	_
to	_	_
the	_	_
responses	_	_
of	_	_
the	_	_
encoder	_	_
block	_	_
.	_	_

#67
The	_	_
overall	_	_
architecture	_	_
is	_	_
illustrated	_	_
in	_	_
Figure	_	_
1	_	_
.	_	_

#68
Encoder	_	_
:	_	_
Encoder	_	_
block	_	_
takes	_	_
an	_	_
image	_	_
as	_	_
input	_	_
and	_	_
iteratively	_	_
computes	_	_
abstract	_	_
representations	_	_
by	_	_
down-sampling	_	_
responses	_	_
.	_	_

#69
Practically	_	_
,	_	_
the	_	_
goal	_	_
of	_	_
the	_	_
block	_	_
is	_	_
to	_	_
unveil	_	_
distinct	_	_
patterns	_	_
about	_	_
data	_	_
which	_	_
assist	_	_
the	_	_
generator	_	_
so	_	_
as	_	_
to	_	_
obtain	_	_
an	_	_
optimal	_	_
image	_	_
mask	_	_
.	_	_

#70
Moreover	_	_
,	_	_
information	_	_
flows	_	_
to	_	_
the	_	_
generator	_	_
are	_	_
maximized	_	_
with	_	_
skip-connections	_	_
[	_	_
13	_	_
]	_	_
.	_	_

#71
Throughout	_	_
the	_	_
paper	_	_
,	_	_
we	_	_
experimented	_	_
with	_	_
two	_	_
different	_	_
encoder	_	_
models	_	_
:	_	_
•	_	_
First	_	_
,	_	_
a	_	_
model	_	_
with	_	_
5	_	_
convolutional	_	_
layers	_	_
and	_	_
random	_	_
parameter	_	_
initialization	_	_
is	_	_
used	_	_
.	_	_

#72
At	_	_
each	_	_
layer	_	_
,	_	_
we	_	_
employ	_	_
a	_	_
batch	_	_
normalization	_	_
layer	_	_
and	_	_
an	_	_
activation	_	_
function	_	_
,	_	_
i.e.	_	_
ReLU	_	_
,	_	_
after	_	_
a	_	_
convolution	_	_
layer	_	_
.	_	_

#73
Later	_	_
,	_	_
we	_	_
down-sample	_	_
the	_	_
responses	_	_
with	_	_
stride	_	_
2	_	_
.	_	_

#74
However	_	_
,	_	_
we	_	_
found	_	_
out	_	_
that	_	_
the	_	_
random	_	_
initialization	_	_
lacks	_	_
to	_	_
reach	_	_
an	_	_
optimal	_	_
solution	_	_
due	_	_
to	_	_
the	_	_
fact	_	_
that	_	_
ground	_	_
truth	_	_
unwillingly	_	_
contains	_	_
noisy	_	_
labels	_	_
by	_	_
omission	_	_
and/or	_	_
registration	_	_
noise	_	_
during	_	_
labeling	_	_
[	_	_
10	_	_
]	_	_
.	_	_

#75
This	_	_
ultimately	_	_
affects	_	_
adversely	_	_
the	_	_
parameters	_	_
at	_	_
the	_	_
end	_	_
and	_	_
the	_	_
parameters	_	_
(	_	_
i.e.	_	_
θc	_	_
)	_	_
tend	_	_
to	_	_
generate	_	_
false-alarms	_	_
in	_	_
the	_	_
inference	_	_
stage	_	_
.	_	_

#76
•	_	_
We	_	_
use	_	_
the	_	_
convolutional	_	_
responses	_	_
of	_	_
a	_	_
pre-trained	_	_
model	_	_
,	_	_
i.e.	_	_
‘conv1	_	_
2’	_	_
,	_	_
‘conv2	_	_
2’	_	_
,	_	_
‘conv3	_	_
2’	_	_
,	_	_
‘conv4	_	_
2’	_	_
and	_	_
‘conv5	_	_
2’	_	_
in	_	_
VGG-19	_	_
[	_	_
14	_	_
]	_	_
,	_	_
and	_	_
no	_	_
finetuning	_	_
is	_	_
allowed	_	_
for	_	_
the	_	_
encoder	_	_
layers	_	_
.	_	_

#77
Eventually	_	_
,	_	_
this	_	_
mitigates	_	_
the	_	_
problem	_	_
and	_	_
more	_	_
confident	_	_
responses	_	_
are	_	_
obtained	_	_
for	_	_
an	_	_
input	_	_
.	_	_

#78
Note	_	_
that	_	_
even	_	_
if	_	_
the	_	_
parameters	_	_
of	_	_
the	_	_
model	_	_
are	_	_
trained	_	_
for	_	_
a	_	_
different	_	_
object	_	_
recognition	_	_
problem	_	_
,	_	_
the	_	_
studies	_	_
have	_	_
already	_	_
shown	_	_
that	_	_
it	_	_
is	_	_
still	_	_
capable	_	_
of	_	_
attaining	_	_
best	_	_
accuracies	_	_
on	_	_
several	_	_
remote	_	_
sensing	_	_
applications	_	_
[	_	_
15	_	_
,	_	_
16	_	_
]	_	_
.	_	_

#79
Generator	_	_
:	_	_
At	_	_
each	_	_
layer	_	_
,	_	_
the	_	_
generator	_	_
block	_	_
fuses	_	_
the	_	_
abstract	_	_
representations	_	_
extracted	_	_
by	_	_
the	_	_
encoder	_	_
block	_	_
by	_	_
adding	_	_
and	_	_
up-sampling	_	_
(	_	_
with	_	_
factor	_	_
2×	_	_
)	_	_
recursively	_	_
as	_	_
illustrated	_	_
in	_	_
Fig.	_	_
2	_	_
.	_	_

#80
Similarly	_	_
,	_	_
we	_	_
use	_	_
batch	_	_
normalizations	_	_
and	_	_
Fig.	_	_
2	_	_
.	_	_

#81
Detail	_	_
visualization	_	_
of	_	_
Generator	_	_
filter	_	_
block	_	_
at	_	_
a	_	_
single	_	_
layer	_	_
.	_	_

#82
ReLU	_	_
functions	_	_
at	_	_
the	_	_
layers	_	_
to	_	_
speed	_	_
up	_	_
the	_	_
optimization	_	_
.	_	_

#83
Other	_	_
advantage	_	_
of	_	_
these	_	_
functions	_	_
is	_	_
to	_	_
improve	_	_
the	_	_
sparsity	_	_
of	_	_
the	_	_
responses	_	_
as	_	_
explained	_	_
in	_	_
[	_	_
17	_	_
]	_	_
for	_	_
remote	_	_
sensing	_	_
.	_	_

#84
At	_	_
the	_	_
last	_	_
layer	_	_
,	_	_
we	_	_
utilize	_	_
a	_	_
softmax	_	_
activation	_	_
to	_	_
produce	_	_
classification	_	_
decisions	_	_
,	_	_
i.e.	_	_
cloud	_	_
or	_	_
ground	_	_
surface	_	_
,	_	_
thus	_	_
it	_	_
is	_	_
inclined	_	_
to	_	_
set	_	_
the	_	_
decisions	_	_
to	_	_
either	_	_
0	_	_
or	_	_
1	_	_
for	_	_
the	_	_
masks	_	_
at	_	_
the	_	_
end	_	_
of	_	_
the	_	_
learning	_	_
stage	_	_
.	_	_

#85
3.3	_	_
.	_	_

#86
Implementation	_	_
Details	_	_
As	_	_
a	_	_
pre-processing	_	_
step	_	_
,	_	_
we	_	_
first	_	_
normalize	_	_
each	_	_
pixel	_	_
in	_	_
an	_	_
image	_	_
with	_	_
the	_	_
constant	_	_
value	_	_
computed	_	_
in	_	_
[	_	_
14	_	_
]	_	_
,	_	_
even	_	_
if	_	_
a	_	_
pre-trained	_	_
encoder	_	_
model	_	_
is	_	_
used	_	_
or	_	_
not	_	_
.	_	_

#87
Ultimately	_	_
,	_	_
it	_	_
centers	_	_
data	_	_
to	_	_
zero-mean	_	_
space	_	_
and	_	_
data	_	_
becomes	_	_
reproducible	_	_
for	_	_
the	_	_
pre-trained	_	_
model	_	_
.	_	_

#88
For	_	_
the	_	_
parameter	_	_
optimization	_	_
,	_	_
Adam	_	_
optimizer	_	_
[	_	_
18	_	_
]	_	_
with	_	_
momentum	_	_
β1	_	_
=	_	_
0.9	_	_
and	_	_
β2	_	_
=	_	_
0.999	_	_
is	_	_
used	_	_
and	_	_
the	_	_
training	_	_
rate	_	_
is	_	_
set	_	_
to	_	_
0.0001	_	_
.	_	_

#89
Moreover	_	_
,	_	_
the	_	_
value	_	_
of	_	_
N	_	_
is	_	_
determined	_	_
as	_	_
10	_	_
for	_	_
512	_	_
×	_	_
512	_	_
RGB	_	_
color	_	_
images	_	_
and	_	_
maximum	_	_
mini-batch	_	_
iteration	_	_
is	_	_
set	_	_
to	_	_
20K	_	_
.	_	_

#90
Note	_	_
that	_	_
no	_	_
data	_	_
augmentation	_	_
is	_	_
utilized	_	_
throughout	_	_
the	_	_
training	_	_
stage	_	_
.	_	_

#91
Lastly	_	_
,	_	_
all	_	_
codes	_	_
are	_	_
implemented	_	_
on	_	_
Python	_	_
using	_	_
Tensorflow	_	_
framework	_	_
.	_	_

#92
The	_	_
models	_	_
are	_	_
trained/evaluated	_	_
on	_	_
NVIDIA	_	_
Tesla	_	_
K40	_	_
GPU	_	_
card	_	_
.	_	_

#93
4	_	_
.	_	_

#94
EXPERIMENTS	_	_
In	_	_
this	_	_
section	_	_
,	_	_
we	_	_
mention	_	_
the	_	_
details	_	_
of	_	_
the	_	_
dataset	_	_
we	_	_
used	_	_
in	_	_
the	_	_
experiments	_	_
.	_	_

#95
Later	_	_
,	_	_
we	_	_
report/discuss	_	_
the	_	_
experimental	_	_
results	_	_
conducted	_	_
on	_	_
this	_	_
dataset	_	_
.	_	_

#96
4.1	_	_
.	_	_

#97
Dataset	_	_
The	_	_
dataset	_	_
consists	_	_
of	_	_
20	_	_
images	_	_
acquired	_	_
from	_	_
low-orbit	_	_
RASAT	_	_
and	_	_
Gokturk-21	_	_
satellites	_	_
,	_	_
and	_	_
their	_	_
RGB	_	_
resolutions	_	_
are	_	_
15.0	_	_
m	_	_
and	_	_
5.0	_	_
m	_	_
respectively	_	_
[	_	_
19	_	_
]	_	_
.	_	_

#98
In	_	_
particular	_	_
,	_	_
we	_	_
opt	_	_
to	_	_
use	_	_
the	_	_
outputs	_	_
of	_	_
two	_	_
different	_	_
sensors	_	_
in	_	_
the	_	_
dataset	_	_
to	_	_
demonstrate	_	_
the	_	_
generalization	_	_
capacity	_	_
of	_	_
the	_	_
proposed	_	_
method	_	_
.	_	_

#99
Moreover	_	_
,	_	_
Level-1	_	_
processed	_	_
data	_	_
is	_	_
utilized	_	_
in	_	_
the	_	_
experiments	_	_
to	_	_
reduce	_	_
the	_	_
defects	_	_
caused	_	_
by	_	_
platform	_	_
motion	_	_
and	_	_
optical	_	_
distortion	_	_
.	_	_

#100
The	_	_
ground	_	_
truth	_	_
masks	_	_
are	_	_
manually	_	_
labeled	_	_
by	_	_
human	_	_
experts	_	_
.	_	_

#101
Lastly	_	_
,	_	_
all	_	_
methods	_	_
are	_	_
trained	_	_
on	_	_
15	_	_
images	_	_
and	_	_
the	_	_
rest	_	_
is	_	_
reserved	_	_
for	_	_
the	_	_
testing	_	_
stage	_	_
.	_	_

#102
4.2	_	_
.	_	_

#103
Experimental	_	_
Results	_	_
To	_	_
evaluate	_	_
the	_	_
success	_	_
of	_	_
the	_	_
proposed	_	_
method	_	_
,	_	_
we	_	_
compare	_	_
the	_	_
method	_	_
with	_	_
two	_	_
baselines	_	_
,	_	_
deep	_	_
pyramid	_	_
network	_	_
1https	_	_
:	_	_
//gezgin.gov.tr/	_	_
Image	_	_
Id	_	_
Accuracy	_	_
Precision	_	_
Latency	_	_
SP+CNN	_	_
[	_	_
3	_	_
]	_	_
0.9820	_	_
0.6676	_	_
≈30	_	_
min	_	_
.	_	_

#104
DPN	_	_
0.9815	_	_
0.7502	_	_
≈1	_	_
min	_	_
.	_	_

#105
DPN+VGG-19	_	_
(	_	_
ours	_	_
)	_	_
0.9874	_	_
0.8776	_	_
≈1	_	_
min	_	_
.	_	_

#106
Table	_	_
1	_	_
.	_	_

#107
Accuracy	_	_
and	_	_
Precision	_	_
scores	_	_
for	_	_
three	_	_
methods	_	_
.	_	_

#108
In	_	_
particular	_	_
,	_	_
DPN+VGG-19	_	_
significantly	_	_
improves	_	_
the	_	_
precision	_	_
score	_	_
compared	_	_
to	_	_
other	_	_
methods	_	_
.	_	_

#109
Latency	_	_
of	_	_
the	_	_
methods	_	_
is	_	_
also	_	_
reported	_	_
for	_	_
the	_	_
inference	_	_
stage	_	_
.	_	_

#110
(	_	_
DPN	_	_
)	_	_
and	_	_
the	_	_
combination	_	_
of	_	_
CNN	_	_
with	_	_
Super-Pixel	_	_
segmentation	_	_
as	_	_
in	_	_
[	_	_
3	_	_
]	_	_
.	_	_

#111
Moreover	_	_
,	_	_
performance	_	_
is	_	_
measured	_	_
by	_	_
three	_	_
score	_	_
metrics	_	_
,	_	_
namely	_	_
Accuracy	_	_
(	_	_
correctness	_	_
of	_	_
the	_	_
prediction	_	_
)	_	_
,	_	_
Precision	_	_
(	_	_
reliability	_	_
of	_	_
the	_	_
prediction	_	_
)	_	_
and	_	_
Latency	_	_
(	_	_
inference	_	_
time	_	_
)	_	_
.	_	_

#112
We	_	_
report	_	_
the	_	_
performance	_	_
scores	_	_
in	_	_
Table	_	_
1	_	_
.	_	_

#113
From	_	_
the	_	_
results	_	_
,	_	_
the	_	_
proposed	_	_
method	_	_
(	_	_
i.e.	_	_
DPN+VGG-19	_	_
)	_	_
achieves	_	_
best	_	_
accuracy	_	_
and	_	_
precision	_	_
scores	_	_
.	_	_

#114
Particularly	_	_
,	_	_
our	_	_
method	_	_
significantly	_	_
improves	_	_
the	_	_
precision	_	_
score	_	_
.	_	_

#115
This	_	_
stems	_	_
by	_	_
the	_	_
fact	_	_
that	_	_
replacing	_	_
a	_	_
pre-trained	_	_
parameter	_	_
model	_	_
at	_	_
the	_	_
encoder	_	_
block	_	_
provides	_	_
robustness	_	_
to	_	_
noisy-labeled	_	_
data	_	_
in	_	_
the	_	_
learning	_	_
phase	_	_
and	_	_
it	_	_
ultimately	_	_
reduces	_	_
the	_	_
false-alarm	_	_
in	_	_
the	_	_
inference	_	_
stage	_	_
.	_	_

#116
Another	_	_
reason	_	_
is	_	_
that	_	_
the	_	_
proposed	_	_
method	_	_
is	_	_
able	_	_
to	_	_
achieve	_	_
segmentation	_	_
and	_	_
classification	_	_
phases	_	_
concurrently	_	_
,	_	_
thus	_	_
the	_	_
parameters	_	_
are	_	_
optimized	_	_
by	_	_
this	_	_
way	_	_
to	_	_
estimate	_	_
best	_	_
segmentation	_	_
masks	_	_
rather	_	_
than	_	_
employing	_	_
these	_	_
steps	_	_
separately	_	_
as	_	_
in	_	_
[	_	_
3	_	_
]	_	_
.	_	_

#117
Lastly	_	_
,	_	_
this	_	_
also	_	_
provides	_	_
some	_	_
advantages	_	_
in	_	_
the	_	_
computation	_	_
time	_	_
(	_	_
i.e	_	_
on	_	_
CPU	_	_
for	_	_
3583×3584	_	_
resolution	_	_
)	_	_
as	_	_
reported	_	_
in	_	_
Table	_	_
1	_	_
(	_	_
Note	_	_
that	_	_
[	_	_
3	_	_
]	_	_
needs	_	_
to	_	_
generate	_	_
a	_	_
decision	_	_
with	_	_
CNN	_	_
for	_	_
each	_	_
local	_	_
patch	_	_
)	_	_
.	_	_

#118
Furthermore	_	_
,	_	_
we	_	_
illustrate	_	_
the	_	_
classification	_	_
masks	_	_
of	_	_
the	_	_
proposed	_	_
method	_	_
and	_	_
SP+CNN	_	_
[	_	_
3	_	_
]	_	_
for	_	_
the	_	_
test	_	_
images	_	_
in	_	_
Fig.	_	_
32	_	_
.	_	_

#119
Perceptually	_	_
,	_	_
our	_	_
method	_	_
obtains	_	_
impressive	_	_
results	_	_
particularly	_	_
for	_	_
hard	_	_
cases	_	_
such	_	_
as	_	_
snowy	_	_
mountains	_	_
.	_	_

#120
Moreover	_	_
,	_	_
the	_	_
method	_	_
is	_	_
also	_	_
able	_	_
to	_	_
detect	_	_
haze	_	_
coverages	_	_
(	_	_
i.e.	_	_
the	_	_
last	_	_
column	_	_
in	_	_
Fig.	_	_
3	_	_
)	_	_
,	_	_
even	_	_
though	_	_
there	_	_
is	_	_
a	_	_
limited	_	_
number	_	_
of	_	_
training	_	_
samples	_	_
for	_	_
such	_	_
haze	_	_
type	_	_
in	_	_
the	_	_
dataset	_	_
.	_	_

#121
The	_	_
reason	_	_
is	_	_
that	_	_
the	_	_
network	_	_
exploits	_	_
the	_	_
texture	_	_
around	_	_
clouds	_	_
rather	_	_
than	_	_
color	_	_
information	_	_
,	_	_
since	_	_
their	_	_
patterns	_	_
are	_	_
more	_	_
discriminative	_	_
for	_	_
clouds	_	_
compared	_	_
to	_	_
snow/saturated	_	_
cases	_	_
.	_	_

#122
5	_	_
.	_	_

#123
CONCLUSION	_	_
In	_	_
this	_	_
paper	_	_
,	_	_
we	_	_
propose	_	_
a	_	_
deep	_	_
pyramid	_	_
network	_	_
to	_	_
tackle	_	_
cloud	_	_
detection	_	_
from	_	_
RGB	_	_
color	_	_
images	_	_
.	_	_

#124
The	_	_
method	_	_
is	_	_
able	_	_
to	_	_
generate	_	_
pixel-level	_	_
decisions	_	_
by	_	_
exploiting	_	_
spatial	_	_
texture	_	_
information	_	_
about	_	_
visual	_	_
data	_	_
.	_	_

#125
Moreover	_	_
,	_	_
we	_	_
show	_	_
that	_	_
the	_	_
integration	_	_
of	_	_
a	_	_
pre-trained	_	_
CNN	_	_
model	_	_
at	_	_
the	_	_
encoder	_	_
layer	_	_
improves	_	_
the	_	_
accuracy	_	_
of	_	_
classification	_	_
masks	_	_
,	_	_
since	_	_
more	_	_
confident	_	_
hidden	_	_
representations	_	_
are	_	_
extracted	_	_
from	_	_
noisy	_	_
labeled	_	_
data	_	_
.	_	_

#126
From	_	_
the	_	_
experimental	_	_
results	_	_
,	_	_
the	_	_
proposed	_	_
methods	_	_
quantitatively	_	_
outperforms	_	_
the	_	_
baselines	_	_
and	_	_
obtains	_	_
perceptually	_	_
superior	_	_
results	_	_
on	_	_
the	_	_
dataset	_	_
.	_	_

#127
2Note	_	_
that	_	_
you	_	_
can	_	_
find	_	_
the	_	_
results	_	_
of	_	_
all	_	_
methods	_	_
as	_	_
well	_	_
as	_	_
ground	_	_
truth	_	_
masks	_	_
in	_	_
the	_	_
project	_	_
webpage	_	_
with	_	_
better	_	_
visual	_	_
quality	_	_
.	_	_

#128
Fig.	_	_
3	_	_
.	_	_

#129
Cloud	_	_
masks	_	_
for	_	_
DPN+VGG-19	_	_
(	_	_
second	_	_
row	_	_
)	_	_
and	_	_
SP+CNN	_	_
[	_	_
3	_	_
]	_	_
(	_	_
third	_	_
row	_	_
)	_	_
with	_	_
RGB	_	_
color	_	_
images	_	_
(	_	_
first	_	_
row	_	_
)	_	_
.	_	_

#130
6	_	_
.	_	_

#131
ACKNOWLEDGMENTS	_	_
The	_	_
authors	_	_
are	_	_
grateful	_	_
to	_	_
NVIDIA	_	_
Corporation	_	_
for	_	_
the	_	_
donation	_	_
of	_	_
Tesla	_	_
K40	_	_
GPU	_	_
card	_	_
used	_	_
for	_	_
this	_	_
research	_	_
.	_	_

#132
7	_	_
.	_	_

#133
REFERENCES	_	_
[	_	_
1	_	_
]	_	_
Q.	_	_
Cheng	_	_
et	_	_
al.	_	_
,	_	_
“Cloud	_	_
removal	_	_
for	_	_
remotely	_	_
sensed	_	_
images	_	_
by	_	_
similar	_	_
pixel	_	_
replacement	_	_
guided	_	_
with	_	_
a	_	_
spatio-temporal	_	_
mrf	_	_
model.”	_	_
ISPRS	_	_
JPRS	_	_
,	_	_
2014	_	_
.	_	_

#134
[	_	_
2	_	_
]	_	_
X.	_	_
Hu	_	_
et	_	_
al.	_	_
,	_	_
“Automatic	_	_
recognition	_	_
of	_	_
cloud	_	_
images	_	_
by	_	_
using	_	_
visual	_	_
saliency	_	_
features.”	_	_
IEEE	_	_
GRSL	_	_
,	_	_
2015	_	_
.	_	_

#135
[	_	_
3	_	_
]	_	_
F.	_	_
Xie	_	_
et	_	_
al.	_	_
,	_	_
“Multilevel	_	_
cloud	_	_
detection	_	_
in	_	_
remote	_	_
sensing	_	_
images	_	_
based	_	_
on	_	_
deep	_	_
learning.”	_	_
IEEE	_	_
JSTAR	_	_
,	_	_
2017	_	_
.	_	_

#136
[	_	_
4	_	_
]	_	_
O.	_	_
Ronneberger	_	_
et	_	_
al.	_	_
,	_	_
“U-net	_	_
:	_	_
Convolutional	_	_
networks	_	_
for	_	_
biomedical	_	_
image	_	_
segmentation.”	_	_
MICCAI	_	_
,	_	_
2015	_	_
.	_	_

#137
[	_	_
5	_	_
]	_	_
T.-Y	_	_
.	_	_

#138
Lin	_	_
et	_	_
al.	_	_
,	_	_
“Feature	_	_
pyramid	_	_
networks	_	_
for	_	_
object	_	_
detection.”	_	_
arXiv	_	_
preprint	_	_
,	_	_
2016	_	_
.	_	_

#139
[	_	_
6	_	_
]	_	_
Z.	_	_
Zhu	_	_
and	_	_
C.	_	_
E.	_	_
Woodcock	_	_
,	_	_
“Object-based	_	_
cloud	_	_
and	_	_
cloud	_	_
shadow	_	_
detection	_	_
in	_	_
landsat	_	_
imagery.”	_	_
Remote	_	_
Sensing	_	_
of	_	_
Environment	_	_
,	_	_
2012	_	_
.	_	_

#140
[	_	_
7	_	_
]	_	_
R.	_	_
R.	_	_
Irish	_	_
et	_	_
al.	_	_
,	_	_
“Characterization	_	_
of	_	_
the	_	_
landsat-7	_	_
etm+	_	_
automated	_	_
cloud-cover	_	_
assessment	_	_
(	_	_
acca	_	_
)	_	_
algorithm.”	_	_
Photogrammetric	_	_
engineering	_	_
and	_	_
remote	_	_
sensing	_	_
,	_	_
2006	_	_
.	_	_

#141
[	_	_
8	_	_
]	_	_
M.	_	_
Harb	_	_
et	_	_
al.	_	_
,	_	_
“Automatic	_	_
delineation	_	_
of	_	_
clouds	_	_
and	_	_
their	_	_
shadows	_	_
in	_	_
landsat	_	_
and	_	_
cbers	_	_
(	_	_
hrcc	_	_
)	_	_
data.”	_	_
IEEE	_	_
JSTAR	_	_
,	_	_
2016	_	_
.	_	_

#142
[	_	_
9	_	_
]	_	_
J.	_	_
D.	_	_
Braaten	_	_
et	_	_
al.	_	_
,	_	_
“Automated	_	_
cloud	_	_
and	_	_
cloud	_	_
shadow	_	_
identification	_	_
in	_	_
landsat	_	_
mss	_	_
imagery	_	_
for	_	_
temperate	_	_
ecosystems.”	_	_
Remote	_	_
Sensing	_	_
of	_	_
Environment	_	_
,	_	_
2015	_	_
.	_	_

#143
[	_	_
10	_	_
]	_	_
V.	_	_
Mnih	_	_
,	_	_
“Machine	_	_
learning	_	_
for	_	_
aerial	_	_
image	_	_
labeling	_	_
,	_	_
”	_	_
University	_	_
of	_	_
Toronto	_	_
,	_	_
2013	_	_
.	_	_

#144
[	_	_
11	_	_
]	_	_
Z.	_	_
Zhu	_	_
and	_	_
C.	_	_
E.	_	_
Woodcock	_	_
,	_	_
“Automated	_	_
cloud	_	_
,	_	_
cloud	_	_
shadow	_	_
,	_	_
and	_	_
snow	_	_
detection	_	_
in	_	_
multitemporal	_	_
landsat	_	_
data	_	_
:	_	_
An	_	_
algorithm	_	_
designed	_	_
specifically	_	_
for	_	_
monitoring	_	_
land	_	_
cover	_	_
change.”	_	_
Remote	_	_
Sensing	_	_
of	_	_
Environment	_	_
,	_	_
2014	_	_
.	_	_

#145
[	_	_
12	_	_
]	_	_
L.	_	_
Gómez-Chova	_	_
et	_	_
al.	_	_
,	_	_
“Cloud	_	_
masking	_	_
and	_	_
removal	_	_
in	_	_
remote	_	_
sensing	_	_
image	_	_
time	_	_
series.”	_	_
Journal	_	_
of	_	_
Applied	_	_
Remote	_	_
Sensing	_	_
,	_	_
2017	_	_
.	_	_

#146
[	_	_
13	_	_
]	_	_
K.	_	_
He	_	_
et	_	_
al.	_	_
,	_	_
“Deep	_	_
residual	_	_
learning	_	_
for	_	_
image	_	_
recognition.”	_	_
CVPR	_	_
,	_	_
2016	_	_
.	_	_

#147
[	_	_
14	_	_
]	_	_
K.	_	_
Simonyan	_	_
and	_	_
A.	_	_
Zisserman	_	_
,	_	_
“Very	_	_
deep	_	_
convolutional	_	_
networks	_	_
for	_	_
large-scale	_	_
image	_	_
recognition.”	_	_
arXiv	_	_
preprint	_	_
,	_	_
2014	_	_
.	_	_

#148
[	_	_
15	_	_
]	_	_
E.	_	_
Maggiori	_	_
et	_	_
al.	_	_
,	_	_
“High-resolution	_	_
semantic	_	_
labeling	_	_
with	_	_
convolutional	_	_
neural	_	_
networks	_	_
,	_	_
”	_	_
IEEE	_	_
TGRS	_	_
,	_	_
2017	_	_
.	_	_

#149
[	_	_
16	_	_
]	_	_
D.	_	_
Marmanis	_	_
et	_	_
al.	_	_
,	_	_
“Deep	_	_
learning	_	_
earth	_	_
observation	_	_
classification	_	_
using	_	_
imagenet	_	_
pretrained	_	_
networks.”	_	_
IEEE	_	_
GRSL	_	_
,	_	_
2016	_	_
.	_	_

#150
[	_	_
17	_	_
]	_	_
S.	_	_
Ozkan	_	_
et	_	_
al.	_	_
,	_	_
“Endnet	_	_
:	_	_
Sparse	_	_
autoencoder	_	_
network	_	_
for	_	_
endmember	_	_
extraction	_	_
and	_	_
hyperspectral	_	_
unmixing.”	_	_
arXiv	_	_
preprint	_	_
,	_	_
2017	_	_
.	_	_

#151
[	_	_
18	_	_
]	_	_
D.	_	_
Kingma	_	_
and	_	_
J.	_	_
Ba	_	_
,	_	_
“Adam	_	_
:	_	_
A	_	_
method	_	_
for	_	_
stochastic	_	_
optimization.”	_	_
arXiv	_	_
preprint	_	_
,	_	_
2014	_	_
.	_	_

#152
[	_	_
19	_	_
]	_	_
M.	_	_
Teke	_	_
,	_	_
“Satellite	_	_
image	_	_
processing	_	_
workflow	_	_
for	_	_
rasat	_	_
and	_	_
gokturk-2.”	_	_
JAST	_	_
,	_	_
2016	_	_
.	_	_