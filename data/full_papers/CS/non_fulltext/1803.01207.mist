#0
Automatic	_	_
Instrument	_	_
Segmentation	_	_
in	_	_
Robot-Assisted	_	_
Surgery	_	_
Using	_	_
Deep	_	_
Learning	_	_
Alexey	_	_
A.	_	_
Shvets1	_	_
,	_	_
Alexander	_	_
Rakhlin2	_	_
,	_	_
Alexandr	_	_
A.	_	_
Kalinin3	_	_
,	_	_
and	_	_
Vladimir	_	_
I.	_	_
Iglovikov4	_	_

#1
1	_	_
Massachusetts	_	_
Institute	_	_
of	_	_
Technology	_	_
,	_	_
Cambridge	_	_
,	_	_
MA	_	_
02142	_	_
,	_	_
USA	_	_

#2
shvets	_	_
@	_	_
mit.edu	_	_

#3
2	_	_
Neuromation	_	_
OU	_	_
,	_	_
Tallinn	_	_
,	_	_
10111	_	_
Estonia	_	_

#4
rakhlin	_	_
@	_	_
neuromation.io	_	_

#5
3	_	_
University	_	_
of	_	_
Michigan	_	_
,	_	_
Ann	_	_
Arbor	_	_
,	_	_
MI	_	_
48109	_	_
,	_	_
USA	_	_

#6
akalinin	_	_
@	_	_
umich.edu	_	_
4	_	_
Lyft	_	_
Inc.	_	_
,	_	_
San	_	_
Francisco	_	_
,	_	_
CA	_	_
94107	_	_
,	_	_
USA	_	_
iglovikov	_	_
@	_	_
gmail.com	_	_
Abstract	_	_
.	_	_

#7
Semantic	_	_
segmentation	_	_
of	_	_
robotic	_	_
instruments	_	_
is	_	_
an	_	_
important	_	_
problem	_	_
for	_	_
the	_	_
robot-assisted	_	_
surgery	_	_
.	_	_

#8
One	_	_
of	_	_
the	_	_
main	_	_
challenges	_	_
is	_	_
to	_	_
correctly	_	_
detect	_	_
an	_	_
instrument’s	_	_
position	_	_
for	_	_
the	_	_
tracking	_	_
and	_	_
pose	_	_
estimation	_	_
in	_	_
the	_	_
vicinity	_	_
of	_	_
surgical	_	_
scenes	_	_
.	_	_

#9
Accurate	_	_
pixel-wise	_	_
instrument	_	_
segmentation	_	_
is	_	_
needed	_	_
to	_	_
address	_	_
this	_	_
challenge	_	_
.	_	_

#10
In	_	_
this	_	_
paper	_	_
we	_	_
describe	_	_
our	_	_
deep	_	_
learning-based	_	_
approach	_	_
for	_	_
robotic	_	_
instrument	_	_
segmentation	_	_
.	_	_

#11
Our	_	_
approach	_	_
demonstrates	_	_
an	_	_
improvement	_	_
over	_	_
the	_	_
state-of-the-art	_	_
results	_	_
using	_	_
several	_	_
novel	_	_
deep	_	_
neural	_	_
network	_	_
architectures	_	_
.	_	_

#12
It	_	_
addressed	_	_
the	_	_
binary	_	_
segmentation	_	_
problem	_	_
,	_	_
where	_	_
every	_	_
pixel	_	_
in	_	_
an	_	_
image	_	_
is	_	_
labeled	_	_
as	_	_
an	_	_
instrument	_	_
or	_	_
background	_	_
from	_	_
the	_	_
surgery	_	_
video	_	_
feed	_	_
.	_	_

#13
In	_	_
addition	_	_
,	_	_
we	_	_
solve	_	_
a	_	_
multi-class	_	_
segmentation	_	_
problem	_	_
,	_	_
in	_	_
which	_	_
we	_	_
distinguish	_	_
between	_	_
different	_	_
instruments	_	_
or	_	_
different	_	_
parts	_	_
of	_	_
an	_	_
instrument	_	_
from	_	_
the	_	_
background	_	_
.	_	_

#14
In	_	_
this	_	_
setting	_	_
,	_	_
our	_	_
approach	_	_
outperforms	_	_
other	_	_
methods	_	_
for	_	_
automatic	_	_
instrument	_	_
segmentation	_	_
thereby	_	_
providing	_	_
state-of-the-art	_	_
results	_	_
for	_	_
these	_	_
problems	_	_
.	_	_

#15
The	_	_
source	_	_
code	_	_
for	_	_
our	_	_
solution	_	_
is	_	_
made	_	_
publicly	_	_
available	_	_
.	_	_

#16
Keywords	_	_
:	_	_
Medical	_	_
imaging	_	_
,	_	_
Robot-assisted	_	_
surgery	_	_
,	_	_
Computer	_	_
vision	_	_
,	_	_
Image	_	_
segmentation	_	_
,	_	_
Deep	_	_
learning	_	_

#17
1	_	_
Introduction	_	_

#18
Research	_	_
in	_	_
robotics	_	_
promises	_	_
to	_	_
revolutionize	_	_
surgery	_	_
towards	_	_
safer	_	_
,	_	_
more	_	_
consistent	_	_
and	_	_
minimally	_	_
invasive	_	_
intervention	_	_
[	_	_
3	_	_
,	_	_
14	_	_
]	_	_
.	_	_

#19
New	_	_
developments	_	_
continues	_	_
on	_	_
the	_	_
way	_	_
to	_	_
robot-assisted	_	_
systems	_	_
and	_	_
moving	_	_
toward	_	_
a	_	_
future	_	_
with	_	_
fully	_	_
autonomous	_	_
robotic	_	_
surgeons	_	_
.	_	_

#20
Thus	_	_
far	_	_
,	_	_
the	_	_
most	_	_
widespread	_	_
surgical	_	_
system	_	_
is	_	_
the	_	_
da	_	_
Vinci	_	_
robot	_	_
,	_	_
which	_	_
has	_	_
already	_	_
proved	_	_
its	_	_
favor	_	_
via	_	_
remote	_	_
controlled	_	_
laparoscopic	_	_
surgery	_	_
in	_	_
gynecology	_	_
,	_	_
urology	_	_
,	_	_
and	_	_
general	_	_
surgery	_	_
[	_	_
3	_	_
]	_	_
.	_	_

#21
ar	_	_
X	_	_
iv	_	_
:1	_	_
3	_	_
.	_	_

#22
7v	_	_
2	_	_
[	_	_
cs	_	_
.C	_	_
V	_	_
]	_	_
1	_	_
9	_	_
Ju	_	_
n	_	_
2	_	_
Shvets	_	_
et	_	_
al.	_	_
Information	_	_
in	_	_
a	_	_
surgical	_	_
console	_	_
of	_	_
a	_	_
robot-assisted	_	_
surgical	_	_
system	_	_
includes	_	_
valuable	_	_
details	_	_
for	_	_
intra-operative	_	_
guidance	_	_
that	_	_
can	_	_
help	_	_
the	_	_
decision	_	_
making	_	_
process	_	_
.	_	_

#23
This	_	_
information	_	_
is	_	_
usually	_	_
represented	_	_
as	_	_
2D	_	_
images	_	_
or	_	_
videos	_	_
that	_	_
contain	_	_
surgical	_	_
instruments	_	_
and	_	_
patient	_	_
tissues	_	_
.	_	_

#24
Understanding	_	_
these	_	_
data	_	_
is	_	_
a	_	_
complex	_	_
problem	_	_
that	_	_
involves	_	_
the	_	_
tracking	_	_
and	_	_
pose	_	_
estimation	_	_
for	_	_
surgical	_	_
instruments	_	_
in	_	_
the	_	_
vicinity	_	_
of	_	_
surgical	_	_
scenes	_	_
.	_	_

#25
A	_	_
critical	_	_
component	_	_
of	_	_
this	_	_
process	_	_
is	_	_
semantic	_	_
segmentation	_	_
of	_	_
the	_	_
instruments	_	_
in	_	_
the	_	_
surgical	_	_
console	_	_
.	_	_

#26
Semantic	_	_
segmentation	_	_
of	_	_
robotic	_	_
instruments	_	_
is	_	_
a	_	_
difficult	_	_
task	_	_
by	_	_
the	_	_
virtue	_	_
of	_	_
light	_	_
changes	_	_
such	_	_
as	_	_
shadows	_	_
and	_	_
specular	_	_
reflections	_	_
,	_	_
visual	_	_
occlusions	_	_
such	_	_
as	_	_
blood	_	_
and	_	_
camera	_	_
lens	_	_
fogging	_	_
,	_	_
and	_	_
due	_	_
to	_	_
the	_	_
complex	_	_
and	_	_
dynamic	_	_
nature	_	_
of	_	_
background	_	_
tissues	_	_
.	_	_

#27
Segmentation	_	_
masks	_	_
can	_	_
be	_	_
used	_	_
to	_	_
provide	_	_
a	_	_
reliable	_	_
input	_	_
to	_	_
instrument	_	_
tracking	_	_
systems	_	_
.	_	_

#28
Therefore	_	_
,	_	_
there	_	_
is	_	_
a	_	_
compelling	_	_
need	_	_
for	_	_
the	_	_
development	_	_
of	_	_
accurate	_	_
and	_	_
robust	_	_
computer	_	_
vision	_	_
methods	_	_
for	_	_
semantic	_	_
segmentation	_	_
of	_	_
surgical	_	_
instruments	_	_
from	_	_
operational	_	_
images	_	_
and	_	_
video	_	_
.	_	_

#29
There	_	_
is	_	_
a	_	_
number	_	_
of	_	_
vision-based	_	_
methods	_	_
developed	_	_
for	_	_
the	_	_
robotic	_	_
instrument	_	_
detection	_	_
and	_	_
tracking	_	_
[	_	_
14	_	_
]	_	_
.	_	_

#30
Instrument-background	_	_
segmentation	_	_
can	_	_
be	_	_
treated	_	_
as	_	_
a	_	_
binary	_	_
or	_	_
instance	_	_
segmentation	_	_
problem	_	_
for	_	_
which	_	_
classical	_	_
machine	_	_
learning	_	_
algorithms	_	_
have	_	_
been	_	_
applied	_	_
using	_	_
color	_	_
and/or	_	_
texture	_	_
features	_	_
[	_	_
6,20	_	_
]	_	_
.	_	_

#31
Later	_	_
applications	_	_
addressed	_	_
this	_	_
problem	_	_
as	_	_
semantic	_	_
segmentation	_	_
,	_	_
aiming	_	_
to	_	_
distinguish	_	_
between	_	_
different	_	_
instruments	_	_
or	_	_
their	_	_
parts	_	_
[	_	_
2	_	_
,	_	_
16	_	_
]	_	_
.	_	_

#32
Recently	_	_
,	_	_
deep	_	_
learning-based	_	_
approaches	_	_
demonstrated	_	_
performance	_	_
improvements	_	_
over	_	_
conventional	_	_
machine	_	_
learning	_	_
methods	_	_
for	_	_
many	_	_
problems	_	_
in	_	_
biomedicine	_	_
[	_	_
5	_	_
,	_	_
12	_	_
]	_	_
.	_	_

#33
In	_	_
the	_	_
domain	_	_
of	_	_
medical	_	_
imaging	_	_
,	_	_
convolutional	_	_
neural	_	_
networks	_	_
(	_	_
CNN	_	_
)	_	_
have	_	_
been	_	_
successfully	_	_
used	_	_
,	_	_
for	_	_
example	_	_
,	_	_
for	_	_
breast	_	_
cancer	_	_
histology	_	_
image	_	_
analysis	_	_
[	_	_
17	_	_
]	_	_
,	_	_
bone	_	_
disease	_	_
prediction	_	_
[	_	_
21	_	_
]	_	_
and	_	_
age	_	_
assessment	_	_
[	_	_
10	_	_
]	_	_
,	_	_
and	_	_
other	_	_
problems	_	_
[	_	_
5	_	_
]	_	_
.	_	_

#34
Previous	_	_
deep	_	_
learning-based	_	_
applications	_	_
to	_	_
robotic	_	_
instrument	_	_
segmentation	_	_
have	_	_
demonstrated	_	_
competitive	_	_
performance	_	_
in	_	_
binary	_	_
segmentation	_	_
[	_	_
1,7	_	_
]	_	_
and	_	_
promising	_	_
results	_	_
in	_	_
multi-class	_	_
segmentation	_	_
[	_	_
15	_	_
]	_	_
.	_	_

#35
In	_	_
this	_	_
paper	_	_
,	_	_
we	_	_
present	_	_
a	_	_
deep	_	_
learning-based	_	_
solution	_	_
for	_	_
robotic	_	_
instrument	_	_
semantic	_	_
segmentation	_	_
that	_	_
achieves	_	_
state-of-the-art	_	_
results	_	_
in	_	_
both	_	_
binary	_	_
and	_	_
multi-class	_	_
setting	_	_
.	_	_

#36
We	_	_
used	_	_
this	_	_
method	_	_
to	_	_
produce	_	_
a	_	_
submission	_	_
to	_	_
the	_	_
MICCAI	_	_

#37
2017	_	_
Endoscopic	_	_
Vision	_	_
SubChallenge	_	_
:	_	_
Robotic	_	_
Instrument	_	_
Segmentation	_	_
[	_	_
13	_	_
]	_	_

#38
to	_	_
achieve	_	_
one	_	_
of	_	_
the	_	_
top	_	_
results	_	_
.	_	_

#39
Here	_	_
we	_	_
describe	_	_
the	_	_
details	_	_
of	_	_
the	_	_
solution	_	_
based	_	_
on	_	_
a	_	_
modification	_	_
of	_	_
the	_	_
U-Net	_	_
model	_	_
[	_	_
9	_	_
,	_	_
18	_	_
]	_	_
.	_	_

#40
Moreover	_	_
,	_	_
we	_	_
provide	_	_
further	_	_
improvements	_	_
over	_	_
this	_	_
solution	_	_
utilizing	_	_
recent	_	_
deep	_	_
architectures	_	_
:	_	_
TernausNet	_	_
[	_	_
11	_	_
]	_	_
and	_	_
a	_	_
modified	_	_
LinkNet	_	_
[	_	_
4	_	_
]	_	_
.	_	_

#41
2	_	_
Methods	_	_

#42
2.1	_	_
Dataset	_	_

#43
The	_	_
training	_	_
dataset	_	_
consists	_	_
of	_	_
8	_	_
×	_	_
225-frame	_	_
sequences	_	_
of	_	_
high	_	_
resolution	_	_
stereo	_	_
camera	_	_
images	_	_
acquired	_	_
from	_	_
a	_	_
da	_	_
Vinci	_	_
Xi	_	_
surgical	_	_
system	_	_
during	_	_
several	_	_
different	_	_
porcine	_	_
procedures	_	_
,	_	_
see	_	_
[	_	_
13	_	_
]	_	_
.	_	_

#44
Training	_	_
sequences	_	_
are	_	_
provided	_	_
with	_	_
2	_	_
Hz	_	_
frame	_	_
rate	_	_
to	_	_
avoid	_	_
redundancy	_	_
.	_	_

#45
Every	_	_
video	_	_
sequence	_	_
consists	_	_
of	_	_
two	_	_
stereo	_	_
channels	_	_
Deep	_	_
Learning	_	_
for	_	_
Surgical	_	_
Instrument	_	_
Segmentation	_	_
3	_	_
Fig.	_	_
1	_	_
:	_	_
A	_	_
snapshot	_	_
from	_	_
a	_	_
robotic	_	_
surgical	_	_
video	_	_
that	_	_
contains	_	_
robotic	_	_
instruments	_	_
and	_	_
patient	_	_
tissues	_	_
:	_	_
(	_	_
1	_	_
)	_	_
original	_	_
video	_	_
frame	_	_
;	_	_
(	_	_
2	_	_
)	_	_
binary	_	_
segmentation	_	_
of	_	_
robotic	_	_
instruments	_	_
shown	_	_
in	_	_
blue	_	_
and	_	_
tissue	_	_
that	_	_
serves	_	_
as	_	_
a	_	_
background	_	_
;	_	_
(	_	_
3	_	_
)	_	_
multi-class	_	_
segmentation	_	_
of	_	_
robotic	_	_
instruments	_	_
where	_	_
each	_	_
class	_	_
corresponds	_	_
to	_	_
a	_	_
different	_	_
part	_	_
of	_	_
the	_	_
robotic	_	_
instrument	_	_
(	_	_
3	_	_
classes	_	_
:	_	_
rigid	_	_
shaft	_	_
,	_	_
articulated	_	_
wrist	_	_
and	_	_
claspers	_	_
)	_	_
;	_	_
and	_	_
(	_	_
4	_	_
)	_	_
multi-class	_	_
segmentation	_	_
of	_	_
robotic	_	_
instruments	_	_
where	_	_
each	_	_
class	_	_
corresponds	_	_
to	_	_
a	_	_
different	_	_
robotic	_	_
instrument	_	_
(	_	_
7	_	_
classes	_	_
)	_	_
.	_	_

#46
taken	_	_
from	_	_
left	_	_
and	_	_
right	_	_
cameras	_	_
and	_	_
has	_	_
a	_	_
1920	_	_
×	_	_
1080	_	_
pixel	_	_
resolution	_	_
in	_	_
RGB	_	_
format	_	_
.	_	_

#47
To	_	_
remove	_	_
black	_	_
canvas	_	_
and	_	_
extract	_	_
original	_	_
1280	_	_
×	_	_
1024	_	_
camera	_	_
images	_	_
from	_	_
the	_	_
frames	_	_
,	_	_
an	_	_
image	_	_
has	_	_
to	_	_
be	_	_
cropped	_	_
starting	_	_
from	_	_
the	_	_
pixel	_	_
at	_	_
the	_	_
(	_	_
320	_	_
,	_	_
28	_	_
)	_	_
position	_	_
.	_	_

#48
Ground	_	_
truth	_	_
labels	_	_
are	_	_
provided	_	_
for	_	_
left	_	_
frames	_	_
only	_	_
,	_	_
therefore	_	_
only	_	_
left	_	_
channel	_	_
images	_	_
are	_	_
used	_	_
for	_	_
training	_	_
.	_	_

#49
The	_	_
articulated	_	_
parts	_	_
of	_	_
the	_	_
robotic	_	_
surgical	_	_
instruments	_	_
,	_	_
such	_	_
as	_	_
a	_	_
rigid	_	_
shaft	_	_
,	_	_
an	_	_
articulated	_	_
wrist	_	_
and	_	_
claspers	_	_
have	_	_
been	_	_
hand	_	_
labelled	_	_
in	_	_
each	_	_
frame	_	_
.	_	_

#50
Ground	_	_
truth	_	_
labels	_	_
are	_	_
encoded	_	_
with	_	_
numerical	_	_
values	_	_
(	_	_
10	_	_
,	_	_
20	_	_
,	_	_
30	_	_
,	_	_
40	_	_
,	_	_
0	_	_
)	_	_
and	_	_
assigned	_	_
to	_	_
each	_	_
part	_	_
of	_	_
an	_	_
instrument	_	_
or	_	_
background	_	_
.	_	_

#51
Furthermore	_	_
,	_	_
there	_	_
are	_	_
instrument	_	_
type	_	_
labels	_	_
that	_	_
categorize	_	_
instruments	_	_
in	_	_
following	_	_
categories	_	_
:	_	_
left/right	_	_
prograsp	_	_
forceps	_	_
,	_	_
monopolar	_	_
curved	_	_
scissors	_	_
,	_	_
large	_	_
needle	_	_
driver	_	_
,	_	_
and	_	_
a	_	_
miscellaneous	_	_
category	_	_
for	_	_
any	_	_
other	_	_
surgical	_	_
instruments	_	_
.	_	_

#52
The	_	_
test	_	_
dataset	_	_
consists	_	_
of	_	_
8×75-frame	_	_
sequences	_	_
containing	_	_
footage	_	_
sampled	_	_
immediately	_	_
after	_	_
each	_	_
training	_	_
sequence	_	_
and	_	_
2	_	_
full	_	_
300-frame	_	_
sequences	_	_
,	_	_
sampled	_	_
at	_	_
the	_	_
same	_	_
rate	_	_
as	_	_
the	_	_
training	_	_
set	_	_
.	_	_

#53
Under	_	_
the	_	_
terms	_	_
of	_	_
the	_	_
challenge	_	_
,	_	_
participants	_	_
should	deontic	_
exclude	_	_
the	_	_
corresponding	_	_
training	_	_
set	_	_
when	_	_
evaluating	_	_
on	_	_
one	_	_
of	_	_
the	_	_
75-frame	_	_
sequences	_	_
.	_	_

#54
2.2	_	_
Network	_	_
architectures	_	_

#55
In	_	_
this	_	_
work	_	_
we	_	_
evaluate	_	_
4	_	_
different	_	_
deep	_	_
architectures	_	_
for	_	_
segmentation	_	_
:	_	_
U-Net	_	_
[	_	_
9	_	_
,	_	_
18	_	_
]	_	_
,	_	_
2	_	_
modifications	_	_
of	_	_
TernausNet	_	_
[	_	_
11	_	_
]	_	_
,	_	_
and	_	_
a	_	_
modification	_	_
of	_	_
LinkNet	_	_
[	_	_
4	_	_
]	_	_
.	_	_

#56
In	_	_
general	_	_
,	_	_
a	_	_
U-Net-like	_	_
architecture	_	_
consists	_	_
of	_	_
a	_	_
contracting	_	_
path	_	_
to	_	_
capture	_	_
context	_	_
and	_	_
of	_	_
a	_	_
symmetrically	_	_
expanding	_	_
path	_	_
that	_	_
enables	_	_
precise	_	_
localization	_	_
(	_	_
for	_	_
example	_	_
,	_	_
see	_	_
Fig.	_	_
2	_	_
)	_	_
.	_	_

#57
The	_	_
contracting	_	_
path	_	_
follows	_	_
the	_	_
typical	_	_
architecture	_	_
of	_	_
a	_	_
convolutional	_	_
network	_	_
with	_	_
alternating	_	_
convolution	_	_
and	_	_
pooling	_	_
operations	_	_
and	_	_
progressively	_	_
downsamples	_	_
feature	_	_
maps	_	_
,	_	_
increasing	_	_
the	_	_
number	_	_
of	_	_
feature	_	_
maps	_	_
per	_	_
layer	_	_
at	_	_
the	_	_
same	_	_
time	_	_
.	_	_

#58
Every	_	_
step	_	_
in	_	_
the	_	_
expansive	_	_
path	_	_
consists	_	_
of	_	_
an	_	_
upsampling	_	_
of	_	_
the	_	_
feature	_	_
map	_	_
followed	_	_
by	_	_
a	_	_
convolution	_	_
.	_	_

#59
Hence	_	_
,	_	_
the	_	_
expansive	_	_
branch	_	_
increases	_	_
the	_	_
resolution	_	_
of	_	_
the	_	_
output	_	_
.	_	_

#60
In	_	_
order	_	_
to	_	_
localize	_	_
,	_	_
upsampled	_	_
4	_	_
Shvets	_	_
et	_	_
al.	_	_
features	_	_
,	_	_
the	_	_
expansive	_	_
path	_	_
combines	_	_
them	_	_
with	_	_
high-resolution	_	_
features	_	_
from	_	_
the	_	_
contracting	_	_
path	_	_
via	_	_
skip-connections	_	_
[	_	_
18	_	_
]	_	_
.	_	_

#61
The	_	_
output	_	_
of	_	_
the	_	_
model	_	_
is	_	_
a	_	_
pixel-by-pixel	_	_
mask	_	_
that	_	_
shows	_	_
the	_	_
class	_	_
of	_	_
each	_	_
pixel	_	_
.	_	_

#62
We	_	_
use	_	_
slightly	_	_
modified	_	_
version	_	_
of	_	_
the	_	_
original	_	_
U-Net	_	_
model	_	_
that	_	_
previously	_	_
proved	_	_
itself	_	_
very	_	_
useful	_	_
for	_	_
segmentation	_	_
problems	_	_
with	_	_
limited	_	_
amounts	_	_
of	_	_
data	_	_
,	_	_
for	_	_
example	_	_
,	_	_
see	_	_
[	_	_
9	_	_
,	_	_
10	_	_
]	_	_
.	_	_

#63
Our	_	_
submission	_	_
to	_	_
the	_	_
MICCAI	_	_
2017	_	_
Endoscopic	_	_
Vision	_	_
SubChallenge	_	_
:	_	_
Robotic	_	_
Instrument	_	_
Segmentation	_	_
[	_	_
13	_	_
]	_	_
was	_	_
produced	_	_
using	_	_
this	_	_
architecture	_	_
.	_	_

#64
Fig.2	_	_
:	_	_
These	_	_
segmentation	_	_
networks	_	_
are	_	_
based	_	_
on	_	_
encoder-decoder	_	_
network	_	_
of	_	_
U-Net	_	_
family	_	_
.	_	_

#65
TernausNet	_	_
uses	_	_
pre-trained	_	_
VGG16	_	_
network	_	_
as	_	_
an	_	_
encoder	_	_
,	_	_
while	_	_
LinkNet-34	_	_
uses	_	_
pre-trained	_	_
ResNet34	_	_
.	_	_

#66
Each	_	_
box	_	_
corresponds	_	_
to	_	_
a	_	_
multi-channel	_	_
feature	_	_
map	_	_
.	_	_

#67
The	_	_
number	_	_
of	_	_
channels	_	_
is	_	_
pointed	_	_
below	_	_
the	_	_
box	_	_
.	_	_

#68
The	_	_
height	_	_
of	_	_
the	_	_
box	_	_
represents	_	_
a	_	_
feature	_	_
map	_	_
resolution	_	_
.	_	_

#69
The	_	_
blue	_	_
arrows	_	_
denote	_	_
skip-connections	_	_
where	_	_
information	_	_
is	_	_
transmitted	_	_
from	_	_
the	_	_
encoder	_	_
to	_	_
the	_	_
decoder	_	_
.	_	_

#70
Deep	_	_
Learning	_	_
for	_	_
Surgical	_	_
Instrument	_	_
Segmentation	_	_
5	_	_
As	_	_
an	_	_
improvement	_	_
over	_	_
U-Net	_	_
,	_	_
we	_	_
use	_	_
similar	_	_
networks	_	_
with	_	_
pre-trained	_	_
encoders	_	_
.	_	_

#71
TernausNet	_	_
[	_	_
11	_	_
]	_	_
is	_	_
a	_	_
U-Net-like	_	_
architecture	_	_
that	_	_
uses	_	_
relatively	_	_
simple	_	_
pre-trained	_	_
VGG11	_	_
or	_	_
VGG16	_	_
[	_	_
19	_	_
]	_	_
networks	_	_
as	_	_
an	_	_
encoder	_	_
(	_	_
see	_	_
Fig.	_	_
2	_	_
)	_	_
.	_	_

#72
VGG11	_	_
consists	_	_
of	_	_
seven	_	_
convolutional	_	_
layers	_	_
,	_	_
each	_	_
followed	_	_
by	_	_
a	_	_
ReLU	_	_
activation	_	_
function	_	_
,	_	_
and	_	_
five	_	_
max	_	_
polling	_	_
operations	_	_
,	_	_
each	_	_
reducing	_	_
feature	_	_
map	_	_
by	_	_
2	_	_
.	_	_

#73
All	_	_
convolutional	_	_
layers	_	_
have	_	_
3	_	_
×	_	_
3	_	_
kernels	_	_
.	_	_

#74
TernausNet16	_	_
has	_	_
a	_	_
similar	_	_
structure	_	_
and	_	_
uses	_	_
VGG16	_	_
network	_	_
as	_	_
an	_	_
encoder	_	_
(	_	_
see	_	_
Fig.	_	_
2	_	_
)	_	_
.	_	_

#75
In	_	_
contrast	_	_
,	_	_
LinkNet	_	_
[	_	_
4	_	_
]	_	_
model	_	_
uses	_	_
an	_	_
encoder	_	_
based	_	_
on	_	_
a	_	_
ResNet-type	_	_
architecture	_	_
[	_	_
8	_	_
]	_	_
.	_	_

#76
In	_	_
this	_	_
work	_	_
,	_	_
we	_	_
use	_	_
pre-trained	_	_
ResNet34	_	_
,	_	_
see	_	_
Fig.	_	_
2	_	_
.	_	_

#77
The	_	_
encoder	_	_
starts	_	_
with	_	_
the	_	_
initial	_	_
block	_	_
that	_	_
performs	_	_
convolution	_	_
with	_	_
a	_	_
kernel	_	_
of	_	_
size	_	_
7	_	_
×	_	_
7	_	_
and	_	_
stride	_	_
2	_	_
.	_	_

#78
This	_	_
block	_	_
is	_	_
followed	_	_
by	_	_
max-pooling	_	_
with	_	_
stride	_	_
2	_	_
.	_	_

#79
The	_	_
later	_	_
portion	_	_
of	_	_
the	_	_
network	_	_
consists	_	_
of	_	_
repetitive	_	_
residual	_	_
blocks	_	_
.	_	_

#80
In	_	_
every	_	_
residual	_	_
block	_	_
,	_	_
the	_	_
first	_	_
convolution	_	_
operation	_	_
is	_	_
implemented	_	_
with	_	_
stride	_	_
2	_	_
to	_	_
provide	_	_
downsampling	_	_
,	_	_
while	_	_
the	_	_
rest	_	_
convolution	_	_
operations	_	_
use	_	_
stride	_	_
1	_	_
.	_	_

#81
In	_	_
addition	_	_
,	_	_
the	_	_
decoder	_	_
of	_	_
the	_	_
network	_	_
consists	_	_
of	_	_
several	_	_
decoder	_	_
blocks	_	_
that	_	_
are	_	_
connected	_	_
with	_	_
the	_	_
corresponding	_	_
encoder	_	_
block	_	_
.	_	_

#82
In	_	_
this	_	_
case	_	_
,	_	_
the	_	_
transmitted	_	_
block	_	_
from	_	_
the	_	_
encoder	_	_
is	_	_
added	_	_
to	_	_
the	_	_
corresponding	_	_
decoder	_	_
block	_	_
.	_	_

#83
Each	_	_
decoder	_	_
block	_	_
includes	_	_
1	_	_
×	_	_
1	_	_
convolution	_	_
operation	_	_
that	_	_
reduces	_	_
the	_	_
number	_	_
of	_	_
filters	_	_
by	_	_
4	_	_
,	_	_
followed	_	_
by	_	_
batch	_	_
normalization	_	_
and	_	_
transposed	_	_
convolution	_	_
to	_	_
upsample	_	_
the	_	_
feature	_	_
map	_	_
.	_	_

#84
2.3	_	_
Training	_	_

#85
We	_	_
use	_	_
Jaccard	_	_
index	_	_
(	_	_
Intersection	_	_
Over	_	_
Union	_	_
)	_	_
as	_	_
the	_	_
evaluation	_	_
metric	_	_
.	_	_

#86
It	_	_
can	_	_
be	_	_
interpreted	_	_
as	_	_
a	_	_
similarity	_	_
measure	_	_
between	_	_
a	_	_
finite	_	_
number	_	_
of	_	_
sets	_	_
.	_	_

#87
For	_	_
two	_	_
sets	_	_
𝐴	_	_
and	_	_
𝐵	_	_
,	_	_
it	_	_
can	_	_
be	_	_
defined	_	_
as	_	_
following	_	_
:	_	_
𝐽	_	_
(	_	_
𝐴	_	_
,	_	_
𝐵	_	_
)	_	_
=	_	_
|𝐴	_	_
∩	_	_
𝐵|	_	_
|𝐴	_	_
∪	_	_
𝐵|	_	_
=	_	_
|𝐴	_	_
∩	_	_
𝐵|	_	_
|𝐴|	_	_
+	_	_
|𝐵|	_	_
−	_	_
|𝐴	_	_
∩	_	_
𝐵|	_	_
(	_	_
1	_	_
)	_	_
Since	_	_
an	_	_
image	_	_
consists	_	_
of	_	_
pixels	_	_
,	_	_
the	_	_
last	_	_
expression	_	_
can	_	_
be	_	_
adapted	_	_
for	_	_
discrete	_	_
objects	_	_
in	_	_
the	_	_
following	_	_
way	_	_
:	_	_
𝐽	_	_
=	_	_
1	_	_
𝑛	_	_
𝑛∑︁	_	_
𝑖=1	_	_
(	_	_
︂	_	_
𝑦𝑖𝑦𝑖	_	_
𝑦𝑖	_	_
+	_	_
𝑦𝑖	_	_
−	_	_
𝑦𝑖𝑦𝑖	_	_
)	_	_
︂	_	_
(	_	_
2	_	_
)	_	_
where	_	_
𝑦𝑖	_	_
and	_	_
𝑦𝑖	_	_
are	_	_
a	_	_
binary	_	_
value	_	_
(	_	_
label	_	_
)	_	_
and	_	_
a	_	_
predicted	_	_
probability	_	_
for	_	_
the	_	_
pixel	_	_
𝑖	_	_
,	_	_
correspondingly	_	_
.	_	_

#88
Since	_	_
image	_	_
segmentation	_	_
task	_	_
can	_	_
also	_	_
be	_	_
considered	_	_
as	_	_
a	_	_
pixel	_	_
classification	_	_
problem	_	_
,	_	_
we	_	_
additionally	_	_
use	_	_
common	_	_
classification	_	_
loss	_	_
functions	_	_
,	_	_
denoted	_	_
as	_	_
𝐻	_	_
.	_	_

#89
For	_	_
a	_	_
binary	_	_
segmentation	_	_
problem	_	_
𝐻	_	_
is	_	_
a	_	_
binary	_	_
cross	_	_
entropy	_	_
,	_	_
while	_	_
for	_	_
a	_	_
multi-class	_	_
segmentation	_	_
problem	_	_
𝐻	_	_
is	_	_
a	_	_
categorical	_	_
cross	_	_
entropy	_	_
.	_	_

#90
The	_	_
final	_	_
expression	_	_
for	_	_
the	_	_
generalized	_	_
loss	_	_
function	_	_
is	_	_
obtained	_	_
by	_	_
combining	_	_
(	_	_
2	_	_
)	_	_
and	_	_
𝐻	_	_
as	_	_
following	_	_
:	_	_
𝐿	_	_
=	_	_
𝐻	_	_
−	_	_
log	_	_
𝐽	_	_
(	_	_
3	_	_
)	_	_
6	_	_
Shvets	_	_
et	_	_
al.	_	_
Fig.3	_	_
:	_	_
Qualitative	_	_
comparison	_	_
between	_	_
several	_	_
neural	_	_
network	_	_
architectures	_	_
implemented	_	_
for	_	_
a	_	_
binary	_	_
and	_	_
multi-class	_	_
segmentation	_	_
.	_	_

#91
By	_	_
minimizing	_	_
this	_	_
loss	_	_
function	_	_
,	_	_
we	_	_
simultaneously	_	_
maximize	_	_
probabilities	_	_
for	_	_
right	_	_
pixels	_	_
to	_	_
be	_	_
predicted	_	_
and	_	_
maximize	_	_
the	_	_
intersection	_	_
𝐽	_	_
between	_	_
masks	_	_
and	_	_
corresponding	_	_
predictions	_	_
[	_	_
9	_	_
]	_	_
.	_	_

#92
As	_	_
an	_	_
output	_	_
of	_	_
a	_	_
model	_	_
,	_	_
we	_	_
obtain	_	_
an	_	_
image	_	_
,	_	_
in	_	_
which	_	_
each	_	_
pixel	_	_
value	_	_
corresponds	_	_
to	_	_
a	_	_
probability	_	_
of	_	_
belonging	_	_
to	_	_
the	_	_
area	_	_
of	_	_
interest	_	_
or	_	_
a	_	_
class	_	_
.	_	_

#93
The	_	_
size	_	_
of	_	_
the	_	_
output	_	_
image	_	_
matches	_	_
the	_	_
input	_	_
image	_	_
size	_	_
.	_	_

#94
For	_	_
binary	_	_
segmentation	_	_
,	_	_
we	_	_
use	_	_
0.3	_	_
as	_	_
a	_	_
threshold	_	_
value	_	_
(	_	_
chosen	_	_
using	_	_
validation	_	_
dataset	_	_
)	_	_
to	_	_
binarize	_	_
pixel	_	_
probabilities	_	_
.	_	_

#95
All	_	_
pixel	_	_
values	_	_
below	_	_
the	_	_
specified	_	_
threshold	_	_
are	_	_
set	_	_
to	_	_
0	_	_
,	_	_
while	_	_
all	_	_
values	_	_
above	_	_
the	_	_
threshold	_	_
are	_	_
set	_	_
to	_	_
255	_	_
to	_	_
produce	_	_
final	_	_
prediction	_	_
mask	_	_
.	_	_

#96
For	_	_
multi-class	_	_
segmentation	_	_
we	_	_
use	_	_
similar	_	_
procedure	_	_
,	_	_
but	_	_
we	_	_
set	_	_
different	_	_
integer	_	_
numbers	_	_
for	_	_
each	_	_
class	_	_
as	_	_
was	_	_
noted	_	_
above	_	_
.	_	_

#97
3	_	_
Results	_	_

#98
The	_	_
qualitative	_	_
comparison	_	_
of	_	_
our	_	_
models	_	_
both	_	_
for	_	_
a	_	_
binary	_	_
and	_	_
multi-class	_	_
segmentation	_	_
is	_	_
presented	_	_
in	_	_
Fig.	_	_
3	_	_
and	_	_
Table	_	_
1	_	_
.	_	_

#99
For	_	_
the	_	_
binary	_	_
segmentation	_	_
task	_	_
the	_	_
best	_	_
results	_	_
is	_	_
achieved	_	_
by	_	_
TernausNet-16	_	_
providing	_	_
𝐼𝑜𝑈	_	_
=	_	_
0.836	_	_
and	_	_
𝐷𝑖𝑐𝑒	_	_
=	_	_
0.901	_	_
.	_	_

#100
These	_	_
values	_	_
are	_	_
the	_	_
best	_	_
reported	_	_
in	_	_
the	_	_
literature	_	_
up	_	_
to	_	_
now	_	_
[	_	_
7,15	_	_
]	_	_
.	_	_

#101
Next	_	_
,	_	_
we	_	_
consider	_	_
multi-class	_	_
segmentation	_	_
of	_	_
different	_	_
parts	_	_
of	_	_
instruments	_	_
.	_	_

#102
As	_	_
before	_	_
,	_	_
the	_	_
best	_	_
results	_	_
reveals	_	_
TernausNet-16	_	_
providing	_	_
𝐼𝑜𝑈	_	_
=	_	_
0.655	_	_
and	_	_
𝐷𝑖𝑐𝑒	_	_
=	_	_
0.760	_	_
.	_	_

#103
For	_	_
the	_	_
multi-class	_	_
class	_	_
instrument	_	_
segmentation	_	_
task	_	_
the	_	_
results	_	_
look	_	_
less	_	_
optimistic	_	_
.	_	_

#104
In	_	_
this	_	_
case	_	_
the	_	_
best	_	_
model	_	_
is	_	_
TernausNet-11	_	_
that	_	_
achieves	_	_
Deep	_	_
Learning	_	_
for	_	_
Surgical	_	_
Instrument	_	_
Segmentation	_	_
7	_	_
Table	_	_
1	_	_
:	_	_
Segmentation	_	_
results	_	_
per	_	_
task	_	_
.	_	_

#105
Intersection	_	_
over	_	_
Union	_	_
(	_	_
IoU	_	_
)	_	_
and	_	_
Dice	_	_
coefficient	_	_
(	_	_
Dice	_	_
)	_	_
are	_	_
in	_	_
%	_	_
and	_	_
inference	_	_
time	_	_
(	_	_
Time	_	_
)	_	_
is	_	_
in	_	_
𝑚𝑠	_	_
.	_	_

#106
Binary	_	_
segmentation	_	_
Parts	_	_
segmentation	_	_
Instrument	_	_
segmentation	_	_
Model	_	_
IOU	_	_
Dice	_	_
Time	_	_
IOU	_	_
Dice	_	_
Time	_	_
IOU	_	_
Dice	_	_
Time	_	_
U-Net	_	_
75.44	_	_
84.37	_	_
93	_	_
48.41	_	_
60.75	_	_
106	_	_
15.80	_	_
23.59	_	_
122	_	_
TernausNet-11	_	_
81.14	_	_
88.07	_	_
142	_	_
62.23	_	_
74.25	_	_
157	_	_
34.61	_	_
45.86	_	_
173	_	_
TernausNet-16	_	_
83.60	_	_
90.01	_	_
184	_	_
65.50	_	_
75.97	_	_
202	_	_
33.78	_	_
44.95	_	_
275	_	_
LinkNet-34	_	_
82.36	_	_
88.87	_	_
88	_	_
34.55	_	_
41.26	_	_
97	_	_
22.47	_	_
24.71	_	_
177	_	_
𝐼𝑜𝑈	_	_
=	_	_
0.346	_	_
and	_	_
𝐷𝑖𝑐𝑒	_	_
=	_	_
0.459	_	_
for	_	_
segmentation	_	_
on	_	_
7	_	_
classes	_	_
.	_	_

#107
Lower	_	_
performance	_	_
can	_	_
be	_	_
explained	_	_
by	_	_
the	_	_
relatively	_	_
small	_	_
dataset	_	_
size	_	_
.	_	_

#108
There	_	_
are	_	_
7	_	_
classes	_	_
and	_	_
several	_	_
classes	_	_
appear	_	_
just	_	_
few	_	_
times	_	_
in	_	_
the	_	_
training	_	_
dataset	_	_
.	_	_

#109
The	_	_
results	_	_
suggests	_	_
that	_	_
this	_	_
results	_	_
can	_	_
be	_	_
improved	_	_
by	_	_
increasing	_	_
the	_	_
dataset	_	_
size	_	_
for	_	_
the	_	_
corresponding	_	_
problem	_	_
.	_	_

#110
When	_	_
compared	_	_
by	_	_
the	_	_
inference	_	_
time	_	_
,	_	_
LinkNet-34	_	_
is	_	_
the	_	_
fastest	_	_
model	_	_
due	_	_
to	_	_
the	_	_
light	_	_
encoder	_	_
.	_	_

#111
In	_	_
the	_	_
case	_	_
of	_	_
a	_	_
binary	_	_
segmentation	_	_
task	_	_
this	_	_
network	_	_
takes	_	_
around	_	_
90	_	_
𝑚𝑠	_	_
for	_	_
1280	_	_
×	_	_
1024	_	_
pixel	_	_
image	_	_
and	_	_
more	_	_
than	_	_
twice	_	_
as	_	_
fast	_	_
as	_	_
TernausNet	_	_
.	_	_

#112
The	_	_
inference	_	_
time	_	_
was	_	_
measured	_	_
using	_	_
one	_	_
NVIDIA	_	_
GTX	_	_
1080Ti	_	_
GPU	_	_
.	_	_

#113
A	_	_
detailed	_	_
comparison	_	_
for	_	_
the	_	_
binary	_	_
and	_	_
multi-class	_	_
tasks	_	_
can	_	_
be	_	_
found	_	_
in	_	_
our	_	_
GitHub	_	_
repository	_	_
at	_	_
https	_	_
:	_	_
//github.com/ternaus/robotsurgerysegmentation	_	_
.	_	_

#114
Suggested	_	_
approach	_	_
demonstrated	_	_
state-of-the-art	_	_
level	_	_
of	_	_
performance	_	_
when	_	_
compared	_	_
to	_	_
other	_	_
deep	_	_
learning-based	_	_
solutions	_	_
within	_	_
to	_	_
the	_	_
MICCAI	_	_
2017	_	_
Endoscopic	_	_
Vision	_	_
SubChallenge	_	_
:	_	_
Robotic	_	_
Instrument	_	_
Segmentation	_	_
[	_	_
13	_	_
]	_	_
.	_	_

#115
4	_	_
Conclusions	_	_

#116
In	_	_
this	_	_
paper	_	_
,	_	_
we	_	_
describe	_	_
our	_	_
solution	_	_
robotic	_	_
instrument	_	_
segmentation	_	_
and	_	_
demonstrate	_	_
comparative	_	_
analysis	_	_
of	_	_
various	_	_
deep	_	_
network	_	_
models	_	_
.	_	_

#117
Our	_	_
approach	_	_
is	_	_
originally	_	_
based	_	_
on	_	_
U-Net	_	_
network	_	_
architecture	_	_
that	_	_
we	_	_
improved	_	_
using	_	_
state-of-the-art	_	_
semantic	_	_
segmentation	_	_
neural	_	_
networks	_	_
known	_	_
as	_	_
LinkNet	_	_
and	_	_
TernausNet	_	_
.	_	_

#118
Our	_	_
results	_	_
shows	_	_
competitive	_	_
performance	_	_
for	_	_
a	_	_
binary	_	_
as	_	_
well	_	_
as	_	_
for	_	_
multi-class	_	_
robotic	_	_
instrument	_	_
segmentation	_	_
.	_	_

#119
All	_	_
of	_	_
these	_	_
networks	_	_
make	_	_
up	_	_
end-to-end	_	_
pipeline	_	_
,	_	_
performing	_	_
efficient	_	_
analysis	_	_
on	_	_
the	_	_
whole	_	_
image	_	_
resolution	_	_
.	_	_

#120
We	_	_
believe	_	_
that	_	_
our	_	_
methods	_	_
can	_	_
lay	_	_
a	_	_
good	_	_
foundation	_	_
for	_	_
similar	_	_
problems	_	_
of	_	_
real-time	_	_
surgical	_	_
instrument	_	_
position	_	_
detection	_	_
.	_	_

#121
This	_	_
,	_	_
in	_	_
turn	_	_
,	_	_
can	_	_
be	_	_
used	_	_
for	_	_
the	_	_
tracking	_	_
and	_	_
pose	_	_
estimation	_	_
in	_	_
the	_	_
vicinity	_	_
of	_	_
surgical	_	_
scenes	_	_
.	_	_