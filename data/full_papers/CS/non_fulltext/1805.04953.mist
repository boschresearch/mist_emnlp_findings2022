#0
Learning	_	_
Rich	_	_
Features	_	_
for	_	_
Image	_	_
Manipulation	_	_
Detection	_	_
Peng	_	_
Zhou1	_	_
Xintong	_	_
Han1	_	_
Vlad	_	_
I.	_	_
Morariu2	_	_
∗	_	_
Larry	_	_
S.	_	_
Davis1	_	_
1University	_	_
of	_	_
Maryland	_	_
,	_	_
College	_	_
Park	_	_
2Adobe	_	_
Research	_	_
pengzhou	_	_
@	_	_
umd.edu	_	_
{	_	_
xintong	_	_
,	_	_
lsd	_	_
}	_	_
@	_	_
umiacs.umd.edu	_	_
morariu	_	_
@	_	_
adobe.com	_	_

#1
Abstract	_	_

#2
Image	_	_
manipulation	_	_
detection	_	_
is	_	_
different	_	_
from	_	_
traditional	_	_
semantic	_	_
object	_	_
detection	_	_
because	_	_
it	_	_
pays	_	_
more	_	_
attention	_	_
to	_	_
tampering	_	_
artifacts	_	_
than	_	_
to	_	_
image	_	_
content	_	_
,	_	_
which	_	_
suggests	_	_
that	_	_
richer	_	_
features	_	_
need	_	_
to	_	_
be	_	_
learned	_	_
.	_	_

#3
We	_	_
propose	_	_
a	_	_
two-stream	_	_
Faster	_	_
R-CNN	_	_
network	_	_
and	_	_
train	_	_
it	_	_
end-to-end	_	_
to	_	_
detect	_	_
the	_	_
tampered	_	_
regions	_	_
given	_	_
a	_	_
manipulated	_	_
image	_	_
.	_	_

#4
One	_	_
of	_	_
the	_	_
two	_	_
streams	_	_
is	_	_
an	_	_
RGB	_	_
stream	_	_
whose	_	_
purpose	_	_
is	_	_
to	_	_
extract	_	_
features	_	_
from	_	_
the	_	_
RGB	_	_
image	_	_
input	_	_
to	_	_
find	_	_
tampering	_	_
artifacts	_	_
like	_	_
strong	_	_
contrast	_	_
difference	_	_
,	_	_
unnatural	_	_
tampered	_	_
boundaries	_	_
,	_	_
and	_	_
so	_	_
on	_	_
.	_	_

#5
The	_	_
other	_	_
is	_	_
a	_	_
noise	_	_
stream	_	_
that	_	_
leverages	_	_
the	_	_
noise	_	_
features	_	_
extracted	_	_
from	_	_
a	_	_
steganalysis	_	_
rich	_	_
model	_	_
filter	_	_
layer	_	_
to	_	_
discover	_	_
the	_	_
noise	_	_
inconsistency	_	_
between	_	_
authentic	_	_
and	_	_
tampered	_	_
regions	_	_
.	_	_

#6
We	_	_
then	_	_
fuse	_	_
features	_	_
from	_	_
the	_	_
two	_	_
streams	_	_
through	_	_
a	_	_
bilinear	_	_
pooling	_	_
layer	_	_
to	_	_
further	_	_
incorporate	_	_
spatial	_	_
co-occurrence	_	_
of	_	_
these	_	_
two	_	_
modalities	_	_
.	_	_

#7
Experiments	_	_
on	_	_
four	_	_
standard	_	_
image	_	_
manipulation	_	_
datasets	_	_
demonstrate	_	_
that	_	_
our	_	_
two-stream	_	_
framework	_	_
outperforms	_	_
each	_	_
individual	_	_
stream	_	_
,	_	_
and	_	_
also	_	_
achieves	_	_
state-of-the-art	_	_
performance	_	_
compared	_	_
to	_	_
alternative	_	_
methods	_	_
with	_	_
robustness	_	_
to	_	_
resizing	_	_
and	_	_
compression	_	_
.	_	_

#8
1	_	_
.	_	_

#9
Introduction	_	_
With	_	_
the	_	_
advances	_	_
of	_	_
image	_	_
editing	_	_
techniques	_	_
and	_	_
userfriendly	_	_
editing	_	_
software	_	_
,	_	_
low-cost	_	_
tampered	_	_
or	_	_
manipulated	_	_
image	_	_
generation	_	_
processes	_	_
have	_	_
become	_	_
widely	_	_
available	_	_
.	_	_

#10
Among	_	_
tampering	_	_
techniques	_	_
,	_	_
splicing	_	_
,	_	_
copy-move	_	_
,	_	_
and	_	_
removal	_	_
are	_	_
the	_	_
most	_	_
common	_	_
manipulations	_	_
.	_	_

#11
Image	_	_
splicing	_	_
copies	_	_
regions	_	_
from	_	_
an	_	_
authentic	_	_
image	_	_
and	_	_
pastes	_	_
them	_	_
to	_	_
other	_	_
images	_	_
,	_	_
copy-move	_	_
copies	_	_
and	_	_
pastes	_	_
regions	_	_
within	_	_
the	_	_
same	_	_
image	_	_
,	_	_
and	_	_
removal	_	_
eliminates	_	_
regions	_	_
from	_	_
an	_	_
authentic	_	_
image	_	_
followed	_	_
by	_	_
inpainting	_	_
.	_	_

#12
Sometimes	_	_
,	_	_
post-processing	_	_
like	_	_
Gaussian	_	_
smoothing	_	_
will	_	_
be	_	_
applied	_	_
after	_	_
these	_	_
tampering	_	_
techniques	_	_
.	_	_

#13
Examples	_	_
of	_	_
these	_	_
manipulations	_	_
are	_	_
shown	_	_
in	_	_
Figure	_	_
1	_	_
.	_	_

#14
Even	_	_
with	_	_
careful	_	_
inspection	_	_
,	_	_
humans	_	_
find	_	_
it	_	_
difficult	_	_
to	_	_
recognize	_	_
the	_	_
tampered	_	_
regions	_	_
.	_	_

#15
∗The	_	_
work	_	_
was	_	_
done	_	_
while	_	_
the	_	_
author	_	_
was	_	_
at	_	_
the	_	_
University	_	_
of	_	_
Maryland	_	_
Authentic	_	_
image	_	_
Ground-truth	_	_
maskTampered	_	_
image	_	_
Sp	_	_
lic	_	_
in	_	_
g	_	_
Co	_	_
py	_	_
-m	_	_
ov	_	_
e	_	_
Re	_	_
m	_	_
ov	_	_
al	_	_
Figure	_	_
1	_	_
.	_	_

#16
Examples	_	_
of	_	_
tampered	_	_
images	_	_
that	_	_
have	_	_
undergone	_	_
different	_	_
tampering	_	_
techniques	_	_
.	_	_

#17
From	_	_
the	_	_
top	_	_
to	_	_
bottom	_	_
are	_	_
the	_	_
examples	_	_
showing	_	_
manipulations	_	_
of	_	_
splicing	_	_
,	_	_
copy-move	_	_
and	_	_
removal	_	_
.	_	_

#18
As	_	_
a	_	_
result	_	_
,	_	_
distinguishing	_	_
authentic	_	_
images	_	_
from	_	_
tampered	_	_
images	_	_
has	_	_
become	_	_
increasingly	_	_
challenging	_	_
.	_	_

#19
The	_	_
emerging	_	_
research	_	_
focusing	_	_
on	_	_
this	_	_
topic	_	_
—	_	_
image	_	_
forensics	_	_
—	_	_
is	_	_
of	_	_
great	_	_
importance	_	_
because	_	_
it	_	_
seeks	_	_
to	_	_
prevent	_	_
attackers	_	_
from	_	_
using	_	_
their	_	_
tampered	_	_
images	_	_
for	_	_
unscrupulous	_	_
business	_	_
or	_	_
political	_	_
purposes	_	_
.	_	_

#20
In	_	_
contrast	_	_
to	_	_
current	_	_
object	_	_
detection	_	_
networks	_	_
[	_	_
28	_	_
,	_	_
18	_	_
,	_	_
10	_	_
,	_	_
32	_	_
,	_	_
16	_	_
,	_	_
31	_	_
]	_	_
which	_	_
aim	_	_
to	_	_
detect	_	_
all	_	_
objects	_	_
of	_	_
different	_	_
categories	_	_
in	_	_
an	_	_
image	_	_
,	_	_
a	_	_
network	_	_
for	_	_
image	_	_
manipulation	_	_
detection	_	_
would	_	_
aim	_	_
to	_	_
detect	_	_
only	_	_
the	_	_
tampered	_	_
regions	_	_
(	_	_
usually	_	_
objects	_	_
)	_	_
.	_	_

#21
We	_	_
investigate	_	_
how	_	_
to	_	_
adopt	_	_
object	_	_
detection	_	_
networks	_	_
to	_	_
perform	_	_
image	_	_
manipulation	_	_
detection	_	_
by	_	_
exploring	_	_
both	_	_
RGB	_	_
image	_	_
content	_	_
and	_	_
image	_	_
noise	_	_
features	_	_
.	_	_

#22
Recent	_	_
work	_	_
on	_	_
image	_	_
forensics	_	_
utilizes	_	_
clues	_	_
such	_	_
as	_	_
local	_	_
noise	_	_
features	_	_
[	_	_
35	_	_
,	_	_
26	_	_
]	_	_
and	_	_
Camera	_	_
Filter	_	_
Array	_	_
(	_	_
CFA	_	_
)	_	_
patterns	_	_
[	_	_
19	_	_
]	_	_
to	_	_
classify	_	_
a	_	_
specific	_	_
patch	_	_
or	_	_
pixel	_	_
[	_	_
11	_	_
]	_	_
in	_	_
an	_	_
image	_	_
as	_	_
tampered	_	_
or	_	_
not	_	_
,	_	_
and	_	_
localize	_	_
the	_	_
tampered	_	_
regions	_	_
[	_	_
19	_	_
,	_	_
9	_	_
,	_	_
6	_	_
]	_	_
.	_	_

#23
Most	_	_
of	_	_
these	_	_
methods	_	_
focus	_	_
on	_	_
a	_	_
single	_	_
tampering	_	_
technique	_	_
.	_	_

#24
A	_	_
recently	_	_
proposed	_	_
architecture	_	_
[	_	_
2	_	_
]	_	_
based	_	_
on	_	_
a	_	_
Long	_	_
Short	_	_
Term	_	_
Network	_	_
(	_	_
LSTM	_	_
)	_	_
segments	_	_
tampered	_	_
patches	_	_
,	_	_
showing	_	_
robustness	_	_
to	_	_
multiple	_	_
tampering	_	_
techar	_	_
X	_	_
iv	_	_
:1	_	_
5	_	_
.	_	_

#25
3v	_	_
1	_	_
[	_	_
cs	_	_
.C	_	_
V	_	_
]	_	_
1	_	_
3	_	_
M	_	_
ay	_	_
2	_	_
Bilinear	_	_
pooling	_	_
bbx_pred	_	_
cls_pred	_	_
RGB	_	_
Conv	_	_
Layers	_	_
Noise	_	_
Conv	_	_
Layers	_	_
RPN	_	_
layer	_	_
RoI	_	_
pooling	_	_
layer	_	_
RGB	_	_
RoI	_	_
features	_	_
Noise	_	_
RoI	_	_
features	_	_
SRM	_	_
filter	_	_
layer	_	_
Noise	_	_
stream	_	_
input	_	_
RGB	_	_
stream	_	_
input	_	_
Figure	_	_
2	_	_
.	_	_

#26
Illustration	_	_
of	_	_
our	_	_
two-stream	_	_
Faster	_	_
R-CNN	_	_
network	_	_
.	_	_

#27
The	_	_
RGB	_	_
stream	_	_
models	_	_
visual	_	_
tampering	_	_
artifacts	_	_
,	_	_
such	_	_
as	_	_
unusually	_	_
high	_	_
contrast	_	_
along	_	_
object	_	_
edges	_	_
,	_	_
and	_	_
regresses	_	_
bounding	_	_
boxes	_	_
to	_	_
the	_	_
ground-truth	_	_
.	_	_

#28
The	_	_
noise	_	_
stream	_	_
first	_	_
obtains	_	_
the	_	_
noise	_	_
feature	_	_
map	_	_
by	_	_
passing	_	_
input	_	_
RGB	_	_
image	_	_
through	_	_
an	_	_
SRM	_	_
filter	_	_
layer	_	_
,	_	_
and	_	_
leverages	_	_
the	_	_
noise	_	_
features	_	_
to	_	_
provide	_	_
additional	_	_
evidence	_	_
for	_	_
manipulation	_	_
classification	_	_
.	_	_

#29
The	_	_
RGB	_	_
and	_	_
noise	_	_
streams	_	_
share	_	_
the	_	_
same	_	_
region	_	_
proposals	_	_
from	_	_
RPN	_	_
network	_	_
which	_	_
only	_	_
uses	_	_
RGB	_	_
features	_	_
as	_	_
input	_	_
.	_	_

#30
The	_	_
RoI	_	_
pooling	_	_
layer	_	_
selects	_	_
spatial	_	_
features	_	_
from	_	_
both	_	_
RGB	_	_
and	_	_
noise	_	_
streams	_	_
.	_	_

#31
The	_	_
predicted	_	_
bounding	_	_
boxes	_	_
(	_	_
denoted	_	_
as	_	_
‘bbx	_	_
pred’	_	_
)	_	_
are	_	_
generated	_	_
from	_	_
RGB	_	_
RoI	_	_
features	_	_
.	_	_

#32
A	_	_
bilinear	_	_
pooling	_	_
[	_	_
23	_	_
,	_	_
17	_	_
]	_	_
layer	_	_
after	_	_
RoI	_	_
pooling	_	_
enables	_	_
the	_	_
network	_	_
to	_	_
combine	_	_
the	_	_
spatial	_	_
co-occurrence	_	_
features	_	_
from	_	_
the	_	_
two	_	_
streams	_	_
.	_	_

#33
Finally	_	_
,	_	_
passing	_	_
the	_	_
results	_	_
through	_	_
a	_	_
fully	_	_
connected	_	_
layer	_	_
and	_	_
a	_	_
softmax	_	_
layer	_	_
,	_	_
the	_	_
network	_	_
produces	_	_
the	_	_
predicted	_	_
label	_	_
(	_	_
denoted	_	_
as	_	_
‘cls	_	_
pred’	_	_
)	_	_
and	_	_
determines	_	_
whether	_	_
predicted	_	_
regions	_	_
have	_	_
been	_	_
manipulated	_	_
or	_	_
not	_	_
.	_	_

#34
niques	_	_
by	_	_
learning	_	_
to	_	_
detect	_	_
tampered	_	_
edges	_	_
.	_	_

#35
Here	_	_
,	_	_
we	_	_
propose	_	_
a	_	_
novel	_	_
two-stream	_	_
manipulation	_	_
detection	_	_
framework	_	_
,	_	_
which	_	_
not	_	_
only	_	_
models	_	_
visual	_	_
tampering	_	_
artifacts	_	_
(	_	_
e.g.	_	_
,	_	_
tampered	_	_
artifacts	_	_
near	_	_
manipulated	_	_
edges	_	_
)	_	_
,	_	_
but	_	_
also	_	_
captures	_	_
inconsistencies	_	_
in	_	_
local	_	_
noise	_	_
features	_	_
.	_	_

#36
More	_	_
specifically	_	_
,	_	_
we	_	_
adopt	_	_
Faster	_	_
R-CNN	_	_
[	_	_
28	_	_
]	_	_
within	_	_
a	_	_
two-stream	_	_
network	_	_
and	_	_
perform	_	_
end-to-end	_	_
training	_	_
.	_	_

#37
A	_	_
summary	_	_
of	_	_
our	_	_
method	_	_
is	_	_
shown	_	_
in	_	_
Figure	_	_
2	_	_
.	_	_

#38
Deep	_	_
learning	_	_
detection	_	_
models	_	_
like	_	_
Faster	_	_
R-CNN	_	_
[	_	_
28	_	_
]	_	_
have	_	_
demonstrated	_	_
good	_	_
performance	_	_
on	_	_
detecting	_	_
semantic	_	_
objects	_	_
over	_	_
a	_	_
range	_	_
of	_	_
scales	_	_
.	_	_

#39
The	_	_
Region	_	_
Proposal	_	_
Network	_	_
(	_	_
RPN	_	_
)	_	_
is	_	_
the	_	_
component	_	_
in	_	_
Faster	_	_
R-CNN	_	_
that	_	_
is	_	_
responsible	_	_
for	_	_
proposing	_	_
image	_	_
regions	_	_
that	_	_
are	_	_
likely	_	_
to	_	_
contain	_	_
objects	_	_
of	_	_
interest	_	_
,	_	_
and	_	_
it	_	_
can	_	_
be	_	_
adapted	_	_
for	_	_
image	_	_
manipulation	_	_
detection	_	_
.	_	_

#40
For	_	_
distinguishing	_	_
tampered	_	_
regions	_	_
from	_	_
authentic	_	_
regions	_	_
,	_	_
we	_	_
utilize	_	_
features	_	_
from	_	_
the	_	_
RGB	_	_
channels	_	_
to	_	_
capture	_	_
clues	_	_
like	_	_
visual	_	_
inconsistencies	_	_
at	_	_
tampered	_	_
boundaries	_	_
and	_	_
contrast	_	_
effect	_	_
between	_	_
tampered	_	_
regions	_	_
and	_	_
authentic	_	_
regions	_	_
.	_	_

#41
The	_	_
second	_	_
stream	_	_
analyzes	_	_
the	_	_
local	_	_
noise	_	_
features	_	_
in	_	_
an	_	_
image	_	_
.	_	_

#42
The	_	_
intuition	_	_
behind	_	_
the	_	_
second	_	_
stream	_	_
is	_	_
that	_	_
when	_	_
an	_	_
object	_	_
is	_	_
removed	_	_
from	_	_
one	_	_
image	_	_
(	_	_
the	_	_
source	_	_
)	_	_
and	_	_
pasted	_	_
into	_	_
another	_	_
(	_	_
the	_	_
target	_	_
)	_	_
,	_	_
the	_	_
noise	_	_
features	_	_
between	_	_
the	_	_
source	_	_
and	_	_
target	_	_
images	_	_
are	_	_
unlikely	_	_
to	_	_
match	_	_
.	_	_

#43
These	_	_
differences	_	_
can	_	_
be	_	_
partially	_	_
masked	_	_
if	_	_
the	_	_
user	_	_
subsequently	_	_
compresses	_	_
the	_	_
tampered	_	_
image	_	_
[	_	_
26	_	_
,	_	_
4	_	_
]	_	_
.	_	_

#44
To	_	_
utilize	_	_
these	_	_
features	_	_
,	_	_
we	_	_
transform	_	_
the	_	_
RGB	_	_
image	_	_
into	_	_
the	_	_
noise	_	_
domain	_	_
and	_	_
use	_	_
the	_	_
local	_	_
noise	_	_
features	_	_
as	_	_
the	_	_
input	_	_
to	_	_
the	_	_
second	_	_
stream	_	_
.	_	_

#45
There	_	_
are	_	_
many	_	_
ways	_	_
to	_	_
produce	_	_
noise	_	_
features	_	_
from	_	_
an	_	_
image	_	_
.	_	_

#46
Based	_	_
on	_	_
recent	_	_
work	_	_
on	_	_
steganalysis	_	_
rich	_	_
model	_	_
(	_	_
SRM	_	_
)	_	_
for	_	_
manipulation	_	_
classification	_	_
[	_	_
35	_	_
,	_	_
15	_	_
]	_	_
,	_	_
we	_	_
select	_	_
SRM	_	_
filter	_	_
kernels	_	_
to	_	_
produce	_	_
the	_	_
noise	_	_
features	_	_
and	_	_
use	_	_
them	_	_
as	_	_
the	_	_
input	_	_
channel	_	_
to	_	_
the	_	_
second	_	_
Faster	_	_
R-CNN	_	_
network	_	_
.	_	_

#47
Features	_	_
from	_	_
these	_	_
two	_	_
streams	_	_
are	_	_
then	_	_
bi-linearly	_	_
pooled	_	_
for	_	_
each	_	_
Region	_	_
of	_	_
Interest	_	_
(	_	_
RoI	_	_
)	_	_
to	_	_
detect	_	_
tampering	_	_
artifacts	_	_
based	_	_
on	_	_
features	_	_
from	_	_
both	_	_
streams	_	_
,	_	_
see	_	_
Figure	_	_
2	_	_
.	_	_

#48
Previous	_	_
image	_	_
manipulation	_	_
datasets	_	_
[	_	_
25	_	_
,	_	_
1	_	_
,	_	_
12	_	_
,	_	_
30	_	_
]	_	_
contain	_	_
only	_	_
several	_	_
hundred	_	_
images	_	_
,	_	_
not	_	_
enough	_	_
to	_	_
train	_	_
a	_	_
deep	_	_
network	_	_
.	_	_

#49
To	_	_
overcome	_	_
this	_	_
,	_	_
we	_	_
created	_	_
a	_	_
synthetic	_	_
tampering	_	_
dataset	_	_
based	_	_
on	_	_
COCO	_	_
[	_	_
22	_	_
]	_	_
for	_	_
pre-training	_	_
our	_	_
model	_	_
and	_	_
then	_	_
finetuned	_	_
the	_	_
model	_	_
on	_	_
different	_	_
datasets	_	_
for	_	_
testing	_	_
.	_	_

#50
Experimental	_	_
results	_	_
of	_	_
our	_	_
approach	_	_
on	_	_
four	_	_
standard	_	_
datasets	_	_
demonstrate	_	_
promising	_	_
performance	_	_
.	_	_

#51
Our	_	_
contribution	_	_
is	_	_
two-fold	_	_
.	_	_

#52
First	_	_
,	_	_
we	_	_
show	_	_
how	_	_
a	_	_
Faster	_	_
R-CNN	_	_
framework	_	_
can	_	_
be	_	_
adapted	_	_
for	_	_
image	_	_
manipulation	_	_
detection	_	_
in	_	_
a	_	_
two-stream	_	_
fashion	_	_
.	_	_

#53
We	_	_
explore	_	_
two	_	_
modalities	_	_
,	_	_
RGB	_	_
tampering	_	_
artifacts	_	_
and	_	_
local	_	_
noise	_	_
feature	_	_
inconsistencies	_	_
,	_	_
bilinearly	_	_
pooling	_	_
them	_	_
to	_	_
identify	_	_
tampered	_	_
regions	_	_
.	_	_

#54
Second	_	_
,	_	_
we	_	_
show	_	_
that	_	_
the	_	_
two	_	_
streams	_	_
are	_	_
complementary	_	_
for	_	_
detecting	_	_
different	_	_
tampered	_	_
techniques	_	_
,	_	_
leading	_	_
to	_	_
improved	_	_
performance	_	_
on	_	_
four	_	_
image	_	_
manipulation	_	_
datasets	_	_
compared	_	_
to	_	_
state-of-the-art	_	_
methods	_	_
.	_	_

#55
2	_	_
.	_	_

#56
Related	_	_
Work	_	_
Research	_	_
on	_	_
image	_	_
forensics	_	_
consists	_	_
of	_	_
various	_	_
approaches	_	_
to	_	_
detect	_	_
the	_	_
low-level	_	_
tampering	_	_
artifacts	_	_
within	_	_
a	_	_
tampered	_	_
image	_	_
,	_	_
including	_	_
double	_	_
JPEG	_	_
compression	_	_
[	_	_
4	_	_
]	_	_
,	_	_
CFA	_	_
color	_	_
array	_	_
anaylsis	_	_
[	_	_
19	_	_
]	_	_
and	_	_
local	_	_
noise	_	_
analysis	_	_
[	_	_
7	_	_
]	_	_
.	_	_

#57
Specifically	_	_
,	_	_
Bianchi	_	_
et	_	_
al.	_	_
[	_	_
4	_	_
]	_	_
propose	_	_
a	_	_
probabilistic	_	_
model	_	_
to	_	_
estimate	_	_
the	_	_
DCT	_	_
coefficients	_	_
and	_	_
quantization	_	_
factors	_	_
for	_	_
different	_	_
regions	_	_
.	_	_

#58
CFA	_	_
based	_	_
methods	_	_
analyze	_	_
low-level	_	_
statistics	_	_
introduced	_	_
by	_	_
the	_	_
camera	_	_
internal	_	_
filter	_	_
patterns	_	_
under	_	_
the	_	_
assumption	_	_
that	_	_
the	_	_
tampered	_	_
regions	_	_
disturb	_	_
these	_	_
patterns	_	_
.	_	_

#59
Goljan	_	_
et	_	_
al.	_	_
[	_	_
19	_	_
]	_	_
propose	_	_
a	_	_
Gaussian	_	_
Mixture	_	_
Model	_	_
(	_	_
GMM	_	_
)	_	_
to	_	_
classify	_	_
CFA	_	_
present	_	_
regions	_	_
(	_	_
authentic	_	_
regions	_	_
)	_	_
and	_	_
CFA	_	_
absent	_	_
regions	_	_
(	_	_
tampered	_	_
regions	_	_
)	_	_
.	_	_

#60
Recently	_	_
,	_	_
local	_	_
noise	_	_
features	_	_
based	_	_
methods	_	_
,	_	_
like	_	_
the	_	_
steganalysis	_	_
rich	_	_
model	_	_
(	_	_
SRM	_	_
)	_	_
[	_	_
15	_	_
]	_	_
,	_	_
have	_	_
shown	_	_
promising	_	_
performance	_	_
in	_	_
image	_	_
forensics	_	_
tasks	_	_
.	_	_

#61
These	_	_
methods	_	_
extract	_	_
local	_	_
noise	_	_
features	_	_
from	_	_
adjacent	_	_
pixels	_	_
,	_	_
capturing	_	_
the	_	_
inconsistency	_	_
between	_	_
tampered	_	_
regions	_	_
and	_	_
authentic	_	_
regions	_	_
.	_	_

#62
Cozzolino	_	_
et	_	_
al.	_	_
[	_	_
7	_	_
]	_	_
explore	_	_
and	_	_
demonstrate	_	_
the	_	_
performance	_	_
of	_	_
SRM	_	_
features	_	_
in	_	_
distinguishing	_	_
tampered	_	_
and	_	_
authentic	_	_
regions	_	_
.	_	_

#63
They	_	_
also	_	_
combine	_	_
SRM	_	_
features	_	_
by	_	_
including	_	_
the	_	_
quantization	_	_
and	_	_
truncation	_	_
operations	_	_
with	_	_
a	_	_
Convolutional	_	_
Neural	_	_
Network	_	_
(	_	_
CNN	_	_
)	_	_
to	_	_
perform	_	_
manipulation	_	_
localization	_	_
[	_	_
8	_	_
]	_	_
.	_	_

#64
Rao	_	_
et	_	_
al.	_	_
[	_	_
27	_	_
]	_	_
use	_	_
an	_	_
SRM	_	_
filter	_	_
kernel	_	_
as	_	_
initialization	_	_
for	_	_
a	_	_
CNN	_	_
to	_	_
boost	_	_
the	_	_
detection	_	_
accuracy	_	_
.	_	_

#65
Most	_	_
of	_	_
these	_	_
methods	_	_
focus	_	_
on	_	_
specific	_	_
tampering	_	_
artifacts	_	_
and	_	_
are	_	_
limited	_	_
to	_	_
specific	_	_
tampering	_	_
techniques	_	_
.	_	_

#66
We	_	_
also	_	_
use	_	_
these	_	_
SRM	_	_
filter	_	_
kernels	_	_
to	_	_
extract	_	_
low-level	_	_
noise	_	_
that	_	_
is	_	_
used	_	_
as	_	_
the	_	_
input	_	_
to	_	_
a	_	_
Faster	_	_
R-CNN	_	_
network	_	_
,	_	_
and	_	_
learn	_	_
to	_	_
capture	_	_
tampering	_	_
traces	_	_
from	_	_
the	_	_
noise	_	_
features	_	_
.	_	_

#67
Moreover	_	_
,	_	_
a	_	_
parallel	_	_
RGB	_	_
stream	_	_
is	_	_
trained	_	_
jointly	_	_
to	_	_
model	_	_
mid-	_	_
and	_	_
high-level	_	_
visual	_	_
tampering	_	_
artifacts	_	_
.	_	_

#68
With	_	_
the	_	_
success	_	_
of	_	_
deep	_	_
learning	_	_
techniques	_	_
in	_	_
various	_	_
computer	_	_
vision	_	_
and	_	_
image	_	_
processing	_	_
tasks	_	_
,	_	_
a	_	_
number	_	_
of	_	_
recent	_	_
techniques	_	_
have	_	_
also	_	_
employed	_	_
deep	_	_
learning	_	_
to	_	_
address	_	_
image	_	_
manipulation	_	_
detection	_	_
.	_	_

#69
Chen	_	_
et	_	_
al.	_	_
[	_	_
5	_	_
]	_	_
add	_	_
a	_	_
low	_	_
pass	_	_
filter	_	_
layer	_	_
before	_	_
a	_	_
CNN	_	_
to	_	_
detect	_	_
median	_	_
filtering	_	_
tampering	_	_
techniques	_	_
.	_	_

#70
Bayar	_	_
et	_	_
al.	_	_
[	_	_
3	_	_
]	_	_
change	_	_
the	_	_
low	_	_
pass	_	_
filter	_	_
layer	_	_
to	_	_
an	_	_
adaptive	_	_
kernel	_	_
layer	_	_
to	_	_
learn	_	_
the	_	_
filtering	_	_
kernel	_	_
used	_	_
in	_	_
tampered	_	_
regions	_	_
.	_	_

#71
Beyond	_	_
filtering	_	_
learning	_	_
,	_	_
Zhang	_	_
et	_	_
al.	_	_
[	_	_
34	_	_
]	_	_
propose	_	_
a	_	_
stacked	_	_
autoencoder	_	_
to	_	_
learn	_	_
context	_	_
features	_	_
for	_	_
image	_	_
manipulation	_	_
detection	_	_
.	_	_

#72
Cozzolino	_	_
et	_	_
al.	_	_
[	_	_
9	_	_
]	_	_
treat	_	_
this	_	_
problem	_	_
as	_	_
an	_	_
anomaly	_	_
detection	_	_
task	_	_
and	_	_
use	_	_
an	_	_
autoencoder	_	_
based	_	_
on	_	_
extracted	_	_
features	_	_
to	_	_
distinguish	_	_
those	_	_
regions	_	_
that	_	_
are	_	_
difficult	_	_
to	_	_
reconstruct	_	_
as	_	_
tampered	_	_
regions	_	_
.	_	_

#73
Salloum	_	_
et	_	_
al.	_	_
[	_	_
29	_	_
]	_	_
use	_	_
a	_	_
Fully	_	_
Convolutional	_	_
Network	_	_
(	_	_
FCN	_	_
)	_	_
framework	_	_
to	_	_
directly	_	_
predict	_	_
the	_	_
tampering	_	_
mask	_	_
given	_	_
an	_	_
image	_	_
.	_	_

#74
They	_	_
also	_	_
learn	_	_
a	_	_
boundary	_	_
mask	_	_
to	_	_
guide	_	_
the	_	_
FCN	_	_
to	_	_
look	_	_
at	_	_
tampered	_	_
edges	_	_
,	_	_
which	_	_
assists	_	_
them	_	_
in	_	_
achieving	_	_
better	_	_
performance	_	_
in	_	_
various	_	_
image	_	_
manipulation	_	_
datasets	_	_
.	_	_

#75
Bappy	_	_
et	_	_
al.	_	_
[	_	_
2	_	_
]	_	_
propose	_	_
an	_	_
LSTM	_	_
based	_	_
network	_	_
applied	_	_
to	_	_
small	_	_
image	_	_
patches	_	_
to	_	_
find	_	_
the	_	_
tampering	_	_
artifacts	_	_
on	_	_
the	_	_
boundaries	_	_
between	_	_
tampered	_	_
patches	_	_
and	_	_
image	_	_
patches	_	_
.	_	_

#76
They	_	_
jointly	_	_
train	_	_
this	_	_
network	_	_
with	_	_
pixel	_	_
level	_	_
segmentation	_	_
to	_	_
improve	_	_
the	_	_
performance	_	_
and	_	_
show	_	_
results	_	_
under	_	_
different	_	_
tampering	_	_
techniques	_	_
.	_	_

#77
However	_	_
,	_	_
only	_	_
focusing	_	_
on	_	_
nearby	_	_
boundaries	_	_
provides	_	_
limited	_	_
success	_	_
in	_	_
different	_	_
scenarios	_	_
,	_	_
e.g.	_	_
,	_	_
removing	_	_
the	_	_
whole	_	_
object	_	_
might	speculation	_
leave	_	_
no	_	_
boundary	_	_
evidence	_	_
for	_	_
detection	_	_
.	_	_

#78
Instead	_	_
,	_	_
we	_	_
use	_	_
global	_	_
visual	_	_
tampering	_	_
artifacts	_	_
as	_	_
well	_	_
as	_	_
the	_	_
local	_	_
noise	_	_
features	_	_
to	_	_
model	_	_
richer	_	_
tampering	_	_
artifacts	_	_
.	_	_

#79
We	_	_
use	_	_
a	_	_
two-stream	_	_
network	_	_
built	_	_
on	_	_
Faster	_	_
R-CNN	_	_
to	_	_
learn	_	_
rich	_	_
features	_	_
for	_	_
image	_	_
manipulation	_	_
detection	_	_
.	_	_

#80
The	_	_
network	_	_
shows	_	_
robustness	_	_
to	_	_
splicing	_	_
,	_	_
copy-move	_	_
and	_	_
removal	_	_
.	_	_

#81
In	_	_
addition	_	_
,	_	_
the	_	_
network	_	_
enables	_	_
us	_	_
to	_	_
make	_	_
a	_	_
classification	_	_
of	_	_
the	_	_
suspected	_	_
tampering	_	_
techniques	_	_
.	_	_

#82
3	_	_
.	_	_

#83
Proposed	_	_
Method	_	_
We	_	_
employ	_	_
a	_	_
multi-task	_	_
framework	_	_
that	_	_
simultaneously	_	_
performs	_	_
manipulation	_	_
classification	_	_
and	_	_
bounding	_	_
box	_	_
regression	_	_
.	_	_

#84
RGB	_	_
images	_	_
are	_	_
provided	_	_
in	_	_
the	_	_
RGB	_	_
stream	_	_
(	_	_
the	_	_
top	_	_
stream	_	_
in	_	_
Figure	_	_
2	_	_
)	_	_
,	_	_
and	_	_
SRM	_	_
images	_	_
in	_	_
the	_	_
noise	_	_
stream	_	_
(	_	_
the	_	_
bottom	_	_
stream	_	_
in	_	_
Figure	_	_
2	_	_
)	_	_
.	_	_

#85
We	_	_
fuse	_	_
the	_	_
two	_	_
streams	_	_
through	_	_
bilinear	_	_
pooling	_	_
before	_	_
a	_	_
fully	_	_
connected	_	_
layer	_	_
for	_	_
manipulation	_	_
classification	_	_
.	_	_

#86
The	_	_
RPN	_	_
uses	_	_
the	_	_
RGB	_	_
stream	_	_
to	_	_
localize	_	_
tampered	_	_
regions	_	_
.	_	_

#87
3.1	_	_
.	_	_

#88
RGB	_	_
Stream	_	_
The	_	_
RGB	_	_
stream	_	_
is	_	_
a	_	_
single	_	_
Faster	_	_
R-CNN	_	_
network	_	_
and	_	_
is	_	_
used	_	_
both	_	_
for	_	_
bounding	_	_
box	_	_
regression	_	_
and	_	_
manipulation	_	_
classification	_	_
.	_	_

#89
We	_	_
use	_	_
a	_	_
ResNet	_	_
101	_	_
network	_	_
[	_	_
20	_	_
]	_	_
to	_	_
learn	_	_
features	_	_
from	_	_
the	_	_
input	_	_
RGB	_	_
image	_	_
.	_	_

#90
The	_	_
output	_	_
features	_	_
of	_	_
the	_	_
last	_	_
convolutional	_	_
layer	_	_
of	_	_
ResNet	_	_
are	_	_
used	_	_
for	_	_
manipulation	_	_
classification	_	_
.	_	_

#91
The	_	_
RPN	_	_
network	_	_
in	_	_
the	_	_
RGB	_	_
stream	_	_
utilizes	_	_
these	_	_
features	_	_
to	_	_
propose	_	_
RoI	_	_
for	_	_
bounding	_	_
box	_	_
regression	_	_
.	_	_

#92
Formally	_	_
,	_	_
the	_	_
loss	_	_
for	_	_
the	_	_
RPN	_	_
network	_	_
is	_	_
defined	_	_
as	_	_
LRPN	_	_
(	_	_
gi	_	_
,	_	_
fi	_	_
)	_	_
=	_	_
Ncls	_	_
∑	_	_
i	_	_
Lcls	_	_
(	_	_
gi	_	_
,	_	_
g	_	_
?	_	_

#93
i	_	_
)	_	_
+λ	_	_
Nreg	_	_
∑	_	_
i	_	_
g	_	_
?	_	_
i	_	_
Lreg	_	_
(	_	_
fi	_	_
,	_	_
f	_	_
?	_	_

#94
i	_	_
)	_	_
,	_	_
(	_	_
1	_	_
)	_	_
where	_	_
gi	_	_
denotes	_	_
the	_	_
probability	_	_
of	_	_
anchor	_	_
i	_	_
being	_	_
a	_	_
potential	_	_
manipulated	_	_
region	_	_
in	_	_
a	_	_
mini	_	_
batch	_	_
,	_	_
and	_	_
g	_	_
?	_	_
i	_	_
denotes	_	_
the	_	_
ground-truth	_	_
label	_	_
for	_	_
anchor	_	_
i	_	_
to	_	_
be	_	_
positive	_	_
.	_	_

#95
The	_	_
terms	_	_
fi	_	_
,	_	_
f	_	_
?	_	_
i	_	_
are	_	_
the	_	_
4	_	_
dimensional	_	_
bounding	_	_
box	_	_
coordinates	_	_
for	_	_
anchor	_	_
i	_	_
and	_	_
the	_	_
ground-truth	_	_
,	_	_
respectively	_	_
.	_	_

#96
Lcls	_	_
denotes	_	_
cross	_	_
entropy	_	_
loss	_	_
for	_	_
RPN	_	_
network	_	_
and	_	_
Lreg	_	_
denotes	_	_
smooth	_	_
L1	_	_
loss	_	_
for	_	_
regression	_	_
for	_	_
the	_	_
proposal	_	_
bounding	_	_
boxes	_	_
.	_	_

#97
Ncls	_	_
denotes	_	_
the	_	_
size	_	_
of	_	_
a	_	_
mini-batch	_	_
in	_	_
the	_	_
RPN	_	_
network	_	_
.	_	_

#98
Nreg	_	_
is	_	_
the	_	_
number	_	_
of	_	_
anchor	_	_
locations	_	_
.	_	_

#99
The	_	_
term	_	_
λ	_	_
is	_	_
a	_	_
hyper-parameter	_	_
to	_	_
balance	_	_
the	_	_
two	_	_
losses	_	_
and	_	_
is	_	_
set	_	_
to	_	_
10	_	_
.	_	_

#100
Note	_	_
that	_	_
in	_	_
contrast	_	_
to	_	_
traditional	_	_
object	_	_
detection	_	_
whose	_	_
RPN	_	_
network	_	_
searches	_	_
for	_	_
regions	_	_
that	_	_
are	_	_
likely	_	_
to	_	_
be	_	_
objects	_	_
,	_	_
our	_	_
RPN	_	_
network	_	_
searches	_	_
for	_	_
regions	_	_
that	_	_
are	_	_
likely	_	_
to	_	_
be	_	_
manipulated	_	_
.	_	_

#101
The	_	_
proposed	_	_
regions	_	_
might	options	_
not	_	_
necessarily	_	_
be	_	_
objects	_	_
,	_	_
e.g.	_	_
,	_	_
the	_	_
case	_	_
in	_	_
the	_	_
removal	_	_
tampering	_	_
process	_	_
.	_	_

#102
3.2.	_	_
Noise	_	_
Stream	_	_

#103
RGB	_	_
channels	_	_
are	_	_
not	_	_
sufficient	_	_
to	_	_
tackle	_	_
all	_	_
the	_	_
different	_	_
cases	_	_
of	_	_
manipulation	_	_
.	_	_

#104
In	_	_
particular	_	_
,	_	_
tampered	_	_
images	_	_
that	_	_
were	_	_
carefully	_	_
post	_	_
processed	_	_
to	_	_
conceal	_	_
the	_	_
splicing	_	_
boundary	_	_
and	_	_
reduce	_	_
contrast	_	_
differences	_	_
are	_	_
challenging	_	_
for	_	_
the	_	_
RGB	_	_
stream	_	_
.	_	_

#105
So	_	_
,	_	_
we	_	_
utilize	_	_
the	_	_
local	_	_
noise	_	_
distributions	_	_
of	_	_
the	_	_
image	_	_
to	_	_
provide	_	_
additional	_	_
evidence	_	_
.	_	_

#106
In	_	_
contrast	_	_
to	_	_
the	_	_
RGB	_	_
stream	_	_
,	_	_
the	_	_
noise	_	_
stream	_	_
is	_	_
designed	_	_
to	_	_
pay	_	_
more	_	_
attention	_	_
to	_	_
noise	_	_
rather	_	_
than	_	_
semantic	_	_
image	_	_
content	_	_
.	_	_

#107
This	_	_
is	_	_
novel	_	_
—	_	_
while	_	_
current	_	_
deep	_	_
learning	_	_
models	_	_
do	_	_
well	_	_
in	_	_
representing	_	_
hierarchical	_	_
features	_	_
from	_	_
RGB	_	_
image	_	_
content	_	_
,	_	_
no	_	_
prior	_	_
work	_	_
in	_	_
deep	_	_
learning	_	_
has	_	_
investigated	_	_
learning	_	_
from	_	_
noise	_	_
distributions	_	_
in	_	_
detection	_	_
.	_	_

#108
Inspired	_	_
by	_	_
recent	_	_
progress	_	_
on	_	_
SRM	_	_
features	_	_
from	_	_
image	_	_
forensics	_	_
[	_	_
15	_	_
]	_	_
,	_	_
we	_	_
use	_	_
SRM	_	_
filters	_	_
to	_	_
extract	_	_
the	_	_
local	_	_
noise	_	_
features	_	_
(	_	_
examples	_	_
shown	_	_
in	_	_
Figure	_	_
3	_	_
)	_	_
from	_	_
RGB	_	_
images	_	_
as	_	_
the	_	_
input	_	_
to	_	_
our	_	_
noise	_	_
stream	_	_
.	_	_

#109
In	_	_
our	_	_
setting	_	_
,	_	_
noise	_	_
is	_	_
modeled	_	_
by	_	_
the	_	_
residual	_	_
between	_	_
a	_	_
pixel’s	_	_
value	_	_
and	_	_
the	_	_
estimate	_	_
of	_	_
that	_	_
pixel’s	_	_
value	_	_
produced	_	_
by	_	_
interpolating	_	_
only	_	_
the	_	_
values	_	_
of	_	_
neighboring	_	_
pixels	_	_
.	_	_

#110
Starting	_	_
from	_	_
30	_	_
basic	_	_
filters	_	_
,	_	_
along	_	_
with	_	_
nonlinear	_	_
operations	_	_
like	_	_
maximum	_	_
and	_	_
minimum	_	_
of	_	_
the	_	_
nearby	_	_
outputs	_	_
after	_	_
filtering	_	_
,	_	_
SRM	_	_
features	_	_
gather	_	_
the	_	_
basic	_	_
noise	_	_
features	_	_
.	_	_

#111
SRM	_	_
quantifies	_	_
and	_	_
truncates	_	_
the	_	_
output	_	_
of	_	_
these	_	_
filters	_	_
and	_	_
extracts	_	_
the	_	_
nearby	_	_
co-occurrence	_	_
information	_	_
as	_	_
the	_	_
final	_	_
features	_	_
.	_	_

#112
The	_	_
feature	_	_
obtained	_	_
from	_	_
this	_	_
process	_	_
can	_	_
be	_	_
regarded	_	_
as	_	_
a	_	_
local	_	_
noise	_	_
descriptor	_	_
[	_	_
7	_	_
]	_	_
.	_	_

#113
We	_	_
find	_	_
that	_	_
only	_	_
using	_	_
3	_	_
kernels	_	_
can	_	_
achieve	_	_
decent	_	_
performance	_	_
,	_	_
and	_	_
applying	_	_
all	_	_
30	_	_
kernels	_	_
does	_	_
not	_	_
give	_	_
significant	_	_
performance	_	_
gain	_	_
.	_	_

#114
Therefore	_	_
,	_	_
we	_	_
choose	_	_
3	_	_
kernels	_	_
,	_	_
whose	_	_
weights	_	_
are	_	_
shown	_	_
in	_	_
Figure	_	_
4	_	_
,	_	_
and	_	_
directly	_	_
feed	_	_
these	_	_
into	_	_
a	_	_
pre-trained	_	_
network	_	_
trained	_	_
on	_	_
3-channel	_	_
inputs	_	_
.	_	_

#115
We	_	_
define	_	_
the	_	_
kernel	_	_
size	_	_
of	_	_
the	_	_
SRM	_	_
filter	_	_
layer	_	_
in	_	_
the	_	_
noise	_	_
stream	_	_
to	_	_
be	_	_
5	_	_
×	_	_
5	_	_
×	_	_
3	_	_
.	_	_

#116
The	_	_
output	_	_
channel	_	_
size	_	_
of	_	_
our	_	_
SRM	_	_
layer	_	_
is	_	_
3	_	_
.	_	_

#117
The	_	_
resulting	_	_
noise	_	_
feature	_	_
maps	_	_
after	_	_
the	_	_
SRM	_	_
layer	_	_
are	_	_
shown	_	_
in	_	_
the	_	_
third	_	_
column	_	_
of	_	_
Figure	_	_
3	_	_
.	_	_

#118
It	_	_
is	_	_
clear	_	_
that	_	_
they	_	_
emphasize	_	_
the	_	_
local	_	_
noise	_	_
instead	_	_
of	_	_
image	_	_
content	_	_
and	_	_
explicitly	_	_
reveal	_	_
tampering	_	_
artifacts	_	_
that	_	_
might	options	_
not	_	_
be	_	_
visible	_	_
in	_	_
the	_	_
RGB	_	_
channels	_	_
.	_	_

#119
We	_	_
directly	_	_
use	_	_
the	_	_
noise	_	_
features	_	_
as	_	_
the	_	_
input	_	_
to	_	_
the	_	_
noise	_	_
stream	_	_
network	_	_
.	_	_

#120
The	_	_
backbone	_	_
convolutional	_	_
network	_	_
architecture	_	_
of	_	_
the	_	_
noise	_	_
stream	_	_
is	_	_
the	_	_
same	_	_
as	_	_
the	_	_
RGB	_	_
stream	_	_
.	_	_

#121
The	_	_
noise	_	_
stream	_	_
shares	_	_
the	_	_
same	_	_
RoI	_	_
pooling	_	_
layer	_	_
as	_	_
the	_	_
RGB	_	_
stream	_	_
.	_	_

#122
For	_	_
bounding	_	_
box	_	_
Tampered	_	_
image	_	_
Visual	_	_
artifacts	_	_
Noise	_	_
Ground-truth	_	_
Figure	_	_
3	_	_
.	_	_

#123
Illustration	_	_
of	_	_
tampering	_	_
artifacts	_	_
.	_	_

#124
Two	_	_
examples	_	_
showing	_	_
tampering	_	_
artifacts	_	_
in	_	_
the	_	_
original	_	_
RGB	_	_
image	_	_
and	_	_
in	_	_
the	_	_
local	_	_
noise	_	_
features	_	_
obtained	_	_
by	_	_
the	_	_
SRM	_	_
filter	_	_
layer	_	_
.	_	_

#125
The	_	_
second	_	_
column	_	_
is	_	_
the	_	_
amplified	_	_
regions	_	_
for	_	_
the	_	_
red	_	_
bounding	_	_
boxes	_	_
in	_	_
the	_	_
first	_	_
column	_	_
.	_	_

#126
As	_	_
shown	_	_
in	_	_
the	_	_
second	_	_
column	_	_
,	_	_
the	_	_
unnaturally	_	_
high	_	_
contrast	_	_
along	_	_
the	_	_
baseball	_	_
player’s	_	_
edges	_	_
provides	_	_
a	_	_
strong	_	_
cue	_	_
about	_	_
the	_	_
presence	_	_
of	_	_
tampering	_	_
.	_	_

#127
The	_	_
third	_	_
column	_	_
shows	_	_
the	_	_
local	_	_
noise	_	_
inconsistency	_	_
between	_	_
tampered	_	_
regions	_	_
and	_	_
authentic	_	_
regions	_	_
.	_	_

#128
In	_	_
different	_	_
scenarios	_	_
,	_	_
visual	_	_
information	_	_
and	_	_
noise	_	_
features	_	_
play	_	_
a	_	_
complementary	_	_
role	_	_
in	_	_
revealing	_	_
tampering	_	_
artifacts	_	_
.	_	_

#129
-2	_	_
1	_	_
0	_	_
0	_	_
0	_	_
0	_	_
0	_	_
0	_	_
0	_	_
0	_	_
0	_	_
0	_	_
0	_	_
0	_	_
0	_	_
-4	_	_
2	_	_
0	_	_
2	_	_
-1	_	_
0	_	_
0	_	_
0	_	_
0	_	_
2	_	_
-1	_	_
0	_	_
0	_	_
0	_	_
0	_	_
-1	_	_
-1	_	_
-12	_	_
8	_	_
-2	_	_
8	_	_
-6	_	_
2	_	_
-2	_	_
2	_	_
-1	_	_
8	_	_
-6	_	_
2	_	_
-2	_	_
2	_	_
-1	_	_
-6	_	_
-6	_	_
-2	_	_
-1	_	_
-1	_	_
Figure	_	_
4	_	_
.	_	_

#130
The	_	_
three	_	_
SRM	_	_
filter	_	_
kernels	_	_
used	_	_
to	_	_
extract	_	_
noise	_	_
features	_	_
.	_	_

#131
regression	_	_
,	_	_
we	_	_
only	_	_
use	_	_
the	_	_
RGB	_	_
channels	_	_
because	_	_
RGB	_	_
features	_	_
perform	_	_
better	_	_
than	_	_
noise	_	_
features	_	_
for	_	_
the	_	_
RPN	_	_
network	_	_
based	_	_
on	_	_
our	_	_
experiments	_	_
(	_	_
See	_	_
Table	_	_
1	_	_
)	_	_
.	_	_

#132
3.3	_	_
.	_	_

#133
Bilinear	_	_
Pooling	_	_
We	_	_
finally	_	_
combine	_	_
the	_	_
RGB	_	_
stream	_	_
with	_	_
the	_	_
noise	_	_
stream	_	_
for	_	_
manipulation	_	_
detection	_	_
.	_	_

#134
Among	_	_
various	_	_
fusion	_	_
methods	_	_
,	_	_
we	_	_
apply	_	_
bilinear	_	_
pooling	_	_
on	_	_
features	_	_
from	_	_
both	_	_
streams	_	_
.	_	_

#135
Bilinear	_	_
pooling	_	_
[	_	_
23	_	_
]	_	_
,	_	_
first	_	_
proposed	_	_
for	_	_
fine-grained	_	_
classification	_	_
,	_	_
combines	_	_
streams	_	_
in	_	_
a	_	_
two-stream	_	_
CNN	_	_
network	_	_
while	_	_
preserving	_	_
spatial	_	_
information	_	_
to	_	_
improve	_	_
the	_	_
detection	_	_
confidence	_	_
.	_	_

#136
The	_	_
output	_	_
of	_	_
our	_	_
bilinear	_	_
pooling	_	_
layer	_	_
is	_	_
x	_	_
=	_	_
fTRGBfN	_	_
,	_	_
where	_	_
fRGB	_	_
is	_	_
the	_	_
RoI	_	_
feature	_	_
of	_	_
the	_	_
RGB	_	_
stream	_	_
and	_	_
fN	_	_
is	_	_
the	_	_
RoI	_	_
feature	_	_
of	_	_
the	_	_
noise	_	_
stream	_	_
.	_	_

#137
Sum	_	_
pooling	_	_
squeezes	_	_
the	_	_
spatial	_	_
feature	_	_
before	_	_
classification	_	_
.	_	_

#138
We	_	_
then	_	_
apply	_	_
signed	_	_
square	_	_
root	_	_
(	_	_
x←	_	_
sign	_	_
(	_	_
x	_	_
)	_	_
√	_	_
|x|	_	_
)	_	_
and	_	_
L2	_	_
normalization	_	_
before	_	_
forwarding	_	_
to	_	_
the	_	_
fully	_	_
connected	_	_
layer	_	_
.	_	_

#139
To	_	_
save	_	_
memory	_	_
and	_	_
speed	_	_
up	_	_
training	_	_
without	_	_
decreasing	_	_
performance	_	_
,	_	_
we	_	_
use	_	_
compact	_	_
bilinear	_	_
pooling	_	_
as	_	_
proposed	_	_
in	_	_
[	_	_
17	_	_
]	_	_
.	_	_

#140
After	_	_
the	_	_
fully	_	_
connected	_	_
and	_	_
softmax	_	_
layers	_	_
,	_	_
we	_	_
obtain	_	_
the	_	_
predicted	_	_
class	_	_
of	_	_
the	_	_
RoI	_	_
regions	_	_
,	_	_
as	_	_
indicated	_	_
in	_	_
Figure	_	_
2	_	_
.	_	_

#141
We	_	_
use	_	_
cross	_	_
entropy	_	_
loss	_	_
for	_	_
manipulation	_	_
classification	_	_
and	_	_
smooth	_	_
L1	_	_
loss	_	_
for	_	_
bounding	_	_
box	_	_
regression	_	_
.	_	_

#142
The	_	_
total	_	_
loss	_	_
function	_	_
is	_	_
:	_	_
Ltotal	_	_
=	_	_
LRPN	_	_
+	_	_
Ltamper	_	_
(	_	_
fRGB	_	_
,	_	_
fN	_	_
)	_	_
+	_	_
Lbbox	_	_
(	_	_
fRGB	_	_
)	_	_
,	_	_
(	_	_
2	_	_
)	_	_
where	_	_
Ltotal	_	_
denotes	_	_
total	_	_
loss	_	_
.	_	_

#143
LRPN	_	_
denotes	_	_
the	_	_
RPN	_	_
loss	_	_
in	_	_
RPN	_	_
network	_	_
.	_	_

#144
Ltamper	_	_
denotes	_	_
the	_	_
final	_	_
cross	_	_
entropy	_	_
classification	_	_
loss	_	_
,	_	_
which	_	_
is	_	_
based	_	_
on	_	_
the	_	_
bilinear	_	_
pooling	_	_
feature	_	_
from	_	_
both	_	_
the	_	_
RGB	_	_
and	_	_
noise	_	_
stream	_	_
.	_	_

#145
Lbbox	_	_
denotes	_	_
the	_	_
final	_	_
bounding	_	_
box	_	_
regression	_	_
loss	_	_
.	_	_

#146
fRGB	_	_
and	_	_
fN	_	_
are	_	_
the	_	_
RoI	_	_
features	_	_
from	_	_
RGB	_	_
and	_	_
noise	_	_
streams	_	_
.	_	_

#147
The	_	_
summation	_	_
of	_	_
all	_	_
terms	_	_
produces	_	_
the	_	_
total	_	_
loss	_	_
function	_	_
.	_	_

#148
3.4	_	_
.	_	_

#149
Implementation	_	_
Detail	_	_
The	_	_
proposed	_	_
network	_	_
is	_	_
trained	_	_
end-to-end	_	_
.	_	_

#150
The	_	_
input	_	_
image	_	_
as	_	_
well	_	_
as	_	_
the	_	_
extracted	_	_
noise	_	_
features	_	_
are	_	_
re-sized	_	_
so	_	_
that	_	_
the	_	_
shorter	_	_
length	_	_
equals	_	_
to	_	_
600	_	_
pixels	_	_
.	_	_

#151
Four	_	_
anchor	_	_
scales	_	_
with	_	_
size	_	_
from	_	_
82	_	_
,	_	_
162	_	_
,	_	_
322	_	_
to	_	_
642	_	_
are	_	_
used	_	_
,	_	_
and	_	_
the	_	_
aspect	_	_
ratios	_	_
are	_	_
1:2	_	_
,	_	_
1:1	_	_
and	_	_
2:1	_	_
.	_	_

#152
The	_	_
feature	_	_
size	_	_
after	_	_
RoI	_	_
pooling	_	_
is	_	_
7	_	_
×	_	_
7	_	_
×	_	_
1024	_	_
for	_	_
both	_	_
RGB	_	_
and	_	_
noise	_	_
streams	_	_
.	_	_

#153
The	_	_
output	_	_
feature	_	_
size	_	_
of	_	_
compact	_	_
bilinear	_	_
pooling	_	_
is	_	_
set	_	_
to	_	_
16384	_	_
.	_	_

#154
The	_	_
batch	_	_
size	_	_
of	_	_
RPN	_	_
proposal	_	_
is	_	_
64	_	_
for	_	_
training	_	_
and	_	_
300	_	_
for	_	_
testing	_	_
.	_	_

#155
Image	_	_
flipping	_	_
is	_	_
used	_	_
for	_	_
data	_	_
augmentation	_	_
.	_	_

#156
The	_	_
Intersection-over	_	_
Union	_	_
(	_	_
IoU	_	_
)	_	_
threshold	_	_
for	_	_
RPN	_	_
positive	_	_
example	_	_
(	_	_
potential	_	_
manipulated	_	_
regions	_	_
)	_	_
is	_	_
0.7	_	_
and	_	_
0.3	_	_
for	_	_
negative	_	_
example	_	_
(	_	_
authentic	_	_
regions	_	_
)	_	_
.	_	_

#157
Learning	_	_
rate	_	_
is	_	_
initially	_	_
set	_	_
to	_	_
0.001	_	_
and	_	_
then	_	_
is	_	_
reduced	_	_
to	_	_
0.0001	_	_
after	_	_
40K	_	_
steps	_	_
.	_	_

#158
We	_	_
train	_	_
our	_	_
model	_	_
for	_	_
110K	_	_
steps	_	_
.	_	_

#159
At	_	_
test	_	_
time	_	_
,	_	_
standard	_	_
Non-Maximum	_	_
Suppression	_	_
(	_	_
NMS	_	_
)	_	_
is	_	_
applied	_	_
to	_	_
reduce	_	_
the	_	_
redundancy	_	_
of	_	_
proposed	_	_
overlapping	_	_
regions	_	_
.	_	_

#160
The	_	_
NMS	_	_
threshold	_	_
is	_	_
set	_	_
to	_	_
0.2	_	_
.	_	_

#161
4	_	_
.	_	_

#162
Experiments	_	_
We	_	_
demonstrate	_	_
our	_	_
two	_	_
stream	_	_
network	_	_
on	_	_
four	_	_
standard	_	_
image	_	_
manipulation	_	_
datasets	_	_
and	_	_
compare	_	_
the	_	_
results	_	_
with	_	_
state-of-the-art	_	_
methods	_	_
.	_	_

#163
We	_	_
also	_	_
compare	_	_
different	_	_
data	_	_
augmentations	_	_
and	_	_
measure	_	_
the	_	_
robustness	_	_
of	_	_
our	_	_
method	_	_
to	_	_
resizing	_	_
and	_	_
JPEG	_	_
compression	_	_
.	_	_

#164
4.1	_	_
.	_	_

#165
Pre-trained	_	_
Model	_	_
Current	_	_
standard	_	_
datasets	_	_
do	_	_
not	_	_
have	_	_
enough	_	_
data	_	_
for	_	_
deep	_	_
neural	_	_
network	_	_
training	_	_
.	_	_

#166
To	_	_
test	_	_
our	_	_
network	_	_
on	_	_
these	_	_
datasets	_	_
,	_	_
we	_	_
pre-train	_	_
our	_	_
model	_	_
on	_	_
our	_	_
synthetic	_	_
dataset	_	_
.	_	_

#167
We	_	_
automatically	_	_
create	_	_
a	_	_
synthetic	_	_
dataset	_	_
using	_	_
the	_	_
images	_	_
and	_	_
annotations	_	_
from	_	_
COCO	_	_
[	_	_
22	_	_
]	_	_
.	_	_

#168
We	_	_
use	_	_
the	_	_
segmentation	_	_
annotations	_	_
to	_	_
randomly	_	_
select	_	_
objects	_	_
from	_	_
COCO	_	_
[	_	_
22	_	_
]	_	_
,	_	_
AP	_	_
Synthetic	_	_
test	_	_
RGB	_	_
Net	_	_
0.445	_	_
Noise	_	_
Net	_	_
0.461	_	_
RGB-N	_	_
noise	_	_
RPN	_	_
0.472	_	_
Noise	_	_
+	_	_
RGB	_	_
RPN	_	_
0.620	_	_
RGB-N	_	_
0.627	_	_
Table	_	_
1	_	_
.	_	_

#169
AP	_	_
comparison	_	_
on	_	_
our	_	_
synthetic	_	_
COCO	_	_
dataset	_	_
.	_	_

#170
The	_	_
row	_	_
is	_	_
the	_	_
model	_	_
architectures	_	_
,	_	_
where	_	_
RGB	_	_
Net	_	_
is	_	_
a	_	_
single	_	_
Faster	_	_
R-CNN	_	_
using	_	_
RGB	_	_
image	_	_
as	_	_
input	_	_
;	_	_
Noise	_	_
Net	_	_
is	_	_
a	_	_
single	_	_
Faster	_	_
R-CNN	_	_
using	_	_
noise	_	_
feature	_	_
map	_	_
as	_	_
input	_	_
;	_	_
RGB-N	_	_
noise	_	_
RPN	_	_
is	_	_
a	_	_
two-stream	_	_
Faster	_	_
R-CNN	_	_
using	_	_
noise	_	_
features	_	_
for	_	_
RPN	_	_
network	_	_
.	_	_

#171
Noise	_	_
+	_	_
RGB	_	_
RPN	_	_
is	_	_
a	_	_
two-stream	_	_
Faster	_	_
R-CNN	_	_
using	_	_
both	_	_
noise	_	_
and	_	_
RGB	_	_
features	_	_
as	_	_
the	_	_
input	_	_
of	_	_
RPN	_	_
network	_	_
.	_	_

#172
RGB-N	_	_
is	_	_
a	_	_
two-stream	_	_
Faster	_	_
R-CNN	_	_
using	_	_
RGB	_	_
features	_	_
for	_	_
RPN	_	_
network	_	_
.	_	_

#173
and	_	_
then	_	_
copy	_	_
and	_	_
paste	_	_
them	_	_
to	_	_
other	_	_
images	_	_
.	_	_

#174
The	_	_
training	_	_
(	_	_
90	_	_
%	_	_
)	_	_
and	_	_
testing	_	_
set	_	_
(	_	_
10	_	_
%	_	_
)	_	_
is	_	_
split	_	_
to	_	_
ensure	_	_
the	_	_
same	_	_
background	_	_
and	_	_
tampered	_	_
object	_	_
do	_	_
not	_	_
appear	_	_
in	_	_
both	_	_
training	_	_
and	_	_
testing	_	_
set	_	_
.	_	_

#175
Finally	_	_
,	_	_
we	_	_
create	_	_
42K	_	_
tampered	_	_
and	_	_
authentic	_	_
image	_	_
pairs	_	_
.	_	_

#176
We	_	_
will	_	_
release	_	_
this	_	_
dataset	_	_
for	_	_
research	_	_
use	_	_
.	_	_

#177
The	_	_
output	_	_
of	_	_
our	_	_
model	_	_
is	_	_
bounding	_	_
boxes	_	_
with	_	_
confidence	_	_
scores	_	_
indicating	_	_
whether	_	_
the	_	_
detected	_	_
regions	_	_
have	_	_
been	_	_
manipulated	_	_
or	_	_
not	_	_
.	_	_

#178
To	_	_
include	_	_
some	_	_
authentic	_	_
regions	_	_
in	_	_
Region	_	_
of	_	_
Interest	_	_
(	_	_
RoI	_	_
)	_	_
for	_	_
better	_	_
comparison	_	_
,	_	_
We	_	_
slightly	_	_
enlarge	_	_
the	_	_
default	_	_
bounding	_	_
boxes	_	_
by	_	_
20	_	_
pixels	_	_
during	_	_
training	_	_
so	_	_
that	_	_
both	_	_
the	_	_
RGB	_	_
and	_	_
noise	_	_
streams	_	_
learn	_	_
the	_	_
inconsistency	_	_
between	_	_
tampered	_	_
and	_	_
authentic	_	_
regions	_	_
.	_	_

#179
We	_	_
train	_	_
our	_	_
model	_	_
end-to-end	_	_
on	_	_
this	_	_
synthetic	_	_
dataset	_	_
.	_	_

#180
The	_	_
ResNet	_	_
101	_	_
used	_	_
in	_	_
Faster	_	_
R-CNN	_	_
is	_	_
pre-trained	_	_
on	_	_
ImageNet	_	_
.	_	_

#181
We	_	_
use	_	_
Average	_	_
Precision	_	_
(	_	_
AP	_	_
)	_	_
for	_	_
evaluation	_	_
,	_	_
the	_	_
metric	_	_
of	_	_
which	_	_
is	_	_
the	_	_
same	_	_
as	_	_
COCO	_	_
[	_	_
22	_	_
]	_	_
detection	_	_
evaluation	_	_
.	_	_

#182
We	_	_
compare	_	_
the	_	_
result	_	_
of	_	_
the	_	_
two-stream	_	_
network	_	_
with	_	_
each	_	_
one	_	_
of	_	_
the	_	_
streams	_	_
in	_	_
Table	_	_
1	_	_
.	_	_

#183
This	_	_
table	_	_
shows	_	_
that	_	_
our	_	_
two-stream	_	_
network	_	_
performs	_	_
better	_	_
than	_	_
each	_	_
single	_	_
stream	_	_
.	_	_

#184
Also	_	_
,	_	_
the	_	_
comparison	_	_
among	_	_
RGB-N	_	_
,	_	_
RGB-N	_	_
using	_	_
noise	_	_
features	_	_
as	_	_
RPN	_	_
and	_	_
RPN	_	_
uses	_	_
both	_	_
features	_	_
shows	_	_
that	_	_
RGB	_	_
features	_	_
are	_	_
more	_	_
suitable	_	_
than	_	_
noise	_	_
features	_	_
to	_	_
generate	_	_
region	_	_
proposals	_	_
.	_	_

#185
4.2	_	_
.	_	_

#186
Testing	_	_
on	_	_
Standard	_	_
Datasets	_	_
Datasets	_	_
.	_	_

#187
We	_	_
compare	_	_
our	_	_
method	_	_
with	_	_
current	_	_
state-of-the-art	_	_
methods	_	_
on	_	_
NIST	_	_
Nimble	_	_
2016	_	_
[	_	_
1	_	_
]	_	_
(	_	_
NIST16	_	_
)	_	_
,	_	_
CASIA	_	_
[	_	_
12	_	_
,	_	_
13	_	_
]	_	_
,	_	_
COVER	_	_
[	_	_
30	_	_
]	_	_
and	_	_
Columbia	_	_
dataset	_	_
.	_	_

#188
•	_	_
NIST16	_	_
is	_	_
a	_	_
challenging	_	_
dataset	_	_
which	_	_
contains	_	_
all	_	_
three	_	_
tampering	_	_
techniques	_	_
.	_	_

#189
The	_	_
manipulations	_	_
in	_	_
this	_	_
dataset	_	_
are	_	_
post-processed	_	_
to	_	_
conceal	_	_
visible	_	_
traces	_	_
.	_	_

#190
They	_	_
also	_	_
provide	_	_
ground-truth	_	_
tampering	_	_
mask	_	_
for	_	_
evaluation	_	_
.	_	_

#191
•	_	_
CASIA	_	_
provides	_	_
spliced	_	_
and	_	_
copy-moved	_	_
images	_	_
of	_	_
various	_	_
objects	_	_
.	_	_

#192
The	_	_
tampered	_	_
regions	_	_
are	_	_
carefully	_	_
selected	_	_
and	_	_
some	_	_
post	_	_
processing	_	_
like	_	_
filtering	_	_
and	_	_
blurring	_	_
is	_	_
also	_	_
applied	_	_
.	_	_

#193
Ground-truth	_	_
masks	_	_
are	_	_
obtained	_	_
by	_	_
thresholding	_	_
Datasets	_	_
NIST16	_	_
CASIA	_	_
Columbia	_	_
COVER	_	_
Training	_	_
404	_	_
5123	_	_
-	_	_
75	_	_
Testing	_	_
160	_	_
921	_	_
180	_	_
25	_	_
Table	_	_
2	_	_
.	_	_

#194
Training	_	_
and	_	_
testing	_	_
split	_	_
(	_	_
number	_	_
of	_	_
images	_	_
)	_	_
for	_	_
four	_	_
standard	_	_
datasets	_	_
.	_	_

#195
Columbia	_	_
is	_	_
only	_	_
used	_	_
for	_	_
testing	_	_
the	_	_
model	_	_
trained	_	_
on	_	_
our	_	_
synthetic	_	_
dataset	_	_
.	_	_

#196
the	_	_
difference	_	_
between	_	_
tampered	_	_
and	_	_
original	_	_
images	_	_
.	_	_

#197
We	_	_
use	_	_
CASIA	_	_
2.0	_	_
for	_	_
training	_	_
and	_	_
CASIA	_	_
1.0	_	_
for	_	_
testing	_	_
.	_	_

#198
•	_	_
COVER	_	_
is	_	_
a	_	_
relatively	_	_
small	_	_
dataset	_	_
focusing	_	_
on	_	_
copymove	_	_
.	_	_

#199
It	_	_
covers	_	_
similar	_	_
objects	_	_
as	_	_
the	_	_
pasted	_	_
regions	_	_
to	_	_
conceal	_	_
the	_	_
tampering	_	_
artifacts	_	_
(	_	_
see	_	_
the	_	_
second	_	_
row	_	_
in	_	_
Figure	_	_
1	_	_
)	_	_
.	_	_

#200
Ground-truth	_	_
masks	_	_
are	_	_
provided	_	_
.	_	_

#201
•	_	_
Columbia	_	_
dataset	_	_
focuses	_	_
on	_	_
splicing	_	_
based	_	_
on	_	_
uncompressed	_	_
images	_	_
.	_	_

#202
Ground-truth	_	_
masks	_	_
are	_	_
provided	_	_
.	_	_

#203
To	_	_
fine-tune	_	_
our	_	_
model	_	_
on	_	_
these	_	_
datasets	_	_
,	_	_
we	_	_
extract	_	_
the	_	_
bounding	_	_
box	_	_
from	_	_
the	_	_
ground-truth	_	_
mask	_	_
.	_	_

#204
We	_	_
compare	_	_
with	_	_
other	_	_
approaches	_	_
on	_	_
the	_	_
same	_	_
training	_	_
and	_	_
testing	_	_
split	_	_
protocol	_	_
as	_	_
[	_	_
2	_	_
]	_	_
(	_	_
for	_	_
NIST16	_	_
and	_	_
COVER	_	_
)	_	_
and	_	_
[	_	_
29	_	_
]	_	_
(	_	_
for	_	_
Columbia	_	_
and	_	_
CASIA	_	_
)	_	_
.	_	_

#205
See	_	_
Table	_	_
2	_	_
.	_	_

#206
Evaluation	_	_
Metric	_	_
.	_	_

#207
We	_	_
use	_	_
pixel	_	_
level	_	_
F1	_	_
score	_	_
and	_	_
Area	_	_
Under	_	_
the	_	_
receiver	_	_
operating	_	_
characteristic	_	_
Curve	_	_
(	_	_
AUC	_	_
)	_	_
as	_	_
our	_	_
evaluation	_	_
metrics	_	_
for	_	_
performance	_	_
comparison	_	_
.	_	_

#208
F1	_	_
score	_	_
is	_	_
a	_	_
pixel	_	_
level	_	_
evaluation	_	_
metric	_	_
for	_	_
image	_	_
manipulation	_	_
detection	_	_
,	_	_
as	_	_
discussed	_	_
in	_	_
[	_	_
33	_	_
,	_	_
29	_	_
]	_	_
.	_	_

#209
We	_	_
vary	_	_
different	_	_
thresholds	_	_
and	_	_
use	_	_
the	_	_
highest	_	_
F1	_	_
score	_	_
as	_	_
the	_	_
final	_	_
score	_	_
for	_	_
each	_	_
image	_	_
,	_	_
which	_	_
follows	_	_
the	_	_
same	_	_
protocol	_	_
in	_	_
[	_	_
33	_	_
,	_	_
29	_	_
]	_	_
.	_	_

#210
We	_	_
assign	_	_
the	_	_
confidence	_	_
score	_	_
to	_	_
every	_	_
pixel	_	_
in	_	_
the	_	_
detected	_	_
bounding	_	_
boxes	_	_
for	_	_
pixel-level	_	_
AUC	_	_
evaluation	_	_
.	_	_

#211
Baseline	_	_
Models	_	_
.	_	_

#212
We	_	_
compare	_	_
our	_	_
proposed	_	_
method	_	_
with	_	_
various	_	_
baseline	_	_
models	_	_
as	_	_
described	_	_
below	_	_
:	_	_
•	_	_
ELA	_	_
:	_	_
An	_	_
error	_	_
level	_	_
analysis	_	_
method	_	_
[	_	_
21	_	_
]	_	_
which	_	_
aims	_	_
to	_	_
find	_	_
the	_	_
compression	_	_
error	_	_
difference	_	_
between	_	_
tampered	_	_
regions	_	_
and	_	_
authentic	_	_
regions	_	_
through	_	_
different	_	_
JPEG	_	_
compression	_	_
qualities	_	_
.	_	_

#213
•	_	_
NOI1	_	_
:	_	_
A	_	_
noise	_	_
inconsistency	_	_
based	_	_
method	_	_
using	_	_
high	_	_
pass	_	_
wavelet	_	_
coefficients	_	_
to	_	_
model	_	_
local	_	_
noise	_	_
[	_	_
24	_	_
]	_	_
.	_	_

#214
•	_	_
CFA1	_	_
:	_	_
A	_	_
CFA	_	_
pattern	_	_
estimation	_	_
method	_	_
[	_	_
14	_	_
]	_	_
which	_	_
uses	_	_
nearby	_	_
pixels	_	_
to	_	_
approximate	_	_
the	_	_
camera	_	_
filter	_	_
array	_	_
patterns	_	_
and	_	_
then	_	_
produces	_	_
the	_	_
tampering	_	_
probability	_	_
for	_	_
each	_	_
pixel	_	_
.	_	_

#215
•MFCN	_	_
:	_	_
A	_	_
multi-task	_	_
edge-enhanced	_	_
FCN	_	_
based	_	_
network	_	_
[	_	_
29	_	_
]	_	_
jointly	_	_
detecting	_	_
tampered	_	_
edges	_	_
using	_	_
edge	_	_
binary	_	_
masks	_	_
and	_	_
tampered	_	_
regions	_	_
using	_	_
tampered	_	_
region	_	_
masks	_	_
.	_	_

#216
•	_	_
J-LSTM	_	_
:	_	_
An	_	_
LSTM	_	_
based	_	_
network	_	_
[	_	_
2	_	_
]	_	_
jointly	_	_
training	_	_
patch	_	_
level	_	_
tampered	_	_
edge	_	_
classification	_	_
and	_	_
pixel	_	_
level	_	_
tampered	_	_
region	_	_
segmentation	_	_
.	_	_

#217
•	_	_
RGB	_	_
Net	_	_
:	_	_
A	_	_
single	_	_
Faster	_	_
R-CNN	_	_
network	_	_
with	_	_
RGB	_	_
images	_	_
as	_	_
input	_	_
.	_	_

#218
i.e.	_	_
,	_	_
our	_	_
RGB	_	_
Faster	_	_
R-CNN	_	_
stream	_	_
.	_	_

#219
•	_	_
Noise	_	_
Net	_	_
:	_	_
A	_	_
single	_	_
Faster	_	_
R-CNN	_	_
network	_	_
with	_	_
noise	_	_
feature	_	_
map	_	_
as	_	_
input	_	_
obtained	_	_
from	_	_
a	_	_
SRM	_	_
filter	_	_
layer	_	_
.	_	_

#220
The	_	_
RPN	_	_
network	_	_
uses	_	_
noise	_	_
features	_	_
in	_	_
this	_	_
case	_	_
.	_	_

#221
•	_	_
Late	_	_
Fusion	_	_
:	_	_
Direct	_	_
fusion	_	_
combining	_	_
all	_	_
detected	_	_
bounding	_	_
boxes	_	_
for	_	_
both	_	_
RGB	_	_
Net	_	_
and	_	_
noise	_	_
Net	_	_
.	_	_

#222
The	_	_
confiNIST16	_	_
Columbia	_	_
COVER	_	_
CASIA	_	_
ELA	_	_
[	_	_
21	_	_
]	_	_
0.236	_	_
0.470	_	_
0.222	_	_
0.214	_	_
NOI1	_	_
[	_	_
24	_	_
]	_	_
0.285	_	_
0.574	_	_
0.269	_	_
0.263	_	_
CFA1	_	_
[	_	_
14	_	_
]	_	_
0.174	_	_
0.467	_	_
0.190	_	_
0.207	_	_
MFCN	_	_
[	_	_
29	_	_
]	_	_
0.571	_	_
0.612	_	_
-	_	_
0.541	_	_
RGB	_	_
Net	_	_
0.567	_	_
0.585	_	_
0.391	_	_
0.392	_	_
Noise	_	_
Net	_	_
0.521	_	_
0.705	_	_
0.355	_	_
0.283	_	_
Late	_	_
Fusion	_	_
0.625	_	_
0.681	_	_
0.371	_	_
0.397	_	_
RGB-N	_	_
(	_	_
ours	_	_
)	_	_
0.722	_	_
0.697	_	_
0.437	_	_
0.408	_	_
Table	_	_
3	_	_
.	_	_

#223
F1	_	_
score	_	_
comparison	_	_
on	_	_
four	_	_
standard	_	_
datasets	_	_
.	_	_

#224
‘-’	_	_
denotes	_	_
that	_	_
the	_	_
result	_	_
is	_	_
not	_	_
available	_	_
in	_	_
the	_	_
literature	_	_
.	_	_

#225
NIST16	_	_
Columbia	_	_
COVER	_	_
CASIA	_	_
ELA	_	_
[	_	_
21	_	_
]	_	_
0.429	_	_
0.581	_	_
0.583	_	_
0.613	_	_
NOI1	_	_
[	_	_
24	_	_
]	_	_
0.487	_	_
0.546	_	_
0.587	_	_
0.612	_	_
CFA1	_	_
[	_	_
14	_	_
]	_	_
0.501	_	_
0.720	_	_
0.485	_	_
0.522	_	_
J-LSTM	_	_
[	_	_
2	_	_
]	_	_
0.764	_	_
-	_	_
0.614	_	_
RGB	_	_
Net	_	_
0.857	_	_
0.796	_	_
0.789	_	_
0.768	_	_
Noise	_	_
Net	_	_
0.881	_	_
0.851	_	_
0.753	_	_
0.693	_	_
Late	_	_
Fusion	_	_
0.924	_	_
0.856	_	_
0.793	_	_
0.777	_	_
RGB-N	_	_
(	_	_
ours	_	_
)	_	_
0.937	_	_
0.858	_	_
0.817	_	_
0.795	_	_
Table	_	_
4	_	_
.	_	_

#226
Pixel	_	_
level	_	_
AUC	_	_
comparison	_	_
on	_	_
four	_	_
standard	_	_
datasets	_	_
.	_	_

#227
‘-’	_	_
denotes	_	_
that	_	_
the	_	_
result	_	_
is	_	_
not	_	_
available	_	_
in	_	_
the	_	_
literature	_	_
.	_	_

#228
dence	_	_
scores	_	_
of	_	_
the	_	_
overlapping	_	_
detected	_	_
regions	_	_
from	_	_
the	_	_
two	_	_
streams	_	_
are	_	_
set	_	_
to	_	_
the	_	_
maximum	_	_
one	_	_
.	_	_

#229
•RGB-N	_	_
:	_	_
Bilinear	_	_
pooling	_	_
of	_	_
RGB	_	_
stream	_	_
and	_	_
noise	_	_
stream	_	_
for	_	_
manipulation	_	_
classification	_	_
and	_	_
RGB	_	_
stream	_	_
for	_	_
bounding	_	_
box	_	_
regression	_	_
.	_	_

#230
i.e.	_	_
our	_	_
full	_	_
model	_	_
.	_	_

#231
We	_	_
use	_	_
the	_	_
F1	_	_
scores	_	_
of	_	_
NOI1	_	_
,	_	_
CFA1	_	_
and	_	_
ELA	_	_
reported	_	_
in	_	_
[	_	_
29	_	_
]	_	_
and	_	_
run	_	_
the	_	_
code	_	_
provided	_	_
by	_	_
[	_	_
33	_	_
]	_	_
to	_	_
obtain	_	_
the	_	_
AUC	_	_
results	_	_
.	_	_

#232
The	_	_
results	_	_
of	_	_
MFCN	_	_
and	_	_
J-LSTM	_	_
are	_	_
replicated	_	_
from	_	_
the	_	_
original	_	_
literatures	_	_
as	_	_
their	_	_
code	_	_
is	_	_
not	_	_
publicly	_	_
available	_	_
.	_	_

#233
Table	_	_
3	_	_
shows	_	_
the	_	_
F1	_	_
score	_	_
comparison	_	_
between	_	_
our	_	_
method	_	_
and	_	_
the	_	_
baselines	_	_
.	_	_

#234
Table	_	_
4	_	_
provides	_	_
the	_	_
AUC	_	_
comparison	_	_
.	_	_

#235
From	_	_
these	_	_
two	_	_
tables	_	_
,	_	_
it	_	_
is	_	_
clear	_	_
that	_	_
our	_	_
method	_	_
outperforms	_	_
conventional	_	_
methods	_	_
like	_	_
ELA	_	_
,	_	_
NOI1	_	_
and	_	_
CFA1	_	_
.	_	_

#236
This	_	_
is	_	_
because	_	_
they	_	_
all	_	_
focus	_	_
on	_	_
specific	_	_
tampering	_	_
artifacts	_	_
that	_	_
only	_	_
contain	_	_
partial	_	_
information	_	_
for	_	_
localization	_	_
,	_	_
which	_	_
limits	_	_
their	_	_
performance	_	_
.	_	_

#237
Our	_	_
approach	_	_
outperforms	_	_
MFCN	_	_
on	_	_
Columbia	_	_
and	_	_
NIST16	_	_
dataset	_	_
.	_	_

#238
One	_	_
of	_	_
the	_	_
reasons	_	_
our	_	_
method	_	_
achieves	_	_
better	_	_
performance	_	_
than	_	_
J-LSTM	_	_
is	_	_
that	_	_
J-LSTM	_	_
seeks	_	_
tampered	_	_
edges	_	_
as	_	_
evidence	_	_
of	_	_
tampering	_	_
,	_	_
which	_	_
can	_	_
not	_	_
always	_	_
detect	_	_
the	_	_
entire	_	_
tampered	_	_
regions	_	_
.	_	_

#239
Also	_	_
,	_	_
our	_	_
method	_	_
has	_	_
larger	_	_
receptive	_	_
field	_	_
and	_	_
captures	_	_
global	_	_
context	_	_
rather	_	_
than	_	_
nearby	_	_
pixels	_	_
,	_	_
which	_	_
helps	_	_
collect	_	_
more	_	_
cues	_	_
like	_	_
contrast	_	_
difference	_	_
for	_	_
manipulation	_	_
classification	_	_
.	_	_

#240
As	_	_
shown	_	_
in	_	_
Table	_	_
3	_	_
and	_	_
4	_	_
,	_	_
our	_	_
RGB-N	_	_
network	_	_
also	_	_
improves	_	_
the	_	_
individual	_	_
streams	_	_
for	_	_
all	_	_
the	_	_
datasets	_	_
except	_	_
Columbia	_	_
.	_	_

#241
Columbia	_	_
only	_	_
contains	_	_
uncompressed	_	_
spliced	_	_
regions	_	_
,	_	_
which	_	_
preserves	_	_
noise	_	_
differences	_	_
so	_	_
well	_	_
that	_	_
it	_	_
is	_	_
Tampered	_	_
image	_	_
Ground-truth	_	_
RGB	_	_
Net	_	_
result	_	_
Noise	_	_
Net	_	_
result	_	_
RGB-N	_	_
result	_	_
Figure	_	_
5	_	_
.	_	_

#242
Qualitative	_	_
visualization	_	_
of	_	_
results	_	_
.	_	_

#243
The	_	_
top	_	_
row	_	_
shows	_	_
a	_	_
qualitative	_	_
result	_	_
from	_	_
the	_	_
COVER	_	_
dataset	_	_
.	_	_

#244
The	_	_
copy-moved	_	_
bag	_	_
confuses	_	_
the	_	_
RGB	_	_
Net	_	_
,	_	_
and	_	_
the	_	_
noise	_	_
Net	_	_
.	_	_

#245
RGB-N	_	_
achieves	_	_
a	_	_
better	_	_
detection	_	_
in	_	_
this	_	_
case	_	_
because	_	_
it	_	_
combines	_	_
the	_	_
features	_	_
from	_	_
the	_	_
two	_	_
streams	_	_
.	_	_

#246
The	_	_
middle	_	_
row	_	_
shows	_	_
a	_	_
qualitative	_	_
result	_	_
from	_	_
the	_	_
Columbia	_	_
.	_	_

#247
The	_	_
RGB	_	_
Net	_	_
produces	_	_
a	_	_
more	_	_
accurate	_	_
result	_	_
than	_	_
noise	_	_
stream	_	_
.	_	_

#248
Taking	_	_
into	_	_
account	_	_
both	_	_
streams	_	_
produces	_	_
a	_	_
better	_	_
result	_	_
for	_	_
RGB-N	_	_
.	_	_

#249
The	_	_
bottom	_	_
row	_	_
shows	_	_
a	_	_
qualitative	_	_
result	_	_
from	_	_
the	_	_
CASIA1.0	_	_
.	_	_

#250
The	_	_
spliced	_	_
object	_	_
leaves	_	_
clear	_	_
tampering	_	_
artifacts	_	_
in	_	_
both	_	_
the	_	_
RGB	_	_
and	_	_
noise	_	_
streams	_	_
,	_	_
which	_	_
yields	_	_
precise	_	_
detections	_	_
for	_	_
the	_	_
RGB	_	_
,	_	_
noise	_	_
,	_	_
and	_	_
RGB-N	_	_
networks	_	_
.	_	_

#251
Authentic	_	_
image	_	_
Tampered	_	_
image	_	_
Noise	_	_
map	_	_
Ground-truth	_	_
Detection	_	_
result	_	_
Figure	_	_
6	_	_
.	_	_

#252
Qualitative	_	_
results	_	_
for	_	_
multi-class	_	_
image	_	_
manipulation	_	_
detection	_	_
on	_	_
NIST16	_	_
dataset	_	_
.	_	_

#253
RGB	_	_
and	_	_
noise	_	_
map	_	_
provide	_	_
different	_	_
information	_	_
for	_	_
splicing	_	_
,	_	_
copy-move	_	_
and	_	_
removal	_	_
.	_	_

#254
By	_	_
combining	_	_
the	_	_
features	_	_
from	_	_
the	_	_
RGB	_	_
image	_	_
with	_	_
the	_	_
noise	_	_
features	_	_
,	_	_
RGB-N	_	_
produces	_	_
the	_	_
correct	_	_
classification	_	_
for	_	_
different	_	_
tamepring	_	_
techniques	_	_
.	_	_

#255
F1/AUC	_	_
NIST16	_	_
COVER	_	_
CASIA	_	_
Flipping	_	_
+	_	_
JPEG	_	_
0.712/0.950	_	_
0.425/0.810	_	_
0.413/0.785	_	_
Flipping	_	_
+	_	_
noise	_	_
0.717/0.947	_	_
0.412/0.801	_	_
0.396/0.776	_	_
Flipping	_	_
0.722/0.937	_	_
0.437/0.817	_	_
0.408/0.795	_	_
No	_	_
flipping	_	_
0.716/0.940	_	_
0.312/0.793	_	_
0.361/0.766	_	_
Table	_	_
5	_	_
.	_	_

#256
Data	_	_
augmentation	_	_
comparison	_	_
.	_	_

#257
Flipping	_	_
:	_	_
image	_	_
flipping	_	_
.	_	_

#258
JPEG	_	_
:	_	_
JPEG	_	_
compression	_	_
with	_	_
quality	_	_
70	_	_
.	_	_

#259
Noise	_	_
:	_	_
adding	_	_
Gaussian	_	_
noise	_	_
with	_	_
variance	_	_
of	_	_
5	_	_
.	_	_

#260
Each	_	_
entry	_	_
is	_	_
F1/AUC	_	_
score	_	_
.	_	_

#261
JPEG/Resizing	_	_
100/1	_	_
70/0.7	_	_
50/0.5	_	_
NOI1	_	_
0.285/0.285	_	_
0.142/0.147	_	_
0.140/0.155	_	_
ELA	_	_
0.236/0.236	_	_
0.119/0.141	_	_
0.114/0.114	_	_
CFA1	_	_
0.174/0.174	_	_
0.152/0.134	_	_
0.139/0.141	_	_
RGB-N	_	_
0.722/0.722	_	_
0.677/0.689	_	_
0.677/0.681	_	_
Table	_	_
6	_	_
.	_	_

#262
F1	_	_
score	_	_
on	_	_
NIST16	_	_
dataset	_	_
for	_	_
JPEG	_	_
compression	_	_
(	_	_
with	_	_
quality	_	_
70	_	_
and	_	_
50	_	_
)	_	_
and	_	_
resizing	_	_
(	_	_
with	_	_
scale	_	_
0.7	_	_
and	_	_
0.5	_	_
)	_	_
attacks	_	_
.	_	_

#263
Each	_	_
entry	_	_
is	_	_
the	_	_
F1	_	_
score	_	_
of	_	_
JPEG/Resizing	_	_
.	_	_

#264
Splicing	_	_
Removal	_	_
Copy-Move	_	_
Mean	_	_
AP	_	_
0.960	_	_
0.939	_	_
0.903	_	_
0.934	_	_
Table	_	_
7	_	_
.	_	_

#265
AP	_	_
comparison	_	_
on	_	_
multi-class	_	_
on	_	_
NIST16	_	_
dataset	_	_
using	_	_
the	_	_
RGB-N	_	_
network	_	_
.	_	_

#266
Mean	_	_
denotes	_	_
the	_	_
mean	_	_
AP	_	_
for	_	_
splicing	_	_
,	_	_
removal	_	_
and	_	_
copy-move	_	_
.	_	_

#267
sufficient	_	_
to	_	_
use	_	_
only	_	_
the	_	_
noise	_	_
features	_	_
.	_	_

#268
This	_	_
yields	_	_
satisfactory	_	_
performance	_	_
for	_	_
the	_	_
noise	_	_
stream	_	_
.	_	_

#269
For	_	_
all	_	_
datasets	_	_
,	_	_
late	_	_
fusion	_	_
performs	_	_
worse	_	_
than	_	_
RGB-N	_	_
,	_	_
which	_	_
shows	_	_
the	_	_
effectiveness	_	_
of	_	_
our	_	_
fusion	_	_
approach	_	_
.	_	_

#270
Data	_	_
Augmentation	_	_
.	_	_

#271
We	_	_
compare	_	_
different	_	_
data	_	_
augmentation	_	_
methods	_	_
in	_	_
Table	_	_
5	_	_
.	_	_

#272
Compared	_	_
with	_	_
no	_	_
augmentation	_	_
,	_	_
image	_	_
flipping	_	_
improves	_	_
the	_	_
performance	_	_
and	_	_
other	_	_
augmentation	_	_
methods	_	_
like	_	_
JPEG	_	_
compression	_	_
and	_	_
noise	_	_
contribute	_	_
little	_	_
improvement	_	_
.	_	_

#273
Robustness	_	_
to	_	_
JPEG	_	_
and	_	_
Resizing	_	_
Attacks	_	_
.	_	_

#274
We	_	_
test	_	_
the	_	_
robustness	_	_
of	_	_
our	_	_
method	_	_
and	_	_
compare	_	_
with	_	_
3	_	_
methods	_	_
(	_	_
whose	_	_
code	_	_
is	_	_
available	_	_
)	_	_
in	_	_
Table	_	_
6	_	_
.	_	_

#275
Our	_	_
method	_	_
is	_	_
more	_	_
robust	_	_
to	_	_
these	_	_
attacks	_	_
and	_	_
outperforms	_	_
other	_	_
methods	_	_
.	_	_

#276
4.3	_	_
.	_	_

#277
Manipulation	_	_
Technique	_	_
Detection	_	_
The	_	_
rich	_	_
feature	_	_
representation	_	_
of	_	_
our	_	_
network	_	_
enables	_	_
it	_	_
to	_	_
distinguish	_	_
between	_	_
different	_	_
manipulation	_	_
techniques	_	_
as	_	_
well	_	_
.	_	_

#278
We	_	_
explore	_	_
manipulation	_	_
technique	_	_
detection	_	_
and	_	_
analyze	_	_
the	_	_
detection	_	_
performance	_	_
for	_	_
all	_	_
three	_	_
tampering	_	_
techniques	_	_
.	_	_

#279
NIST16	_	_
contains	_	_
the	_	_
labels	_	_
for	_	_
all	_	_
three	_	_
tampering	_	_
techniques	_	_
,	_	_
which	_	_
enables	_	_
multi-class	_	_
image	_	_
manipulation	_	_
detection	_	_
.	_	_

#280
We	_	_
change	_	_
the	_	_
classes	_	_
for	_	_
manipulation	_	_
classification	_	_
to	_	_
be	_	_
splicing	_	_
,	_	_
removal	_	_
and	_	_
copy-move	_	_
so	_	_
as	_	_
to	_	_
learn	_	_
distinct	_	_
visual	_	_
tampering	_	_
artifacts	_	_
and	_	_
noise	_	_
features	_	_
for	_	_
each	_	_
class	_	_
.	_	_

#281
The	_	_
performance	_	_
of	_	_
each	_	_
tamper	_	_
class	_	_
is	_	_
shown	_	_
in	_	_
Table	_	_
7	_	_
.	_	_

#282
The	_	_
AP	_	_
result	_	_
in	_	_
Table	_	_
7	_	_
indicates	_	_
that	_	_
splicing	_	_
is	_	_
the	_	_
easiest	_	_
manipulation	_	_
techniques	_	_
to	_	_
detect	_	_
using	_	_
our	_	_
method	_	_
.	_	_

#283
This	_	_
is	_	_
because	_	_
splicing	_	_
has	_	_
a	_	_
high	_	_
probability	_	_
to	_	_
produce	_	_
both	_	_
RGB	_	_
artifacts	_	_
like	_	_
unnatural	_	_
edges	_	_
,	_	_
contrast	_	_
differences	_	_
as	_	_
well	_	_
as	_	_
noise	_	_
artifacts	_	_
.	_	_

#284
Removal	_	_
detection	_	_
performance	_	_
also	_	_
beats	_	_
copy-move	_	_
because	_	_
the	_	_
inpainting	_	_
that	_	_
follows	_	_
the	_	_
removal	_	_
process	_	_
has	_	_
a	_	_
large	_	_
effect	_	_
on	_	_
the	_	_
noise	_	_
features	_	_
,	_	_
as	_	_
shown	_	_
in	_	_
Figure	_	_
3	_	_
.	_	_

#285
Copy-move	_	_
is	_	_
the	_	_
most	_	_
difficult	_	_
tamper	_	_
technique	_	_
for	_	_
our	_	_
proposed	_	_
method	_	_
.	_	_

#286
The	_	_
explanation	_	_
is	_	_
that	_	_
on	_	_
one	_	_
hand	_	_
,	_	_
the	_	_
copied	_	_
regions	_	_
are	_	_
from	_	_
the	_	_
same	_	_
image	_	_
,	_	_
which	_	_
yields	_	_
a	_	_
similar	_	_
noise	_	_
distribution	_	_
to	_	_
confuse	_	_
our	_	_
noise	_	_
stream	_	_
.	_	_

#287
On	_	_
the	_	_
other	_	_
hand	_	_
,	_	_
the	_	_
two	_	_
regions	_	_
generally	_	_
have	_	_
the	_	_
same	_	_
contrast	_	_
.	_	_

#288
Also	_	_
,	_	_
the	_	_
technique	_	_
would	_	_
ideally	_	_
need	_	_
to	_	_
compare	_	_
the	_	_
two	_	_
objects	_	_
to	_	_
each	_	_
other	_	_
(	_	_
i.e.	_	_
,	_	_
it	_	_
would	_	_
need	_	_
to	_	_
find	_	_
and	_	_
compare	_	_
two	_	_
RoIs	_	_
at	_	_
the	_	_
same	_	_
time	_	_
)	_	_
,	_	_
which	_	_
the	_	_
current	_	_
approach	_	_
does	_	_
not	_	_
do	_	_
.	_	_

#289
Thus	_	_
,	_	_
our	_	_
RGB	_	_
stream	_	_
has	_	_
less	_	_
evidence	_	_
to	_	_
distinguish	_	_
between	_	_
the	_	_
two	_	_
regions	_	_
.	_	_

#290
4.4	_	_
.	_	_

#291
Qualitative	_	_
Result	_	_
We	_	_
show	_	_
some	_	_
qualitative	_	_
results	_	_
in	_	_
Figure	_	_
5	_	_
for	_	_
comparison	_	_
of	_	_
RGB	_	_
,	_	_
noise	_	_
and	_	_
RGB-N	_	_
network	_	_
in	_	_
two-class	_	_
image	_	_
manipulation	_	_
detection	_	_
.	_	_

#292
The	_	_
images	_	_
are	_	_
selected	_	_
from	_	_
the	_	_
COVER	_	_
,	_	_
Columbia	_	_
and	_	_
CASIA	_	_
1.0	_	_
.	_	_

#293
Figure	_	_
5	_	_
provides	_	_
examples	_	_
for	_	_
which	_	_
our	_	_
two-stream	_	_
network	_	_
yields	_	_
good	_	_
performance	_	_
even	_	_
if	_	_
one	_	_
of	_	_
the	_	_
single	_	_
streams	_	_
fails	_	_
(	_	_
the	_	_
first	_	_
and	_	_
second	_	_
row	_	_
in	_	_
Figure	_	_
5	_	_
)	_	_
.	_	_

#294
Figure	_	_
6	_	_
shows	_	_
the	_	_
results	_	_
of	_	_
the	_	_
RGB-N	_	_
network	_	_
on	_	_
the	_	_
task	_	_
of	_	_
manipulation	_	_
technique	_	_
detection	_	_
task	_	_
using	_	_
the	_	_
NIST16	_	_
.	_	_

#295
As	_	_
is	_	_
shown	_	_
in	_	_
the	_	_
figure	_	_
,	_	_
our	_	_
network	_	_
produces	_	_
accurate	_	_
results	_	_
for	_	_
different	_	_
tampering	_	_
techniques	_	_
.	_	_

#296
5	_	_
.	_	_

#297
Conclusion	_	_
We	_	_
propose	_	_
a	_	_
novel	_	_
network	_	_
using	_	_
both	_	_
an	_	_
RGB	_	_
stream	_	_
and	_	_
a	_	_
noise	_	_
stream	_	_
to	_	_
learn	_	_
rich	_	_
features	_	_
for	_	_
image	_	_
manipulation	_	_
detection	_	_
.	_	_

#298
We	_	_
extract	_	_
noise	_	_
features	_	_
by	_	_
an	_	_
SRM	_	_
filter	_	_
layer	_	_
adapted	_	_
from	_	_
steganalysis	_	_
literatures	_	_
,	_	_
which	_	_
enables	_	_
our	_	_
model	_	_
to	_	_
capture	_	_
noise	_	_
inconsistency	_	_
between	_	_
tampered	_	_
and	_	_
authentic	_	_
regions	_	_
.	_	_

#299
We	_	_
explore	_	_
the	_	_
complementary	_	_
contribution	_	_
of	_	_
finding	_	_
tampered	_	_
regions	_	_
from	_	_
RGB	_	_
and	_	_
the	_	_
noise	_	_
features	_	_
of	_	_
an	_	_
image	_	_
.	_	_

#300
Not	_	_
surprisingly	_	_
,	_	_
the	_	_
fusion	_	_
of	_	_
the	_	_
two	_	_
streams	_	_
leads	_	_
to	_	_
improved	_	_
performance	_	_
.	_	_

#301
Experiments	_	_
on	_	_
standard	_	_
datasets	_	_
show	_	_
that	_	_
our	_	_
method	_	_
not	_	_
only	_	_
detects	_	_
tampering	_	_
artifacts	_	_
but	_	_
also	_	_
distinguishes	_	_
between	_	_
various	_	_
tampering	_	_
techniques	_	_
.	_	_

#302
More	_	_
features	_	_
,	_	_
including	_	_
JPEG	_	_
compression	_	_
,	_	_
will	_	_
be	_	_
explored	_	_
in	_	_
the	_	_
future	_	_
.	_	_

#303
Acknowledgement	_	_
This	_	_
work	_	_
was	_	_
supported	_	_
by	_	_
the	_	_
DARPA	_	_
MediFor	_	_
program	_	_
under	_	_
cooperative	_	_
agreement	_	_
FA87501620191	_	_
,	_	_
“Physical	_	_
and	_	_
Semantic	_	_
Integrity	_	_
Measures	_	_
for	_	_
Media	_	_
Forensics”	_	_
.	_	_

#304
The	_	_
authors	_	_
acknowledge	_	_
the	_	_
Maryland	_	_
Advanced	_	_
Research	_	_
Computing	_	_
Center	_	_
(	_	_
MARCC	_	_
)	_	_
for	_	_
providing	_	_
computing	_	_
resources	_	_
.	_	_