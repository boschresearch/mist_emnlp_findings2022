#0
ar	_	_
X	_	_
iv	_	_
:1	_	_
5	_	_
.	_	_

#1
0v	_	_
1	_	_
[	_	_
cs	_	_
.C	_	_
V	_	_
]	_	_
3	_	_
M	_	_
ay	_	_
2	_	_
Semantic	_	_
segmentation	_	_
of	_	_
mFISH	_	_
images	_	_
using	_	_
convolutional	_	_
networks	_	_
Esteban	_	_
Pardoa	_	_
,	_	_
José	_	_
Mário	_	_
T	_	_
Morgadob	_	_
,	_	_
Norberto	_	_
Malpicaa	_	_
aMedical	_	_
Image	_	_
Analysis	_	_
and	_	_
Biometry	_	_
Lab	_	_
,	_	_
Universidad	_	_
Rey	_	_
Juan	_	_
Carlos	_	_
,	_	_
Móstoles	_	_
,	_	_
Madrid	_	_
,	_	_
Spain	_	_
bCytognos	_	_
SL	_	_
,	_	_
Salamanca	_	_
,	_	_
Spain	_	_

#2
Abstract	_	_

#3
Multicolor	_	_
in	_	_
situ	_	_
hybridization	_	_
(	_	_
mFISH	_	_
)	_	_
is	_	_
a	_	_
karyotyping	_	_
technique	_	_
used	_	_
to	_	_
detect	_	_
major	_	_
chromosomal	_	_
alterations	_	_
using	_	_
fluorescent	_	_
probes	_	_
and	_	_
imaging	_	_
techniques	_	_
.	_	_

#4
Manual	_	_
interpretation	_	_
of	_	_
mFISH	_	_
images	_	_
is	_	_
a	_	_
time	_	_
consuming	_	_
step	_	_
that	_	_
can	_	_
be	_	_
automated	_	_
using	_	_
machine	_	_
learning	_	_
;	_	_
in	_	_
previous	_	_
works	_	_
,	_	_
pixel	_	_
or	_	_
patch	_	_
wise	_	_
classification	_	_
was	_	_
employed	_	_
,	_	_
overlooking	_	_
spatial	_	_
information	_	_
which	_	_
can	_	_
help	_	_
identify	_	_
chromosomes	_	_
.	_	_

#5
In	_	_
this	_	_
work	_	_
,	_	_
we	_	_
propose	_	_
a	_	_
fully	_	_
convolutional	_	_
semantic	_	_
segmentation	_	_
network	_	_
for	_	_
the	_	_
interpretation	_	_
of	_	_
mFISH	_	_
images	_	_
,	_	_
which	_	_
uses	_	_
both	_	_
spatial	_	_
and	_	_
spectral	_	_
information	_	_
to	_	_
classify	_	_
each	_	_
pixel	_	_
in	_	_
an	_	_
end-to-end	_	_
fashion	_	_
.	_	_

#6
The	_	_
semantic	_	_
segmentation	_	_
network	_	_
developed	_	_
was	_	_
tested	_	_
on	_	_
samples	_	_
extracted	_	_
from	_	_
a	_	_
public	_	_
dataset	_	_
using	_	_
cross	_	_
validation	_	_
.	_	_

#7
Despite	_	_
having	_	_
no	_	_
labeling	_	_
information	_	_
of	_	_
the	_	_
image	_	_
it	_	_
was	_	_
tested	_	_
on	_	_
our	_	_
algorithm	_	_
yielded	_	_
an	_	_
average	_	_
correct	_	_
classification	_	_
ratio	_	_
(	_	_
CCR	_	_
)	_	_
of	_	_
87.41	_	_
%	_	_
.	_	_

#8
Previously	_	_
,	_	_
this	_	_
level	_	_
of	_	_
accuracy	_	_
was	_	_
only	_	_
achieved	_	_
with	_	_
state	_	_
of	_	_
the	_	_
art	_	_
algorithms	_	_
when	_	_
classifying	_	_
pixels	_	_
from	_	_
the	_	_
same	_	_
image	_	_
in	_	_
which	_	_
the	_	_
classifier	_	_
has	_	_
been	_	_
trained	_	_
.	_	_

#9
These	_	_
results	_	_
provide	_	_
evidence	_	_
that	_	_
fully	_	_
convolutional	_	_
semantic	_	_
segmentation	_	_
networks	_	_
may	_	_
be	_	_
employed	_	_
in	_	_
the	_	_
computer	_	_
aided	_	_
diagnosis	_	_
of	_	_
genetic	_	_
diseases	_	_
with	_	_
improved	_	_
performance	_	_
over	_	_
the	_	_
current	_	_
methods	_	_
of	_	_
image	_	_
analysis	_	_
.	_	_

#10
This	_	_
is	_	_
the	_	_
pre-peer	_	_
reviewed	_	_
version	_	_
of	_	_
the	_	_
following	_	_
article	_	_
:	_	_
"	_	_
Pardo	_	_
,	_	_
E.	_	_
,	_	_
Morgado	_	_
,	_	_
J.	_	_
M.	_	_
and	_	_
Malpica	_	_
,	_	_
N.	_	_
(	_	_
2018	_	_
)	_	_
,	_	_
Semantic	_	_
segmentation	_	_
of	_	_
mFISH	_	_
images	_	_
using	_	_
convolutional	_	_
networks	_	_
.	_	_

#11
Cytometry	_	_
Part	_	_
A	_	_
"	_	_
,	_	_
which	_	_
has	_	_
been	_	_
published	_	_
in	_	_
final	_	_
form	_	_
at	_	_
https	_	_
:	_	_
//doi.org/10.1002/cyto.a.23375	_	_
.	_	_

#12
This	_	_
article	_	_
may	_	_
be	_	_
used	_	_
for	_	_
non-commercial	_	_
purposes	_	_
in	_	_
accordance	_	_
with	_	_
Wiley	_	_
Terms	_	_
and	_	_
Conditions	_	_
for	_	_
Self-Archiving	_	_
.	_	_

#13
Keywords	_	_
:	_	_
mFISH	_	_
,	_	_
Convolutional	_	_
Networks	_	_
,	_	_
Semantic	_	_
Segmentation	_	_
,	_	_
chromosome	_	_
image	_	_
analysis	_	_
1	_	_
.	_	_

#14
Introduction	_	_
Multicolor	_	_
fluorescence	_	_
in	_	_
situ	_	_
hybridization	_	_
(	_	_
mFISH	_	_
)	_	_
is	_	_
a	_	_
cytogenetic	_	_
methodology	_	_
that	_	_
allows	_	_
the	_	_
simultaneous	_	_
visualization	_	_
of	_	_
each	_	_
chromosome	_	_
pair	_	_
in	_	_
a	_	_
different	_	_
color	_	_
,	_	_
providing	_	_
a	_	_
genome-wide	_	_
picture	_	_
of	_	_
cytogenetic	_	_
abnormalities	_	_
in	_	_
a	_	_
single	_	_
experiment	_	_
(	_	_
Speicher	_	_
et	_	_
al.	_	_
,	_	_
1996	_	_
;	_	_
Schrock	_	_
et	_	_
al.	_	_
,	_	_
1996	_	_
)	_	_
.	_	_

#15
It	_	_
was	_	_
introduced	_	_
in	_	_
1996	_	_
as	_	_
spectral	_	_
karyotyping	_	_
(	_	_
SKY	_	_
)	_	_
(	_	_
Schrock	_	_
et	_	_
al.	_	_
,	_	_
1996	_	_
)	_	_
and	_	_
multiplex-FISH	_	_
(	_	_
M-FISH	_	_
)	_	_
(	_	_
Speicher	_	_
et	_	_
al.	_	_
,	_	_
1996	_	_
)	_	_
,	_	_
similar	_	_
methodologies	_	_
in	_	_
terms	_	_
of	_	_
labeling	_	_
but	_	_
differing	_	_
in	_	_
terms	_	_
of	_	_
imaging	_	_
system	_	_
requirements	_	_
and	_	_
image	_	_
acquisition	_	_
and	_	_
analysis	_	_
process	_	_
.	_	_

#16
After	_	_
the	_	_
mFISH	_	_
spectral	_	_
information	_	_
has	_	_
been	_	_
acquired	_	_
,	_	_
different	_	_
features	_	_
can	_	_
be	_	_
Preprint	_	_
submitted	_	_
to	_	_
Cytometry	_	_
Part	_	_
A	_	_
January	_	_
22	_	_
,	_	_
2021	_	_
analyzed	_	_
to	_	_
assign	_	_
a	_	_
chromosome	_	_
label	_	_
to	_	_
each	_	_
pixel	_	_
.	_	_

#17
Manual	_	_
interpretation	_	_
of	_	_
mFISH	_	_
images	_	_
is	_	_
a	_	_
time-consuming	_	_
task	_	_
where	_	_
not	_	_
only	_	_
the	_	_
intensity	_	_
of	_	_
each	_	_
pixel	_	_
is	_	_
compared	_	_
across	_	_
channels	_	_
but	_	_
also	_	_
the	_	_
shape	_	_
,	_	_
size	_	_
and	_	_
centromere	_	_
position	_	_
.	_	_

#18
Many	_	_
attempts	_	_
were	_	_
made	_	_
to	_	_
automate	_	_
the	_	_
task	_	_
,	_	_
being	_	_
the	_	_
most	_	_
notable	_	_
approaches	_	_
pixel	_	_
and	_	_
region	_	_
based	_	_
classifiers	_	_
.	_	_

#19
These	_	_
classifiers	_	_
usually	_	_
build	_	_
a	_	_
feature	_	_
vector	_	_
using	_	_
pixel	_	_
or	_	_
patch	_	_
based	_	_
intensity	_	_
information	_	_
and	_	_
use	_	_
that	_	_
information	_	_
to	_	_
train	_	_
a	_	_
classifier	_	_
,	_	_
which	_	_
is	_	_
later	_	_
used	_	_
to	_	_
classify	_	_
pixels	_	_
from	_	_
the	_	_
same	_	_
image	_	_
(	_	_
Wang	_	_
et	_	_
al.	_	_
,	_	_
2017	_	_
;	_	_
Li	_	_
et	_	_
al.	_	_
,	_	_
2012	_	_
)	_	_
,	_	_
or	_	_
from	_	_
a	_	_
different	_	_
one	_	_
(	_	_
Choi	_	_
et	_	_
al.	_	_
,	_	_
2004	_	_
,	_	_
2008	_	_
)	_	_
.	_	_

#20
Multiple	_	_
pixel	_	_
based	_	_
classifiers	_	_
have	_	_
been	_	_
developed	_	_
for	_	_
the	_	_
analysis	_	_
of	_	_
mFISH	_	_
images	_	_
,	_	_
showing	_	_
that	_	_
the	_	_
spectral	_	_
information	_	_
present	_	_
in	_	_
a	_	_
pixel	_	_
can	_	_
be	_	_
successfully	_	_
used	_	_
to	_	_
train	_	_
machine	_	_
learning	_	_
classifiers	_	_
.	_	_

#21
(	_	_
Schwartzkopf	_	_
et	_	_
al.	_	_
,	_	_
2005	_	_
;	_	_
Choi	_	_
et	_	_
al.	_	_
,	_	_
2008	_	_
)	_	_
.	_	_

#22
In	_	_
the	_	_
other	_	_
hand	_	_
,	_	_
region	_	_
based	_	_
classification	_	_
has	_	_
also	_	_
been	_	_
studied	_	_
,	_	_
showing	_	_
that	_	_
it	_	_
generally	_	_
outperforms	_	_
pixel	_	_
based	_	_
classification	_	_
approaches	_	_
.	_	_

#23
(	_	_
Li	_	_
et	_	_
al.	_	_
,	_	_
2012	_	_
;	_	_
Wang	_	_
et	_	_
al.	_	_
,	_	_
2017	_	_
)	_	_
,	_	_
underlining	_	_
the	_	_
importance	_	_
of	_	_
using	_	_
spatial	_	_
information	_	_
to	_	_
improve	_	_
the	_	_
performance	_	_
of	_	_
mFISH	_	_
analysis	_	_
algorithms	_	_
.	_	_

#24
Despite	_	_
the	_	_
relative	_	_
success	_	_
of	_	_
the	_	_
above	_	_
mentioned	_	_
approaches	_	_
,	_	_
none	_	_
of	_	_
them	_	_
take	_	_
into	_	_
account	_	_
spatial	_	_
information	_	_
about	_	_
the	_	_
shape	_	_
,	_	_
size	_	_
,	_	_
or	_	_
texture	_	_
of	_	_
the	_	_
objects	_	_
being	_	_
analyzed	_	_
.	_	_

#25
This	_	_
limits	_	_
the	_	_
performance	_	_
of	_	_
the	_	_
algorithms	_	_
in	_	_
challenging	_	_
scenarios	_	_
where	_	_
the	_	_
identification	_	_
of	_	_
the	_	_
chromosome	_	_
is	_	_
not	_	_
clear	_	_
based	_	_
only	_	_
on	_	_
the	_	_
spectral	_	_
information	_	_
.	_	_

#26
Some	_	_
important	_	_
features	_	_
typically	_	_
used	_	_
in	_	_
manual	_	_
analysis	_	_
,	_	_
but	_	_
not	_	_
incorporated	_	_
into	_	_
classification	_	_
algorithms	_	_
,	_	_
are	_	_
the	_	_
relative	_	_
length	_	_
of	_	_
a	_	_
chromosome	_	_
,	_	_
the	_	_
arm	_	_
ratio	_	_
,	_	_
or	_	_
the	_	_
centromeric	_	_
index	_	_
(	_	_
Lejeune	_	_
et	_	_
al.	_	_
,	_	_
1960	_	_
)	_	_
.	_	_

#27
Such	_	_
features	_	_
can	_	_
be	_	_
automatically	_	_
learned	_	_
running	_	_
the	_	_
input	_	_
images	_	_
through	_	_
a	_	_
network	_	_
of	_	_
convolutions	_	_
and	_	_
resampling	_	_
operations	_	_
,	_	_
comparing	_	_
the	_	_
resulting	_	_
image	_	_
to	_	_
the	_	_
expected	_	_
segmentation	_	_
map	_	_
,	_	_
and	_	_
backpropagating	_	_
the	_	_
error	_	_
to	_	_
learn	_	_
the	_	_
network	_	_
parameter	_	_
.	_	_

#28
This	_	_
approach	_	_
is	_	_
usually	_	_
called	_	_
“end	_	_
to	_	_
end	_	_
semantic	_	_
segmentation”	_	_
.	_	_

#29
End	_	_
to	_	_
end	_	_
semantic	_	_
segmentation	_	_
using	_	_
convolutional	_	_
networks	_	_
has	_	_
been	_	_
shown	_	_
to	_	_
achieve	_	_
state	_	_
of	_	_
the	_	_
art	_	_
results	_	_
by	_	_
automatically	_	_
learning	_	_
features	_	_
based	_	_
on	_	_
spatial	_	_
and	_	_
intensity	_	_
information	_	_
(	_	_
Ronneberger	_	_
et	_	_
al.	_	_
,	_	_
2015	_	_
;	_	_
Badrinarayanan	_	_
et	_	_
al.	_	_
,	_	_
2015	_	_
;	_	_
Chen	_	_
et	_	_
al.	_	_
,	_	_
2016	_	_
)	_	_
.	_	_

#30
The	_	_
convolutional	_	_
network	_	_
approach	_	_
shifts	_	_
the	_	_
focus	_	_
from	_	_
feature	_	_
engineering	_	_
to	_	_
network	_	_
architecture	_	_
engineering	_	_
,	_	_
searching	_	_
for	_	_
the	_	_
best	_	_
network	_	_
layout	_	_
for	_	_
a	_	_
given	_	_
problem	_	_
.	_	_

#31
In	_	_
the	_	_
field	_	_
of	_	_
biomedical	_	_
image	_	_
processing	_	_
,	_	_
network	_	_
architectures	_	_
such	_	_
as	_	_
U-Net	_	_
(	_	_
Ronneberger	_	_
et	_	_
al.	_	_
,	_	_
2015	_	_
)	_	_
have	_	_
been	_	_
widely	_	_
used	_	_
to	_	_
perform	_	_
end	_	_
to	_	_
end	_	_
semantic	_	_
segmentation	_	_
.	_	_

#32
This	_	_
architecture	_	_
consists	_	_
of	_	_
two	_	_
paths	_	_
:	_	_
the	_	_
first	_	_
one	_	_
builds	_	_
an	_	_
abstract	_	_
representation	_	_
of	_	_
the	_	_
image	_	_
by	_	_
iteratively	_	_
convolving	_	_
and	_	_
subsampling	_	_
the	_	_
image	_	_
,	_	_
while	_	_
the	_	_
second	_	_
creates	_	_
the	_	_
target	_	_
segmentation	_	_
map	_	_
by	_	_
iterative	_	_
upsampling	_	_
and	_	_
convolving	_	_
the	_	_
abstract	_	_
feature	_	_
maps	_	_
.	_	_

#33
These	_	_
two	_	_
paths	_	_
are	_	_
symmetrical	_	_
and	_	_
connected	_	_
by	_	_
connecting	_	_
each	_	_
subsampling	_	_
step	_	_
with	_	_
the	_	_
analogous	_	_
upsampling	_	_
step	_	_
by	_	_
concatenating	_	_
the	_	_
corresponding	_	_
layers	_	_
.	_	_

#34
Different	_	_
architectures	_	_
of	_	_
end-to-end	_	_
convolutional	_	_
networks	_	_
for	_	_
semantic	_	_
segmentation	_	_
have	_	_
been	_	_
developed	_	_
since	_	_
the	_	_
creation	_	_
of	_	_
U-Net	_	_
,	_	_
being	_	_
Deep-Lab	_	_
architecture	_	_
(	_	_
Chen	_	_
et	_	_
al.	_	_
,	_	_
2016	_	_
)	_	_
(	_	_
Chen	_	_
et	_	_
al.	_	_
,	_	_
2017	_	_
)	_	_
one	_	_
of	_	_
the	_	_
best	_	_
performing	_	_
ones	_	_
,	_	_
with	_	_
an	_	_
average	_	_
precision	_	_
of	_	_
86.9	_	_
%	_	_
in	_	_
the	_	_
Pascal	_	_
VOC	_	_
challenge	_	_
(	_	_
Everingham	_	_
et	_	_
al.	_	_
,	_	_
2010	_	_
)	_	_
.	_	_

#35
The	_	_
core	_	_
of	_	_
this	_	_
architecture	_	_
is	_	_
the	_	_
use	_	_
of	_	_
atrous	_	_
convolution	_	_
for	_	_
probing	_	_
convolutional	_	_
features	_	_
at	_	_
different	_	_
scales	_	_
which	_	_
has	_	_
proven	_	_
to	_	_
be	_	_
a	_	_
powerful	_	_
way	_	_
of	_	_
incorporating	_	_
context	_	_
information	_	_
.	_	_

#36
The	_	_
good	_	_
results	_	_
in	_	_
the	_	_
Pascal	_	_
VOC	_	_
2012	_	_
semantic	_	_
segmentation	_	_
challenge	_	_
led	_	_
us	_	_
to	_	_
incorporate	_	_
some	_	_
of	_	_
the	_	_
main	_	_
ideas	_	_
into	_	_
our	_	_
work	_	_
with	_	_
mFISH	_	_
images	_	_
.	_	_

#37
The	_	_
main	_	_
challenge	_	_
of	_	_
applying	_	_
end	_	_
to	_	_
end	_	_
convolutional	_	_
networks	_	_
is	_	_
the	_	_
limited	_	_
number	_	_
of	_	_
samples	_	_
found	_	_
in	_	_
the	_	_
commonly	_	_
used	_	_
benchmarks	_	_
,	_	_
mainly	_	_
the	_	_
ADIR	_	_
dataset	_	_
(	_	_
Choi	_	_
et	_	_
al.	_	_
,	_	_
2004	_	_
,	_	_
2008	_	_
;	_	_
Li	_	_
et	_	_
al.	_	_
,	_	_
2012	_	_
;	_	_
Wang	_	_
et	_	_
al.	_	_
,	_	_
2017	_	_
)	_	_
.	_	_

#38
This	_	_
dataset	_	_
contains	_	_
mFISH	_	_
samples	_	_
prepared	_	_
using	_	_
Vysis	_	_
,	_	_
ASI	_	_
,	_	_
and	_	_
PSI/Cytocell	_	_
probes	_	_
,	_	_
were	_	_
each	_	_
cell	_	_
is	_	_
captured	_	_
in	_	_
7	_	_
images	_	_
,	_	_
6	_	_
of	_	_
them	_	_
representing	_	_
the	_	_
observed	_	_
intensity	_	_
of	_	_
each	_	_
fluorophore	_	_
and	_	_
the	_	_
remaining	_	_
one	_	_
containing	_	_
manual	_	_
expert	_	_
labeling	_	_
of	_	_
every	_	_
pixel	_	_
.	_	_

#39
The	_	_
three	_	_
different	_	_
probes	_	_
used	_	_
to	_	_
prepare	_	_
the	_	_
samples	_	_
do	_	_
not	_	_
share	_	_
a	_	_
common	_	_
labeling	_	_
scheme	_	_
,	_	_
which	_	_
means	_	_
that	_	_
the	_	_
features	_	_
used	_	_
to	_	_
segment	_	_
a	_	_
sample	_	_
hybridized	_	_
with	_	_
a	_	_
Vysis	_	_
probe	_	_
set	_	_
may	_	_
not	_	_
work	_	_
in	_	_
samples	_	_
where	_	_
the	_	_
ASI	_	_
probes	_	_
were	_	_
used	_	_
.	_	_

#40
To	_	_
reduce	_	_
the	_	_
impact	_	_
of	_	_
using	_	_
different	_	_
probe	_	_
sets	_	_
for	_	_
training	_	_
and	_	_
testing	_	_
,	_	_
this	_	_
work	_	_
focuses	_	_
on	_	_
the	_	_
Vysis	_	_
subset	_	_
,	_	_
since	_	_
it	_	_
is	_	_
the	_	_
largest	_	_
one	_	_
.	_	_

#41
In	_	_
this	_	_
work	_	_
,	_	_
we	_	_
present	_	_
a	_	_
fully	_	_
convolutional	_	_
network	_	_
for	_	_
semantic	_	_
segmentation	_	_
of	_	_
mFISH	_	_
images	_	_
that	_	_
uses	_	_
both	_	_
spectral	_	_
and	_	_
spatial	_	_
information	_	_
to	_	_
classify	_	_
every	_	_
pixel	_	_
in	_	_
an	_	_
image	_	_
in	_	_
and	_	_
end-to-end	_	_
fashion	_	_
and	_	_
provide	_	_
evidence	_	_
that	_	_
our	_	_
approach	_	_
performs	_	_
well	_	_
even	_	_
in	_	_
challenging	_	_
scenarios	_	_
.	_	_

#42
2	_	_
.	_	_

#43
Materials	_	_
The	_	_
ADIR	_	_
dataset	_	_
was	_	_
used	_	_
to	_	_
design	_	_
and	_	_
evaluate	_	_
the	_	_
network	_	_
.	_	_

#44
This	_	_
dataset	_	_
contains	_	_
samples	_	_
prepared	_	_
with	_	_
different	_	_
probe	_	_
sets	_	_
:	_	_
ASI	_	_
,	_	_
PSI/Cytocell	_	_
and	_	_
Vysis	_	_
.	_	_

#45
Each	_	_
probe	_	_
set	_	_
uses	_	_
different	_	_
dyes	_	_
and	_	_
combinatorial	_	_
labeling	_	_
schemes	_	_
,	_	_
this	_	_
means	_	_
that	_	_
even	_	_
if	_	_
all	_	_
mFISH	_	_
images	_	_
have	_	_
6	_	_
channels	_	_
,	_	_
these	_	_
channels	_	_
have	_	_
different	_	_
meanings	_	_
depending	_	_
on	_	_
the	_	_
probes	_	_
used	_	_
.	_	_

#46
There	_	_
are	_	_
some	_	_
cases	_	_
when	_	_
the	_	_
emitted	_	_
spectra	_	_
overlap	_	_
among	_	_
different	_	_
subsets	_	_
,	_	_
ASI	_	_
and	_	_
Vysis	_	_
probes	_	_
both	_	_
emit	_	_
fluorescence	_	_
in	_	_
the	_	_
Spectrum	_	_
Green	_	_
channel	_	_
,	_	_
and	_	_
ASI	_	_
and	_	_
PSI/Cytocell	_	_
both	_	_
emit	_	_
fluorescence	_	_
in	_	_
the	_	_
Cy5	_	_
channel	_	_
.	_	_

#47
Despite	_	_
this	_	_
overlap	_	_
,	_	_
the	_	_
underlying	_	_
probes	_	_
are	_	_
hybridized	_	_
to	_	_
different	_	_
chromosomes	_	_
,	_	_
which	_	_
means	_	_
that	_	_
this	_	_
information	_	_
is	_	_
not	_	_
easily	_	_
reusable	_	_
for	_	_
learning	_	_
the	_	_
segmentation	_	_
maps	_	_
.	_	_

#48
The	_	_
dataset	_	_
contains	_	_
71	_	_
ASI	_	_
images	_	_
,	_	_
29	_	_
PSI/Cytocell	_	_
images	_	_
,	_	_
and	_	_
84	_	_
Vysis	_	_
images	_	_
.	_	_

#49
We	_	_
decided	_	_
to	_	_
evaluate	_	_
our	_	_
algorithm	_	_
on	_	_
samples	_	_
prepared	_	_
with	_	_
the	_	_
Vysis	_	_
probe	_	_
sets	_	_
,	_	_
since	_	_
they	_	_
are	_	_
the	_	_
most	_	_
frequent	_	_
.	_	_

#50
The	_	_
Vysis	_	_
subset	_	_
was	_	_
further	_	_
refined	_	_
by	_	_
removing	_	_
14	_	_
low	_	_
quality	_	_
images	_	_
.	_	_

#51
Some	_	_
authors	_	_
have	_	_
reported	_	_
a	_	_
list	_	_
of	_	_
low	_	_
quality	_	_
images	_	_
due	_	_
to	_	_
ill-hybridization	_	_
,	_	_
wrong	_	_
exposure	_	_
times	_	_
,	_	_
channel	_	_
cross	_	_
talk	_	_
,	_	_
channel	_	_
misalignment	_	_
,	_	_
or	_	_
using	_	_
different	_	_
probes	_	_
that	_	_
the	_	_
ones	_	_
reported	_	_
(	_	_
Choi	_	_
et	_	_
al.	_	_
,	_	_
2008	_	_
)	_	_
.	_	_

#52
To	_	_
ensure	_	_
that	_	_
the	_	_
estimated	_	_
CCR	_	_
is	_	_
not	_	_
biased	_	_
by	_	_
avoidable	_	_
issues	_	_
in	_	_
the	_	_
sample	_	_
preparation	_	_
and	_	_
acquisition	_	_
steps	_	_
,	_	_
the	_	_
images	_	_
listed	_	_
in	_	_
(	_	_
Choi	_	_
et	_	_
al.	_	_
,	_	_
2008	_	_
)	_	_
have	_	_
been	_	_
removed	_	_
from	_	_
the	_	_
dataset	_	_
.	_	_

#53
Additionally	_	_
,	_	_
when	_	_
analyzing	_	_
the	_	_
achieved	_	_
CCR	_	_
on	_	_
the	_	_
remaining	_	_
samples	_	_
we	_	_
detected	_	_
some	_	_
outliers	_	_
,	_	_
visual	_	_
inspection	_	_
of	_	_
these	_	_
samples	_	_
confirmed	_	_
issues	_	_
in	_	_
the	_	_
preparation	_	_
or	_	_
acquisition	_	_
steps	_	_
which	_	_
can	_	_
be	_	_
observed	_	_
in	_	_
figure	_	_
4	_	_
.	_	_

#54
We	_	_
removed	_	_
4	_	_
additional	_	_
samples	_	_
that	_	_
presented	_	_
abnormal	_	_
intensity	_	_
levels	_	_
in	_	_
some	_	_
of	_	_
the	_	_
channels	_	_
and	_	_
limited	_	_
the	_	_
performance	_	_
of	_	_
the	_	_
network	_	_
,	_	_
we	_	_
also	_	_
kept	_	_
samples	_	_
with	_	_
similar	_	_
but	_	_
less	_	_
intense	_	_
problems	_	_
since	_	_
most	_	_
of	_	_
the	_	_
noisy	_	_
samples	_	_
did	_	_
not	_	_
have	_	_
large	_	_
negative	_	_
impact	_	_
to	_	_
the	_	_
performance	_	_
of	_	_
the	_	_
network	_	_
and	_	_
helped	_	_
to	_	_
maintain	_	_
a	_	_
realistic	_	_
variability	_	_
in	_	_
the	_	_
dataset	_	_
.	_	_

#55
The	_	_
list	_	_
of	_	_
removed	_	_
images	_	_
can	_	_
be	_	_
consulted	_	_
in	_	_
table	_	_
1	_	_
.	_	_

#56
Table	_	_
1	_	_
:	_	_
List	_	_
of	_	_
images	_	_
removed	_	_
from	_	_
the	_	_
Vysis	_	_
subset	_	_
File	_	_
name	_	_
Condition	_	_
File	_	_
name	_	_
Condition	_	_
V250253	_	_
Ill-hybridization/Wrong	_	_
exposure	_	_
V290962	_	_
Ill-hybridization/Wrong	_	_
exposure	_	_
V260754	_	_
Channel	_	_
cross	_	_
talk	_	_
V291562	_	_
Channel	_	_
misalignment	_	_
V260856	_	_
Channel	_	_
cross	_	_
talk	_	_
V1701XY	_	_
Wrong	_	_
probe	_	_
label	_	_
V290162	_	_
Channel	_	_
cross	_	_
talk	_	_
V1702XY	_	_
Wrong	_	_
probe	_	_
label	_	_
V290362	_	_
Channel	_	_
cross	_	_
talk	_	_
V1703XY	_	_
Wrong	_	_
probe	_	_
label	_	_
V270259	_	_
Ill-hybridization/Wrong	_	_
exposure	_	_
V1402XX	_	_
Ill-hybridization/Wrong	_	_
exposure	_	_
V280162	_	_
Ill-hybridization/Wrong	_	_
exposure	_	_
V190442	_	_
Ill-hybridization/Wrong	_	_
exposure	_	_
Figure	_	_
1	_	_
:	_	_
Network	_	_
architecture	_	_
.	_	_

#57
The	_	_
Conv	_	_
block	_	_
illustrates	_	_
a	_	_
convolution	_	_
followed	_	_
by	_	_
a	_	_
ReLU	_	_
activation	_	_
and	_	_
batch	_	_
normalization	_	_
,	_	_
for	_	_
the	_	_
last	_	_
Conv	_	_
block	_	_
there	_	_
is	_	_
no	_	_
batch	_	_
normalization	_	_
and	_	_
the	_	_
activation	_	_
is	_	_
switched	_	_
to	_	_
a	_	_
Softmax	_	_
function	_	_
.	_	_

#58
The	_	_
parameters	_	_
in	_	_
a	_	_
Conv	_	_
block	_	_
represent	_	_
the	_	_
kernel	_	_
size	_	_
,	_	_
the	_	_
dilation	_	_
rate	_	_
,	_	_
and	_	_
the	_	_
number	_	_
of	_	_
filters	_	_
.	_	_

#59
The	_	_
MaxPool	_	_
block	_	_
represents	_	_
a	_	_
max	_	_
pooling	_	_
operation	_	_
where	_	_
the	_	_
first	_	_
parameter	_	_
is	_	_
the	_	_
pool	_	_
size	_	_
,	_	_
and	_	_
the	_	_
second	_	_
is	_	_
the	_	_
stride	_	_
.	_	_

#60
The	_	_
parameter	_	_
for	_	_
the	_	_
Dropout	_	_
block	_	_
represents	_	_
the	_	_
dropout	_	_
rate	_	_
.	_	_

#61
Whenever	_	_
a	_	_
x2	_	_
is	_	_
present	_	_
,	_	_
2	_	_
blocks	_	_
are	_	_
performed	_	_
sequentially	_	_
.	_	_

#62
After	_	_
two	_	_
downsampling	_	_
steps	_	_
,	_	_
an	_	_
ASPP	_	_
module	_	_
is	_	_
used	_	_
to	_	_
probe	_	_
information	_	_
at	_	_
different	_	_
resolutions	_	_
.	_	_

#63
The	_	_
different	_	_
ASPP	_	_
branches	_	_
are	_	_
concatenated	_	_
and	_	_
a	_	_
1x1	_	_
convolution	_	_
is	_	_
used	_	_
to	_	_
combine	_	_
the	_	_
information	_	_
.	_	_

#64
The	_	_
final	_	_
feature	_	_
maps	_	_
are	_	_
upsampled	_	_
using	_	_
bilinear	_	_
interpolation	_	_
.	_	_

#65
We	_	_
found	_	_
useful	_	_
to	_	_
apply	_	_
dropout	_	_
after	_	_
concatenating	_	_
the	_	_
ASPP	_	_
branches	_	_
due	_	_
to	_	_
the	_	_
low	_	_
number	_	_
of	_	_
samples	_	_
available	_	_
.	_	_

#66
3	_	_
.	_	_

#67
Methods	_	_
The	_	_
low	_	_
number	_	_
of	_	_
samples	_	_
in	_	_
the	_	_
ADIR	_	_
dataset	_	_
,	_	_
their	_	_
variability	_	_
and	_	_
the	_	_
large	_	_
number	_	_
of	_	_
classes	_	_
to	_	_
be	_	_
segmented	_	_
led	_	_
to	_	_
a	_	_
set	_	_
of	_	_
carefully	_	_
designed	_	_
choices	_	_
in	_	_
the	_	_
network	_	_
architecture	_	_
.	_	_

#68
The	_	_
underlying	_	_
driving	_	_
force	_	_
when	_	_
designing	_	_
the	_	_
network	_	_
was	_	_
to	_	_
use	_	_
cost-effective	_	_
convolutional	_	_
blocks	_	_
in	_	_
terms	_	_
of	_	_
number	_	_
of	_	_
parameters	_	_
and	_	_
performance	_	_
.	_	_

#69
Thus	_	_
we	_	_
have	_	_
designed	_	_
a	_	_
network	_	_
which	_	_
is	_	_
relatively	_	_
shallow	_	_
when	_	_
compared	_	_
to	_	_
deeper	_	_
ones	_	_
such	_	_
as	_	_
ResNet	_	_
(	_	_
He	_	_
et	_	_
al.	_	_
,	_	_
2016	_	_
)	_	_
or	_	_
Inception	_	_
(	_	_
Szegedy	_	_
et	_	_
al.	_	_
,	_	_
2015	_	_
)	_	_
,	_	_
but	_	_
nonetheless	_	_
achieves	_	_
high	_	_
CCR	_	_
in	_	_
the	_	_
segmentation	_	_
of	_	_
mFISH	_	_
samples	_	_
.	_	_

#70
This	_	_
section	_	_
presents	_	_
the	_	_
main	_	_
blocks	_	_
of	_	_
the	_	_
network	_	_
,	_	_
and	_	_
describes	_	_
the	_	_
training	_	_
procedure	_	_
.	_	_

#71
An	_	_
overview	_	_
of	_	_
the	_	_
network	_	_
architecture	_	_
is	_	_
illustrated	_	_
in	_	_
figure	_	_
1	_	_
.	_	_

#72
3.1	_	_
.	_	_

#73
Convolutional	_	_
block	_	_
Convolutional	_	_
networks	_	_
are	_	_
usually	_	_
comprised	_	_
of	_	_
different	_	_
blocks	_	_
that	_	_
encapsulate	_	_
a	_	_
specific	_	_
behavior	_	_
.	_	_

#74
The	_	_
VGG	_	_
network	_	_
(	_	_
Simonyan	_	_
and	_	_
Zisserman	_	_
,	_	_
2014	_	_
)	_	_
uses	_	_
a	_	_
basic	_	_
block	_	_
in	_	_
which	_	_
2	_	_
or	_	_
more	_	_
convolutions	_	_
with	_	_
3x3	_	_
kernels	_	_
are	_	_
followed	_	_
by	_	_
a	_	_
pooling	_	_
operation	_	_
,	_	_
the	_	_
idea	_	_
behind	_	_
this	_	_
block	_	_
is	_	_
that	_	_
a	_	_
stack	_	_
of	_	_
two	_	_
or	_	_
more	_	_
3x3	_	_
convolutional	_	_
layers	_	_
,	_	_
without	_	_
spatial	_	_
pooling	_	_
between	_	_
them	_	_
,	_	_
emulates	_	_
a	_	_
larger	_	_
receptive	_	_
field	_	_
with	_	_
a	_	_
smaller	_	_
number	_	_
of	_	_
parameters	_	_
;	_	_
as	_	_
an	_	_
example	_	_
,	_	_
two	_	_
1-channel	_	_
3x3	_	_
convolutional	_	_
layers	_	_
have	_	_
9	_	_
parameters	_	_
and	_	_
an	_	_
effective	_	_
receptive	_	_
field	_	_
of	_	_
5x5	_	_
,	_	_
whereas	_	_
a	_	_
1-channel	_	_
5x5	_	_
convolutional	_	_
layer	_	_
has	_	_
25	_	_
parameters	_	_
for	_	_
the	_	_
same	_	_
receptive	_	_
field	_	_
.	_	_

#75
Since	_	_
the	_	_
creation	_	_
of	_	_
VGG	_	_
,	_	_
deeper	_	_
networks	_	_
such	_	_
as	_	_
Inception	_	_
(	_	_
Szegedy	_	_
et	_	_
al.	_	_
,	_	_
2015	_	_
)	_	_
and	_	_
ResNet	_	_
(	_	_
He	_	_
et	_	_
al.	_	_
,	_	_
2016	_	_
)	_	_
have	_	_
been	_	_
developed	_	_
.	_	_

#76
These	_	_
networks	_	_
are	_	_
usually	_	_
trained	_	_
on	_	_
datasets	_	_
containing	_	_
thousands	_	_
of	_	_
images	_	_
and	_	_
are	_	_
designed	_	_
to	_	_
account	_	_
for	_	_
the	_	_
large	_	_
variability	_	_
present	_	_
on	_	_
those	_	_
datasets	_	_
.	_	_

#77
Specifically	_	_
,	_	_
the	_	_
main	_	_
idea	_	_
behind	_	_
Inception	_	_
is	_	_
to	_	_
use	_	_
dense	_	_
components	_	_
to	_	_
approximate	_	_
the	_	_
local	_	_
sparse	_	_
structure	_	_
usually	_	_
found	_	_
in	_	_
convolutional	_	_
networks	_	_
.	_	_

#78
That	_	_
is	_	_
,	_	_
to	_	_
cover	_	_
local	_	_
activation	_	_
clusters	_	_
using	_	_
1x1	_	_
convolutions	_	_
and	_	_
more	_	_
spatially	_	_
spread	_	_
activation	_	_
clusters	_	_
using	_	_
larger	_	_
3x3	_	_
and	_	_
5x5	_	_
convolutions	_	_
.	_	_

#79
On	_	_
the	_	_
other	_	_
hand	_	_
,	_	_
ResNet	_	_
blocks	_	_
introduce	_	_
shortcut	_	_
connections	_	_
to	_	_
ease	_	_
the	_	_
training	_	_
of	_	_
deep	_	_
networks	_	_
.	_	_

#80
Because	_	_
the	_	_
deepest	_	_
layers	_	_
of	_	_
a	_	_
network	_	_
introduce	_	_
small	_	_
changes	_	_
to	_	_
the	_	_
features	_	_
,	_	_
residual	_	_
learning	_	_
is	_	_
better	_	_
preconditioned	_	_
than	_	_
standard	_	_
learning	_	_
.	_	_

#81
Despite	_	_
this	_	_
progress	_	_
in	_	_
convolutional	_	_
networks	_	_
,	_	_
the	_	_
relatively	_	_
small	_	_
size	_	_
of	_	_
the	_	_
ADIR	_	_
dataset	_	_
makes	_	_
these	_	_
blocks	_	_
unfit	_	_
for	_	_
the	_	_
semantic	_	_
segmentation	_	_
of	_	_
mFISH	_	_
images	_	_
.	_	_

#82
Because	_	_
the	_	_
goal	_	_
of	_	_
this	_	_
work	_	_
is	_	_
to	_	_
build	_	_
a	_	_
cost	_	_
effective	_	_
convolutional	_	_
network	_	_
for	_	_
the	_	_
segmentation	_	_
of	_	_
mFISH	_	_
images	_	_
,	_	_
a	_	_
VGG-like	_	_
layout	_	_
was	_	_
used	_	_
in	_	_
the	_	_
first	_	_
section	_	_
of	_	_
the	_	_
architecture	_	_
.	_	_

#83
The	_	_
first	_	_
4	_	_
blocks	_	_
in	_	_
figure	_	_
1	_	_
are	_	_
comprised	_	_
of	_	_
2	_	_
pairs	_	_
of	_	_
3x3	_	_
convolutions	_	_
followed	_	_
by	_	_
max	_	_
pooling	_	_
operations	_	_
.	_	_

#84
This	_	_
layout	_	_
resembles	_	_
the	_	_
combination	_	_
of	_	_
small	_	_
3x3	_	_
kernels	_	_
and	_	_
downsampling	_	_
operations	_	_
used	_	_
in	_	_
the	_	_
VGG	_	_
network	_	_
and	_	_
its	_	_
goal	_	_
is	_	_
to	_	_
create	_	_
an	_	_
initial	_	_
set	_	_
of	_	_
high	_	_
level	_	_
features	_	_
that	_	_
will	_	_
be	_	_
later	_	_
refined	_	_
by	_	_
using	_	_
dilated	_	_
convolutions	_	_
to	_	_
aggregate	_	_
contextual	_	_
information	_	_
.	_	_

#85
3.2	_	_
.	_	_

#86
Dilated	_	_
convolution	_	_
Atrous	_	_
or	_	_
dilated	_	_
convolution	_	_
(	_	_
Yu	_	_
and	_	_
Koltun	_	_
,	_	_
2015	_	_
;	_	_
Chen	_	_
et	_	_
al.	_	_
,	_	_
2016	_	_
,	_	_
2017	_	_
)	_	_
is	_	_
an	_	_
efficient	_	_
way	_	_
of	_	_
aggregating	_	_
multiscale	_	_
contextual	_	_
information	_	_
by	_	_
explicitly	_	_
adjusting	_	_
the	_	_
rate	_	_
at	_	_
which	_	_
the	_	_
input	_	_
signal	_	_
is	_	_
sampled	_	_
or	_	_
,	_	_
in	_	_
an	_	_
equivalent	_	_
view	_	_
,	_	_
the	_	_
rate	_	_
at	_	_
which	_	_
the	_	_
filters	_	_
are	_	_
upsampled	_	_
.	_	_

#87
Specifically	_	_
,	_	_
this	_	_
operator	_	_
is	_	_
a	_	_
generalization	_	_
of	_	_
the	_	_
standard	_	_
convolution	_	_
where	_	_
the	_	_
value	_	_
of	_	_
the	_	_
dilated	_	_
convolution	_	_
between	_	_
signal	_	_
f	_	_
and	_	_
filter	_	_
k	_	_
,	_	_
with	_	_
dilation	_	_
rate	_	_
l	_	_
,	_	_
is	_	_
computed	_	_
following	_	_
equation	_	_
1	_	_
.	_	_

#88
(	_	_
f	_	_
∗l	_	_
k	_	_
)	_	_
(	_	_
x	_	_
)	_	_
=	_	_
∞∑	_	_
m=−∞	_	_
f	_	_
(	_	_
m	_	_
)	_	_
k	_	_
(	_	_
x−	_	_
lm	_	_
)	_	_
(	_	_
1	_	_
)	_	_
By	_	_
tuning	_	_
the	_	_
dilation	_	_
rate	_	_
,	_	_
the	_	_
network	_	_
can	_	_
probe	_	_
image	_	_
features	_	_
at	_	_
large	_	_
receptive	_	_
fields	_	_
.	_	_

#89
This	_	_
enables	_	_
the	_	_
network	_	_
to	_	_
include	_	_
long	_	_
range	_	_
context	_	_
information	_	_
with	_	_
a	_	_
more	_	_
limited	_	_
cost	_	_
than	_	_
using	_	_
successive	_	_
convolution	_	_
and	_	_
pooling	_	_
operations	_	_
.	_	_

#90
On	_	_
the	_	_
other	_	_
hand	_	_
,	_	_
it	_	_
is	_	_
easy	_	_
to	_	_
see	_	_
that	_	_
equation	_	_
1	_	_
with	_	_
a	_	_
dilation	_	_
rate	_	_
l	_	_
of	_	_
1	_	_
is	_	_
equivalent	_	_
to	_	_
a	_	_
standard	_	_
discrete	_	_
convolution	_	_
.	_	_

#91
When	_	_
comparing	_	_
dilated	_	_
convolution	_	_
to	_	_
the	_	_
way	_	_
U-Net	_	_
style	_	_
networks	_	_
aggregate	_	_
context	_	_
information	_	_
,	_	_
one	_	_
drawback	_	_
of	_	_
U-Net	_	_
style	_	_
architectures	_	_
is	_	_
that	_	_
the	_	_
context	_	_
information	_	_
is	_	_
captured	_	_
using	_	_
downsampling	_	_
operations	_	_
.	_	_

#92
Pooling	_	_
operations	_	_
are	_	_
useful	_	_
to	_	_
build	_	_
high	_	_
level	_	_
features	_	_
at	_	_
the	_	_
expense	_	_
of	_	_
losing	_	_
resolution	_	_
.	_	_

#93
This	_	_
is	_	_
very	_	_
convenient	_	_
for	_	_
the	_	_
classification	_	_
task	_	_
since	_	_
no	_	_
location	_	_
information	_	_
needs	_	_
to	_	_
be	_	_
preserved	_	_
.	_	_

#94
On	_	_
the	_	_
contrary	_	_
,	_	_
semantic	_	_
segmentation	_	_
performs	_	_
a	_	_
pixel	_	_
wise	_	_
classification	_	_
,	_	_
meaning	_	_
that	_	_
spatial	_	_
information	_	_
needs	_	_
to	_	_
be	_	_
preserved	_	_
however	_	_
,	_	_
the	_	_
spatial	_	_
information	_	_
lost	_	_
on	_	_
the	_	_
downsampling	_	_
path	_	_
is	_	_
recovered	_	_
by	_	_
complex	_	_
upsampling	_	_
operations	_	_
involving	_	_
transpose	_	_
convolutions	_	_
,	_	_
and	_	_
regular	_	_
convolutions	_	_
.	_	_

#95
The	_	_
upsampling	_	_
path	_	_
may	_	_
be	_	_
avoided	_	_
if	_	_
contextual	_	_
information	_	_
is	_	_
captured	_	_
using	_	_
modules	_	_
that	_	_
do	_	_
not	_	_
downsample	_	_
the	_	_
feature	_	_
maps	_	_
.	_	_

#96
This	_	_
is	_	_
where	_	_
dilated	_	_
convolutions	_	_
come	_	_
into	_	_
play	_	_
.	_	_

#97
The	_	_
proposed	_	_
architecture	_	_
introduces	_	_
dilated	_	_
convolutions	_	_
after	_	_
the	_	_
second	_	_
down-sampling	_	_
operation	_	_
.	_	_

#98
For	_	_
the	_	_
problem	_	_
of	_	_
mFISH	_	_
semantic	_	_
segmentation	_	_
,	_	_
we	_	_
found	_	_
that	_	_
building	_	_
a	_	_
first	_	_
level	_	_
of	_	_
abstract	_	_
features	_	_
using	_	_
two	_	_
downsampling	_	_
operations	_	_
,	_	_
works	_	_
better	_	_
than	_	_
using	_	_
a	_	_
deeper	_	_
first	_	_
stage	_	_
with	_	_
more	_	_
downsampling	_	_
operations	_	_
or	_	_
a	_	_
shallower	_	_
one	_	_
with	_	_
fewer	_	_
ones	_	_
.	_	_

#99
3.3	_	_
.	_	_

#100
Atrous	_	_
spatial	_	_
pyramid	_	_
pooling	_	_
Spatial	_	_
pyramid	_	_
pooling	_	_
(	_	_
He	_	_
et	_	_
al.	_	_
,	_	_
2014	_	_
)	_	_
was	_	_
designed	_	_
to	_	_
overcome	_	_
the	_	_
problem	_	_
of	_	_
analyzing	_	_
information	_	_
at	_	_
different	_	_
scales	_	_
,	_	_
sizes	_	_
,	_	_
and	_	_
aspect	_	_
ratios	_	_
.	_	_

#101
The	_	_
module	_	_
pools	_	_
image	_	_
features	_	_
at	_	_
different	_	_
scales	_	_
to	_	_
build	_	_
a	_	_
fixed	_	_
size	_	_
feature	_	_
vector	_	_
.	_	_

#102
This	_	_
enables	_	_
the	_	_
classification	_	_
of	_	_
arbitrary	_	_
sized	_	_
images	_	_
,	_	_
and	_	_
also	_	_
improves	_	_
the	_	_
performance	_	_
for	_	_
objects	_	_
undergoing	_	_
deformations	_	_
or	_	_
scale	_	_
transformations	_	_
.	_	_

#103
The	_	_
successful	_	_
application	_	_
of	_	_
spatial	_	_
pyramid	_	_
pooling	_	_
in	_	_
image	_	_
classification	_	_
and	_	_
object	_	_
detection	_	_
led	_	_
to	_	_
the	_	_
development	_	_
of	_	_
atrous	_	_
spatial	_	_
pyramid	_	_
pooling	_	_
(	_	_
Chen	_	_
et	_	_
al.	_	_
,	_	_
2016	_	_
,	_	_
2017	_	_
)	_	_
.	_	_

#104
This	_	_
new	_	_
module	_	_
applies	_	_
some	_	_
of	_	_
the	_	_
core	_	_
ideas	_	_
of	_	_
spatial	_	_
pyramid	_	_
pooling	_	_
to	_	_
the	_	_
field	_	_
of	_	_
image	_	_
segmentation	_	_
,	_	_
dilated	_	_
convolutions	_	_
are	_	_
used	_	_
to	_	_
capture	_	_
information	_	_
at	_	_
different	_	_
resolutions	_	_
,	_	_
1x1	_	_
convolutions	_	_
express	_	_
the	_	_
degenerate	_	_
case	_	_
of	_	_
dilated	_	_
convolutions	_	_
where	_	_
only	_	_
the	_	_
center	_	_
weight	_	_
is	_	_
active	_	_
,	_	_
and	_	_
global	_	_
average	_	_
pooling	_	_
is	_	_
used	_	_
to	_	_
capture	_	_
image	_	_
features	_	_
.	_	_

#105
In	_	_
this	_	_
work	_	_
,	_	_
the	_	_
atrous	_	_
spatial	_	_
pyramid	_	_
pooling	_	_
module	_	_
is	_	_
introduced	_	_
after	_	_
the	_	_
second	_	_
max	_	_
pooling	_	_
operation	_	_
.	_	_

#106
This	_	_
module	_	_
performs	_	_
a	_	_
resolution	_	_
wise	_	_
analysis	_	_
of	_	_
the	_	_
initial	_	_
set	_	_
of	_	_
low	_	_
level	_	_
features	_	_
,	_	_
aggregating	_	_
spatial	_	_
information	_	_
to	_	_
improve	_	_
the	_	_
initial	_	_
spectral	_	_
analysis	_	_
.	_	_

#107
3.4.	_	_
Training	_	_

#108
In	_	_
order	_	_
to	_	_
train	_	_
the	_	_
network	_	_
,	_	_
a	_	_
set	_	_
of	_	_
guidelines	_	_
must	deontic	_
be	_	_
followed	_	_
to	_	_
fully	_	_
reproduce	_	_
our	_	_
work	_	_
.	_	_

#109
This	_	_
section	_	_
presents	_	_
the	_	_
key	_	_
points	_	_
of	_	_
our	_	_
training	_	_
protocol	_	_
.	_	_

#110
Loss	_	_
function	_	_
:	_	_
The	_	_
training	_	_
is	_	_
performed	_	_
in	_	_
an	_	_
end-to-end	_	_
fashion	_	_
,	_	_
where	_	_
a	_	_
batch	_	_
of	_	_
6	_	_
channel	_	_
images	_	_
is	_	_
fed	_	_
into	_	_
the	_	_
system	_	_
and	_	_
the	_	_
network	_	_
outputs	_	_
a	_	_
batch	_	_
of	_	_
24	_	_
channel	_	_
images	_	_
representing	_	_
the	_	_
class	_	_
likelihood	_	_
for	_	_
each	_	_
pixel	_	_
.	_	_

#111
The	_	_
output	_	_
of	_	_
the	_	_
network	_	_
is	_	_
converted	_	_
into	_	_
a	_	_
categorical	_	_
distribution	_	_
using	_	_
the	_	_
softmax	_	_
function	_	_
2	_	_
,	_	_
where	_	_
Sc	_	_
(	_	_
x	_	_
)	_	_
denotes	_	_
the	_	_
softmax	_	_
value	_	_
of	_	_
class	_	_
c	_	_
at	_	_
pixel	_	_
x	_	_
,	_	_
f	_	_
(	_	_
x	_	_
)	_	_
c	_	_
is	_	_
the	_	_
value	_	_
of	_	_
the	_	_
feature	_	_
in	_	_
the	_	_
pixel	_	_
x	_	_
and	_	_
channel	_	_
c	_	_
,	_	_
and	_	_
C	_	_
represents	_	_
the	_	_
number	_	_
of	_	_
channels	_	_
or	_	_
classes	_	_
.	_	_

#112
Finally	_	_
,	_	_
this	_	_
categorical	_	_
distribution	_	_
is	_	_
compared	_	_
to	_	_
the	_	_
ground	_	_
truth	_	_
using	_	_
the	_	_
cross	_	_
entropy	_	_
loss	_	_
function	_	_
3	_	_
,	_	_
where	_	_
p	_	_
(	_	_
x	_	_
)	_	_
denotes	_	_
the	_	_
ground	_	_
truth	_	_
class	_	_
distribution	_	_
at	_	_
pixel	_	_
x	_	_
and	_	_
q	_	_
(	_	_
x	_	_
)	_	_
is	_	_
the	_	_
predicted	_	_
distribution	_	_
.	_	_

#113
To	_	_
compare	_	_
the	_	_
predictions	_	_
to	_	_
the	_	_
ground	_	_
truth	_	_
,	_	_
either	_	_
the	_	_
ground	_	_
truth	_	_
has	_	_
to	_	_
be	_	_
scaled	_	_
to	_	_
the	_	_
size	_	_
of	_	_
the	_	_
logits	_	_
(	_	_
Chen	_	_
et	_	_
al.	_	_
,	_	_
2016	_	_
)	_	_
,	_	_
or	_	_
the	_	_
predictions	_	_
need	_	_
to	_	_
be	_	_
scaled	_	_
to	_	_
the	_	_
size	_	_
of	_	_
the	_	_
ground	_	_
truth	_	_
(	_	_
Chen	_	_
et	_	_
al.	_	_
,	_	_
2017	_	_
)	_	_
;	_	_
scaling	_	_
the	_	_
ground	_	_
truth	_	_
would	_	_
remove	_	_
part	_	_
of	_	_
the	_	_
information	_	_
used	_	_
in	_	_
training	_	_
,	_	_
so	_	_
the	_	_
second	_	_
option	_	_
was	_	_
chosen	_	_
.	_	_

#114
Besides	_	_
,	_	_
the	_	_
ground	_	_
truth	_	_
presents	_	_
additional	_	_
labels	_	_
for	_	_
background	_	_
and	_	_
overlapping	_	_
chromosomes	_	_
,	_	_
however	_	_
,	_	_
these	_	_
are	_	_
not	_	_
usually	_	_
taken	_	_
into	_	_
account	_	_
when	_	_
training	_	_
and	_	_
calculating	_	_
the	_	_
CCR	_	_
(	_	_
Wang	_	_
et	_	_
al.	_	_
,	_	_
2017	_	_
)	_	_
,	_	_
because	_	_
of	_	_
that	_	_
,	_	_
after	_	_
creating	_	_
the	_	_
one	_	_
hot	_	_
encoded	_	_
labels	_	_
the	_	_
image	_	_
slices	_	_
representing	_	_
the	_	_
background	_	_
and	_	_
overlapping	_	_
labels	_	_
are	_	_
removed	_	_
,	_	_
this	_	_
guarantees	_	_
that	_	_
the	_	_
background	_	_
and	_	_
overlapping	_	_
pixels	_	_
are	_	_
not	_	_
taken	_	_
into	_	_
account	_	_
during	_	_
the	_	_
training	_	_
process	_	_
.	_	_

#115
Sc	_	_
(	_	_
x	_	_
)	_	_
=	_	_
ef	_	_
(	_	_
x	_	_
)	_	_
c	_	_
∑C	_	_
i=1	_	_
e	_	_
f	_	_
(	_	_
x	_	_
)	_	_
i	_	_
(	_	_
2	_	_
)	_	_
E	_	_
(	_	_
p	_	_
,	_	_
q	_	_
)	_	_
=	_	_
−	_	_
∑	_	_
x	_	_
p	_	_
(	_	_
x	_	_
)	_	_
log	_	_
(	_	_
q	_	_
(	_	_
x	_	_
)	_	_
)	_	_
(	_	_
3	_	_
)	_	_
Optimizer	_	_
:	_	_
The	_	_
Adam	_	_
algorithm	_	_
(	_	_
Kingma	_	_
and	_	_
Ba	_	_
,	_	_
2014	_	_
)	_	_
was	_	_
used	_	_
to	_	_
perform	_	_
optimization	_	_
.	_	_

#116
This	_	_
optimizer	_	_
was	_	_
designed	_	_
to	_	_
combine	_	_
the	_	_
benefits	_	_
of	_	_
AdaGrad	_	_
(	_	_
Duchi	_	_
et	_	_
al.	_	_
,	_	_
2011	_	_
)	_	_
,	_	_
which	_	_
works	_	_
well	_	_
with	_	_
sparse	_	_
gradients	_	_
usually	_	_
found	_	_
in	_	_
computer	_	_
vision	_	_
problems	_	_
,	_	_
and	_	_
RMSProp	_	_
(	_	_
Tieleman	_	_
and	_	_
Hinton	_	_
,	_	_
2012	_	_
)	_	_
which	_	_
works	_	_
well	_	_
in	_	_
on-line	_	_
and	_	_
non-stationary	_	_
settings	_	_
.	_	_

#117
The	_	_
method	_	_
computes	_	_
individual	_	_
adaptive	_	_
learning	_	_
rates	_	_
for	_	_
different	_	_
parameters	_	_
from	_	_
estimates	_	_
of	_	_
first	_	_
and	_	_
second	_	_
moments	_	_
of	_	_
the	_	_
gradients	_	_
,	_	_
and	_	_
it	_	_
has	_	_
been	_	_
shown	_	_
to	_	_
converge	_	_
faster	_	_
on	_	_
some	_	_
convolutional	_	_
network	_	_
architectures	_	_
.	_	_

#118
Batch	_	_
normalization	_	_
:	_	_
Batch	_	_
normalization	_	_
(	_	_
Ioffe	_	_
and	_	_
Szegedy	_	_
,	_	_
2015	_	_
)	_	_
is	_	_
used	_	_
to	_	_
regularize	_	_
the	_	_
features	_	_
in	_	_
the	_	_
intermediate	_	_
layers	_	_
.	_	_

#119
When	_	_
training	_	_
convolutional	_	_
networks	_	_
,	_	_
the	_	_
inputs	_	_
of	_	_
a	_	_
convolution	_	_
layer	_	_
have	_	_
different	_	_
distributions	_	_
in	_	_
each	_	_
iteration	_	_
.	_	_

#120
This	_	_
is	_	_
known	_	_
as	_	_
the	_	_
internal	_	_
covariate	_	_
shift	_	_
and	_	_
is	_	_
addressed	_	_
by	_	_
normalizing	_	_
the	_	_
inputs	_	_
of	_	_
a	_	_
layer	_	_
.	_	_

#121
This	_	_
form	_	_
of	_	_
regularization	_	_
improves	_	_
the	_	_
convergence	_	_
and	_	_
generalization	_	_
of	_	_
the	_	_
network	_	_
.	_	_

#122
Batch	_	_
normalization	_	_
works	_	_
optimally	_	_
when	_	_
batches	_	_
have	_	_
a	_	_
enough	_	_
number	_	_
of	_	_
samples	_	_
,	_	_
so	_	_
that	_	_
the	_	_
batch-wise	_	_
statistics	_	_
are	_	_
significant	_	_
.	_	_

#123
We	_	_
decided	_	_
to	_	_
use	_	_
a	_	_
batch	_	_
size	_	_
of	_	_
16	_	_
,	_	_
since	_	_
it	_	_
has	_	_
been	_	_
shown	_	_
to	_	_
be	_	_
sufficient	_	_
for	_	_
the	_	_
segmentation	_	_
network	_	_
proposed	_	_
in	_	_
(	_	_
Chen	_	_
et	_	_
al.	_	_
,	_	_
2017	_	_
)	_	_
.	_	_

#124
Dropout	_	_
:	_	_
Dropout	_	_
(	_	_
Srivastava	_	_
et	_	_
al.	_	_
,	_	_
2014	_	_
)	_	_
was	_	_
also	_	_
used	_	_
for	_	_
regularization	_	_
.	_	_

#125
This	_	_
technique	_	_
works	_	_
by	_	_
randomly	_	_
setting	_	_
to	_	_
0	_	_
a	_	_
fraction	_	_
of	_	_
the	_	_
units	_	_
in	_	_
a	_	_
layer	_	_
.	_	_

#126
While	_	_
it	_	_
has	_	_
been	_	_
widely	_	_
used	_	_
to	_	_
create	_	_
"	_	_
thinned	_	_
"	_	_
fully	_	_
connected	_	_
layers	_	_
when	_	_
training	_	_
classification	_	_
networks	_	_
(	_	_
Krizhevsky	_	_
et	_	_
al.	_	_
,	_	_
2012	_	_
;	_	_
Szegedy	_	_
et	_	_
al.	_	_
,	_	_
2015	_	_
)	_	_
,	_	_
it	_	_
has	_	_
also	_	_
been	_	_
used	_	_
successfully	_	_
in	_	_
segmentation	_	_
networks	_	_
(	_	_
Badrinarayanan	_	_
et	_	_
al.	_	_
,	_	_
2015	_	_
)	_	_
.	_	_

#127
In	_	_
this	_	_
work	_	_
,	_	_
we	_	_
introduced	_	_
a	_	_
dropout	_	_
layer	_	_
between	_	_
the	_	_
concatenation	_	_
of	_	_
ASPP	_	_
branches	_	_
and	_	_
the	_	_
final	_	_
1x1	_	_
convolution	_	_
,	_	_
this	_	_
forces	_	_
the	_	_
network	_	_
to	_	_
learn	_	_
more	_	_
significant	_	_
and	_	_
general	_	_
features	_	_
which	_	_
,	_	_
in	_	_
turn	_	_
,	_	_
improves	_	_
generalization	_	_
.	_	_

#128
Image	_	_
preprocessing	_	_
:	_	_
To	_	_
speed	_	_
up	_	_
the	_	_
process	_	_
of	_	_
training	_	_
and	_	_
enable	_	_
larger	_	_
batch	_	_
sizes	_	_
,	_	_
the	_	_
images	_	_
were	_	_
cropped	_	_
and	_	_
scaled	_	_
.	_	_

#129
First	_	_
,	_	_
all	_	_
samples	_	_
were	_	_
cropped	_	_
to	_	_
a	_	_
536x490	_	_
window	_	_
,	_	_
the	_	_
minimum	_	_
window	_	_
that	_	_
ensures	_	_
that	_	_
no	_	_
chromosome	_	_
information	_	_
is	_	_
left	_	_
outside	_	_
.	_	_

#130
The	_	_
resulting	_	_
images	_	_
were	_	_
then	_	_
downscaled	_	_
by	_	_
30	_	_
%	_	_
,	_	_
which	_	_
produces	_	_
images	_	_
of	_	_
375x343	_	_
pixels	_	_
.	_	_

#131
Data	_	_
augmentation	_	_
:	_	_
To	_	_
prevent	_	_
the	_	_
network	_	_
from	_	_
over	_	_
fitting	_	_
the	_	_
training	_	_
samples	_	_
we	_	_
have	_	_
used	_	_
data	_	_
augmentation	_	_
.	_	_

#132
This	_	_
is	_	_
an	_	_
essential	_	_
step	_	_
when	_	_
training	_	_
with	_	_
a	_	_
small	_	_
number	_	_
of	_	_
samples	_	_
since	_	_
it	_	_
increases	_	_
the	_	_
variance	_	_
of	_	_
the	_	_
data	_	_
used	_	_
to	_	_
train	_	_
the	_	_
network	_	_
.	_	_

#133
Training	_	_
samples	_	_
were	_	_
subjected	_	_
to	_	_
random	_	_
scaling	_	_
,	_	_
rotations	_	_
,	_	_
and	_	_
translations	_	_
,	_	_
which	_	_
are	_	_
some	_	_
of	_	_
the	_	_
main	_	_
types	_	_
of	_	_
deformations	_	_
that	_	_
can	_	_
be	_	_
observed	_	_
in	_	_
microscopic	_	_
images	_	_
,	_	_
and	_	_
the	_	_
resulting	_	_
images	_	_
were	_	_
added	_	_
to	_	_
the	_	_
training	_	_
set	_	_
.	_	_

#134
4	_	_
.	_	_

#135
Results	_	_
The	_	_
performance	_	_
of	_	_
the	_	_
network	_	_
is	_	_
reported	_	_
by	_	_
estimating	_	_
the	_	_
CCR	_	_
,	_	_
computed	_	_
using	_	_
equation	_	_
4	_	_
,	_	_
of	_	_
the	_	_
Vysis	_	_
samples	_	_
from	_	_
the	_	_
ADIR	_	_
dataset	_	_
,	_	_
using	_	_
leaveoneoutcrossvalidation	_	_
.	_	_

#136
The	_	_
test	_	_
was	_	_
designed	_	_
to	_	_
avoid	_	_
some	_	_
common	_	_
flaws	_	_
encountered	_	_
in	_	_
the	_	_
testing	_	_
of	_	_
mFISH	_	_
classification	_	_
algorithms	_	_
,	_	_
such	_	_
as	_	_
using	_	_
a	_	_
test	_	_
set	_	_
extracted	_	_
from	_	_
the	_	_
same	_	_
image	_	_
the	_	_
algorithm	_	_
was	_	_
trained	_	_
on	_	_
.	_	_

#137
In	_	_
the	_	_
following	_	_
sections	_	_
,	_	_
we	_	_
first	_	_
analyze	_	_
the	_	_
performance	_	_
of	_	_
some	_	_
state	_	_
of	_	_
the	_	_
art	_	_
methods	_	_
and	_	_
finally	_	_
report	_	_
the	_	_
CCR	_	_
achieved	_	_
by	_	_
our	_	_
method	_	_
.	_	_

#138
CCR	_	_
=	_	_
#	_	_
chromosome	_	_
pixels	_	_
correctly	_	_
classified	_	_
#	_	_
total	_	_
chromosome	_	_
pixels	_	_
(	_	_
4	_	_
)	_	_
4.1	_	_
.	_	_

#139
Performance	_	_
analysis	_	_
of	_	_
HOSVD	_	_
We	_	_
selected	_	_
the	_	_
HOSVD	_	_
algorithm	_	_
(	_	_
Wang	_	_
et	_	_
al.	_	_
,	_	_
2017	_	_
)	_	_
to	_	_
highlight	_	_
the	_	_
performance	_	_
drop	_	_
that	_	_
some	_	_
state	_	_
of	_	_
the	_	_
art	_	_
algorithms	_	_
undergo	_	_
when	_	_
trained	_	_
and	_	_
tested	_	_
on	_	_
different	_	_
images	_	_
.	_	_

#140
A	_	_
branch	_	_
of	_	_
mFISH	_	_
analysis	_	_
algorithms	_	_
including	_	_
HOSVD	_	_
(	_	_
Wang	_	_
et	_	_
al.	_	_
,	_	_
2017	_	_
;	_	_
Cao	_	_
et	_	_
al.	_	_
,	_	_
2012	_	_
)	_	_
are	_	_
designed	_	_
to	_	_
perform	_	_
analysis	_	_
on	_	_
the	_	_
same	_	_
image	_	_
used	_	_
for	_	_
training	_	_
.	_	_

#141
Specifically	_	_
,	_	_
HOSVD	_	_
works	_	_
by	_	_
first	_	_
selecting	_	_
30	_	_
random	_	_
patches	_	_
from	_	_
every	_	_
chromosome	_	_
type	_	_
in	_	_
a	_	_
image	_	_
,	_	_
these	_	_
patches	_	_
are	_	_
later	_	_
used	_	_
to	_	_
build	_	_
the	_	_
feature	_	_
vectors	_	_
needed	_	_
to	_	_
classify	_	_
the	_	_
rest	_	_
of	_	_
the	_	_
patches	_	_
in	_	_
the	_	_
same	_	_
image	_	_
.	_	_

#142
This	_	_
analysis	_	_
pipeline	_	_
turns	_	_
algorithms	_	_
into	_	_
semiautomatic	_	_
approaches	_	_
if	_	_
the	_	_
seed	_	_
points	_	_
are	_	_
manually	_	_
annotated	_	_
,	_	_
as	_	_
in	_	_
the	_	_
case	_	_
of	_	_
the	_	_
ADIR	_	_
dataset	_	_
.	_	_

#143
The	_	_
proposed	_	_
dataset	_	_
was	_	_
used	_	_
to	_	_
evaluate	_	_
HOSVD	_	_
by	_	_
testing	_	_
every	_	_
sample	_	_
using	_	_
each	_	_
sample	_	_
for	_	_
training	_	_
.	_	_

#144
Given	_	_
a	_	_
mFISH	_	_
sample	_	_
,	_	_
30	_	_
random	_	_
patches	_	_
for	_	_
each	_	_
chromosome	_	_
type	_	_
were	_	_
used	_	_
to	_	_
build	_	_
an	_	_
HOSVD	_	_
tensor	_	_
,	_	_
this	_	_
tensor	_	_
was	_	_
later	_	_
used	_	_
to	_	_
classify	_	_
not	_	_
only	_	_
the	_	_
rest	_	_
of	_	_
the	_	_
image	_	_
(	_	_
Wang	_	_
et	_	_
al.	_	_
,	_	_
2017	_	_
)	_	_
,	_	_
but	_	_
also	_	_
the	_	_
rest	_	_
of	_	_
the	_	_
dataset	_	_
.	_	_

#145
This	_	_
process	_	_
was	_	_
repeated	_	_
for	_	_
every	_	_
sample	_	_
in	_	_
the	_	_
dataset	_	_
,	_	_
and	_	_
the	_	_
CCR	_	_
was	_	_
computed	_	_
at	_	_
every	_	_
iteration	_	_
,	_	_
generating	_	_
the	_	_
matrix	_	_
illustrated	_	_
in	_	_
figure	_	_
2	_	_
.	_	_

#146
When	_	_
performing	_	_
training	_	_
and	_	_
testing	_	_
on	_	_
the	_	_
same	_	_
image	_	_
,	_	_
HOSVD	_	_
achieved	_	_
a	_	_
CCR	_	_
of	_	_
89.13	_	_
%	_	_
,	_	_
which	_	_
is	_	_
2.49	_	_
%	_	_
less	_	_
than	_	_
the	_	_
CCR	_	_
reported	_	_
in	_	_
the	_	_
original	_	_
work	_	_
.	_	_

#147
In	_	_
98.46	_	_
%	_	_
of	_	_
the	_	_
experiments	_	_
,	_	_
the	_	_
highest	_	_
CCR	_	_
was	_	_
achieved	_	_
when	_	_
performing	_	_
training	_	_
and	_	_
testing	_	_
on	_	_
the	_	_
same	_	_
image	_	_
.	_	_

#148
Only	_	_
once	_	_
did	_	_
HOSVD	_	_
achieve	_	_
a	_	_
higher	_	_
CCR	_	_
when	_	_
training	_	_
on	_	_
a	_	_
different	_	_
sample	_	_
to	_	_
the	_	_
one	_	_
being	_	_
tested	_	_
.	_	_

#149
When	_	_
excluding	_	_
the	_	_
sample	_	_
being	_	_
tested	_	_
from	_	_
the	_	_
training	_	_
set	_	_
,	_	_
the	_	_
highest	_	_
CCR	_	_
averaged	_	_
over	_	_
all	_	_
tested	_	_
samples	_	_
was	_	_
68.58	_	_
%	_	_
,	_	_
which	_	_
is	_	_
a	_	_
24.97	_	_
%	_	_
less	_	_
than	_	_
the	_	_
CCR	_	_
reported	_	_
in	_	_
the	_	_
original	_	_
work	_	_
.	_	_

#150
A	_	_
similar	_	_
performance	_	_
reduction	_	_
was	_	_
reported	_	_
in	_	_
(	_	_
Choi	_	_
et	_	_
al.	_	_
,	_	_
2008	_	_
)	_	_
for	_	_
a	_	_
different	_	_
classification	_	_
algorithm	_	_
.	_	_

#151
In	_	_
that	_	_
case	_	_
,	_	_
the	_	_
CCR	_	_
dropped	_	_
from	_	_
89.95	_	_
%	_	_
,	_	_
when	_	_
performing	_	_
self	_	_
training-testing	_	_
,	_	_
to	_	_
72.72	_	_
%	_	_
,	_	_
when	_	_
performing	_	_
training	_	_
and	_	_
testing	_	_
with	_	_
different	_	_
sets	_	_
.	_	_

#152
These	_	_
results	_	_
show	_	_
that	_	_
state	_	_
of	_	_
the	_	_
art	_	_
performance	_	_
is	_	_
around	_	_
70	_	_
%	_	_
for	_	_
the	_	_
analysis	_	_
of	_	_
unlabeled	_	_
mFISH	_	_
images	_	_
.	_	_

#153
0	_	_
10	_	_
20	_	_
30	_	_
40	_	_
50	_	_
60	_	_
Testing	_	_
sample	_	_
Tr	_	_
ai	_	_
ni	_	_
ng	_	_
sa	_	_
m	_	_
pl	_	_
e	_	_
CCR	_	_
matrix	_	_
Figure	_	_
2	_	_
:	_	_
HOSVD	_	_
error	_	_
matrix	_	_
.	_	_

#154
(	_	_
a	_	_
)	_	_
Aqua	_	_
channel	_	_
of	_	_
image	_	_
V1306XY	_	_
(	_	_
b	_	_
)	_	_
Far	_	_
red	_	_
channel	_	_
of	_	_
image	_	_
V1306XY	_	_
(	_	_
c	_	_
)	_	_
Green	_	_
channel	_	_
of	_	_
image	_	_
V1306XY	_	_
(	_	_
d	_	_
)	_	_
Red	_	_
channel	_	_
of	_	_
image	_	_
V1306XY	_	_
(	_	_
e	_	_
)	_	_
Gold	_	_
channel	_	_
of	_	_
image	_	_
V1306XY	_	_
(	_	_
f	_	_
)	_	_
DAPI	_	_
channel	_	_
of	_	_
image	_	_
V1306XY	_	_
Figure	_	_
3	_	_
:	_	_
Channels	_	_
of	_	_
V1306XY	_	_
.	_	_

#155
All	_	_
chromosomes	_	_
present	_	_
high	_	_
intensity	_	_
values	_	_
in	_	_
the	_	_
DAPI	_	_
channel	_	_
,	_	_
and	_	_
some	_	_
chromosomes	_	_
are	_	_
brighter	_	_
than	_	_
others	_	_
in	_	_
the	_	_
rest	_	_
of	_	_
the	_	_
channels	_	_
.	_	_

#156
4.2	_	_
.	_	_

#157
Results	_	_
of	_	_
semantic	_	_
segmentation	_	_
on	_	_
the	_	_
Vysis	_	_
subset	_	_
The	_	_
65	_	_
images	_	_
in	_	_
the	_	_
dataset	_	_
were	_	_
used	_	_
to	_	_
train	_	_
and	_	_
evaluate	_	_
the	_	_
proposed	_	_
architecture	_	_
using	_	_
leave	_	_
one	_	_
out	_	_
cross	_	_
validation	_	_
.	_	_

#158
To	_	_
estimate	_	_
the	_	_
CCR	_	_
,	_	_
the	_	_
model	_	_
(	_	_
a	_	_
)	_	_
Far	_	_
red	_	_
channel	_	_
of	_	_
image	_	_
V190442	_	_
(	_	_
b	_	_
)	_	_
Far	_	_
red	_	_
channel	_	_
of	_	_
image	_	_
V190542	_	_
Figure	_	_
4	_	_
:	_	_
The	_	_
far	_	_
red	_	_
channel	_	_
of	_	_
the	_	_
image	_	_
V190442	_	_
has	_	_
different	_	_
intensity	_	_
levels	_	_
than	_	_
other	_	_
images	_	_
from	_	_
the	_	_
dataset	_	_
.	_	_

#159
The	_	_
same	_	_
channel	_	_
extracted	_	_
form	_	_
image	_	_
V190542	_	_
is	_	_
shown	_	_
for	_	_
comparison	_	_
.	_	_

#160
was	_	_
trained	_	_
for	_	_
150	_	_
epochs	_	_
and	_	_
,	_	_
for	_	_
the	_	_
last	_	_
5	_	_
iterations	_	_
,	_	_
the	_	_
test	_	_
set	_	_
was	_	_
evaluated	_	_
,	_	_
the	_	_
final	_	_
CRR	_	_
estimate	_	_
for	_	_
the	_	_
test	_	_
set	_	_
is	_	_
calculated	_	_
by	_	_
averaging	_	_
these	_	_
CCR	_	_
values	_	_
.	_	_

#161
Following	_	_
this	_	_
methodology	_	_
,	_	_
the	_	_
proposed	_	_
method	_	_
achieved	_	_
a	_	_
CCR	_	_
of	_	_
87.41	_	_
%	_	_
.	_	_

#162
To	_	_
address	_	_
the	_	_
impact	_	_
of	_	_
the	_	_
removed	_	_
images	_	_
the	_	_
same	_	_
evaluation	_	_
procedure	_	_
was	_	_
carried	_	_
for	_	_
the	_	_
whole	_	_
Vysis	_	_
subset	_	_
,	_	_
in	_	_
this	_	_
test	_	_
the	_	_
network	_	_
achieved	_	_
a	_	_
CCR	_	_
of	_	_
83.91	_	_
%	_	_
.	_	_

#163
5	_	_
.	_	_

#164
Discussion	_	_
Our	_	_
tests	_	_
have	_	_
shown	_	_
that	_	_
HOSVD	_	_
underperforms	_	_
,	_	_
similarly	_	_
to	_	_
prior	_	_
work	_	_
,	_	_
when	_	_
analyzing	_	_
unlabeled	_	_
samples	_	_
.	_	_

#165
Although	_	_
the	_	_
common	_	_
approach	_	_
in	_	_
machine	_	_
learning	_	_
research	_	_
is	_	_
to	_	_
build	_	_
feature	_	_
vectors	_	_
using	_	_
images	_	_
other	_	_
than	_	_
the	_	_
one	_	_
being	_	_
analyzed	_	_
,	_	_
this	_	_
procedure	_	_
seems	_	_
to	_	_
reduce	_	_
the	_	_
performance	_	_
of	_	_
state	_	_
of	_	_
the	_	_
art	_	_
algorithms	_	_
when	_	_
compared	_	_
to	_	_
the	_	_
results	_	_
achieved	_	_
while	_	_
training	_	_
and	_	_
testing	_	_
on	_	_
the	_	_
same	_	_
image	_	_
.	_	_

#166
Comparing	_	_
the	_	_
results	_	_
achieved	_	_
by	_	_
HOSVD	_	_
when	_	_
performing	_	_
classification	_	_
and	_	_
training	_	_
on	_	_
the	_	_
same	_	_
image	_	_
to	_	_
the	_	_
results	_	_
achieved	_	_
by	_	_
our	_	_
approach	_	_
suggests	_	_
that	_	_
,	_	_
for	_	_
the	_	_
ADIR	_	_
dataset	_	_
,	_	_
using	_	_
HOSVD	_	_
may	_	_
be	_	_
more	_	_
robust	_	_
to	_	_
exposure	_	_
variability	_	_
across	_	_
images	_	_
.	_	_

#167
However	_	_
,	_	_
given	_	_
that	_	_
our	_	_
method	_	_
significantly	_	_
outperforms	_	_
state	_	_
of	_	_
the	_	_
art	_	_
algorithms	_	_
on	_	_
unlabeled	_	_
samples	_	_
,	_	_
one	_	_
can	_	_
expect	_	_
that	_	_
end	_	_
to	_	_
end	_	_
segmentation	_	_
using	_	_
convolutional	_	_
networks	_	_
will	_	_
completely	_	_
outperform	_	_
algorithms	_	_
that	_	_
perform	_	_
training	_	_
and	_	_
analysis	_	_
on	_	_
the	_	_
same	_	_
image	_	_
.	_	_

#168
For	_	_
the	_	_
sample	_	_
shown	_	_
in	_	_
figure	_	_
5	_	_
,	_	_
despite	_	_
the	_	_
presence	_	_
of	_	_
speckle	_	_
noise	_	_
,	_	_
the	_	_
proposed	_	_
networks	_	_
achieves	_	_
a	_	_
CCR	_	_
of	_	_
99	_	_
%	_	_
while	_	_
HOSVD	_	_
achieves	_	_
a	_	_
lower	_	_
score	_	_
of	_	_
90	_	_
%	_	_
.	_	_

#169
This	_	_
result	_	_
may	_	_
also	_	_
suggest	_	_
that	_	_
,	_	_
while	_	_
our	_	_
method	_	_
is	_	_
more	_	_
susceptible	_	_
to	_	_
overall	_	_
changes	_	_
in	_	_
the	_	_
sample	_	_
intensity	_	_
levels	_	_
than	_	_
HOSVD	_	_
,	_	_
it	_	_
is	_	_
more	_	_
robust	_	_
to	_	_
image	_	_
noise	_	_
and	_	_
will	_	_
achieve	_	_
optimum	_	_
results	_	_
on	_	_
larger	_	_
and	_	_
carefully	_	_
acquired	_	_
datasets	_	_
.	_	_

#170
The	_	_
results	_	_
also	_	_
suggest	_	_
that	_	_
end	_	_
to	_	_
end	_	_
convolutional	_	_
networks	_	_
exploit	_	_
a	_	_
richer	_	_
set	_	_
of	_	_
features	_	_
than	_	_
previous	_	_
algorithms	_	_
.	_	_

#171
The	_	_
analysis	_	_
of	_	_
both	_	_
spectral	_	_
and	_	_
spatial	_	_
features	_	_
leads	_	_
to	_	_
a	_	_
CCR	_	_
increase	_	_
of	_	_
at	_	_
least	_	_
20	_	_
%	_	_
when	_	_
compared	_	_
to	_	_
previous	_	_
algorithms	_	_
in	_	_
the	_	_
unlabeled	_	_
image	_	_
scenario	_	_
,	_	_
and	_	_
a	_	_
CCR	_	_
drop	_	_
smaller	_	_
than	_	_
3	_	_
%	_	_
when	_	_
compared	_	_
to	_	_
HOSVD	_	_
analysis	_	_
with	_	_
prior	_	_
labeling	_	_
information	_	_
.	_	_

#172
(	_	_
a	_	_
)	_	_
Far	_	_
Red	_	_
channel	_	_
of	_	_
V2704XY	_	_
.	_	_

#173
0	_	_
100	_	_
200	_	_
300	_	_
400	_	_
(	_	_
b	_	_
)	_	_
Ground	_	_
truth	_	_
0	_	_
100	_	_
200	_	_
300	_	_
400	_	_
(	_	_
c	_	_
)	_	_
Prediction	_	_
Figure	_	_
5	_	_
:	_	_
The	_	_
proposed	_	_
network	_	_
was	_	_
applied	_	_
to	_	_
the	_	_
sample	_	_
V2704XY	_	_
after	_	_
being	_	_
trained	_	_
using	_	_
the	_	_
rest	_	_
of	_	_
the	_	_
working	_	_
dataset	_	_
.	_	_

#174
The	_	_
method	_	_
achieved	_	_
a	_	_
CCR	_	_
of	_	_
99	_	_
%	_	_
.	_	_

#175
6	_	_
.	_	_

#176
Conclusion	_	_
In	_	_
this	_	_
work	_	_
,	_	_
we	_	_
proposed	_	_
a	_	_
convolutional	_	_
network	_	_
architecture	_	_
for	_	_
the	_	_
semantic	_	_
segmentation	_	_
of	_	_
mFISH	_	_
images	_	_
.	_	_

#177
The	_	_
architecture	_	_
shares	_	_
some	_	_
of	_	_
the	_	_
foundations	_	_
of	_	_
VGG	_	_
(	_	_
Simonyan	_	_
and	_	_
Zisserman	_	_
,	_	_
2014	_	_
)	_	_
,	_	_
spatial	_	_
piramid	_	_
pooling	_	_
networks	_	_
(	_	_
He	_	_
et	_	_
al.	_	_
,	_	_
2014	_	_
)	_	_
,	_	_
dilated	_	_
convolution	_	_
networks	_	_
(	_	_
Yu	_	_
and	_	_
Koltun	_	_
,	_	_
2015	_	_
)	_	_
,	_	_
and	_	_
the	_	_
DeepLab	_	_
architecture	_	_
(	_	_
Chen	_	_
et	_	_
al.	_	_
,	_	_
2017	_	_
)	_	_
while	_	_
adapting	_	_
them	_	_
to	_	_
the	_	_
field	_	_
of	_	_
mFISH	_	_
semantic	_	_
segmentation	_	_
.	_	_

#178
VGG	_	_
blocks	_	_
build	_	_
an	_	_
initial	_	_
set	_	_
of	_	_
low	_	_
level	_	_
features	_	_
,	_	_
and	_	_
dilated	_	_
convolutions	_	_
further	_	_
refine	_	_
them	_	_
following	_	_
a	_	_
multi	_	_
resolution	_	_
strategy	_	_
,	_	_
a	_	_
pyramid	_	_
pooling	_	_
layout	_	_
is	_	_
used	_	_
used	_	_
to	_	_
capture	_	_
context	_	_
at	_	_
several	_	_
ranges	_	_
and	_	_
the	_	_
information	_	_
is	_	_
combined	_	_
using	_	_
a	_	_
concatenation	_	_
+	_	_
dropout	_	_
strategy	_	_
.	_	_

#179
The	_	_
final	_	_
feature	_	_
set	_	_
is	_	_
upsampled	_	_
using	_	_
bilineal	_	_
interpolation	_	_
resulting	_	_
in	_	_
the	_	_
final	_	_
segmentation	_	_
map	_	_
.	_	_

#180
Our	_	_
experimental	_	_
results	_	_
show	_	_
that	_	_
the	_	_
proposed	_	_
algorithm	_	_
achieves	_	_
state	_	_
of	_	_
the	_	_
art	_	_
CCR	_	_
for	_	_
the	_	_
analysis	_	_
of	_	_
unlabeled	_	_
images	_	_
.	_	_

#181
Our	_	_
end	_	_
to	_	_
end	_	_
architecture	_	_
scored	_	_
a	_	_
CCR	_	_
of	_	_
87.41	_	_
%	_	_
in	_	_
the	_	_
Vysis	_	_
subset	_	_
of	_	_
the	_	_
ADIR	_	_
dataset	_	_
,	_	_
which	_	_
is	_	_
a	_	_
27	_	_
%	_	_
better	_	_
than	_	_
HOSVD	_	_
results	_	_
when	_	_
classifying	_	_
images	_	_
that	_	_
were	_	_
not	_	_
used	_	_
in	_	_
training	_	_
time	_	_
,	_	_
and	_	_
a	_	_
20	_	_
%	_	_
better	_	_
than	_	_
the	_	_
results	_	_
reported	_	_
in	_	_
(	_	_
Choi	_	_
et	_	_
al.	_	_
,	_	_
2008	_	_
)	_	_
when	_	_
using	_	_
a	_	_
subset	_	_
of	_	_
the	_	_
testing	_	_
image	_	_
set	_	_
for	_	_
training	_	_
.	_	_

#182
These	_	_
results	_	_
underline	_	_
the	_	_
importance	_	_
of	_	_
using	_	_
end	_	_
to	_	_
end	_	_
architectures	_	_
to	_	_
further	_	_
exploit	_	_
spatial	_	_
information	_	_
while	_	_
leveraging	_	_
the	_	_
rich	_	_
spectral	_	_
information	_	_
available	_	_
when	_	_
training	_	_
on	_	_
multiple	_	_
images	_	_
.	_	_

#183
Finally	_	_
,	_	_
the	_	_
number	_	_
of	_	_
samples	_	_
and	_	_
,	_	_
specially	_	_
,	_	_
the	_	_
relation	_	_
between	_	_
number	_	_
of	_	_
samples	_	_
and	_	_
number	_	_
of	_	_
classes	_	_
may	_	_
be	_	_
a	_	_
limiting	_	_
factor	_	_
of	_	_
this	_	_
approach	_	_
.	_	_

#184
Successful	_	_
applications	_	_
of	_	_
end	_	_
to	_	_
end	_	_
convolutional	_	_
networks	_	_
are	_	_
usually	_	_
trained	_	_
on	_	_
thousands	_	_
of	_	_
samples	_	_
.	_	_

#185
For	_	_
this	_	_
reason	_	_
,	_	_
we	_	_
believe	_	_
that	_	_
training	_	_
with	_	_
a	_	_
larger	_	_
sample	_	_
size	_	_
will	_	_
improve	_	_
the	_	_
CCR	_	_
and	_	_
allow	_	_
for	_	_
deeper	_	_
networks	_	_
that	_	_
have	_	_
been	_	_
successfully	_	_
used	_	_
in	_	_
the	_	_
semantic	_	_
segmentation	_	_
of	_	_
other	_	_
image	_	_
sets	_	_
.	_	_

#186
7	_	_
.	_	_

#187
Acknowledgments	_	_
This	_	_
work	_	_
was	_	_
partially	_	_
funded	_	_
by	_	_
Banco	_	_
Santander	_	_
and	_	_
Universidad	_	_
Rey	_	_
Juan	_	_
Carlos	_	_
in	_	_
the	_	_
Funding	_	_
Program	_	_
for	_	_
Excellence	_	_
Research	_	_
Groups	_	_
,	_	_
ref	_	_
.	_	_

#188
"	_	_
Computer	_	_
Vision	_	_
and	_	_
Image	_	_
Processing	_	_
"	_	_
and	_	_
by	_	_
Project	_	_
RTC-2015-4167-1	_	_
of	_	_
the	_	_
Spanish	_	_
Ministry	_	_
of	_	_
Economy	_	_
and	_	_
Competitiveness	_	_
.	_	_

#189
We	_	_
gratefully	_	_
acknowledge	_	_
the	_	_
support	_	_
of	_	_
NVIDIA	_	_
Corporation	_	_
with	_	_
the	_	_
donation	_	_
of	_	_
the	_	_
Tesla	_	_
K40	_	_
GPU	_	_
used	_	_
for	_	_
this	_	_
research	_	_
.	_	_