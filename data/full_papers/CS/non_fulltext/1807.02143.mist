#0
Spatiotemporal	_	_
KSVD	_	_
Dictionary	_	_
Learning	_	_
for	_	_
Online	_	_
Multi-target	_	_
Tracking	_	_
Huynh	_	_
Manh	_	_
Department	_	_
of	_	_
Computer	_	_
Science	_	_
and	_	_
Engineering	_	_
University	_	_
of	_	_
Colorado	_	_
Denver	_	_
Denver	_	_
,	_	_
Colorado	_	_
,	_	_
USA	_	_
huynh.manh	_	_
@	_	_
ucdenver.edu	_	_
Gita	_	_
Alaghband	_	_
Department	_	_
of	_	_
Computer	_	_
Science	_	_
and	_	_
Engineering	_	_
University	_	_
of	_	_
Colorado	_	_
Denver	_	_
Denver	_	_
,	_	_
Colorado	_	_
,	_	_
USA	_	_
gita.alaghband	_	_
@	_	_
ucdenver.edu	_	_
Abstract—	_	_
In	_	_
this	_	_
paper	_	_
,	_	_
we	_	_
present	_	_
a	_	_
new	_	_
spatiotemporal	_	_
discriminative	_	_
KSVD	_	_
dictionary	_	_
algorithm	_	_
(	_	_
STKSVD	_	_
)	_	_
for	_	_
learning	_	_
target	_	_
appearance	_	_
in	_	_
online	_	_
multi-target	_	_
tracking	_	_
system	_	_
.	_	_

#1
Different	_	_
from	_	_
other	_	_
classification/recognition	_	_
tasks	_	_
(	_	_
e.g.	_	_
face	_	_
,	_	_
image	_	_
recognition	_	_
)	_	_
,	_	_
learning	_	_
target’s	_	_
appearance	_	_
in	_	_
online	_	_
multi-target	_	_
tracking	_	_
is	_	_
impacted	_	_
by	_	_
factors	_	_
such	_	_
as	_	_
:	_	_
posture/articulation	_	_
changes	_	_
,	_	_
partial	_	_
occlusion	_	_
by	_	_
background	_	_
scene	_	_
or	_	_
other	_	_
targets	_	_
,	_	_
background	_	_
changes	_	_
(	_	_
human	_	_
detection	_	_
bounding	_	_
box	_	_
covers	_	_
both	_	_
human	_	_
parts	_	_
and	_	_
part	_	_
of	_	_
the	_	_
scene	_	_
)	_	_
,	_	_
etc	_	_
.	_	_

#2
However	_	_
,	_	_
we	_	_
observe	_	_
that	_	_
these	_	_
variations	_	_
occur	_	_
gradually	_	_
relative	_	_
to	_	_
spatial	_	_
and	_	_
temporal	_	_
dynamics	_	_
.	_	_

#3
We	_	_
characterize	_	_
the	_	_
spatial	_	_
and	_	_
temporal	_	_
information	_	_
between	_	_
target’s	_	_
samples	_	_
through	_	_
a	_	_
new	_	_
STKSVD	_	_
appearance	_	_
learning	_	_
algorithm	_	_
to	_	_
better	_	_
discriminate	_	_
targets	_	_
.	_	_

#4
Our	_	_
STKSVD	_	_
method	_	_
is	_	_
able	_	_
to	_	_
learn	_	_
discriminative	_	_
sparse	_	_
code	_	_
,	_	_
linear	_	_
classifier	_	_
parameters	_	_
,	_	_
and	_	_
minimize	_	_
reconstruction	_	_
error	_	_
in	_	_
single	_	_
optimization	_	_
system	_	_
.	_	_

#5
Our	_	_
appearance	_	_
learning	_	_
algorithm	_	_
and	_	_
tracking	_	_
framework	_	_
employs	_	_
two	_	_
different	_	_
methods	_	_
of	_	_
calculating	_	_
appearance	_	_
similarity	_	_
score	_	_
in	_	_
each	_	_
stage	_	_
of	_	_
a	_	_
two-stage	_	_
association	_	_
:	_	_
a	_	_
linear	_	_
classifier	_	_
in	_	_
the	_	_
first	_	_
stage	_	_
,	_	_
and	_	_
minimum	_	_
residual	_	_
errors	_	_
in	_	_
the	_	_
second	_	_
stage	_	_
.	_	_

#6
The	_	_
results	_	_
tested	_	_
using	_	_
2DMOT2015	_	_
dataset	_	_
and	_	_
its	_	_
public	_	_
Aggregated	_	_
Channel	_	_
Features	_	_
(	_	_
ACF	_	_
)	_	_
human	_	_
detection	_	_
for	_	_
all	_	_
comparisons	_	_
show	_	_
that	_	_
our	_	_
method	_	_
outperforms	_	_
the	_	_
existing	_	_
related	_	_
learning	_	_
methods	_	_
.	_	_

#7
Keywords-multi-target	_	_
tracking	_	_
;	_	_
dictionary	_	_
learning	_	_
;	_	_
online	_	_
appearance	_	_
learning	_	_
.	_	_

#8
I	_	_
.	_	_

#9
INTRODUCTION	_	_
Multi-target	_	_
tracking	_	_
is	_	_
one	_	_
of	_	_
the	_	_
computer	_	_
vision	_	_
challenging	_	_
problems	_	_
.	_	_

#10
The	_	_
task	_	_
is	_	_
to	_	_
keep	_	_
track	_	_
of	_	_
all	_	_
targets	_	_
,	_	_
humans	_	_
in	_	_
our	_	_
case	_	_
,	_	_
in	_	_
a	_	_
scene	_	_
(	_	_
i.e.	_	_
,	_	_
a	_	_
video	_	_
sequence	_	_
)	_	_
and	_	_
maintain	_	_
their	_	_
identities	_	_
throughout	_	_
their	_	_
presence	_	_
in	_	_
the	_	_
sequence	_	_
.	_	_

#11
Multi-target	_	_
tracking	_	_
systems	_	_
have	_	_
applications	_	_
in	_	_
robot	_	_
navigation	_	_
[	_	_
1	_	_
]	_	_
,	_	_
surveillance	_	_
systems	_	_
[	_	_
2	_	_
]	_	_
,	_	_
video	_	_
analysis	_	_
[	_	_
2	_	_
]	_	_
and	_	_
autonomous	_	_
driving	_	_
cars	_	_
[	_	_
3	_	_
]	_	_
.	_	_

#12
Despite	_	_
great	_	_
improvements	_	_
achieved	_	_
in	_	_
tracking	_	_
performance	_	_
,	_	_
there	_	_
remains	_	_
challenges	_	_
arising	_	_
from	_	_
factors	_	_
such	_	_
as	_	_
:	_	_
(	_	_
1	_	_
)	_	_
Occlusion	_	_
,	_	_
i.e.	_	_
,	_	_
people	_	_
often	_	_
partially	_	_
or	_	_
fully	_	_
occlude	_	_
each	_	_
other	_	_
while	_	_
moving	_	_
or	_	_
are	_	_
occluded	_	_
by	_	_
background	_	_
and	_	_
other	_	_
objects	_	_
(	_	_
e.g.	_	_
,	_	_
trees	_	_
,	_	_
cars	_	_
,	_	_
etc.	_	_
)	_	_
.	_	_

#13
(	_	_
2	_	_
)	_	_
Motion	_	_
prediction	_	_
,	_	_
i.e.	_	_
,	_	_
unpredictable	_	_
movement	_	_
of	_	_
targets	_	_
involving	_	_
linear	_	_
and	_	_
non-linear	_	_
motion	_	_
which	_	_
can	_	_
also	_	_
cause	_	_
large	_	_
variations	_	_
in	_	_
appearance	_	_
.	_	_

#14
(	_	_
3	_	_
)	_	_
Discriminative	_	_
appearance	_	_
,	_	_
i.e.	_	_
,	_	_
distinguishing	_	_
individuals	_	_
with	_	_
similar	_	_
appearance	_	_
(	_	_
e.g.	_	_
,	_	_
same	_	_
clothes’	_	_
color	_	_
)	_	_
.	_	_

#15
Of	_	_
course	_	_
,	_	_
other	_	_
factors	_	_
like	_	_
abrupt	_	_
camera	_	_
motions	_	_
,	_	_
light	_	_
changes	_	_
,	_	_
etc	_	_
.	_	_

#16
will	_	_
also	_	_
impact	_	_
tracking	_	_
systems	_	_
.	_	_

#17
Since	_	_
it	_	_
is	_	_
hard	_	_
to	_	_
solve	_	_
all	_	_
of	_	_
the	_	_
above	_	_
problems	_	_
in	_	_
one	_	_
unified	_	_
tracking	_	_
framework	_	_
,	_	_
researchers	_	_
often	_	_
focus	_	_
on	_	_
either	_	_
motion	_	_
modeling	_	_
[	_	_
4	_	_
]	_	_
–	_	_
[	_	_
6	_	_
]	_	_
,	_	_
appearance	_	_
learning	_	_
[	_	_
7	_	_
]	_	_
–	_	_
[	_	_
9	_	_
]	_	_
or	_	_
tracking	_	_
systems	_	_
that	_	_
combine	_	_
a	_	_
subset	_	_
of	_	_
tracking	_	_
components	_	_
(	_	_
i.e.	_	_
,	_	_
motion	_	_
,	_	_
shape	_	_
,	_	_
appearance	_	_
)	_	_
[	_	_
7	_	_
]	_	_
,	_	_
[	_	_
10	_	_
]	_	_
.	_	_

#18
An	_	_
efficient	_	_
target	_	_
appearance	_	_
learning	_	_
model	_	_
plays	_	_
a	_	_
very	_	_
important	_	_
role	_	_
in	_	_
tracking	_	_
systems	_	_
.	_	_

#19
Several	_	_
appearance	_	_
learning	_	_
methods	_	_
have	_	_
been	_	_
used	_	_
in	_	_
variety	_	_
of	_	_
tracking	_	_
systems	_	_
such	_	_
as	_	_
incremental	_	_
linear	_	_
discriminant	_	_
analysis	_	_
(	_	_
ILDA	_	_
)	_	_
[	_	_
7	_	_
]	_	_
,	_	_
incremental/decremental	_	_
support	_	_
vector	_	_
machine	_	_
(	_	_
ID-SV	_	_
)	_	_
[	_	_
11	_	_
]	_	_
,	_	_
label	_	_
consistent	_	_
KSVD	_	_
(	_	_
LCKSVD	_	_
)	_	_
[	_	_
8	_	_
]	_	_
,	_	_
and	_	_
reinforcement	_	_
learning	_	_
[	_	_
10	_	_
]	_	_
.	_	_

#20
These	_	_
methods	_	_
apply	_	_
well-known	_	_
learning	_	_
algorithms	_	_
in	_	_
multi-target	_	_
tracking	_	_
systems	_	_
without	_	_
considering	_	_
the	_	_
spatial	_	_
and	_	_
temporal	_	_
relationship	_	_
between	_	_
target’s	_	_
samples	_	_
.	_	_

#21
Most	_	_
existing	_	_
tracking	_	_
systems	_	_
calculate	_	_
motion	_	_
,	_	_
location	_	_
,	_	_
and	_	_
appearance	_	_
similarity	_	_
separately	_	_
to	_	_
form	_	_
a	_	_
final	_	_
similar	_	_
score	_	_
,	_	_
and	_	_
then	_	_
apply	_	_
a	_	_
data	_	_
association	_	_
(	_	_
e.g.	_	_
,	_	_
Hungarian	_	_
algorithm	_	_
[	_	_
12	_	_
]	_	_
or	_	_
greedy	_	_
algorithm	_	_
[	_	_
11	_	_
]	_	_
)	_	_
to	_	_
find	_	_
matching	_	_
pairs	_	_
between	_	_
detections	_	_
and	_	_
targets	_	_
.	_	_

#22
We	_	_
note	_	_
that	_	_
the	_	_
spatial	_	_
and	_	_
temporal	_	_
information	_	_
must	deontic	_
be	_	_
inherently	_	_
encoded	_	_
in	_	_
appearance	_	_
changes	_	_
.	_	_

#23
We	_	_
also	_	_
observe	_	_
several	_	_
differences	_	_
between	_	_
appearance	_	_
learning	_	_
in	_	_
other	_	_
image	_	_
recognition/classification	_	_
tasks	_	_
(	_	_
e.g.	_	_
,	_	_
face	_	_
recognition	_	_
)	_	_
and	_	_
in	_	_
multi	_	_
target	_	_
tracking	_	_
.	_	_

#24
For	_	_
example	_	_
,	_	_
face	_	_
images	_	_
are	_	_
usually	_	_
fixed	_	_
with	_	_
frontal	_	_
faces	_	_
while	_	_
target	_	_
appearances	_	_
have	_	_
much	_	_
larger	_	_
variances	_	_
along	_	_
with	_	_
nonlinear	_	_
motions	_	_
.	_	_

#25
In	_	_
addition	_	_
,	_	_
human	_	_
detection	_	_
bounding	_	_
box	_	_
(	_	_
encompassing	_	_
rectangle	_	_
generated	_	_
by	_	_
human	_	_
detectors	_	_
)	_	_
does	_	_
not	_	_
only	_	_
cover	_	_
target’s	_	_
appearance	_	_
but	_	_
also	_	_
parts	_	_
of	_	_
the	_	_
background	_	_
scene	_	_
,	_	_
making	_	_
the	_	_
task	_	_
of	_	_
appearance	_	_
modeling	_	_
more	_	_
difficult	_	_
.	_	_

#26
In	_	_
this	_	_
work	_	_
,	_	_
we	_	_
propose	_	_
a	_	_
novel	_	_
online	_	_
appearance	_	_
learning	_	_
algorithm	_	_
,	_	_
based	_	_
on	_	_
discriminative	_	_
KSVD	_	_
dictionary	_	_
learning	_	_
,	_	_
that	_	_
incorporates	_	_
the	_	_
changes	_	_
with	_	_
respect	_	_
to	_	_
target’s	_	_
location	_	_
and	_	_
time	_	_
,	_	_
called	_	_
spatiotemporal	_	_
KSVD	_	_
algorithm	_	_
(	_	_
STKSVD	_	_
)	_	_
.	_	_

#27
The	_	_
reason	_	_
for	_	_
choosing	_	_
the	_	_
KSVD	_	_
dictionary	_	_
learning	_	_
method	_	_
as	_	_
the	_	_
baseline	_	_
for	_	_
our	_	_
appearance	_	_
learning	_	_
are	_	_
two-fold	_	_
:	_	_
(	_	_
1	_	_
)	_	_
the	_	_
original	_	_
KSVD	_	_
algorithm	_	_
[	_	_
13	_	_
]	_	_
and	_	_
its	_	_
improved	_	_
versions	_	_
of	_	_
discriminative	_	_
learning	_	_
[	_	_
14	_	_
]	_	_
,	_	_
[	_	_
15	_	_
]	_	_
have	_	_
been	_	_
successful	_	_
in	_	_
handling	_	_
partial	_	_
occlusions	_	_
in	_	_
image	_	_
recognition	_	_
.	_	_

#28
(	_	_
2	_	_
)	_	_
KSVD	_	_
algorithm	_	_
or	_	_
other	_	_
dictionary	_	_
learning	_	_
algorithms	_	_
,	_	_
in	_	_
general	_	_
,	_	_
operate	_	_
on	_	_
dictionary	_	_
columns	_	_
(	_	_
i.e.	_	_
,	_	_
atoms	_	_
)	_	_
,	_	_
which	_	_
will	_	_
be	_	_
learned/trained	_	_
through	_	_
a	_	_
learning	_	_
step	_	_
.	_	_

#29
One	_	_
can	_	_
imagine	_	_
that	_	_
one	_	_
atom	_	_
represents	_	_
one	_	_
target’s	_	_
sample	_	_
at	_	_
a	_	_
specific	_	_
time	_	_
.	_	_

#30
Thus	_	_
,	_	_
it	_	_
is	_	_
a	_	_
suitable	_	_
base	_	_
model	_	_
for	_	_
our	_	_
purpose	_	_
to	_	_
characterize	_	_
and	_	_
encode	_	_
the	_	_
spatial	_	_
and	_	_
temporal	_	_
relationship	_	_
between	_	_
these	_	_
different	_	_
atoms	_	_
and	_	_
between	_	_
atoms	_	_
and	_	_
training	_	_
data	_	_
.	_	_

#31
Thereby	_	_
providing	_	_
the	_	_
ability	_	_
to	_	_
exploit	_	_
the	_	_
locality	_	_
information	_	_
pertinent	_	_
to	_	_
each	_	_
target	_	_
at	_	_
a	_	_
given	_	_
time	_	_
and	_	_
location	_	_
.	_	_

#32
Our	_	_
method	_	_
aims	_	_
to	_	_
learn	_	_
spatially	_	_
and	_	_
temporally	_	_
discriminative	_	_
sparse	_	_
code	_	_
and	_	_
a	_	_
set	_	_
of	_	_
linear	_	_
classifier	_	_
parameters	_	_
to	_	_
further	_	_
reduce	_	_
classification	_	_
error	_	_
and	_	_
signal	_	_
reconstruction	_	_
error	_	_
.	_	_

#33
We	_	_
also	_	_
combine	_	_
our	_	_
learning	_	_
appearance	_	_
with	_	_
location	_	_
similarity	_	_
and	_	_
shape	_	_
similarity	_	_
for	_	_
calculating	_	_
the	_	_
final	_	_
similarity	_	_
score	_	_
.	_	_

#34
In	_	_
summary	_	_
,	_	_
our	_	_
contributions	_	_
are	_	_
:	_	_
•	_	_
A	_	_
new	_	_
spatiotemporal	_	_
KSVD	_	_
algorithm	_	_
(	_	_
STKSVD	_	_
)	_	_
for	_	_
learning	_	_
online	_	_
target	_	_
appearance	_	_
in	_	_
multi-target	_	_
tracking	_	_
.	_	_

#35
The	_	_
model	_	_
encodes	_	_
the	_	_
spatial	_	_
and	_	_
temporal	_	_
relationship	_	_
between	_	_
training	_	_
data	_	_
and	_	_
dictionary	_	_
atoms	_	_
making	_	_
sparse	_	_
representation	_	_
of	_	_
human	_	_
detections	_	_
more	_	_
discriminative	_	_
.	_	_

#36
•	_	_
Implementing	_	_
two	_	_
different	_	_
scenarios	_	_
for	_	_
calculating	_	_
appearance	_	_
similarity	_	_
scores	_	_
for	_	_
each	_	_
of	_	_
the	_	_
two	_	_
association	_	_
stages	_	_
.	_	_

#37
It	_	_
is	_	_
done	_	_
by	_	_
passing	_	_
the	_	_
spare	_	_
code	_	_
of	_	_
a	_	_
detection	_	_
into	_	_
a	_	_
linear	_	_
classifier	_	_
in	_	_
the	_	_
first	_	_
stage	_	_
and	_	_
calculating	_	_
the	_	_
minimum	_	_
residual	_	_
error	_	_
in	_	_
the	_	_
second	_	_
stage	_	_
of	_	_
association	_	_
.	_	_

#38
The	_	_
remaining	_	_
of	_	_
the	_	_
paper	_	_
is	_	_
organized	_	_
as	_	_
follows	_	_
.	_	_

#39
In	_	_
section	_	_
II	_	_
,	_	_
we	_	_
review	_	_
the	_	_
related	_	_
work	_	_
.	_	_

#40
We	_	_
will	_	_
discuss	_	_
our	_	_
system	_	_
design	_	_
in	_	_
section	_	_
III	_	_
and	_	_
present	_	_
the	_	_
new	_	_
spatiotemporal	_	_
STKSVD	_	_
dictionary	_	_
learning	_	_
in	_	_
section	_	_
IV	_	_
.	_	_

#41
We	_	_
present	_	_
our	_	_
results	_	_
in	_	_
section	_	_
V	_	_
followed	_	_
by	_	_
a	_	_
discussion	_	_
of	_	_
our	_	_
system	_	_
limitations	_	_
and	_	_
future	_	_
work	_	_
in	_	_
section	_	_
VI	_	_
.	_	_

#42
II	_	_
.	_	_

#43
RELATED	_	_
WORKS	_	_
Multi-target	_	_
Tracking	_	_
by	_	_
Detection	_	_
:	_	_
One	_	_
can	_	_
classify	_	_
multi-target	_	_
tracking	_	_
into	_	_
different	_	_
categories	_	_
depending	_	_
on	_	_
the	_	_
characteristics	_	_
of	_	_
tracking	_	_
systems	_	_
,	_	_
namely	_	_
tracking	_	_
by	_	_
detections	_	_
[	_	_
10	_	_
]	_	_
versus	_	_
tracking	_	_
without	_	_
detections	_	_
[	_	_
16	_	_
]	_	_
combined	_	_
with	_	_
online	_	_
tracking	_	_
[	_	_
7	_	_
]	_	_
versus	_	_
batch	_	_
tracking	_	_
[	_	_
17	_	_
]	_	_
which	_	_
can	_	_
be	_	_
further	_	_
combined	_	_
with	_	_
or	_	_
without	_	_
offline	_	_
motion/appearance	_	_
learning	_	_
[	_	_
10	_	_
]	_	_
.	_	_

#44
Based	_	_
on	_	_
this	_	_
information	_	_
,	_	_
we	_	_
classify	_	_
our	_	_
tracking	_	_
system	_	_
into	_	_
online	_	_
trackingbydetections	_	_
,	_	_
without	_	_
offline	_	_
learning	_	_
.	_	_

#45
Tracking-by-detection	_	_
framework	_	_
uses	_	_
human	_	_
detection	_	_
sets	_	_
as	_	_
its	_	_
input	_	_
.	_	_

#46
Thus	_	_
,	_	_
tracking	_	_
performances	_	_
are	_	_
highly	_	_
dependent	_	_
on	_	_
the	_	_
accuracy	_	_
of	_	_
the	_	_
human	_	_
detector	_	_
algorithm	_	_
employed	_	_
.	_	_

#47
Although	_	_
recent	_	_
tracking-by-detection	_	_
systems	_	_
have	_	_
shown	_	_
to	_	_
be	_	_
superior	_	_
to	_	_
tracking-by-non-detection	_	_
methods	_	_
,	_	_
their	_	_
accuracy	_	_
are	_	_
still	_	_
low	_	_
overall	_	_
.	_	_

#48
In	_	_
this	_	_
work	_	_
,	_	_
we	_	_
opt	_	_
to	_	_
use	_	_
public	_	_
Aggregate	_	_
Channel	_	_
Features	_	_
(	_	_
ACF	_	_
)	_	_
detector	_	_
[	_	_
18	_	_
]	_	_
that	_	_
has	_	_
produced	_	_
the	_	_
most	_	_
reliable	_	_
results	_	_
so	_	_
far	_	_
,	_	_
to	_	_
produce	_	_
the	_	_
human	_	_
detection	_	_
sets	_	_
for	_	_
all	_	_
of	_	_
our	_	_
test	_	_
cases	_	_
and	_	_
those	_	_
used	_	_
in	_	_
producing	_	_
comparison	_	_
results	_	_
.	_	_

#49
Furthermore	_	_
,	_	_
using	_	_
the	_	_
same	_	_
method	_	_
to	_	_
produce	_	_
the	_	_
input	_	_
set	_	_
(	_	_
ACF	_	_
)	_	_
makes	_	_
the	_	_
comparison	_	_
between	_	_
methods	_	_
meaningful	_	_
.	_	_

#50
Our	_	_
system	_	_
is	_	_
an	_	_
online	_	_
tracking	_	_
,	_	_
which	_	_
is	_	_
quite	_	_
different	_	_
from	_	_
batch	_	_
tracking	_	_
systems	_	_
that	_	_
can	_	_
use	_	_
future	_	_
frames	_	_
to	_	_
correct	_	_
past	_	_
frames	_	_
and	_	_
thus	_	_
gain	_	_
higher	_	_
tracking	_	_
accuracy	_	_
.	_	_

#51
Online	_	_
multi-target	_	_
tracking	_	_
systems	_	_
allow	_	_
use	_	_
of	_	_
all	_	_
information	_	_
up	_	_
to	_	_
the	_	_
current	_	_
frame	_	_
to	_	_
predict	_	_
target’s	_	_
state	_	_
in	_	_
the	_	_
next	_	_
frames	_	_
.	_	_

#52
These	_	_
systems	_	_
could	_	_
use	_	_
various	_	_
tracking	_	_
components/cues	_	_
such	_	_
as	_	_
:	_	_
motion	_	_
,	_	_
shape	_	_
and	_	_
appearances	_	_
combined	_	_
in	_	_
the	_	_
same	_	_
tracking	_	_
system	_	_
.	_	_

#53
A	_	_
two-stage	_	_
association	_	_
tracking	_	_
framework	_	_
described	_	_
in	_	_
[	_	_
7	_	_
]	_	_
classifies	_	_
targets	_	_
into	_	_
two	_	_
types	_	_
:	_	_
a	_	_
high	_	_
confidence	_	_
and	_	_
a	_	_
low	_	_
confidence	_	_
.	_	_

#54
It	_	_
calculates	_	_
a	_	_
confidence	_	_
level	_	_
for	_	_
each	_	_
target	_	_
by	_	_
using	_	_
the	_	_
length	_	_
of	_	_
target’s	_	_
trajectory	_	_
and	_	_
average	_	_
similarity	_	_
score	_	_
between	_	_
a	_	_
target	_	_
and	_	_
associated	_	_
detections	_	_
.	_	_

#55
A	_	_
target	_	_
is	_	_
called	_	_
“high	_	_
confident”	_	_
(	_	_
i.e.	_	_
highly	_	_
reliable	_	_
)	_	_
if	_	_
its	_	_
confidence	_	_
level	_	_
is	_	_
greater	_	_
than	_	_
a	_	_
threshold	_	_
.	_	_

#56
Otherwise	_	_
,	_	_
it	_	_
is	_	_
low	_	_
confident	_	_
.	_	_

#57
High	_	_
confident	_	_
targets	_	_
are	_	_
assigned	_	_
as	_	_
human	_	_
detections	_	_
in	_	_
the	_	_
first	_	_
association	_	_
stage	_	_
while	_	_
the	_	_
low	_	_
confident	_	_
targets	_	_
are	_	_
further	_	_
compared	_	_
with	_	_
all	_	_
remaining	_	_
targets	_	_
and	_	_
detections	_	_
in	_	_
the	_	_
second	_	_
stage	_	_
to	_	_
determine	_	_
their	_	_
probable	_	_
associations	_	_
.	_	_

#58
We	_	_
implement	_	_
several	_	_
improvements	_	_
to	_	_
the	_	_
two-stage	_	_
target	_	_
confident	_	_
appearance	_	_
framework	_	_
[	_	_
7	_	_
]	_	_
to	_	_
implement	_	_
our	_	_
new	_	_
spatiotemporal	_	_
STKSVD	_	_
dictionary	_	_
learning	_	_
method	_	_
for	_	_
online	_	_
target’s	_	_
appearance	_	_
learning	_	_
and	_	_
show	_	_
results	_	_
that	_	_
are	_	_
more	_	_
accurate	_	_
than	_	_
the	_	_
existing	_	_
methods	_	_
.	_	_

#59
It	_	_
is	_	_
important	_	_
to	_	_
note	_	_
that	_	_
the	_	_
proposed	_	_
STKSVD	_	_
is	_	_
framework-free	_	_
and	_	_
can	_	_
easily	_	_
be	_	_
used	_	_
with	_	_
other	_	_
tracking	_	_
frameworks	_	_
or	_	_
combined	_	_
with	_	_
different	_	_
tracking	_	_
components	_	_
.	_	_

#60
Discriminative	_	_
Dictionary	_	_
Learning	_	_
:	_	_
Most	_	_
optimization	_	_
algorithms	_	_
for	_	_
dictionary	_	_
learning	_	_
to	_	_
solve	_	_
classification/recognition	_	_
problems	_	_
focus	_	_
on	_	_
face	_	_
recognition	_	_
applications	_	_
[	_	_
19	_	_
]	_	_
,	_	_
[	_	_
20	_	_
]	_	_
.	_	_

#61
In	_	_
multi-target	_	_
tracking	_	_
domain	_	_
,	_	_
sparse	_	_
representation	_	_
(	_	_
i.e.	_	_
using	_	_
accelerated	_	_
proximal	_	_
gradient	_	_
descent	_	_
method	_	_
[	_	_
21	_	_
]	_	_
)	_	_
of	_	_
each	_	_
detection	_	_
is	_	_
mainly	_	_
used	_	_
to	_	_
find	_	_
residual	_	_
error	_	_
between	_	_
a	_	_
detection	_	_
and	_	_
targets	_	_
as	_	_
[	_	_
22	_	_
]	_	_
,	_	_
[	_	_
23	_	_
]	_	_
.	_	_

#62
These	_	_
residual	_	_
errors	_	_
are	_	_
directly	_	_
used	_	_
for	_	_
calculating	_	_
appearance	_	_
similarity	_	_
score	_	_
.	_	_

#63
These	_	_
methods	_	_
collect	_	_
all	_	_
or	_	_
some	_	_
target	_	_
samples	_	_
from	_	_
previous	_	_
frame	_	_
to	_	_
construct	_	_
a	_	_
dictionary	_	_
for	_	_
each	_	_
target	_	_
but	_	_
none	_	_
have	_	_
employed	_	_
spatiotemporal	_	_
appearance	_	_
learning	_	_
steps	_	_
.	_	_

#64
A	_	_
Label	_	_
Consistent	_	_
KSVD	_	_
(	_	_
LCKSVD	_	_
)	_	_
method	_	_
proposed	_	_
in	_	_
[	_	_
8	_	_
]	_	_
attempted	_	_
to	_	_
apply	_	_
a	_	_
face	_	_
recognition	_	_
appearance	_	_
learning	_	_
technique	_	_
directly	_	_
to	_	_
multi-target	_	_
tracking	_	_
problem	_	_
.	_	_

#65
They	_	_
did	_	_
not	_	_
incorporate	_	_
the	_	_
key	_	_
differences	_	_
between	_	_
the	_	_
two	_	_
problems	_	_
and	_	_
did	_	_
not	_	_
produce	_	_
satisfactory	_	_
results	_	_
in	_	_
terms	_	_
of	_	_
accuracy	_	_
.	_	_

#66
III	_	_
.	_	_

#67
SYSTEM	_	_
DESIGN	_	_
A	_	_
.	_	_

#68
System	_	_
Overview	_	_
A	_	_
high	_	_
level	_	_
description	_	_
of	_	_
our	_	_
system	_	_
design	_	_
and	_	_
tracking	_	_
algorithm	_	_
are	_	_
shown	_	_
in	_	_
Figure	_	_
1	_	_
and	_	_
Algorithm	_	_
1	_	_
,	_	_
respectively	_	_
.	_	_

#69
We	_	_
define	_	_
the	_	_
following	_	_
terms	_	_
used	_	_
throughout	_	_
the	_	_
paper	_	_
:	_	_
(	_	_
1	_	_
)	_	_
Detection	_	_
,	_	_
the	_	_
output	_	_
of	_	_
the	_	_
“human	_	_
detector”	_	_
(	_	_
ACF	_	_
)	_	_
algorithm	_	_
,	_	_
consists	_	_
of	_	_
the	_	_
bounding	_	_
box	_	_
and	_	_
its	_	_
encompassing	_	_
human	_	_
object	_	_
plus	_	_
size	_	_
,	_	_
time	_	_
,	_	_
and	_	_
location	_	_
.	_	_

#70
(	_	_
2	_	_
)	_	_
Target	_	_
,	_	_
a	_	_
detected	_	_
human	_	_
that	_	_
has	_	_
been	_	_
learned	_	_
and	_	_
entered	_	_
in	_	_
the	_	_
dictionary	_	_
.	_	_

#71
(	_	_
3	_	_
)	_	_
Samples	_	_
,	_	_
entries	_	_
in	_	_
the	_	_
dictionary	_	_
corresponding	_	_
to	_	_
the	_	_
same	_	_
target	_	_
,	_	_
which	_	_
can	_	_
be	_	_
due	_	_
to	_	_
different	_	_
detections	_	_
(	_	_
variations	_	_
)	_	_
.	_	_

#72
Furthermore	_	_
,	_	_
throughout	_	_
the	_	_
paper	_	_
we	_	_
refer	_	_
to	_	_
one	_	_
column	_	_
of	_	_
the	_	_
dictionary	_	_
regardless	_	_
of	_	_
whether	_	_
it	_	_
corresponds	_	_
to	_	_
different	_	_
targets	_	_
or	_	_
samples	_	_
of	_	_
the	_	_
same	_	_
target	_	_
as	_	_
an	_	_
“atom”	_	_
.	_	_

#73
Initialization	_	_
:	_	_
The	_	_
dictionary	_	_
is	_	_
initialized	_	_
using	_	_
the	_	_
first	_	_
few	_	_
frames	_	_
(	_	_
#	_	_
initFrames	_	_
=	_	_
5	_	_
in	_	_
our	_	_
test	_	_
cases	_	_
)	_	_
to	_	_
generate	_	_
a	_	_
number	_	_
of	_	_
targets	_	_
.	_	_

#74
A	_	_
target	_	_
is	_	_
generated	_	_
by	_	_
comparing	_	_
the	_	_
overlap	_	_
between	_	_
detected	_	_
humans	_	_
in	_	_
frame	_	_
#	_	_
1	_	_
with	_	_
subsequent	_	_
frames	_	_
(	_	_
1	_	_
&	_	_
2	_	_
,	_	_
2	_	_
&	_	_
3	_	_
,	_	_
3	_	_
&	_	_
4	_	_
,	_	_
4	_	_
&	_	_
5	_	_
)	_	_
.	_	_

#75
When	_	_
overlap	_	_
is	_	_
within	_	_
a	_	_
threshold	_	_
(	_	_
0.5	_	_
)	_	_
the	_	_
detection	_	_
is	_	_
entered	_	_
in	_	_
the	_	_
dictionary	_	_
as	_	_
a	_	_
target	_	_
.	_	_

#76
These	_	_
initial	_	_
targets	_	_
are	_	_
assigned	_	_
a	_	_
0.75	_	_
value	_	_
for	_	_
“high	_	_
confident”	_	_
targets	_	_
.	_	_

#77
Once	_	_
we	_	_
have	_	_
the	_	_
initial	_	_
targets	_	_
,	_	_
we	_	_
apply	_	_
our	_	_
STKSVD	_	_
algorithm	_	_
to	_	_
learn	_	_
appearances	_	_
of	_	_
these	_	_
initial	_	_
targets	_	_
.	_	_

#78
Overview	_	_
of	_	_
Multi-target	_	_
Tracking	_	_
Steps	_	_
:	_	_
For	_	_
each	_	_
frame	_	_
in	_	_
the	_	_
input	_	_
video	_	_
sequence	_	_
,	_	_
we	_	_
first	_	_
apply	_	_
ACF	_	_
human	_	_
detector	_	_
[	_	_
24	_	_
]	_	_
to	_	_
detect	_	_
all	_	_
people	_	_
in	_	_
the	_	_
scene	_	_
.	_	_

#79
In	_	_
the	_	_
feature	_	_
extraction	_	_
step	_	_
,	_	_
we	_	_
scale	_	_
all	_	_
human	_	_
detection	_	_
bounding	_	_
boxes	_	_
to	_	_
the	_	_
same	_	_
scale	_	_
(	_	_
32x64	_	_
)	_	_
and	_	_
calculate	_	_
color	_	_
histograms	_	_
on	_	_
the	_	_
upper	_	_
and	_	_
lower	_	_
body	_	_
part	_	_
(	_	_
i.e.	_	_
the	_	_
top	_	_
and	_	_
bottom	_	_
half	_	_
of	_	_
the	_	_
bounding	_	_
box	_	_
)	_	_
for	_	_
each	_	_
detection	_	_
.	_	_

#80
We	_	_
also	_	_
extract	_	_
size	_	_
(	_	_
before	_	_
scaling	_	_
)	_	_
and	_	_
location	_	_
features	_	_
of	_	_
each	_	_
detection	_	_
in	_	_
order	_	_
to	_	_
calculate	_	_
the	_	_
shape	_	_
similarity	_	_
Ss	_	_
and	_	_
location	_	_
similarity	_	_
Sl	_	_
with	_	_
existing	_	_
dictionary	_	_
targets	_	_
in	_	_
the	_	_
association	_	_
stages	_	_
.	_	_

#81
Given	_	_
color	_	_
histogram	_	_
feature	_	_
of	_	_
each	_	_
human	_	_
detection	_	_
and	_	_
learned	_	_
dictionary	_	_
D	_	_
of	_	_
all	_	_
existing	_	_
targets	_	_
,	_	_
we	_	_
calculate	_	_
the	_	_
sparse	_	_
representation	_	_
of	_	_
each	_	_
detection	_	_
using	_	_
Orthogonal	_	_
Matching	_	_
Pursuit	_	_
(	_	_
OMP	_	_
)	_	_
algorithm	_	_
[	_	_
25	_	_
]	_	_
.	_	_

#82
OMP	_	_
algorithm	_	_
computes	_	_
the	_	_
nonlinear	_	_
approximation	_	_
(	_	_
i.e.	_	_
sparse	_	_
representation	_	_
)	_	_
of	_	_
a	_	_
signal	_	_
(	_	_
e.g.	_	_
appearance	_	_
feature	_	_
in	_	_
our	_	_
case	_	_
)	_	_
in	_	_
a	_	_
dictionary	_	_
D	_	_
.	_	_

#83
Sparse	_	_
representation	_	_
brings	_	_
up	_	_
the	_	_
salient	_	_
features	_	_
that	_	_
help	_	_
in	_	_
discriminating	_	_
among	_	_
different	_	_
targets	_	_
.	_	_

#84
Note	_	_
that	_	_
our	_	_
dictionary	_	_
consists	_	_
of	_	_
learned	_	_
atoms	_	_
of	_	_
all	_	_
targets	_	_
from	_	_
high	_	_
confidence	_	_
targets	_	_
(	_	_
red	_	_
columns	_	_
)	_	_
to	_	_
low	_	_
confidence	_	_
targets	_	_
(	_	_
blue	_	_
columns	_	_
)	_	_
as	_	_
shown	_	_
in	_	_
figure	_	_
1	_	_
.	_	_

#85
In	_	_
the	_	_
first	_	_
stage	_	_
of	_	_
association	_	_
,	_	_
sparse	_	_
representation	_	_
of	_	_
each	_	_
detection	_	_
is	_	_
used	_	_
as	_	_
an	_	_
input	_	_
to	_	_
the	_	_
linear	_	_
classifier	_	_
in	_	_
order	_	_
to	_	_
produce	_	_
appearance	_	_
similarity	_	_
score	_	_
between	_	_
a	_	_
detection	_	_
and	_	_
all	_	_
targets	_	_
.	_	_

#86
We	_	_
multiply	_	_
location	_	_
,	_	_
shape	_	_
and	_	_
appearance	_	_
similarities	_	_
to	_	_
get	_	_
the	_	_
final	_	_
similarity	_	_
score	_	_
.	_	_

#87
Then	_	_
,	_	_
the	_	_
inverse	_	_
of	_	_
final	_	_
similarity	_	_
score	_	_
is	_	_
used	_	_
as	_	_
the	_	_
cost	_	_
(	_	_
i.e.	_	_
an	_	_
element	_	_
of	_	_
the	_	_
cost	_	_
matrix	_	_
)	_	_
between	_	_
a	_	_
target	_	_
and	_	_
a	_	_
detection	_	_
.	_	_

#88
The	_	_
dimensions	_	_
of	_	_
the	_	_
cost	_	_
matrix	_	_
in	_	_
this	_	_
stage	_	_
are	_	_
𝑓	_	_
×	_	_
𝑛	_	_
,	_	_
where	_	_
𝑓	_	_
is	_	_
the	_	_
number	_	_
of	_	_
targets	_	_
and	_	_
𝑛	_	_
is	_	_
the	_	_
number	_	_
of	_	_
detections	_	_
.	_	_

#89
Next	_	_
,	_	_
we	_	_
apply	_	_
the	_	_
Hungarian	_	_
algorithm	_	_
[	_	_
12	_	_
]	_	_
to	_	_
the	_	_
cost	_	_
matrix	_	_
to	_	_
find	_	_
the	_	_
matched	_	_
pairs	_	_
between	_	_
detections	_	_
and	_	_
targets	_	_
.	_	_

#90
The	_	_
Hungarian	_	_
algorithm	_	_
generally	_	_
solves	_	_
an	_	_
assignment	_	_
problem	_	_
by	_	_
finding	_	_
pairs	_	_
(	_	_
pairs	_	_
of	_	_
targets	_	_
and	_	_
detection	_	_
in	_	_
our	_	_
case	_	_
)	_	_
that	_	_
minimize	_	_
the	_	_
total	_	_
cost	_	_
.	_	_

#91
In	_	_
the	_	_
second	_	_
stage	_	_
of	_	_
association	_	_
,	_	_
the	_	_
low	_	_
confident	_	_
targets	_	_
are	_	_
assigned	_	_
to	_	_
either	_	_
the	_	_
remaining	_	_
detections	_	_
or	_	_
one	_	_
of	_	_
the	_	_
high	_	_
confident	_	_
targets	_	_
.	_	_

#92
In	_	_
this	_	_
stage	_	_
,	_	_
we	_	_
again	_	_
use	_	_
location	_	_
,	_	_
shape	_	_
and	_	_
appearance	_	_
similarity	_	_
to	_	_
construct	_	_
a	_	_
secondary	_	_
cost	_	_
matrix	_	_
.	_	_

#93
The	_	_
dimensions	_	_
of	_	_
this	_	_
cost	_	_
matrix	_	_
are	_	_
the	_	_
number	_	_
of	_	_
low	_	_
confident	_	_
targets	_	_
(	_	_
fl	_	_
)	_	_
by	_	_
the	_	_
number	_	_
of	_	_
remaining	_	_
detections	_	_
plus	_	_
the	_	_
number	_	_
of	_	_
high	_	_
confident	_	_
targets	_	_
(	_	_
fh	_	_
)	_	_
.The	_	_
difference	_	_
in	_	_
computation	_	_
in	_	_
this	_	_
stage	_	_
is	_	_
that	_	_
the	_	_
inverse	_	_
of	_	_
the	_	_
minimum	_	_
residual	_	_
reconstruction	_	_
error	_	_
is	_	_
used	_	_
as	_	_
appearance	_	_
similarity	_	_
score	_	_
instead	_	_
of	_	_
using	_	_
linear	_	_
classifier	_	_
function	_	_
.	_	_

#94
After	_	_
the	_	_
two	_	_
stages	_	_
of	_	_
associations	_	_
,	_	_
we	_	_
update	_	_
the	_	_
existing	_	_
targets’	_	_
states	_	_
which	_	_
include	_	_
velocity	_	_
,	_	_
location	_	_
and	_	_
confidence	_	_
level	_	_
.	_	_

#95
Finally	_	_
,	_	_
our	_	_
STKSVD	_	_
algorithm	_	_
is	_	_
applied	_	_
to	_	_
learn	_	_
appearance	_	_
of	_	_
existing	_	_
targets	_	_
,	_	_
which	_	_
results	_	_
in	_	_
updated	_	_
learned	_	_
dictionary	_	_
𝐷	_	_
and	_	_
linear	_	_
classifier	_	_
parameters	_	_
𝑊	_	_
.	_	_

#96
Next	_	_
,	_	_
we	_	_
will	_	_
present	_	_
our	_	_
calculations	_	_
of	_	_
confidence	_	_
level	_	_
,	_	_
similarity	_	_
score	_	_
and	_	_
target	_	_
generation/termination	_	_
.	_	_

#97
Target	_	_
Confidence	_	_
:	_	_
The	_	_
idea	_	_
is	_	_
to	_	_
use	_	_
the	_	_
target’s	_	_
computed	_	_
confidence	_	_
to	_	_
set	_	_
a	_	_
higher	_	_
priority	_	_
for	_	_
“high	_	_
confident”	_	_
targets	_	_
to	_	_
associate	_	_
with	_	_
human	_	_
detection	_	_
set	_	_
in	_	_
first	_	_
stage	_	_
.	_	_

#98
Then	_	_
the	_	_
remaining	_	_
human	_	_
detections	_	_
are	_	_
matched	_	_
with	_	_
low	_	_
confident	_	_
targets	_	_
in	_	_
the	_	_
second	_	_
stage	_	_
.	_	_

#99
We	_	_
define	_	_
parameters	_	_
amplifier	_	_
α	_	_
,	_	_
and	_	_
attenuate	_	_
β	_	_
,	_	_
to	_	_
promote	_	_
and	_	_
demote	_	_
the	_	_
affinity	_	_
score	_	_
when	_	_
there	_	_
is	_	_
a	_	_
match	_	_
between	_	_
a	_	_
detection	_	_
and	_	_
target	_	_
.	_	_

#100
In	_	_
in	_	_
our	_	_
experiments	_	_
,	_	_
we	_	_
set	_	_
a	_	_
fixed	_	_
value	_	_
for	_	_
α	_	_
=	_	_
1.5	_	_
and	_	_
β	_	_
=	_	_
0.8.	_	_
α	_	_
increases	_	_
the	_	_
target’s	_	_
confidence	_	_
level	_	_
when	_	_
there	_	_
is	_	_
re-identification	_	_
of	_	_
the	_	_
target	_	_
while	_	_
β	_	_
decreases	_	_
the	_	_
confidence	_	_
level	_	_
of	_	_
a	_	_
target	_	_
when	_	_
it	_	_
is	_	_
not	_	_
detected	_	_
.	_	_

#101
We	_	_
reset	_	_
the	_	_
confidence	_	_
level	_	_
of	_	_
a	_	_
low-confident	_	_
target	_	_
to	_	_
its	_	_
initial	_	_
value	_	_
(	_	_
0.75	_	_
in	_	_
our	_	_
experiments	_	_
)	_	_
in	_	_
the	_	_
current	_	_
frame	_	_
upon	_	_
a	_	_
new	_	_
detection	_	_
of	_	_
this	_	_
target	_	_
.	_	_

#102
We	_	_
observe	_	_
that	_	_
it	_	_
helps	_	_
recover	_	_
the	_	_
state	_	_
of	_	_
this	_	_
target	_	_
faster	_	_
after	_	_
occlusions	_	_
.	_	_

#103
In	_	_
summary	_	_
,	_	_
the	_	_
confidence	_	_
score	_	_
of	_	_
target	_	_
τi	_	_
at	_	_
current	_	_
frame	_	_
if	_	_
there	_	_
is	_	_
association	_	_
between	_	_
a	_	_
detection	_	_
dj	_	_
and	_	_
τi	_	_
is	_	_
updated	_	_
as	_	_
:	_	_
Conf	_	_
(	_	_
τi	_	_
)	_	_
=	_	_
L	_	_
Σt=ts	_	_
t=tcS	_	_
(	_	_
τi	_	_
,	_	_
dj	_	_
)	_	_
∗	_	_
(	_	_
1	_	_
−	_	_
exp	_	_
(	_	_
√L	_	_
)	_	_
(	_	_
1	_	_
)	_	_
Where	_	_
ts	_	_
and	_	_
tc	_	_
are	_	_
start	_	_
frame	_	_
and	_	_
current	_	_
frame	_	_
,	_	_
respectively	_	_
.	_	_

#104
L	_	_
is	_	_
the	_	_
length	_	_
of	_	_
target’s	_	_
trajectory	_	_
L	_	_
=	_	_
tc	_	_
−	_	_
ts	_	_
.	_	_

#105
S	_	_
(	_	_
i	_	_
,	_	_
dj	_	_
)	_	_
is	_	_
similarity	_	_
score	_	_
between	_	_
detection	_	_
dj	_	_
and	_	_
target	_	_
i	_	_
,	_	_
which	_	_
is	_	_
amplified	_	_
or	_	_
attenuated	_	_
using	_	_
α	_	_
or	_	_
β	_	_
.	_	_

#106
Figure	_	_
1	_	_
.	_	_

#107
System	_	_
Design	_	_
T1	_	_
T2	_	_
Tn-1	_	_
TnHuman	_	_
detection	_	_
Video	_	_
Sequence	_	_
...	_	_
Update	_	_
Target	_	_
States	_	_
Generate/	_	_
Terminate	_	_
targets	_	_
Dictionary	_	_
...	_	_

#108
Sparse	_	_
Representation	_	_
(	_	_
OMP	_	_
)	_	_
Low	_	_
Confident	_	_
Level	_	_
:	_	_
For	_	_
each	_	_
frame	_	_
STKSVD	_	_
Target	_	_
Appearance	_	_
Learning	_	_
High	_	_
Feature	_	_
Extraction	_	_
Size	_	_
Location	_	_
Color	_	_
histogram	_	_
Ss	_	_
Sl	_	_
Sa	_	_
Cost	_	_
matrix	_	_
Pair	_	_
(	_	_
di	_	_
,	_	_
Tj	_	_
)	_	_
Linear	_	_
Classifier	_	_
Hungarian	_	_
algorithm	_	_
Ss	_	_
Sl	_	_
Sa	_	_
Cost	_	_
matrix	_	_
Pair	_	_
(	_	_
di	_	_
,	_	_
Tj	_	_
)	_	_
Hungarian	_	_
algorithm	_	_
Min	_	_
Residual	_	_
First	_	_
stage	_	_
assocation	_	_
Second	_	_
stage	_	_
assocation	_	_
Predict	_	_
next	_	_
locations	_	_
Similarity	_	_
Score	_	_
:	_	_
For	_	_
each	_	_
stage	_	_
of	_	_
target-detection	_	_
association	_	_
,	_	_
we	_	_
define	_	_
a	_	_
similarity	_	_
score	_	_
between	_	_
detection	_	_
and	_	_
target	_	_
using	_	_
shape	_	_
similarity	_	_
Ss	_	_
,	_	_
position	_	_
similaritySp	_	_
,	_	_
and	_	_
appearance	_	_
similarity	_	_
Sa	_	_
.	_	_

#109
The	_	_
overall	_	_
similarity	_	_
score	_	_
is	_	_
S	_	_
=	_	_
SsSaSp	_	_
.	_	_

#110
The	_	_
predicted	_	_
position	_	_
,	_	_
ptc=	_	_
ptc-1+vtc-1×t	_	_
,	_	_
of	_	_
a	_	_
target	_	_
from	_	_
last	_	_
frame	_	_
is	_	_
used	_	_
to	_	_
estimate	_	_
position	_	_
similarity	_	_
using	_	_
a	_	_
Gaussian	_	_
distribution	_	_
as	_	_
:	_	_
Sp	_	_
=	_	_
√2πσ2	_	_
e−	_	_
(	_	_
ptc−pdc	_	_
)	_	_
^2	_	_
2σ2	_	_
,	_	_
where	_	_
pdc	_	_
is	_	_
the	_	_
position	_	_
of	_	_
a	_	_
detection	_	_
in	_	_
the	_	_
current	_	_
frame	_	_
,	_	_
vtc-1	_	_
is	_	_
velocity	_	_
of	_	_
the	_	_
target	_	_
in	_	_
previous	_	_
frame	_	_
and	_	_
σ	_	_
=	_	_
[	_	_
σx	_	_
,	_	_
σy	_	_
]	_	_
is	_	_
the	_	_
spatial	_	_
variance	_	_
in	_	_
2D	_	_
coordinates	_	_
(	_	_
σx	_	_
=	_	_
75	_	_
,	_	_
σy=	_	_
50	_	_
in	_	_
our	_	_
experiments	_	_
)	_	_
.	_	_

#111
For	_	_
shape	_	_
similarity	_	_
,	_	_
we	_	_
use	_	_
Ss	_	_
(	_	_
X	_	_
,	_	_
Y	_	_
)	_	_
=	_	_
exp	_	_
(	_	_
−	_	_
{	_	_
hX−hY	_	_
hX+hY	_	_
+	_	_
wX−wY	_	_
wX+wY	_	_
}	_	_
)	_	_
as	_	_
in	_	_
[	_	_
7	_	_
]	_	_
.	_	_

#112
Where	_	_
X	_	_
and	_	_
Y	_	_
are	_	_
target	_	_
or	_	_
detection	_	_
,	_	_
h	_	_
and	_	_
w	_	_
indicate	_	_
height	_	_
and	_	_
width	_	_
of	_	_
the	_	_
detection	_	_
or	_	_
target	_	_
.	_	_

#113
Given	_	_
the	_	_
learned	_	_
set	_	_
of	_	_
parameters	_	_
W	_	_
=	_	_
{	_	_
ω1	_	_
,	_	_
…	_	_
,	_	_
ωn	_	_
}	_	_
∈	_	_
Rn×K	_	_
and	_	_
dictionary	_	_
D	_	_
,	_	_
we	_	_
calculate	_	_
the	_	_
appearance	_	_
similarity	_	_
score	_	_
Sa	_	_
between	_	_
a	_	_
target	_	_
τi	_	_
and	_	_
detection	_	_
dj	_	_
for	_	_
each	_	_
of	_	_
the	_	_
two	_	_
association	_	_
stages	_	_
.	_	_

#114
In	_	_
the	_	_
first	_	_
stage	_	_
,	_	_
we	_	_
calculate	_	_
the	_	_
sparse	_	_
codes	_	_
xj	_	_
for	_	_
each	_	_
detection’s	_	_
appearance	_	_
features	_	_
using	_	_
OMP	_	_
algorithm	_	_
[	_	_
25	_	_
]	_	_
.	_	_

#115
Then	_	_
,	_	_
the	_	_
sparse	_	_
codes	_	_
are	_	_
used	_	_
as	_	_
feature	_	_
inputs	_	_
in	_	_
a	_	_
linear	_	_
classifier	_	_
to	_	_
find	_	_
appearance	_	_
score	_	_
similarity	_	_
between	_	_
each	_	_
detection	_	_
and	_	_
the	_	_
existing	_	_
high	_	_
confident	_	_
targets	_	_
as	_	_
:	_	_
Sa	_	_
(	_	_
τi	_	_
,	_	_
dj	_	_
)	_	_
=	_	_
Wxj	_	_
1	_	_
≤	_	_
i	_	_
≤	_	_
f	_	_
&	_	_
1	_	_
≤	_	_
j	_	_
≤	_	_
n	_	_
(	_	_
2	_	_
)	_	_
Where	_	_
f	_	_
is	_	_
the	_	_
number	_	_
of	_	_
targets	_	_
and	_	_
n	_	_
is	_	_
the	_	_
number	_	_
of	_	_
detections	_	_
.	_	_

#116
In	_	_
the	_	_
second	_	_
stage	_	_
,	_	_
we	_	_
calculate	_	_
a	_	_
similarity	_	_
score	_	_
to	_	_
assign	_	_
a	_	_
low	_	_
confident	_	_
target	_	_
to	_	_
the	_	_
remaining	_	_
detections	_	_
or	_	_
other	_	_
targets	_	_
in	_	_
the	_	_
dictionary	_	_
.	_	_

#117
Thus	_	_
,	_	_
only	_	_
the	_	_
part	_	_
of	_	_
the	_	_
dictionary	_	_
consisting	_	_
of	_	_
atoms	_	_
of	_	_
low-confident	_	_
targets	_	_
are	_	_
needed	_	_
for	_	_
this	_	_
calculation	_	_
.	_	_

#118
We	_	_
use	_	_
the	_	_
inverse	_	_
of	_	_
minimum	_	_
reconstruction	_	_
error	_	_
for	_	_
appearance	_	_
similarity	_	_
score	_	_
as	_	_
it	_	_
will	_	_
give	_	_
the	_	_
maximum	_	_
probability	_	_
of	_	_
similarity	_	_
for	_	_
this	_	_
set	_	_
of	_	_
targets	_	_
and	_	_
detections	_	_
.	_	_

#119
Given	_	_
a	_	_
dictionary	_	_
of	_	_
low	_	_
confident	_	_
targets	_	_
DL	_	_
⊂	_	_
D	_	_
,	_	_
sparse	_	_
codes	_	_
xj	_	_
of	_	_
each	_	_
detection´s	_	_
features	_	_
yj	_	_
d	_	_
or	_	_
existing	_	_
target	_	_
features	_	_
yj	_	_
τe	_	_
are	_	_
calculated	_	_
as	_	_
in	_	_
stage	_	_
one	_	_
.	_	_

#120
Then	_	_
,	_	_
the	_	_
residual	_	_
error	_	_
of	_	_
each	_	_
detection/existing	_	_
target	_	_
yj	_	_
=	_	_
{	_	_
yj	_	_
d	_	_
,	_	_
yj	_	_
τe	_	_
}	_	_
on	_	_
different	_	_
low	_	_
confident	_	_
targets	_	_
τi	_	_
l	_	_
is	_	_
calculated	_	_
as	_	_
:	_	_
rij	_	_
=	_	_
‖yj	_	_
−	_	_
DLxij‖2	_	_
(	_	_
3	_	_
)	_	_
where	_	_
xij	_	_
is	_	_
part	_	_
of	_	_
xj	_	_
for	_	_
a	_	_
specific	_	_
target	_	_
class	_	_
by	_	_
keeping	_	_
the	_	_
coefficients	_	_
for	_	_
all	_	_
dictionary	_	_
atoms	_	_
in	_	_
target	_	_
class	_	_
τi	_	_
l	_	_
,	_	_
and	_	_
setting	_	_
0	_	_
for	_	_
other	_	_
classes	_	_
.	_	_

#121
The	_	_
appearance	_	_
similarity	_	_
between	_	_
detection	_	_
dj	_	_
/existing	_	_
target	_	_
j	_	_
e	_	_
and	_	_
target	_	_
𝜏𝑖	_	_
𝑙	_	_
is	_	_
defined	_	_
as	_	_
:	_	_
Sa	_	_
(	_	_
τi	_	_
l	_	_
,	_	_
dj/j	_	_
e	_	_
)	_	_
=	_	_
rij	_	_
.	_	_

#122
B.	_	_
Generation/Termination	_	_
of	_	_
Target	_	_
Generation	_	_
:	_	_
Since	_	_
we	_	_
can	_	_
not	_	_
make	_	_
any	_	_
assumptions	_	_
about	_	_
information	_	_
related	_	_
to	_	_
exits/entries	_	_
of	_	_
targets	_	_
in	_	_
a	_	_
scene	_	_
,	_	_
it	_	_
is	_	_
important	_	_
to	_	_
have	_	_
a	_	_
reliable	_	_
target	_	_
generation	_	_
method	_	_
in	_	_
our	_	_
multi-target	_	_
tracking	_	_
system	_	_
.	_	_

#123
Most	_	_
existing	_	_
methods	_	_
assign	_	_
a	_	_
new	_	_
target	_	_
for	_	_
any	_	_
unassigned	_	_
detection	_	_
in	_	_
a	_	_
frame	_	_
.	_	_

#124
This	_	_
increases	_	_
the	_	_
chance	_	_
of	_	_
creating	_	_
new	_	_
false	_	_
targets	_	_
because	_	_
of	_	_
the	_	_
imperfection	_	_
of	_	_
human	_	_
detection	_	_
sets	_	_
(	_	_
e.g.	_	_
a	_	_
target	_	_
may	_	_
be	_	_
covered	_	_
by	_	_
several	_	_
overlapping	_	_
bounding	_	_
boxes	_	_
)	_	_
.	_	_

#125
Bae	_	_
et	_	_
al.	_	_
,	_	_
in	_	_
[	_	_
7	_	_
]	_	_
generate	_	_
a	_	_
new	_	_
target	_	_
by	_	_
considering	_	_
the	_	_
past	_	_
pre-defined	_	_
number	_	_
of	_	_
frames	_	_
and	_	_
look	_	_
for	_	_
the	_	_
continuous	_	_
overlap	_	_
and	_	_
height	_	_
similarity	_	_
in	_	_
these	_	_
frames	_	_
.	_	_

#126
We	_	_
generate	_	_
a	_	_
new	_	_
target	_	_
by	_	_
considering	_	_
its	_	_
overlapped	_	_
trajectory	_	_
with	_	_
existing	_	_
target	_	_
trajectories	_	_
to	_	_
determine	_	_
whether	_	_
the	_	_
ratio	_	_
of	_	_
overlap	_	_
between	_	_
the	_	_
pairs	_	_
of	_	_
trajectories	_	_
is	_	_
less	_	_
than	_	_
a	_	_
pre-defined	_	_
threshold	_	_
.	_	_

#127
Termination	_	_
:	_	_
We	_	_
terminate	_	_
tracking	_	_
a	_	_
target	_	_
if	_	_
it	_	_
has	_	_
not	_	_
been	_	_
detected	_	_
in	_	_
a	_	_
fixed	_	_
consecutive	_	_
number	_	_
of	_	_
frames	_	_
(	_	_
5	_	_
in	_	_
this	_	_
implementation	_	_
)	_	_
.	_	_

#128
This	_	_
usually	_	_
occurs	_	_
when	_	_
a	_	_
target	_	_
is	_	_
under	_	_
occlusion	_	_
for	_	_
a	_	_
period	_	_
of	_	_
time	_	_
greater	_	_
than	_	_
a	_	_
predefined	_	_
number	_	_
of	_	_
frames	_	_
or	_	_
if	_	_
it	_	_
is	_	_
out	_	_
of	_	_
the	_	_
scene	_	_
.	_	_

#129
The	_	_
re-identification	_	_
of	_	_
a	_	_
target	_	_
when	_	_
it	_	_
is	_	_
out	_	_
of	_	_
the	_	_
scene	_	_
is	_	_
in	_	_
general	_	_
not	_	_
applied	_	_
within	_	_
the	_	_
multi-target	_	_
tracking	_	_
research	_	_
domain	_	_
.	_	_

#130
IV	_	_
.	_	_

#131
ONLINE	_	_
APPEARANCE	_	_
LEARNING	_	_
USING	_	_
SPATIOTEMPORAL	_	_
STKSVD	_	_
DICTIONARY	_	_
Dictionary	_	_
learning	_	_
may	_	_
be	_	_
divided	_	_
in	_	_
two	_	_
categories	_	_
of	_	_
(	_	_
a	_	_
)	_	_
reconstruction	_	_
where	_	_
one	_	_
attempts	_	_
to	_	_
learn	_	_
the	_	_
dictionary	_	_
by	_	_
finding	_	_
sparse	_	_
representation	_	_
of	_	_
input	_	_
signals	_	_
that	_	_
minimize	_	_
the	_	_
reconstruction	_	_
error	_	_
[	_	_
13	_	_
]	_	_
,	_	_
[	_	_
26	_	_
]	_	_
and	_	_
(	_	_
b	_	_
)	_	_
classification	_	_
where	_	_
the	_	_
dictionary	_	_
learning	_	_
combines	_	_
the	_	_
reconstruction	_	_
error	_	_
minimization	_	_
simultaneously	_	_
with	_	_
a	_	_
linear	_	_
classifier	_	_
[	_	_
8	_	_
]	_	_
,	_	_
[	_	_
14	_	_
]	_	_
.	_	_

#132
Our	_	_
proposed	_	_
STKSVD	_	_
algorithm	_	_
learns	_	_
dictionary	_	_
D	_	_
of	_	_
all	_	_
targets	_	_
and	_	_
linear	_	_
classifier	_	_
parameters	_	_
𝑊	_	_
to	_	_
reduce	_	_
reconstruction	_	_
and	_	_
classification	_	_
errors	_	_
.	_	_

#133
We	_	_
develop	_	_
the	_	_
STKSVD	_	_
algorithm	_	_
by	_	_
incorporating	_	_
spatiotemporal	_	_
features	_	_
Algorithm	_	_
1	_	_
:	_	_
Multi-target	_	_
tracking	_	_
algorithm	_	_
Input	_	_
:	_	_
•	_	_
Learned	_	_
dictionary	_	_
𝐷	_	_
=	_	_
{	_	_
𝑎1	_	_
,	_	_
…	_	_
,	_	_
𝑎𝐾	_	_
}	_	_
∈	_	_
𝑅𝑁×𝐾	_	_
of	_	_
all	_	_
targets	_	_
.	_	_

#134
•	_	_
Learned	_	_
linear	_	_
classifier	_	_
parameters	_	_
𝑊	_	_
•	_	_
Existing	_	_
target	_	_
τ	_	_
=	_	_
{	_	_
1	_	_
,	_	_
…	_	_
,	_	_
𝑓	_	_
}	_	_
,	_	_
where	_	_
f	_	_
is	_	_
the	_	_
number	_	_
of	_	_
targets	_	_
.	_	_

#135
•	_	_
A	_	_
set	_	_
of	_	_
human	_	_
detection	_	_
𝑃	_	_
=	_	_
{	_	_
𝑑1	_	_
,	_	_
…	_	_
,	_	_
𝑑𝑛	_	_
}	_	_
,	_	_
where	_	_
n	_	_
is	_	_
the	_	_
number	_	_
of	_	_
detections	_	_
.	_	_

#136
Output	_	_
:	_	_
•	_	_
Continuously	_	_
track	_	_
all	_	_
targets	_	_
•	_	_
Generate	_	_
new	_	_
targets	_	_
.	_	_

#137
1	_	_
.	_	_

#138
For	_	_
frame	_	_
=	_	_
#	_	_
initFrames	_	_
+	_	_
1	_	_
to	_	_
lastFrame	_	_
2	_	_
.	_	_

#139
Extract	_	_
color	_	_
histogram	_	_
feature	_	_
𝐹𝑖	_	_
∈	_	_
𝑅𝑁×1	_	_
for	_	_
each	_	_
human	_	_
detection	_	_
3	_	_
.	_	_

#140
Find	_	_
matched	_	_
detections	_	_
for	_	_
high	_	_
confident	_	_
target	_	_
.	_	_

#141
(	_	_
first	_	_
association	_	_
stage	_	_
)	_	_
4	_	_
.	_	_

#142
On	_	_
remaining	_	_
detections	_	_
,	_	_
find	_	_
matched	_	_
ones	_	_
for	_	_
low	_	_
confident	_	_
targets	_	_
.	_	_

#143
(	_	_
second	_	_
association	_	_
stage	_	_
)	_	_
5	_	_
.	_	_

#144
Update	_	_
confidence	_	_
value	_	_
for	_	_
all	_	_
targets	_	_
.	_	_

#145
6	_	_
.	_	_

#146
Update	_	_
target	_	_
state	_	_
and	_	_
predict	_	_
location	_	_
in	_	_
the	_	_
next	_	_
frame	_	_
7	_	_
.	_	_

#147
Generate/	_	_
terminate	_	_
targets	_	_
8	_	_
.	_	_

#148
STKSVD	_	_
target	_	_
appearance	_	_
learning	_	_
.	_	_

#149
9	_	_
.	_	_

#150
End	_	_
For	_	_
Figure	_	_
2	_	_
.	_	_

#151
An	_	_
example	_	_
showing	_	_
how	_	_
atoms	_	_
for	_	_
a	_	_
target	_	_
𝜏	_	_
are	_	_
chosen	_	_
to	_	_
update	_	_
the	_	_
dictionary	_	_
.	_	_

#152
It	_	_
also	_	_
illustrate	_	_
the	_	_
appearance	_	_
similarity	_	_
between	_	_
an	_	_
atom	_	_
and	_	_
its	_	_
nearby	_	_
samples	_	_
.	_	_

#153
Each	_	_
circle	_	_
represents	_	_
a	_	_
detected	_	_
sample	_	_
in	_	_
a	_	_
frame	_	_
for	_	_
𝜏.	_	_
so	_	_
that	_	_
it	_	_
learns	_	_
dictionary	_	_
D	_	_
and	_	_
linear	_	_
classifier	_	_
parameters	_	_
W	_	_
simultaneously	_	_
as	_	_
formulated	_	_
below	_	_
:	_	_
<	_	_
𝐷	_	_
,	_	_
𝑋	_	_
,	_	_
𝑊	_	_
>	_	_
=	_	_
argmin	_	_
𝐷	_	_
,	_	_
𝑋	_	_
,	_	_
𝑊	_	_
‖𝑌	_	_
−	_	_
𝐷𝑋‖2	_	_
2	_	_
+	_	_
𝜅	_	_
‖𝑄	_	_
−	_	_
𝐴𝑋‖2	_	_
+	_	_
𝜆	_	_
‖𝐻	_	_
−	_	_
𝑊𝑋‖2	_	_
2	_	_
𝑠.	_	_
𝑡	_	_
.	_	_

#154
∀𝑖	_	_
,	_	_
‖𝑥𝑖	_	_
‖0	_	_
≤	_	_
𝑇	_	_
(	_	_
4	_	_
)	_	_
where	_	_
‖Y	_	_
−	_	_
DX‖2	_	_
2	_	_
is	_	_
the	_	_
reconstruction	_	_
error	_	_
term	_	_
.	_	_

#155
‖H	_	_
−	_	_
WX‖2	_	_
2	_	_
is	_	_
the	_	_
classification	_	_
error	_	_
.	_	_

#156
𝜅	_	_
and	_	_
𝜆	_	_
are	_	_
scalars	_	_
that	_	_
control	_	_
the	_	_
contribution	_	_
of	_	_
each	_	_
term	_	_
.	_	_

#157
The	_	_
columns	_	_
of	_	_
the	_	_
label	_	_
matrix	_	_
H	_	_
=	_	_
{	_	_
h1	_	_
,	_	_
…	_	_
,	_	_
hn	_	_
}	_	_
indicate	_	_
which	_	_
class	_	_
each	_	_
of	_	_
the	_	_
input	_	_
signals	_	_
belong	_	_
to	_	_
.	_	_

#158
For	_	_
example	_	_
,	_	_
h1	_	_
=	_	_
{	_	_
1,0	_	_
,	_	_
.	_	_

#159
.0	_	_
}	_	_
indicates	_	_
that	_	_
input	_	_
signal	_	_
y1	_	_
belongs	_	_
to	_	_
class	_	_
1	_	_
.	_	_

#160
‖Q	_	_
−	_	_
AX‖2	_	_
2	_	_
is	_	_
the	_	_
sparse	_	_
code	_	_
error	_	_
term	_	_
,	_	_
where	_	_
we	_	_
enforce	_	_
sparse	_	_
code	_	_
to	_	_
be	_	_
discriminative	_	_
between	_	_
targets	_	_
with	_	_
respect	_	_
to	_	_
spatial	_	_
and	_	_
temporal	_	_
features	_	_
.	_	_

#161
A	_	_
is	_	_
a	_	_
linear	_	_
transformation	_	_
matrix	_	_
transforming	_	_
the	_	_
original	_	_
sparse	_	_
codes	_	_
to	_	_
the	_	_
more	_	_
discriminative	_	_
sparse	_	_
codes	_	_
.	_	_

#162
Different	_	_
from	_	_
existing	_	_
work	_	_
,	_	_
we	_	_
construct	_	_
discriminative	_	_
sparse	_	_
code	_	_
matrix	_	_
Q	_	_
from	_	_
two	_	_
matrices	_	_
Ql	_	_
and	_	_
Qst	_	_
satisfying	_	_
each	_	_
of	_	_
the	_	_
following	_	_
two	_	_
criteria	_	_
:	_	_
(	_	_
1	_	_
)	_	_
Each	_	_
sparse	_	_
code	_	_
should	_	_
have	_	_
label	_	_
consistency	_	_
,	_	_
which	_	_
means	_	_
it	_	_
should	_	_
have	_	_
strong	_	_
bias	_	_
to	_	_
the	_	_
atoms	_	_
in	_	_
the	_	_
same	_	_
class	_	_
.	_	_

#163
We	_	_
expect	_	_
that	_	_
each	_	_
of	_	_
the	_	_
input	_	_
signals	_	_
can	_	_
be	_	_
constructed	_	_
by	_	_
atoms	_	_
in	_	_
same	_	_
class	_	_
.	_	_

#164
We	_	_
denote	_	_
this	_	_
sparse	_	_
code	_	_
matrix	_	_
as	_	_
Ql	_	_
=	_	_
{	_	_
q1	_	_
,	_	_
…	_	_
,	_	_
qn	_	_
)	_	_
where	_	_
column	_	_
qi	_	_
is	_	_
the	_	_
expected	_	_
sparse	_	_
code	_	_
of	_	_
signal	_	_
yi	_	_
.	_	_

#165
For	_	_
example	_	_
,	_	_
in	_	_
column	_	_
qi	_	_
=	_	_
{	_	_
0	_	_
,	_	_
…	_	_
,1,1	_	_
,	_	_
…	_	_
0	_	_
}	_	_
a	_	_
0	_	_
in	_	_
position	_	_
k	_	_
indicates	_	_
that	_	_
signal	_	_
yi	_	_
and	_	_
the	_	_
dictionary	_	_
atom	_	_
dk	_	_
in	_	_
D	_	_
do	_	_
not	_	_
belong	_	_
to	_	_
the	_	_
same	_	_
class	_	_
.	_	_

#166
(	_	_
2	_	_
)	_	_
Associating	_	_
a	_	_
detected	_	_
bounding	_	_
box	_	_
with	_	_
a	_	_
target	_	_
should	_	_
take	_	_
into	_	_
account	_	_
the	_	_
time	_	_
and	_	_
location	_	_
of	_	_
the	_	_
detected	_	_
boxes	_	_
in	_	_
order	_	_
to	_	_
match	_	_
it	_	_
with	_	_
the	_	_
best	_	_
target	_	_
and	_	_
learn	_	_
more	_	_
effectively	_	_
when	_	_
several	_	_
similarities	_	_
are	_	_
possible	_	_
.	_	_

#167
To	_	_
account	_	_
for	_	_
this	_	_
spatiotemporal	_	_
improvement	_	_
,	_	_
we	_	_
denote	_	_
Qst	_	_
=	_	_
{	_	_
θij	_	_
}	_	_
,	_	_
i	_	_
=	_	_
{	_	_
1	_	_
…	_	_
K	_	_
}	_	_
,	_	_
j	_	_
=	_	_
{	_	_
1	_	_
…	_	_
N	_	_
}	_	_
spatial	_	_
and	_	_
temporal	_	_
similarity	_	_
score	_	_
matrix	_	_
between	_	_
atoms	_	_
and	_	_
training	_	_
signals	_	_
,	_	_
where	_	_
each	_	_
of	_	_
element	_	_
θij	_	_
is	_	_
defined	_	_
as	_	_
:	_	_
θij	_	_
=	_	_
e	_	_
(	_	_
−	_	_
|ti−tj|∗	_	_
‖pi−pj‖	_	_
σs	_	_
)	_	_
(	_	_
5	_	_
)	_	_
where	_	_
t	_	_
and	_	_
p	_	_
are	_	_
the	_	_
time	_	_
and	_	_
position	_	_
of	_	_
the	_	_
target’s	_	_
training	_	_
sample	_	_
and	_	_
atom	_	_
.	_	_

#168
σs	_	_
is	_	_
the	_	_
variance	_	_
of	_	_
spatial	_	_
information	_	_
.	_	_

#169
Finally	_	_
,	_	_
our	_	_
discriminative	_	_
sparse	_	_
code	_	_
Q	_	_
can	_	_
be	_	_
calculated	_	_
as	_	_
element-wise	_	_
multiplication	_	_
of	_	_
two	_	_
matrices	_	_
Ql	_	_
and	_	_
Qst	_	_
:	_	_
Q	_	_
=	_	_
Ql	_	_
⨂	_	_
Qst	_	_
(	_	_
6	_	_
)	_	_
Optimization	_	_
:	_	_
Equation	_	_
(	_	_
4	_	_
)	_	_
can	_	_
be	_	_
approximated	_	_
using	_	_
the	_	_
original	_	_
KSVD	_	_
algorithm	_	_
as	_	_
:	_	_
<	_	_
D′	_	_
,	_	_
X	_	_
>	_	_
=	_	_
argmin	_	_
D	_	_
,	_	_
X	_	_
,	_	_
W	_	_
‖Y′	_	_
−	_	_
D′X‖2	_	_
2	_	_
s.	_	_
t	_	_
∀i	_	_
,	_	_
‖xi‖0	_	_
≤	_	_
T	_	_
(	_	_
7	_	_
)	_	_
where	_	_
Y′	_	_
=	_	_
(	_	_
YT	_	_
,	_	_
√𝜅QT	_	_
,	_	_
√𝜆HT	_	_
)	_	_
and	_	_
D′	_	_
=	_	_
(	_	_
YT	_	_
,	_	_
√𝜅AT	_	_
,	_	_
√𝜆WT	_	_
)	_	_
.	_	_

#170
[	_	_
8	_	_
]	_	_
,	_	_
[	_	_
14	_	_
]	_	_
provide	_	_
more	_	_
details	_	_
of	_	_
optimization	_	_
algorithms	_	_
used	_	_
for	_	_
KSVD	_	_
.	_	_

#171
The	_	_
training	_	_
is	_	_
done	_	_
for	_	_
each	_	_
target	_	_
by	_	_
using	_	_
all	_	_
detected	_	_
samples	_	_
for	_	_
a	_	_
given	_	_
target	_	_
from	_	_
all	_	_
previous	_	_
frames	_	_
up	_	_
to	_	_
the	_	_
current	_	_
frame	_	_
.	_	_

#172
For	_	_
a	_	_
given	_	_
target	_	_
,	_	_
we	_	_
select	_	_
the	_	_
detected	_	_
sample	_	_
in	_	_
the	_	_
trajectory	_	_
of	_	_
that	_	_
target	_	_
(	_	_
temporal	_	_
and	_	_
spatial	_	_
)	_	_
that	_	_
best	_	_
represent	_	_
it	_	_
within	_	_
the	_	_
last	_	_
few	_	_
frames	_	_
(	_	_
five	_	_
in	_	_
our	_	_
case	_	_
)	_	_
plus	_	_
within	_	_
all	_	_
target	_	_
samples	_	_
already	_	_
in	_	_
the	_	_
dictionary	_	_
.	_	_

#173
This	_	_
is	_	_
the	_	_
sample	_	_
that	_	_
is	_	_
stored	_	_
in	_	_
the	_	_
dictionary	_	_
with	_	_
the	_	_
same	_	_
class	_	_
of	_	_
the	_	_
target	_	_
.	_	_

#174
Figure	_	_
2	_	_
,	_	_
shows	_	_
target	_	_
samples	_	_
(	_	_
in	_	_
red	_	_
)	_	_
that	_	_
are	_	_
stored	_	_
in	_	_
the	_	_
dictionary	_	_
as	_	_
training	_	_
continues	_	_
for	_	_
a	_	_
specific	_	_
target	_	_
	_	_
.	_	_

#175
For	_	_
example	_	_
,	_	_
atom	_	_
4	_	_
in	_	_
the	_	_
figure	_	_
is	_	_
selected	_	_
from	_	_
detected	_	_
samples	_	_
from	_	_
the	_	_
last	_	_
five	_	_
frames	_	_
and	_	_
atoms	_	_
1	_	_
,	_	_
2	_	_
,	_	_
and	_	_
3	_	_
(	_	_
already	_	_
in	_	_
the	_	_
dictionary	_	_
)	_	_
representing	_	_
samples	_	_
of	_	_
	_	_
.	_	_

#176
The	_	_
linear	_	_
classifier	_	_
parameters	_	_
W	_	_
are	_	_
initialized	_	_
by	_	_
solving	_	_
the	_	_
quadratic	_	_
loss	_	_
and	_	_
L2	_	_
norm	_	_
regularization	_	_
function	_	_
as	_	_
described	_	_
in	_	_
[	_	_
27	_	_
]	_	_
:	_	_
W	_	_
=	_	_
argmin	_	_
W	_	_
‖H	_	_
−	_	_
WX‖2	_	_
2	_	_
+	_	_
ξ‖W‖2	_	_
2	_	_
(	_	_
8	_	_
)	_	_
By	_	_
using	_	_
regression	_	_
model	_	_
,	_	_
Equation	_	_
8	_	_
is	_	_
solved	_	_
as	_	_
:	_	_
W	_	_
=	_	_
(	_	_
XXT	_	_
+	_	_
ξI	_	_
)	_	_
−1	_	_
XHT	_	_
.	_	_

#177
A	_	_
similar	_	_
technique	_	_
is	_	_
applied	_	_
for	_	_
initializing	_	_
A	_	_
as	_	_
:	_	_
A	_	_
=	_	_
(	_	_
XXT	_	_
+	_	_
ξI	_	_
)	_	_
−1	_	_
XQT	_	_
.	_	_

#178
V.	_	_
EXPERIMENTS	_	_
Implementation	_	_
Details	_	_
:	_	_
We	_	_
have	_	_
implemented	_	_
our	_	_
system	_	_
on	_	_
a	_	_
Xeon	_	_
CPU	_	_
E5-2650	_	_
v4	_	_
@	_	_
2.2GHz	_	_
and	_	_
utilized	_	_
OMP	_	_
and	_	_
KSVD	_	_
toolbox	_	_
[	_	_
28	_	_
]	_	_
.	_	_

#179
In	_	_
this	_	_
section	_	_
,	_	_
we	_	_
present	_	_
the	_	_
results	_	_
of	_	_
three	_	_
experiments	_	_
:	_	_
(	_	_
a	_	_
)	_	_
Explore	_	_
the	_	_
impact	_	_
of	_	_
appearance	_	_
learning	_	_
model	_	_
on	_	_
overall	_	_
tracking	_	_
systems	_	_
by	_	_
varying	_	_
the	_	_
number	_	_
of	_	_
atoms	_	_
.	_	_

#180
(	_	_
b	_	_
)	_	_
Compare	_	_
four	_	_
existing	_	_
appearance	_	_
learning	_	_
methods	_	_
with	_	_
our	_	_
STKSVD	_	_
.	_	_

#181
(	_	_
c	_	_
)	_	_
Compare	_	_
the	_	_
overall	_	_
accuracy	_	_
of	_	_
two	_	_
existing	_	_
target	_	_
appearance	_	_
learning-based	_	_
tracking	_	_
systems	_	_
with	_	_
our	_	_
system	_	_
.	_	_

#182
For	_	_
meaningful	_	_
comparison	_	_
,	_	_
all	_	_
systems	_	_
being	_	_
tested	_	_
use	_	_
2DMOT2015	_	_
dataset	_	_
[	_	_
29	_	_
]	_	_
,	_	_
which	_	_
provides	_	_
the	_	_
same	_	_
human	_	_
detection	_	_
set	_	_
(	_	_
i.e.	_	_
resulted	_	_
from	_	_
ACF	_	_
detector	_	_
[	_	_
24	_	_
]	_	_
)	_	_
and	_	_
evaluation	_	_
tools	_	_
.	_	_

#183
For	_	_
all	_	_
experiments	_	_
,	_	_
we	_	_
set	_	_
the	_	_
following	_	_
values	_	_
for	_	_
the	_	_
system	_	_
parameters	_	_
as	_	_
follows	_	_
:	_	_
The	_	_
association	_	_
scores	_	_
in	_	_
both	_	_
stages	_	_
is	_	_
set	_	_
to	_	_
equal	_	_
0.4	_	_
.	_	_

#184
Target	_	_
samples	_	_
are	_	_
scaled	_	_
to	_	_
size	_	_
(	_	_
64	_	_
,	_	_
32	_	_
)	_	_
and	_	_
their	_	_
cascaded	_	_
RGB	_	_
color	_	_
histogram	_	_
is	_	_
set	_	_
to	_	_
48	_	_
bins	_	_
so	_	_
that	_	_
variation	_	_
of	_	_
target	_	_
sizes	_	_
do	_	_
not	_	_
impact	_	_
target	_	_
appearance	_	_
variations	_	_
.	_	_

#185
In	_	_
STKSVD	_	_
learning	_	_
process	_	_
,	_	_
we	_	_
also	_	_
set	_	_
spatiotemporal	_	_
constraint	_	_
term	_	_
𝜅	_	_
=	_	_
2	_	_
and	_	_
classification	_	_
error	_	_
term	_	_
𝜆	_	_
=	_	_
4	_	_
.	_	_

#186
Datasets	_	_
and	_	_
Detections	_	_
:	_	_
We	_	_
use	_	_
]	_	_
2DMOT2015	_	_
dataset	_	_
for	_	_
performance	_	_
evaluation	_	_
.	_	_

#187
Depending	_	_
on	_	_
the	_	_
ground	_	_
truth	_	_
of	_	_
each	_	_
sequence	_	_
and	_	_
published	_	_
results	_	_
available	_	_
,	_	_
we	_	_
set	_	_
up	_	_
two	_	_
different	_	_
experiments	_	_
.	_	_

#188
The	_	_
first	_	_
experiment	_	_
is	_	_
conducted	_	_
on	_	_
sequences	_	_
that	_	_
have	_	_
made	_	_
their	_	_
ground	_	_
truth	_	_
available	_	_
so	_	_
that	_	_
we	_	_
can	_	_
observe	_	_
the	_	_
results	_	_
on	_	_
different	_	_
parameters	_	_
and	_	_
compare	_	_
different	_	_
learning	_	_
appearance	_	_
techniques	_	_
in	_	_
our	_	_
Samples	_	_
are	_	_
used	_	_
to	_	_
initialize	_	_
dictionary	_	_
atoms	_	_
Target	_	_
s	_	_
sample	_	_
Target	_	_
s	_	_
trajectory	_	_
t	_	_
=1	_	_
t	_	_
=	_	_
n	_	_
Samples	_	_
have	_	_
higher	_	_
appearance	_	_
similarity	_	_
scores	_	_
for	_	_
atoms	_	_
1	_	_
and	_	_
2	_	_
than	_	_
others	_	_
tracking	_	_
system	_	_
.	_	_

#189
The	_	_
name	_	_
of	_	_
sequences	_	_
used	_	_
in	_	_
this	_	_
experiment	_	_
are	_	_
in	_	_
Figure	_	_
3	_	_
.	_	_

#190
In	_	_
the	_	_
second	_	_
experiment	_	_
,	_	_
we	_	_
compare	_	_
our	_	_
results	_	_
with	_	_
related	_	_
previous	_	_
work	_	_
so	_	_
we	_	_
choose	_	_
a	_	_
set	_	_
of	_	_
sequences	_	_
for	_	_
which	_	_
implementation	_	_
and	_	_
results	_	_
are	_	_
available	_	_
.	_	_

#191
The	_	_
names	_	_
of	_	_
these	_	_
sequences	_	_
are	_	_
indicated	_	_
in	_	_
each	_	_
experiment	_	_
.	_	_

#192
In	_	_
general	_	_
,	_	_
all	_	_
selected	_	_
sequences	_	_
cover	_	_
all	_	_
possible	_	_
scenarios	_	_
that	_	_
may	_	_
occur	_	_
in	_	_
daily	_	_
life	_	_
such	_	_
as	_	_
static	_	_
camera	_	_
sequences	_	_
(	_	_
e.g.	_	_
PETS09-S2L1	_	_
,	_	_
PETS09-S2L2	_	_
,	_	_
KITTI-16	_	_
)	_	_
,	_	_
moving	_	_
camera	_	_
sequence	_	_
(	_	_
e.g.	_	_
ETH	_	_
sequences	_	_
)	_	_
,	_	_
sparse	_	_
crowd	_	_
(	_	_
e.g.	_	_
PETS09-S2L1	_	_
)	_	_
,	_	_
medium	_	_
crowd	_	_
(	_	_
e.g.	_	_
ETHBahnof	_	_
,	_	_
KITTI-16	_	_
)	_	_
dense	_	_
crowd	_	_
(	_	_
e.g.	_	_
PETS09-S2L2	_	_
)	_	_
,	_	_
and	_	_
also	_	_
from	_	_
different	_	_
angles	_	_
and	_	_
positions	_	_
of	_	_
camera	_	_
views	_	_
.	_	_

#193
These	_	_
sequences	_	_
cover	_	_
most	_	_
possible	_	_
challenges	_	_
we	_	_
may	_	_
encounter	_	_
in	_	_
multi-target	_	_
tracking	_	_
.	_	_

#194
Since	_	_
the	_	_
performance	_	_
of	_	_
current	_	_
tracking-by	_	_
detection	_	_
method	_	_
depends	_	_
significantly	_	_
on	_	_
the	_	_
performance	_	_
of	_	_
human	_	_
detectors	_	_
,	_	_
we	_	_
believe	_	_
that	_	_
tracking	_	_
algorithms	_	_
should	_	_
use	_	_
the	_	_
same	_	_
human	_	_
detector	_	_
.	_	_

#195
Thus	_	_
,	_	_
we	_	_
use	_	_
the	_	_
same	_	_
publicly	_	_
available	_	_
detection	_	_
method	_	_
(	_	_
ACF	_	_
detector	_	_
)	_	_
and	_	_
compare	_	_
only	_	_
the	_	_
tracking	_	_
systems	_	_
.	_	_

#196
Evaluation	_	_
Metrics	_	_
:	_	_
We	_	_
use	_	_
the	_	_
CLEAR	_	_
MOT	_	_
[	_	_
30	_	_
]	_	_
,	_	_
which	_	_
consists	_	_
of	_	_
multiple	_	_
metrics	_	_
for	_	_
evaluations	_	_
as	_	_
follows	_	_
:	_	_
(	_	_
1	_	_
)	_	_
MOTP	_	_
(	_	_
multiple	_	_
object	_	_
tracking	_	_
precision	_	_
)	_	_
evaluates	_	_
the	_	_
intersection	_	_
over	_	_
the	_	_
union	_	_
area	_	_
between	_	_
a	_	_
detected	_	_
bounding	_	_
box	_	_
and	_	_
the	_	_
ground	_	_
truth	_	_
bounding	_	_
box	_	_
.	_	_

#197
(	_	_
2	_	_
)	_	_
MOTA	_	_
(	_	_
multiple	_	_
object	_	_
tracking	_	_
accuracy	_	_
)	_	_
is	_	_
calculated	_	_
using	_	_
three	_	_
sources	_	_
of	_	_
errors	_	_
:	_	_
false	_	_
negative	_	_
(	_	_
FN	_	_
)	_	_
,	_	_
false	_	_
positive	_	_
(	_	_
FP	_	_
)	_	_
,	_	_
and	_	_
ID	_	_
switch	_	_
(	_	_
IDS	_	_
)	_	_
.	_	_

#198
(	_	_
3	_	_
)	_	_
FAF	_	_
is	_	_
the	_	_
average	_	_
false	_	_
alarms	_	_
or	_	_
false	_	_
positive	_	_
(	_	_
FP	_	_
)	_	_
per	_	_
frame	_	_
.	_	_

#199
(	_	_
4	_	_
)	_	_
MT	_	_
(	_	_
mostly	_	_
tracked	_	_
targets	_	_
)	_	_
is	_	_
the	_	_
ratio	_	_
of	_	_
ground-truth	_	_
trajectories	_	_
(	_	_
GTT	_	_
)	_	_
covered	_	_
by	_	_
track	_	_
hypothesis	_	_
for	_	_
at	_	_
least	_	_
80	_	_
%	_	_
of	_	_
their	_	_
life	_	_
span	_	_
.	_	_

#200
(	_	_
5	_	_
)	_	_
ML	_	_
(	_	_
mostly	_	_
lost	_	_
)	_	_
is	_	_
the	_	_
ratio	_	_
of	_	_
ground-truth	_	_
trajectories	_	_
(	_	_
GTT	_	_
)	_	_
covered	_	_
by	_	_
track	_	_
hypothesis	_	_
for	_	_
at	_	_
most	_	_
20	_	_
%	_	_
of	_	_
their	_	_
life	_	_
span	_	_
.	_	_

#201
(	_	_
6	_	_
)	_	_
FP	_	_
is	_	_
the	_	_
total	_	_
number	_	_
of	_	_
false	_	_
positives	_	_
in	_	_
a	_	_
sequence	_	_
.	_	_

#202
(	_	_
7	_	_
)	_	_
FN	_	_
is	_	_
the	_	_
total	_	_
number	_	_
of	_	_
false	_	_
negatives	_	_
in	_	_
a	_	_
sequence	_	_
.	_	_

#203
(	_	_
8	_	_
)	_	_
IDS	_	_
is	_	_
the	_	_
total	_	_
number	_	_
of	_	_
identity	_	_
switches	_	_
.	_	_

#204
(	_	_
9	_	_
)	_	_
Frag	_	_
is	_	_
the	_	_
total	_	_
number	_	_
of	_	_
times	_	_
a	_	_
trajectory	_	_
is	_	_
fragmented	_	_
(	_	_
i.e.	_	_
interrupted	_	_
during	_	_
tracking	_	_
)	_	_
.	_	_

#205
Analysis	_	_
on	_	_
different	_	_
number	_	_
of	_	_
atoms	_	_
:	_	_
In	_	_
this	_	_
experiment	_	_
,	_	_
we	_	_
vary	_	_
the	_	_
number	_	_
of	_	_
atoms	_	_
and	_	_
observe	_	_
the	_	_
impact	_	_
of	_	_
it	_	_
on	_	_
the	_	_
accuracy	_	_
of	_	_
our	_	_
system	_	_
.	_	_

#206
The	_	_
purpose	_	_
of	_	_
this	_	_
experiment	_	_
is	_	_
to	_	_
find	_	_
the	_	_
number	_	_
of	_	_
atoms	_	_
for	_	_
which	_	_
STKSVD	_	_
generates	_	_
most	_	_
accurate	_	_
results	_	_
for	_	_
each	_	_
sequence	_	_
.	_	_

#207
We	_	_
use	_	_
the	_	_
resulting	_	_
number	_	_
of	_	_
atoms	_	_
in	_	_
the	_	_
next	_	_
two	_	_
sets	_	_
of	_	_
experiments	_	_
(	_	_
circled	_	_
on	_	_
Figure	_	_
3	_	_
)	_	_
.	_	_

#208
We	_	_
set	_	_
the	_	_
STKSVD	_	_
appearance	_	_
learning	_	_
iterations	_	_
to	_	_
10	_	_
and	_	_
vary	_	_
the	_	_
number	_	_
of	_	_
atoms	_	_
for	_	_
each	_	_
target	_	_
in	_	_
the	_	_
dictionary	_	_
from	_	_
5	_	_
to	_	_
40	_	_
and	_	_
observe	_	_
the	_	_
results	_	_
on	_	_
11	_	_
video	_	_
sequences	_	_
as	_	_
listed	_	_
in	_	_
Figure	_	_
3	_	_
.	_	_

#209
Note	_	_
that	_	_
our	_	_
work	_	_
focuses	_	_
on	_	_
appearance	_	_
learning	_	_
but	_	_
only	_	_
linear	_	_
motion	_	_
predictions	_	_
.	_	_

#210
We	_	_
observe	_	_
that	_	_
our	_	_
system	_	_
achieves	_	_
better	_	_
results	_	_
in	_	_
sequences	_	_
that	_	_
have	_	_
the	_	_
following	_	_
features	_	_
:	_	_
(	_	_
1	_	_
)	_	_
consisting	_	_
of	_	_
high	_	_
number	_	_
of	_	_
targets	_	_
that	_	_
move	_	_
linearly	_	_
,	_	_
(	_	_
2	_	_
)	_	_
targets	_	_
that	_	_
have	_	_
long	_	_
trajectories	_	_
so	_	_
that	_	_
our	_	_
system	_	_
can	_	_
collect	_	_
enough	_	_
training	_	_
data	_	_
.	_	_

#211
Our	_	_
best	_	_
results	_	_
are	_	_
on	_	_
PETS09-S2L1	_	_
where	_	_
most	_	_
of	_	_
the	_	_
targets	_	_
have	_	_
long	_	_
trajectories	_	_
with	_	_
linear	_	_
movements	_	_
and	_	_
fewer	_	_
occlusions	_	_
than	_	_
other	_	_
sequences	_	_
.	_	_

#212
In	_	_
addition	_	_
,	_	_
the	_	_
higher	_	_
number	_	_
of	_	_
atoms	_	_
positively	_	_
improves	_	_
the	_	_
accuracy	_	_
in	_	_
this	_	_
sequence	_	_
.	_	_

#213
If	_	_
the	_	_
number	_	_
of	_	_
atoms	_	_
is	_	_
too	_	_
low	_	_
,	_	_
there	_	_
won’t	_	_
be	_	_
enough	_	_
samples	_	_
to	_	_
represent	_	_
the	_	_
salient	_	_
features	_	_
of	_	_
the	_	_
target	_	_
,	_	_
i.e.	_	_
,	_	_
MOTA	_	_
is	_	_
low	_	_
(	_	_
70	_	_
%	_	_
)	_	_
.	_	_

#214
When	_	_
the	_	_
number	_	_
of	_	_
atoms	_	_
is	_	_
too	_	_
large	_	_
,	_	_
the	_	_
variance	_	_
of	_	_
target	_	_
appearances	_	_
becomes	_	_
too	_	_
large	_	_
which	_	_
in	_	_
turn	_	_
reduces	_	_
the	_	_
accuracy	_	_
.	_	_

#215
For	_	_
example	_	_
,	_	_
when	_	_
the	_	_
number	_	_
of	_	_
atoms	_	_
are	_	_
40	_	_
,	_	_
tracking	_	_
accuracy	_	_
is	_	_
74.5	_	_
%	_	_
while	_	_
we	_	_
obtain	_	_
a	_	_
higher	_	_
accuracy	_	_
of	_	_
78.2	_	_
%	_	_
when	_	_
the	_	_
number	_	_
of	_	_
atoms	_	_
are	_	_
30	_	_
.	_	_

#216
We	_	_
do	_	_
not	_	_
observe	_	_
a	_	_
similar	_	_
impact	_	_
from	_	_
varying	_	_
the	_	_
number	_	_
of	_	_
atoms	_	_
used	_	_
on	_	_
the	_	_
rest	_	_
of	_	_
sequences	_	_
.	_	_

#217
This	_	_
is	_	_
because	_	_
the	_	_
trajectories	_	_
of	_	_
targets	_	_
in	_	_
these	_	_
sequences	_	_
are	_	_
often	_	_
short	_	_
.	_	_

#218
We	_	_
further	_	_
observe	_	_
that	_	_
our	_	_
system	_	_
does	_	_
not	_	_
perform	_	_
well	_	_
in	_	_
sequences	_	_
that	_	_
appearances	_	_
of	_	_
targets	_	_
are	_	_
difficult	_	_
to	_	_
distinguish	_	_
such	_	_
as	_	_
when	_	_
targets	_	_
are	_	_
usually	_	_
small	_	_
,	_	_
affected	_	_
by	_	_
dark	_	_
light	_	_
,	_	_
or	_	_
are	_	_
blurred	_	_
by	_	_
abrupt	_	_
camera	_	_
motions	_	_
.	_	_

#219
The	_	_
tracking	_	_
accuracy	_	_
of	_	_
these	_	_
sequences	_	_
(	_	_
ADL-Rundle-8	_	_
and	_	_
Venice-2	_	_
)	_	_
are	_	_
-6	_	_
%	_	_
and	_	_
-11	_	_
%	_	_
respectively	_	_
.	_	_

#220
Note	_	_
that	_	_
negative	_	_
results	_	_
mean	_	_
that	_	_
the	_	_
sum	_	_
of	_	_
FP	_	_
,	_	_
FN	_	_
and	_	_
IDS	_	_
is	_	_
larger	_	_
than	_	_
the	_	_
ground	_	_
truth	_	_
detections	_	_
,	_	_
which	_	_
is	_	_
mostly	_	_
due	_	_
to	_	_
large	_	_
FP	_	_
and	_	_
FN	_	_
.	_	_

#221
Comparison	_	_
with	_	_
four	_	_
appearance	_	_
learning	_	_
algorithms	_	_
In	_	_
this	_	_
section	_	_
,	_	_
we	_	_
compare	_	_
the	_	_
results	_	_
of	_	_
our	_	_
appearance	_	_
learning	_	_
model	_	_
,	_	_
STKSVD	_	_
,	_	_
with	_	_
several	_	_
known	_	_
appearance	_	_
learning	_	_
algorithms	_	_
:	_	_
LCKSVD	_	_
[	_	_
8	_	_
]	_	_
,	_	_
ILDA	_	_
[	_	_
7	_	_
]	_	_
,	_	_
KSVD	_	_
[	_	_
13	_	_
]	_	_
,	_	_
and	_	_
[	_	_
7	_	_
]	_	_
which	_	_
uses	_	_
the	_	_
Bhattacharyya	_	_
distance	_	_
using	_	_
the	_	_
set	_	_
of	_	_
sequences	_	_
in	_	_
Figure	_	_
3	_	_
.	_	_

#222
All	_	_
the	_	_
above	_	_
algorithms	_	_
are	_	_
run	_	_
within	_	_
the	_	_
same	_	_
two-stage	_	_
association	_	_
tracking	_	_
system	_	_
.	_	_

#223
Table	_	_
1	_	_
shows	_	_
the	_	_
higher	_	_
average	_	_
accuracy	_	_
of	_	_
using	_	_
our	_	_
proposed	_	_
STKVD	_	_
on	_	_
the	_	_
11	_	_
video	_	_
sequences	_	_
.	_	_

#224
The	_	_
STKSVD	_	_
achieves	_	_
20	_	_
%	_	_
accuracy	_	_
while	_	_
Bhattacharyya	_	_
distance	_	_
,	_	_
LCKSVD	_	_
,	_	_
and	_	_
ILDA	_	_
achieve	_	_
18.4	_	_
%	_	_
,	_	_
17.5	_	_
%	_	_
and	_	_
17.5	_	_
%	_	_
accuracy	_	_
,	_	_
respectively	_	_
.	_	_

#225
It	_	_
is	_	_
also	_	_
of	_	_
interest	_	_
that	_	_
STKVD	_	_
also	_	_
has	_	_
better	_	_
average	_	_
ID	_	_
switch	_	_
metric	_	_
for	_	_
the	_	_
video	_	_
sequences	_	_
.	_	_

#226
Figure	_	_
4	_	_
compares	_	_
several	_	_
scenarios	_	_
where	_	_
STKSVD	_	_
produces	_	_
more	_	_
accurate	_	_
results	_	_
than	_	_
its	_	_
counterpart	_	_
.	_	_

#227
In	_	_
Figure	_	_
4-a	_	_
,	_	_
STKSVD	_	_
can	_	_
adaptively	_	_
re-identify	_	_
the	_	_
missing	_	_
target	_	_
“10”	_	_
under	_	_
partial	_	_
occlusion	_	_
while	_	_
LCKSVD	_	_
results	_	_
in	_	_
a	_	_
false	_	_
detection	_	_
(	_	_
on	_	_
target	_	_
“6”	_	_
)	_	_
and	_	_
misses	_	_
target	_	_
“10”	_	_
altogether	_	_
.	_	_

#228
Figure	_	_
4-b	_	_
shows	_	_
an	_	_
example	_	_
of	_	_
when	_	_
STKSVD	_	_
perform	_	_
better	_	_
during	_	_
camera’s	_	_
abrupt	_	_
motion	_	_
in	_	_
sequence	_	_
Figure	_	_
3	_	_
.	_	_

#229
Effects	_	_
of	_	_
different	_	_
number	_	_
of	_	_
dictionary	_	_
oms	_	_
on	_	_
tracking	_	_
accuracy	_	_
.	_	_

#230
ETH-SunnyDay	_	_
(	_	_
a	_	_
sequence	_	_
recorded	_	_
with	_	_
a	_	_
mobile	_	_
device	_	_
)	_	_
.	_	_

#231
As	_	_
we	_	_
see	_	_
,	_	_
STKSVD	_	_
is	_	_
able	_	_
to	_	_
re-identify	_	_
a	_	_
small	_	_
target	_	_
“9”	_	_
while	_	_
LCKSVD	_	_
completely	_	_
misses	_	_
it	_	_
.	_	_

#232
Figure	_	_
4-c	_	_
shows	_	_
a	_	_
case	_	_
where	_	_
STKSVD	_	_
outperforms	_	_
ILDA	_	_
when	_	_
target	_	_
“10”	_	_
changes	_	_
posture	_	_
.	_	_

#233
Tracking	_	_
System	_	_
Comparisons	_	_
:	_	_
In	_	_
this	_	_
section	_	_
,	_	_
we	_	_
compare	_	_
STKSVD	_	_
with	_	_
other	_	_
tracking	_	_
systems	_	_
:	_	_
TC	_	_
ODAL	_	_
[	_	_
4	_	_
]	_	_
and	_	_
GSCR	_	_
[	_	_
12	_	_
]	_	_
.	_	_

#234
TC_ODAL	_	_
is	_	_
a	_	_
tracking	_	_
system	_	_
that	_	_
is	_	_
not	_	_
a	_	_
dictionary	_	_
learning-based	_	_
method	_	_
but	_	_
uses	_	_
target	_	_
confidence	_	_
and	_	_
incremental	_	_
linear	_	_
discriminant	_	_
analysis	_	_
,	_	_
ILDA	_	_
,	_	_
for	_	_
online	_	_
target	_	_
appearance	_	_
learning	_	_
.	_	_

#235
GSCR	_	_
uses	_	_
accelerated	_	_
proximal	_	_
gradient	_	_
algorithm	_	_
for	_	_
learning	_	_
dictionary	_	_
D.	_	_
Similar	_	_
to	_	_
our	_	_
work	_	_
,	_	_
the	_	_
tracking	_	_
accuracy	_	_
of	_	_
these	_	_
methods	_	_
are	_	_
mostly	_	_
impacted	_	_
by	_	_
a	_	_
target	_	_
appearance	_	_
learning	_	_
model	_	_
.	_	_

#236
They	_	_
also	_	_
use	_	_
Kalman	_	_
filter	_	_
for	_	_
linear	_	_
motion	_	_
prediction	_	_
.	_	_

#237
The	_	_
experiment	_	_
is	_	_
conducted	_	_
on	_	_
several	_	_
sequences	_	_
in	_	_
2DMOT2015	_	_
dataset	_	_
as	_	_
shown	_	_
in	_	_
Table	_	_
2	_	_
and	_	_
shows	_	_
that	_	_
STKSVD	_	_
achieves	_	_
higher	_	_
accuracy	_	_
than	_	_
other	_	_
methods	_	_
in	_	_
every	_	_
case	_	_
.	_	_

#238
Furthermore	_	_
,	_	_
we	_	_
observe	_	_
better	_	_
(	_	_
i.e.	_	_
lower	_	_
)	_	_
FNs	_	_
and	_	_
IDS	_	_
in	_	_
several	_	_
sequences	_	_
with	_	_
STKSVD	_	_
except	_	_
for	_	_
the	_	_
PETS09S2L1	_	_
sequence	_	_
.	_	_

#239
However	_	_
,	_	_
in	_	_
PETS09S2L1	_	_
we	_	_
achieve	_	_
lower	_	_
FPs	_	_
,	_	_
which	_	_
also	_	_
results	_	_
in	_	_
a	_	_
higher	_	_
accuracy	_	_
in	_	_
general	_	_
.	_	_

#240
VI	_	_
.	_	_

#241
DISCUSSION	_	_
&	_	_
CONCLUSION	_	_
We	_	_
have	_	_
developed	_	_
a	_	_
new	_	_
spatial-temporal	_	_
KSVD	_	_
dictionary	_	_
learning	_	_
algorithm	_	_
STKSVD	_	_
,	_	_
for	_	_
target	_	_
appearance	_	_
learning	_	_
to	_	_
solve	_	_
online	_	_
multi-target	_	_
problem	_	_
.	_	_

#242
STKSVD	_	_
characterizes	_	_
the	_	_
spatial	_	_
and	_	_
temporal	_	_
dependencies	_	_
between	_	_
training	_	_
data	_	_
and	_	_
dictionary	_	_
atoms	_	_
.	_	_

#243
Thus	_	_
,	_	_
it	_	_
better	_	_
learns	_	_
a	_	_
discriminative	_	_
dictionary	_	_
.	_	_

#244
We	_	_
also	_	_
improve	_	_
the	_	_
overall	_	_
appearance	_	_
learning	_	_
method	_	_
by	_	_
using	_	_
two	_	_
different	_	_
methods	_	_
to	_	_
calculate	_	_
the	_	_
appearance	_	_
score	_	_
similarity	_	_
between	_	_
detections	_	_
and	_	_
targets	_	_
in	_	_
a	_	_
two-stage	_	_
associations	_	_
system	_	_
.	_	_

#245
Our	_	_
experiments	_	_
show	_	_
that	_	_
STKSVD	_	_
outperforms	_	_
its	_	_
counterpart	_	_
appearance	_	_
learning	_	_
methods	_	_
and	_	_
tracking	_	_
systems	_	_
.	_	_

#246
There	_	_
remain	_	_
several	_	_
limitations	_	_
to	_	_
be	_	_
addressed	_	_
as	_	_
we	_	_
further	_	_
development	_	_
our	_	_
work	_	_
:	_	_
•	_	_
The	_	_
performance	_	_
of	_	_
tracking-by-detection	_	_
methods	_	_
are	_	_
significantly	_	_
affected	_	_
by	_	_
human	_	_
detector	_	_
performance	_	_
.	_	_

#247
ACF	_	_
human	_	_
detector	_	_
that	_	_
we	_	_
used	_	_
in	_	_
this	_	_
work	_	_
often	_	_
fails	_	_
to	_	_
detect	_	_
up-close	_	_
and	_	_
large	_	_
targets	_	_
,	_	_
which	_	_
leads	_	_
to	_	_
tracking	_	_
failures	_	_
.	_	_

#248
It	_	_
is	_	_
reported	_	_
that	_	_
ACF	_	_
detectors	_	_
have	_	_
on	_	_
average	_	_
about	_	_
60	_	_
%	_	_
precision	_	_
and	_	_
46	_	_
%	_	_
recall	_	_
on	_	_
the	_	_
sequences	_	_
tested	_	_
[	_	_
29	_	_
]	_	_
.	_	_

#249
We	_	_
believe	_	_
that	_	_
as	_	_
better	_	_
human	_	_
detection	_	_
or	_	_
development	_	_
of	_	_
a	_	_
joint	_	_
tracking	_	_
and	_	_
(	_	_
a	_	_
)	_	_
Examples	_	_
on	_	_
PETS09S2L1	_	_
frame	_	_
12	_	_
,	_	_
where	_	_
STKVD	_	_
(	_	_
left	_	_
)	_	_
correctly	_	_
tracks	_	_
under	_	_
short-term	_	_
occlusion	_	_
compared	_	_
to	_	_
LCKSVD	_	_
(	_	_
right	_	_
)	_	_
(	_	_
b	_	_
)	_	_
Examples	_	_
on	_	_
ETH-Sunnyday	_	_
frame	_	_
82	_	_
,	_	_
where	_	_
STKVD	_	_
(	_	_
left	_	_
)	_	_
keeps	_	_
tracking	_	_
a	_	_
small	_	_
target	_	_
correctly	_	_
,	_	_
while	_	_
LCKSVD	_	_
(	_	_
right	_	_
)	_	_
lost	_	_
this	_	_
target	_	_
(	_	_
c	_	_
)	_	_
In	_	_
ADL-Rundle	_	_
6	_	_
frame	_	_
278	_	_
,	_	_
STKSVD	_	_
(	_	_
left	_	_
)	_	_
shows	_	_
better	_	_
performance	_	_
compared	_	_
to	_	_
ILDA	_	_
(	_	_
right	_	_
)	_	_
when	_	_
it	_	_
is	_	_
able	_	_
to	_	_
track	_	_
target	_	_
in	_	_
partial	_	_
occlusion	_	_
and	_	_
another	_	_
target	_	_
while	_	_
changing	_	_
posture	_	_
Figure	_	_
4	_	_
.	_	_

#250
Some	_	_
example	_	_
results	_	_
of	_	_
STKVD	_	_
compared	_	_
to	_	_
other	_	_
learning	_	_
methods	_	_
.	_	_

#251
Frames	_	_
are	_	_
slightly	_	_
cropped	_	_
out	_	_
for	_	_
better	_	_
viewing	_	_
detection	_	_
frameworks	_	_
will	_	_
improve	_	_
the	_	_
tracking	_	_
performance	_	_
significantly	_	_
.	_	_

#252
•	_	_
In	_	_
this	_	_
work	_	_
we	_	_
predict	_	_
human	_	_
detections	_	_
linearly	_	_
using	_	_
Kalman	_	_
filtering	_	_
[	_	_
31	_	_
]	_	_
which	_	_
often	_	_
fails	_	_
under	_	_
long-term	_	_
and	_	_
multi-target	_	_
occlusions	_	_
.	_	_

#253
These	_	_
are	_	_
often	_	_
scenarios	_	_
where	_	_
people’s	_	_
movements	_	_
are	_	_
unpredictable	_	_
.	_	_

#254
Using	_	_
STKSVD	_	_
with	_	_
non-linear	_	_
motion	_	_
models	_	_
(	_	_
e.g.	_	_
,	_	_
[	_	_
4	_	_
]	_	_
,	_	_
[	_	_
5	_	_
]	_	_
)	_	_
will	_	_
result	_	_
in	_	_
improved	_	_
tracking	_	_
performance	_	_
.	_	_