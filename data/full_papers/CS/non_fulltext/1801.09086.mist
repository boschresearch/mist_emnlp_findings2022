#0
A	_	_
Generative	_	_
Approach	_	_
to	_	_
Zero-Shot	_	_
and	_	_
Few-Shot	_	_
Action	_	_
Recognition	_	_
Ashish	_	_
Mishra∗,1	_	_
,	_	_
Vinay	_	_
Kumar	_	_
Verma†,1	_	_
,	_	_
M	_	_
Shiva	_	_
Krishna	_	_
Reddy∗	_	_
,	_	_
Arulkumar	_	_
S∗	_	_
Piyush	_	_
Rai†	_	_
and	_	_
Anurag	_	_
Mittal∗	_	_
∗Indian	_	_
Institute	_	_
of	_	_
Technology	_	_
Madras	_	_
†Indian	_	_
Institute	_	_
of	_	_
Technology	_	_
Kanpur	_	_
{	_	_
vkverma	_	_
,	_	_
piyush	_	_
}	_	_
@	_	_
cse.iitk.ac.in	_	_
,	_	_
{	_	_
mishra	_	_
,	_	_
shiva	_	_
,	_	_
aruls	_	_
,	_	_
amittal	_	_
}	_	_
@	_	_
cse.iitm.ac.in	_	_

#1
Abstract	_	_

#2
We	_	_
present	_	_
a	_	_
generative	_	_
framework	_	_
for	_	_
zero-shot	_	_
action	_	_
recognition	_	_
where	_	_
some	_	_
of	_	_
the	_	_
possible	_	_
action	_	_
classes	_	_
do	_	_
not	_	_
occur	_	_
in	_	_
the	_	_
training	_	_
data	_	_
.	_	_

#3
Our	_	_
approach	_	_
is	_	_
based	_	_
on	_	_
modeling	_	_
each	_	_
action	_	_
class	_	_
using	_	_
a	_	_
probability	_	_
distribution	_	_
whose	_	_
parameters	_	_
are	_	_
functions	_	_
of	_	_
the	_	_
attribute	_	_
vector	_	_
representing	_	_
that	_	_
action	_	_
class	_	_
.	_	_

#4
In	_	_
particular	_	_
,	_	_
we	_	_
assume	_	_
that	_	_
the	_	_
distribution	_	_
parameters	_	_
for	_	_
any	_	_
action	_	_
class	_	_
in	_	_
the	_	_
visual	_	_
space	_	_
can	_	_
be	_	_
expressed	_	_
as	_	_
a	_	_
linear	_	_
combination	_	_
of	_	_
a	_	_
set	_	_
of	_	_
basis	_	_
vectors	_	_
where	_	_
the	_	_
combination	_	_
weights	_	_
are	_	_
given	_	_
by	_	_
the	_	_
attributes	_	_
of	_	_
the	_	_
action	_	_
class	_	_
.	_	_

#5
These	_	_
basis	_	_
vectors	_	_
can	_	_
be	_	_
learned	_	_
solely	_	_
using	_	_
labeled	_	_
data	_	_
from	_	_
the	_	_
known	_	_
(	_	_
i.e.	_	_
,	_	_
previously	_	_
seen	_	_
)	_	_
action	_	_
classes	_	_
,	_	_
and	_	_
can	_	_
then	_	_
be	_	_
used	_	_
to	_	_
predict	_	_
the	_	_
parameters	_	_
of	_	_
the	_	_
probability	_	_
distributions	_	_
of	_	_
unseen	_	_
action	_	_
classes	_	_
.	_	_

#6
We	_	_
consider	_	_
two	_	_
settings	_	_
:	_	_
(	_	_
1	_	_
)	_	_
Inductive	_	_
setting	_	_
,	_	_
where	_	_
we	_	_
use	_	_
only	_	_
the	_	_
labeled	_	_
examples	_	_
of	_	_
the	_	_
seen	_	_
action	_	_
classes	_	_
to	_	_
predict	_	_
the	_	_
unseen	_	_
action	_	_
class	_	_
parameters	_	_
;	_	_
and	_	_
(	_	_
2	_	_
)	_	_
Transductive	_	_
setting	_	_
which	_	_
further	_	_
leverages	_	_
unlabeled	_	_
data	_	_
from	_	_
the	_	_
unseen	_	_
action	_	_
classes	_	_
.	_	_

#7
Our	_	_
framework	_	_
also	_	_
naturally	_	_
extends	_	_
to	_	_
few-shot	_	_
action	_	_
recognition	_	_
where	_	_
a	_	_
few	_	_
labelled	_	_
examples	_	_
from	_	_
unseen	_	_
classes	_	_
are	_	_
available	_	_
.	_	_

#8
Our	_	_
experiments	_	_
on	_	_
benchmark	_	_
datasets	_	_
(	_	_
UCF101	_	_
,	_	_
HMDB51	_	_
and	_	_
Olympic	_	_
)	_	_
show	_	_
significant	_	_
performance	_	_
improvements	_	_
as	_	_
compared	_	_
to	_	_
various	_	_
baselines	_	_
,	_	_
in	_	_
both	_	_
standard	_	_
zero-shot	_	_
(	_	_
disjoint	_	_
seen	_	_
and	_	_
unseen	_	_
classes	_	_
)	_	_
and	_	_
generalized	_	_
zero-shot	_	_
learning	_	_
settings	_	_
.	_	_

#9
1	_	_
.	_	_

#10
Introduction	_	_
Action	_	_
Recognition	_	_
is	_	_
an	_	_
important	_	_
problem	_	_
in	_	_
Computer	_	_
Vision	_	_
in	_	_
which	_	_
knowledge	_	_
about	_	_
a	_	_
sequence	_	_
of	_	_
actions	_	_
is	_	_
learned	_	_
from	_	_
a	_	_
large	_	_
collection	_	_
of	_	_
video	_	_
clips	_	_
.	_	_

#11
It	_	_
is	_	_
a	_	_
challenging	_	_
task	_	_
due	_	_
to	_	_
the	_	_
inherent	_	_
variability	_	_
in	_	_
actions	_	_
,	_	_
non-deterministic	_	_
occlusion	_	_
patterns	_	_
,	_	_
abrupt	_	_
changes	_	_
in	_	_
illumination	_	_
,	_	_
cluttered	_	_
dynamic	_	_
background	_	_
,	_	_
and	_	_
noisy	_	_
videos	_	_
.	_	_

#12
Knowledge	_	_
about	_	_
an	_	_
action	_	_
is	_	_
inferred	_	_
usually	_	_
by	_	_
learning	_	_
from	_	_
the	_	_
labelled	_	_
data	_	_
in	_	_
a	_	_
supervised	_	_
manner	_	_
.	_	_

#13
Even	_	_
as	_	_
1Both	_	_
authors	_	_
contributed	_	_
equally	_	_
.	_	_

#14
more	_	_
complex	_	_
models	_	_
are	_	_
being	_	_
built	_	_
,	_	_
it	_	_
is	_	_
a	_	_
common	_	_
observation	_	_
that	_	_
the	_	_
number	_	_
of	_	_
categories	_	_
of	_	_
actions	_	_
is	_	_
progressively	_	_
increasing	_	_
(	_	_
for	_	_
example	_	_
,	_	_
one	_	_
of	_	_
the	_	_
earliest	_	_
benchmark	_	_
datasets	_	_
KTH	_	_
has	_	_
6	_	_
categories	_	_
while	_	_
Olympic	_	_
,	_	_
HMDB	_	_
and	_	_
UCF	_	_
datasets	_	_
have	_	_
16	_	_
,	_	_
51	_	_
,	_	_
and	_	_
101	_	_
categories	_	_
,	_	_
respectively	_	_
)	_	_
.	_	_

#15
Consequently	_	_
,	_	_
annotating	_	_
videos	_	_
of	_	_
this	_	_
growing	_	_
number	_	_
of	_	_
categories	_	_
can	_	_
be	_	_
a	_	_
very	_	_
cumbersome	_	_
task	_	_
and	_	_
consequently	_	_
restricts	_	_
the	_	_
scalability	_	_
of	_	_
a	_	_
fully	_	_
supervised	_	_
action	_	_
recognition	_	_
for	_	_
a	_	_
large	_	_
number	_	_
of	_	_
categories	_	_
.	_	_

#16
To	_	_
circumvent	_	_
this	_	_
problem	_	_
,	_	_
Zero-Shot	_	_
Learning	_	_
(	_	_
ZSL	_	_
)	_	_
of	_	_
actions	_	_
has	_	_
been	_	_
actively	_	_
pursued	_	_
[	_	_
35	_	_
,	_	_
34	_	_
,	_	_
21	_	_
]	_	_
.	_	_

#17
In	_	_
the	_	_
conventional	_	_
Action	_	_
Recognition	_	_
framework	_	_
,	_	_
only	_	_
the	_	_
classes	_	_
present	_	_
in	_	_
the	_	_
training	_	_
data	_	_
can	_	_
be	_	_
recognized	_	_
by	_	_
the	_	_
model	_	_
during	_	_
the	_	_
test	_	_
phase	_	_
.	_	_

#18
In	_	_
Zero-Shot	_	_
Learning	_	_
,	_	_
however	_	_
,	_	_
the	_	_
model	_	_
is	_	_
expected	_	_
to	_	_
recognize	_	_
and	_	_
categorize	_	_
action	_	_
classes	_	_
that	_	_
did	_	_
not	_	_
appear	_	_
in	_	_
the	_	_
training	_	_
phase	_	_
at	_	_
all	_	_
.	_	_

#19
The	_	_
information	_	_
about	_	_
the	_	_
unseen	_	_
classes	_	_
is	_	_
provided	_	_
via	_	_
other	_	_
modalities	_	_
such	_	_
as	_	_
language	_	_
in	_	_
the	_	_
form	_	_
of	_	_
textual	_	_
descriptions	_	_
,	_	_
word2vec	_	_
[	_	_
19	_	_
]	_	_
or	_	_
human	_	_
annotated	_	_
attributes	_	_
.	_	_

#20
Essentially	_	_
,	_	_
the	_	_
model	_	_
has	_	_
to	_	_
learn	_	_
to	_	_
recognize	_	_
the	_	_
unseen	_	_
action	_	_
classes	_	_
based	_	_
on	_	_
the	_	_
knowledge	_	_
acquired	_	_
from	_	_
the	_	_
data	_	_
instances	_	_
of	_	_
the	_	_
seen	_	_
action	_	_
classes	_	_
.	_	_

#21
Zero-shot	_	_
learning	_	_
is	_	_
typically	_	_
defined	_	_
in	_	_
two	_	_
settings	_	_
:	_	_
(	_	_
1	_	_
)	_	_
the	_	_
conventional	_	_
setting	_	_
,	_	_
in	_	_
which	_	_
set	_	_
of	_	_
classes	_	_
for	_	_
the	_	_
training	_	_
and	_	_
test	_	_
instances	_	_
are	_	_
disjoint	_	_
(	_	_
Ytr	_	_
∩	_	_
Tte	_	_
=	_	_
∅	_	_
)	_	_
;	_	_
and	_	_
(	_	_
2	_	_
)	_	_
the	_	_
generalized	_	_
zero-shot	_	_
(	_	_
GZSL	_	_
)	_	_
setting	_	_
,	_	_
in	_	_
which	_	_
the	_	_
set	_	_
of	_	_
classes	_	_
for	_	_
the	_	_
training	_	_
and	_	_
test	_	_
instances	_	_
may	deontic-options	_
have	_	_
an	_	_
overlap	_	_
[	_	_
16	_	_
,	_	_
20	_	_
]	_	_
.	_	_

#22
The	_	_
generalized	_	_
zero-shot	_	_
setting	_	_
is	_	_
considered	_	_
much	_	_
harder	_	_
than	_	_
standard	_	_
setting	_	_
(	_	_
disjoint	_	_
setting	_	_
)	_	_
since	_	_
the	_	_
learned	_	_
models	_	_
tend	_	_
to	_	_
be	_	_
biased	_	_
towards	_	_
predicting	_	_
seen	_	_
classes	_	_
at	_	_
training	_	_
time	_	_
(	_	_
as	_	_
they	_	_
are	_	_
learned	_	_
solely	_	_
from	_	_
the	_	_
unseen	_	_
class	_	_
training	_	_
data	_	_
)	_	_
.	_	_

#23
While	_	_
much	_	_
of	_	_
the	_	_
prior	_	_
work	_	_
in	_	_
ZSL	_	_
has	_	_
focused	_	_
on	_	_
the	_	_
conventional	_	_
setting	_	_
,	_	_
the	_	_
focus	_	_
has	_	_
recently	_	_
shifted	_	_
to	_	_
the	_	_
more	_	_
realistic	_	_
GZSL	_	_
setting	_	_
.	_	_

#24
In	_	_
this	_	_
work	_	_
,	_	_
we	_	_
present	_	_
a	_	_
simple	_	_
generative	_	_
approach	_	_
for	_	_
zero	_	_
shot	_	_
action	_	_
recognition	_	_
,	_	_
which	_	_
works	_	_
in	_	_
both	_	_
standard	_	_
as	_	_
well	_	_
as	_	_
generalized	_	_
ZSL	_	_
setting	_	_
.	_	_

#25
Our	_	_
approach	_	_
models	_	_
each	_	_
action	_	_
class	_	_
as	_	_
a	_	_
probability	_	_
distribution	_	_
in	_	_
the	_	_
visual	_	_
space	_	_
where	_	_
the	_	_
parameters	_	_
of	_	_
this	_	_
distribution	_	_
are	_	_
assumed	_	_
to	_	_
be	_	_
a	_	_
linear	_	_
combination	_	_
of	_	_
a	_	_
set	_	_
of	_	_
“basis”	_	_
parameters	_	_
,	_	_
ar	_	_
X	_	_
iv	_	_
:1	_	_
1	_	_
.	_	_

#26
6v	_	_
1	_	_
[	_	_
cs	_	_
.C	_	_
V	_	_
]	_	_
2	_	_
7	_	_
Ja	_	_
n	_	_
Figure	_	_
1	_	_
.	_	_

#27
Proposed	_	_
Model	_	_
:	_	_
Each	_	_
class	_	_
attribute	_	_
is	_	_
projected	_	_
to	_	_
the	_	_
visual	_	_
space	_	_
,	_	_
In	_	_
the	_	_
visual	_	_
space	_	_
each	_	_
class	_	_
is	_	_
represented	_	_
by	_	_
a	_	_
Gaussian	_	_
distribution	_	_
.	_	_

#28
To	_	_
avoid	_	_
information	_	_
loss	_	_
,	_	_
a	_	_
reconstruction	_	_
regularizer	_	_
is	_	_
added	_	_
.	_	_

#29
where	_	_
the	_	_
combination	_	_
weights	_	_
are	_	_
given	_	_
by	_	_
the	_	_
(	_	_
known	_	_
)	_	_
attribute	_	_
vector	_	_
of	_	_
that	_	_
class	_	_
.	_	_

#30
This	_	_
is	_	_
akin	_	_
to	_	_
assuming	_	_
that	_	_
each	_	_
action	_	_
class	_	_
can	_	_
be	_	_
represented	_	_
as	_	_
a	_	_
combination	_	_
of	_	_
a	_	_
set	_	_
of	_	_
“prototype”	_	_
action	_	_
classes	_	_
.	_	_

#31
The	_	_
complete	_	_
architecture	_	_
of	_	_
our	_	_
model	_	_
is	_	_
shown	_	_
in	_	_
Fig.	_	_
1	_	_
.	_	_

#32
Once	_	_
the	_	_
basis	_	_
vectors	_	_
are	_	_
learned	_	_
using	_	_
the	_	_
training	_	_
instances	_	_
from	_	_
seen	_	_
action	_	_
classes	_	_
,	_	_
the	_	_
parameters	_	_
of	_	_
an	_	_
unseen	_	_
action	_	_
class	_	_
distribution	_	_
can	_	_
be	_	_
easily	_	_
computed	_	_
via	_	_
a	_	_
weighted	_	_
combination	_	_
of	_	_
the	_	_
learned	_	_
basis	_	_
vectors	_	_
,	_	_
with	_	_
weights	_	_
being	_	_
the	_	_
attributes	_	_
of	_	_
the	_	_
respective	_	_
unseen	_	_
class	_	_
.	_	_

#33
The	_	_
loss	_	_
function	_	_
(	_	_
More	_	_
details	_	_
in	_	_
Methodology	_	_
section	_	_
)	_	_
is	_	_
formulated	_	_
in	_	_
such	_	_
a	_	_
way	_	_
that	_	_
,	_	_
for	_	_
each	_	_
seen	_	_
action	_	_
class	_	_
,	_	_
the	_	_
weighted	_	_
combination	_	_
of	_	_
the	_	_
basis	_	_
vectors	_	_
is	_	_
close	_	_
to	_	_
the	_	_
maximum	_	_
likelihood	_	_
estimate	_	_
(	_	_
MLE	_	_
)	_	_
of	_	_
the	_	_
class	_	_
distribution’s	_	_
parameters	_	_
.	_	_

#34
The	_	_
MLE	_	_
estimate	_	_
can	_	_
also	_	_
be	_	_
replaced	_	_
by	_	_
maximum-a-posteriori	_	_
(	_	_
MAP	_	_
)	_	_
estimate	_	_
.	_	_

#35
Our	_	_
approach	_	_
is	_	_
akin	_	_
to	_	_
the	_	_
one	_	_
proposed	_	_
recently	_	_
in	_	_
[	_	_
29	_	_
]	_	_
for	_	_
zero-shot	_	_
learning	_	_
,	_	_
though	_	_
our	_	_
focus	_	_
an	_	_
application	_	_
is	_	_
specifically	_	_
the	_	_
zero-shot	_	_
action	_	_
recognition	_	_
problem	_	_
.	_	_

#36
In	_	_
addition	_	_
,	_	_
we	_	_
add	_	_
an	_	_
additional	_	_
“reverse	_	_
direction”	_	_
regularizer	_	_
to	_	_
encourage	_	_
reconstruction	_	_
ability	_	_
of	_	_
the	_	_
class	_	_
attribute	_	_
vectors	_	_
from	_	_
the	_	_
parameters	_	_
of	_	_
the	_	_
seen	_	_
class	_	_
distributions	_	_
so	_	_
as	_	_
to	_	_
minimize	_	_
the	_	_
information	_	_
loss	_	_
.	_	_

#37
Note	_	_
that	_	_
this	_	_
is	_	_
akin	_	_
to	_	_
an	_	_
autoencoder	_	_
(	_	_
cf	_	_
,	_	_
Fig.	_	_
1	_	_
)	_	_
.	_	_

#38
One	_	_
of	_	_
the	_	_
appealing	_	_
aspects	_	_
of	_	_
our	_	_
model	_	_
is	_	_
that	_	_
it	_	_
admits	_	_
a	_	_
simple	_	_
closed-form	_	_
solution	_	_
.	_	_

#39
Our	_	_
main	_	_
contributions	_	_
can	_	_
be	_	_
summarized	_	_
as	_	_
follows	_	_
•	_	_
We	_	_
provide	_	_
a	_	_
probabilistic	_	_
generative	_	_
approach	_	_
for	_	_
zero-shot	_	_
learning	_	_
(	_	_
ZSL	_	_
)	_	_
where	_	_
each	_	_
action	_	_
class	_	_
is	_	_
represented	_	_
by	_	_
a	_	_
Gaussian	_	_
distribution	_	_
(	_	_
although	_	_
the	_	_
Gaussian	_	_
can	_	_
be	_	_
replaced	_	_
by	_	_
other	_	_
distributions	_	_
without	_	_
changing	_	_
the	_	_
rest	_	_
of	_	_
our	_	_
model	_	_
)	_	_
.	_	_

#40
•	_	_
We	_	_
show	_	_
that	_	_
our	_	_
approach	_	_
,	_	_
although	_	_
simple	_	_
,	_	_
generalizes	_	_
well	_	_
to	_	_
the	_	_
unseen	_	_
classes	_	_
in	_	_
the	_	_
inductive	_	_
setting	_	_
and	_	_
improves	_	_
over	_	_
the	_	_
state-of-the-art	_	_
.	_	_

#41
•	_	_
We	_	_
show	_	_
that	_	_
our	_	_
approach	_	_
can	_	_
be	_	_
easily	_	_
generalized	_	_
to	_	_
the	_	_
transductive	_	_
setting	_	_
where	_	_
unlabeled	_	_
data	_	_
from	_	_
unseen	_	_
classes	_	_
are	_	_
available	_	_
at	_	_
training	_	_
time	_	_
.	_	_

#42
•	_	_
Our	_	_
model	_	_
also	_	_
naturally	_	_
extends	_	_
to	_	_
be	_	_
“few-shot	_	_
learning”	_	_
setting	_	_
where	_	_
a	_	_
few	_	_
examples	_	_
of	_	_
each	_	_
unseen	_	_
class	_	_
are	_	_
available	_	_
as	_	_
well	_	_
.	_	_

#43
In	_	_
particular	_	_
,	_	_
the	_	_
parameters	_	_
of	_	_
the	_	_
class	_	_
distribution	_	_
can	_	_
be	_	_
updated	_	_
easily	_	_
given	_	_
a	_	_
few	_	_
additional	_	_
labeled	_	_
examples	_	_
from	_	_
that	_	_
class	_	_
.	_	_

#44
Through	_	_
extensive	_	_
experimentation	_	_
on	_	_
three	_	_
benchmark	_	_
datasets	_	_
,	_	_
we	_	_
show	_	_
that	_	_
our	_	_
simple	_	_
approach	_	_
gives	_	_
significant	_	_
performance	_	_
gains	_	_
in	_	_
all	_	_
three	_	_
settings	_	_
over	_	_
the	_	_
state-of-the-art	_	_
methods	_	_
.	_	_

#45
•	_	_
Finally	_	_
,	_	_
since	_	_
our	_	_
approach	_	_
is	_	_
generative	_	_
,	_	_
we	_	_
can	_	_
also	_	_
synthesize	_	_
novel	_	_
examples	_	_
for	_	_
any	_	_
unseen	_	_
class	_	_
by	_	_
sampling	_	_
from	_	_
the	_	_
respective	_	_
class	_	_
distribution	_	_
.	_	_

#46
Since	_	_
we	_	_
can	_	_
now	_	_
have	_	_
labeled	_	_
data	_	_
from	_	_
seen	_	_
as	_	_
well	_	_
as	_	_
unseen	_	_
classes	_	_
,	_	_
it	_	_
is	_	_
possible	_	_
to	_	_
train	_	_
a	_	_
classifier	_	_
in	_	_
the	_	_
generalized	_	_
zero-shot	_	_
setting	_	_
which	_	_
is	_	_
much	_	_
harder	_	_
than	_	_
the	_	_
standard	_	_
(	_	_
disjoint	_	_
)	_	_
setting	_	_
.	_	_

#47
2	_	_
.	_	_

#48
Methodology	_	_
For	_	_
the	_	_
zero-shot	_	_
action	_	_
recognition	_	_
setting	_	_
,	_	_
we	_	_
denote	_	_
the	_	_
total	_	_
number	_	_
of	_	_
seen	_	_
action	_	_
classes	_	_
by	_	_
S	_	_
and	_	_
the	_	_
total	_	_
number	_	_
of	_	_
unseen	_	_
action	_	_
classes	_	_
by	_	_
U	_	_
.	_	_

#49
We	_	_
take	_	_
a	_	_
generative	_	_
classification	_	_
based	_	_
approach	_	_
to	_	_
the	_	_
action	_	_
recognition	_	_
problem	_	_
where	_	_
we	_	_
assume	_	_
that	_	_
the	_	_
data	_	_
instances	_	_
of	_	_
each	_	_
action	_	_
class	_	_
(	_	_
seen/unseen	_	_
)	_	_
c	_	_
are	_	_
generated	_	_
by	_	_
a	_	_
distribution	_	_
p	_	_
(	_	_
x|θc	_	_
)	_	_
.	_	_

#50
Without	_	_
loss	_	_
of	_	_
generality	_	_
,	_	_
and	_	_
for	_	_
simplicity	_	_
of	_	_
exposition	_	_
,	_	_
we	_	_
will	_	_
assume	_	_
these	_	_
distributions	_	_
to	_	_
be	_	_
Gaussians	_	_
(	_	_
note	_	_
that	_	_
our	_	_
approach	_	_
can	_	_
be	_	_
used	_	_
with	_	_
other	_	_
distributions	_	_
as	_	_
well	_	_
)	_	_
.	_	_

#51
In	_	_
the	_	_
Gaussian	_	_
case	_	_
,	_	_
the	_	_
parameters	_	_
θc	_	_
consist	_	_
of	_	_
the	_	_
mean	_	_
vector	_	_
µc	_	_
∈	_	_
RD	_	_
and	_	_
a	_	_
diagonal	_	_
covariance	_	_
matrix	_	_
Σc	_	_
=	_	_
diag	_	_
(	_	_
σ2	_	_
c	_	_
)	_	_
,	_	_
where	_	_
σ2	_	_
c	_	_
∈	_	_
RD+	_	_
.	_	_

#52
We	_	_
assume	_	_
a	_	_
diagonal	_	_
covariance	_	_
matrix	_	_
to	_	_
reduce	_	_
the	_	_
total	_	_
number	_	_
of	_	_
parameter	_	_
estimated	_	_
and	_	_
prevent	_	_
overfitting	_	_
especially	_	_
when	_	_
the	_	_
number	_	_
of	_	_
examples	_	_
from	_	_
each	_	_
class	_	_
is	_	_
small	_	_
.	_	_

#53
However	_	_
,	_	_
other	_	_
forms	_	_
for	_	_
the	_	_
covariance	_	_
matrix	_	_
can	_	_
also	_	_
be	_	_
used	_	_
.	_	_

#54
Given	_	_
labeled	_	_
data	_	_
from	_	_
the	_	_
seen	_	_
classes	_	_
,	_	_
it	_	_
is	_	_
straight-forward	_	_
to	_	_
estimate	_	_
the	_	_
parameters	_	_
µc	_	_
,	_	_
σc	_	_
using	_	_
Maximum	_	_
Likelihood	_	_
Estimation	_	_
(	_	_
MLE	_	_
)	_	_
or	_	_
MaximumaPosteriori	_	_
(	_	_
MAP	_	_
)	_	_
estimation	_	_
.	_	_

#55
For	_	_
example	_	_
,	_	_
using	_	_
MLE	_	_
,	_	_
the	_	_
mean	_	_
is	_	_
estimated	_	_
as	_	_
µc	_	_
=	_	_
1	_	_
Nc	_	_
∑Nc	_	_
i=1	_	_
xi	_	_
and	_	_
σ2	_	_
c	_	_
=	_	_
diag	_	_
(	_	_
1	_	_
Nc	_	_
∑Nc	_	_
i=1	_	_
(	_	_
xi	_	_
−	_	_
µc	_	_
)	_	_
(	_	_
xi	_	_
−	_	_
µc	_	_
)	_	_
>	_	_
)	_	_
whereNc	_	_
denotes	_	_
the	_	_
number	_	_
of	_	_
labeled	_	_
examples	_	_
from	_	_
class	_	_
c.	_	_
However	_	_
,	_	_
this	_	_
approach	_	_
can	_	_
not	_	_
be	_	_
used	_	_
to	_	_
estimate	_	_
the	_	_
parameters	_	_
θc	_	_
(	_	_
c	_	_
=	_	_
S	_	_
+	_	_
1	_	_
,	_	_
...	_	_
,	_	_
S	_	_
+	_	_
U	_	_
)	_	_
of	_	_
unseen	_	_
classes	_	_
due	_	_
to	_	_
unavailability	_	_
of	_	_
labeled	_	_
data	_	_
corresponding	_	_
to	_	_
unseen	_	_
classes	_	_
.	_	_

#56
To	_	_
resolve	_	_
this	_	_
problem	_	_
,	_	_
we	_	_
model	_	_
the	_	_
parameters	_	_
θc	_	_
=	_	_
(	_	_
µc	_	_
,	_	_
σ	_	_
c	_	_
)	_	_
of	_	_
each	_	_
seen/unseen	_	_
clas	_	_
as	_	_
a	_	_
function	_	_
of	_	_
the	_	_
respective	_	_
class	_	_
attribute	_	_
vector	_	_
ac	_	_
,	_	_
i.e.	_	_
,	_	_
θc	_	_
=	_	_
f	_	_
(	_	_
ac	_	_
)	_	_
.	_	_

#57
In	_	_
the	_	_
zero-shot	_	_
learning	_	_
setting	_	_
,	_	_
the	_	_
class	_	_
attribute	_	_
vector	_	_
ac	_	_
∈	_	_
RK	_	_
is	_	_
either	_	_
provided	_	_
by	_	_
a	_	_
human	_	_
expert	_	_
or	_	_
as	_	_
the	_	_
WORD2VEC	_	_
embedding	_	_
of	_	_
the	_	_
name	_	_
of	_	_
the	_	_
action	_	_
.	_	_

#58
The	_	_
function	_	_
f	_	_
can	_	_
be	_	_
linear	_	_
or	_	_
nonlinear	_	_
and	_	_
can	_	_
be	_	_
learned	_	_
using	_	_
the	_	_
labeled	_	_
data	_	_
instances	_	_
of	_	_
seen	_	_
classes	_	_
in	_	_
visual	_	_
feature	_	_
space	_	_
.	_	_

#59
Once	_	_
learned	_	_
,	_	_
the	_	_
function	_	_
f	_	_
can	_	_
be	_	_
used	_	_
to	_	_
predict	_	_
θc	_	_
for	_	_
all	_	_
the	_	_
unseen	_	_
class	_	_
actions	_	_
c	_	_
=	_	_
S	_	_
+	_	_
1	_	_
,	_	_
.	_	_

#60
.	_	_

#61
.	_	_

#62
,	_	_
S	_	_
+	_	_
U	_	_
using	_	_
their	_	_
respective	_	_
class	_	_
attributes	_	_
.	_	_

#63
A	_	_
simple	_	_
choice	_	_
of	_	_
f	_	_
is	_	_
a	_	_
linear	_	_
model	_	_
that	_	_
maps	_	_
the	_	_
class	_	_
attributes	_	_
ac	_	_
to	_	_
the	_	_
class	_	_
parameters	_	_
θc	_	_
.	_	_

#64
In	_	_
the	_	_
Gaussian	_	_
class	_	_
distribution	_	_
case	_	_
,	_	_
for	_	_
the	_	_
mean	_	_
µc	_	_
,	_	_
such	_	_
a	_	_
linear	_	_
function	_	_
f	_	_
can	_	_
be	_	_
defined	_	_
as	_	_
µc	_	_
=	_	_
fµ	_	_
(	_	_
ac	_	_
)	_	_
=	_	_
Wµac	_	_
(	_	_
1	_	_
)	_	_
Note	_	_
that	_	_
the	_	_
above	_	_
linear	_	_
model	_	_
represents	_	_
the	_	_
mean	_	_
µc	_	_
∈	_	_
RD	_	_
as	_	_
a	_	_
weighted	_	_
linear	_	_
combination	_	_
of	_	_
K	_	_
basis	_	_
vectors	_	_
Wµ	_	_
=	_	_
[	_	_
wµ1	_	_
,	_	_
wµ2	_	_
,	_	_
..	_	_
,	_	_
wµK	_	_
]	_	_
∈	_	_
RD×K	_	_
is	_	_
a	_	_
set	_	_
of	_	_
learned	_	_
basis	_	_
vectors	_	_
in	_	_
the	_	_
visual	_	_
space	_	_
.	_	_

#65
The	_	_
basis	_	_
vectors	_	_
Wµ	_	_
can	_	_
be	_	_
learned	_	_
using	_	_
the	_	_
seen	_	_
class	_	_
training	_	_
data	_	_
.	_	_

#66
In	_	_
particular	_	_
,	_	_
given	_	_
the	_	_
empirical	_	_
estimates	_	_
µ̂c	_	_
,	_	_
c	_	_
=	_	_
1	_	_
,	_	_
.	_	_

#67
.	_	_

#68
.	_	_

#69
,	_	_
S	_	_
of	_	_
means	_	_
of	_	_
the	_	_
seen	_	_
class	_	_
distributions	_	_
,	_	_
we	_	_
can	_	_
use	_	_
(	_	_
ac	_	_
,	_	_
µ̂c	_	_
)	_	_
as	_	_
“training	_	_
data”	_	_
to	_	_
learn	_	_
the	_	_
regression	_	_
model	_	_
Wµ	_	_
that	_	_
maps	_	_
ac	_	_
to	_	_
µ̂c	_	_
.	_	_

#70
While	_	_
the	_	_
above	_	_
model	_	_
can	_	_
be	_	_
seen	_	_
as	_	_
mapping	_	_
the	_	_
class	_	_
attribute	_	_
vector	_	_
ac	_	_
to	_	_
the	_	_
class	_	_
mean	_	_
µc	_	_
,	_	_
we	_	_
further	_	_
impose	_	_
the	_	_
condition	_	_
that	_	_
the	_	_
class	_	_
means	_	_
can	_	_
also	_	_
be	_	_
used	_	_
to	_	_
reconstruct	_	_
the	_	_
class	_	_
attribute	_	_
vector	_	_
via	_	_
a	_	_
“reverse	_	_
map”	_	_
akin	_	_
to	_	_
an	_	_
autoencoder	_	_
,	_	_
i.e.	_	_
,	_	_
ac	_	_
=	_	_
WT	_	_
µµc	_	_
,	_	_
which	_	_
leads	_	_
to	_	_
µc	_	_
=	_	_
Wµac	_	_
=	_	_
WµW	_	_
>	_	_
µµc	_	_
(	_	_
2	_	_
)	_	_
A	_	_
similar	_	_
procedure	_	_
can	_	_
be	_	_
employed	_	_
for	_	_
learning	_	_
the	_	_
mapping	_	_
from	_	_
the	_	_
class	_	_
attributes	_	_
ac	_	_
to	_	_
the	_	_
variance	_	_
parameters	_	_
σ2	_	_
c	_	_
of	_	_
the	_	_
distribution	_	_
of	_	_
class	_	_
c	_	_
via	_	_
another	_	_
set	_	_
of	_	_
basis	_	_
vectors	_	_
Wσ2	_	_
.	_	_

#71
Sections	_	_
2.1	_	_
and	_	_
2.2	_	_
provide	_	_
more	_	_
details	_	_
.	_	_

#72
Once	_	_
the	_	_
basis	_	_
vectors	_	_
Wµ	_	_
,	_	_
Wσ2	_	_
(	_	_
which	_	_
define	_	_
the	_	_
functions	_	_
fµ	_	_
and	_	_
fσ	_	_
)	_	_
are	_	_
learned	_	_
,	_	_
we	_	_
can	_	_
use	_	_
them	_	_
to	_	_
estimate	_	_
the	_	_
parameters	_	_
(	_	_
e.g.	_	_
,	_	_
µc	_	_
,	_	_
σ2	_	_
c	_	_
)	_	_
of	_	_
the	_	_
distribution	_	_
of	_	_
each	_	_
unseen	_	_
class	_	_
.	_	_

#73
For	_	_
example	_	_
,	_	_
given	_	_
the	_	_
class	_	_
attribute	_	_
vector	_	_
ac	_	_
of	_	_
an	_	_
unseen	_	_
class	_	_
c	_	_
=	_	_
S	_	_
+	_	_
1	_	_
,	_	_
.	_	_

#74
.	_	_

#75
.	_	_

#76
,	_	_
S	_	_
+U	_	_
,	_	_
we	_	_
can	_	_
estimate	_	_
µc	_	_
simply	_	_
as	_	_
µc	_	_
=	_	_
Wµac	_	_
.	_	_

#77
The	_	_
mapping	_	_
f	_	_
(	_	_
which	_	_
is	_	_
essentially	_	_
a	_	_
regression	_	_
model	_	_
)	_	_
from	_	_
the	_	_
class	_	_
attribute	_	_
vector	_	_
to	_	_
the	_	_
parameters	_	_
of	_	_
the	_	_
class	_	_
distribution	_	_
can	_	_
be	_	_
linear	_	_
or	_	_
nonlinear	_	_
.	_	_

#78
We	_	_
describe	_	_
both	_	_
these	_	_
cases	_	_
in	_	_
the	_	_
next	_	_
two	_	_
sections	_	_
.	_	_

#79
2.1	_	_
.	_	_

#80
Linear	_	_
Regression	_	_
Given	_	_
the	_	_
labeled	_	_
data	_	_
from	_	_
seen	_	_
classes	_	_
c	_	_
=	_	_
1	_	_
,	_	_
...	_	_
,	_	_
S	_	_
,	_	_
we	_	_
can	_	_
estimate	_	_
their	_	_
class	_	_
distribution	_	_
parameters	_	_
using	_	_
MLE	_	_
.	_	_

#81
We	_	_
can	_	_
then	_	_
learn	_	_
the	_	_
functions	_	_
fµ	_	_
and	_	_
fσ2	_	_
using	_	_
training	_	_
data	_	_
of	_	_
the	_	_
form	_	_
(	_	_
ac	_	_
,	_	_
µc	_	_
)	_	_
S	_	_
c=1	_	_
and	_	_
(	_	_
ac	_	_
,	_	_
σ	_	_
c	_	_
)	_	_
S	_	_
c=1	_	_
.	_	_

#82
In	_	_
the	_	_
linear	_	_
regression	_	_
approach	_	_
µc	_	_
=	_	_
fµ	_	_
(	_	_
ac	_	_
)	_	_
and	_	_
σ2	_	_
c	_	_
=	_	_
fσ	_	_
(	_	_
ac	_	_
)	_	_
,	_	_
we	_	_
assume	_	_
the	_	_
functions	_	_
fµ	_	_
and	_	_
fσ	_	_
to	_	_
be	_	_
linear	_	_
projections	_	_
with	_	_
weight	_	_
matrices	_	_
,	_	_
Wµ	_	_
and	_	_
Wσ	_	_
,	_	_
making	_	_
this	_	_
problem	_	_
equivalent	_	_
to	_	_
the	_	_
following	_	_
regression	_	_
problem	_	_
:	_	_
µc	_	_
=	_	_
Wµac	_	_
s.t	_	_
.	_	_

#83
ac	_	_
=	_	_
WT	_	_
µµc	_	_
ρc	_	_
=	_	_
logσ2	_	_
c	_	_
=	_	_
Wσ2ac	_	_
s.t	_	_
.	_	_

#84
ac	_	_
=	_	_
WT	_	_
σ2σ2	_	_
c	_	_
The	_	_
projection	_	_
matrices	_	_
Wµ	_	_
and	_	_
Wσ2	_	_
can	_	_
be	_	_
easily	_	_
learned	_	_
using	_	_
a	_	_
multi-output	_	_
ridge	_	_
regression	_	_
problem	_	_
with	_	_
training	_	_
data	_	_
(	_	_
ac	_	_
,	_	_
µc	_	_
)	_	_
S	_	_
c=1	_	_
and	_	_
(	_	_
ac	_	_
,	_	_
σ	_	_
c	_	_
)	_	_
S	_	_
c=1	_	_
.	_	_

#85
These	_	_
problems	_	_
have	_	_
simple	_	_
closed	_	_
form	_	_
solution	_	_
and	_	_
we	_	_
omit	_	_
the	_	_
equations	_	_
here	_	_
for	_	_
brevity	_	_
.	_	_

#86
We	_	_
give	_	_
details	_	_
equations	_	_
for	_	_
the	_	_
nonlinear	_	_
case	_	_
,	_	_
as	_	_
shown	_	_
below	_	_
.	_	_

#87
2.2	_	_
.	_	_

#88
Nonlinear	_	_
Regression	_	_
For	_	_
the	_	_
non-linear	_	_
regression	_	_
,	_	_
we	_	_
first	_	_
map	_	_
the	_	_
attributes	_	_
{	_	_
ac	_	_
}	_	_
Sc=1	_	_
to	_	_
the	_	_
kernel	_	_
space	_	_
using	_	_
the	_	_
kernel	_	_
function	_	_
k	_	_
which	_	_
is	_	_
defined	_	_
as	_	_
a	_	_
nonlinear	_	_
mapping	_	_
φ	_	_
.	_	_

#89
Using	_	_
the	_	_
Representer	_	_
theorem	_	_
[	_	_
24	_	_
]	_	_
,	_	_
we	_	_
can	_	_
re-formulate	_	_
the	_	_
regression	_	_
problem	_	_
in	_	_
kernel	_	_
space	_	_
as	_	_
given	_	_
in	_	_
Eq.	_	_
3	_	_
.	_	_

#90
Note	_	_
that	_	_
instead	_	_
of	_	_
computing	_	_
the	_	_
φ	_	_
(	_	_
ac	_	_
)	_	_
explicitly	_	_
,	_	_
we	_	_
have	_	_
to	_	_
compute	_	_
only	_	_
the	_	_
dot	_	_
product	_	_
φ	_	_
(	_	_
ac	_	_
)	_	_
Tφ	_	_
(	_	_
ac′	_	_
)	_	_
=	_	_
k	_	_
(	_	_
ac	_	_
,	_	_
ac′	_	_
)	_	_
for	_	_
the	_	_
non-linear	_	_
mapping	_	_
of	_	_
the	_	_
two	_	_
class	_	_
c	_	_
and	_	_
c′	_	_
.	_	_

#91
Let	_	_
K	_	_
be	_	_
the	_	_
kernel	_	_
matrix	_	_
of	_	_
size	_	_
S×S	_	_
containing	_	_
pairwise	_	_
similarities	_	_
of	_	_
the	_	_
attributes	_	_
of	_	_
the	_	_
seen	_	_
classes	_	_
,	_	_
M	_	_
be	_	_
the	_	_
D	_	_
×	_	_
S	_	_
matrix	_	_
containing	_	_
the	_	_
means	_	_
of	_	_
the	_	_
distributions	_	_
of	_	_
all	_	_
the	_	_
seen	_	_
classes	_	_
,	_	_
then	_	_
the	_	_
attribute	_	_
to	_	_
mean	_	_
nonlinear	_	_
mapping	_	_
can	_	_
be	_	_
learned	_	_
by	_	_
solving	_	_
the	_	_
following	_	_
problem	_	_
min	_	_
Wµ	_	_
||M−WµK||2F	_	_
+	_	_
λµ||Wµ||22	_	_
s.t	_	_
.	_	_

#92
K	_	_
=	_	_
W∗	_	_
µM	_	_
(	_	_
3	_	_
)	_	_
Eq	_	_
3	_	_
shows	_	_
our	_	_
main	_	_
objective	_	_
function	_	_
.	_	_

#93
Here	_	_
the	_	_
first	_	_
term	_	_
can	_	_
be	_	_
interpreted	_	_
as	_	_
learning	_	_
an	_	_
optimal	_	_
weight	_	_
matrix	_	_
that	_	_
projects	_	_
the	_	_
attribute	_	_
space	_	_
to	_	_
the	_	_
visual	_	_
space	_	_
using	_	_
the	_	_
kernel	_	_
regression	_	_
.	_	_

#94
The	_	_
second	_	_
term	_	_
ensures	_	_
that	_	_
we	_	_
can	_	_
reconstruct	_	_
the	_	_
attribute	_	_
vector	_	_
from	_	_
the	_	_
visual	_	_
space	_	_
and	_	_
acts	_	_
as	_	_
a	_	_
regularization	_	_
term	_	_
.	_	_

#95
Akin	_	_
to	_	_
an	_	_
autoencoder	_	_
[	_	_
9	_	_
]	_	_
,	_	_
we	_	_
assume	_	_
the	_	_
two	_	_
mappings	_	_
to	_	_
be	_	_
reverse	_	_
of	_	_
each	_	_
other	_	_
W∗	_	_
µ	_	_
=	_	_
WT	_	_
µ	_	_
Therefore	_	_
the	_	_
complete	_	_
objective	_	_
can	_	_
be	_	_
written	_	_
as	_	_
:	_	_
W∗	_	_
µ	_	_
=	_	_
argmin	_	_
Wµ	_	_
||M−WµK||2F	_	_
+	_	_
λµ||Wµ||22	_	_
+λ1||K−WT	_	_
µM||2F	_	_
(	_	_
4	_	_
)	_	_
The	_	_
next	_	_
section	_	_
provides	_	_
details	_	_
of	_	_
the	_	_
optimization	_	_
procedure	_	_
used	_	_
for	_	_
solving	_	_
Eq.	_	_
4	_	_

#96
2.2.1	_	_
Optimization	_	_

#97
Noting	_	_
Tr	_	_
(	_	_
K	_	_
)	_	_
=	_	_
Tr	_	_
(	_	_
KT	_	_
)	_	_
and	_	_
Tr	_	_
(	_	_
WT	_	_
µM	_	_
)	_	_
=	_	_
Tr	_	_
(	_	_
MTWµ	_	_
)	_	_
,	_	_
Eq.	_	_
4	_	_
can	_	_
be	_	_
written	_	_
as	_	_
:	_	_
W∗	_	_
µ	_	_
=	_	_
argmin	_	_
Wµ	_	_
||M−WµK||2F	_	_
+	_	_
λµ||Wµ||22	_	_
+λ1||KT	_	_
−MTWµ||2F	_	_
(	_	_
5	_	_
)	_	_
Taking	_	_
the	_	_
derivative	_	_
of	_	_
Eq.	_	_
5	_	_
and	_	_
equating	_	_
to	_	_
zero	_	_
we	_	_
have	_	_
.	_	_

#98
MMTWµ+Wµλ1KKT	_	_
+λµWµ	_	_
=	_	_
(	_	_
1+λ1	_	_
)	_	_
MKT	_	_
(	_	_
6	_	_
)	_	_
MMTWµ	_	_
+	_	_
Wµ	_	_
(	_	_
λ1KKT	_	_
+	_	_
λµ	_	_
)	_	_
=	_	_
(	_	_
1	_	_
+	_	_
λ1	_	_
)	_	_
MKT	_	_
(	_	_
7	_	_
)	_	_
The	_	_
above	_	_
equation	_	_
has	_	_
the	_	_
form	_	_
AW	_	_
+	_	_
WB	_	_
=	_	_
C	_	_
(	_	_
8	_	_
)	_	_
This	_	_
is	_	_
a	_	_
well-known	_	_
Sylvester	_	_
equation	_	_
which	_	_
can	_	_
be	_	_
solved	_	_
using	_	_
the	_	_
Bartels-Stewart	_	_
algorithm	_	_
[	_	_
5	_	_
]	_	_
efficiently	_	_
,	_	_
and	_	_
several	_	_
off-the-shelf	_	_
solvers	_	_
exist	_	_
(	_	_
we	_	_
used	_	_
a	_	_
MATLAB	_	_
implementation	_	_
for	_	_
the	_	_
same	_	_
)	_	_
.	_	_

#99
The	_	_
various	_	_
quantities	_	_
in	_	_
the	_	_
above	_	_
equation	_	_
are	_	_
defined	_	_
as	_	_
A	_	_
=	_	_
MMT	_	_
(	_	_
9	_	_
)	_	_
B	_	_
=	_	_
λ1KKT	_	_
+	_	_
λµ	_	_
(	_	_
10	_	_
)	_	_
C	_	_
=	_	_
(	_	_
1	_	_
+	_	_
λ1	_	_
)	_	_
MKT	_	_
(	_	_
11	_	_
)	_	_
Likewise	_	_
,	_	_
the	_	_
nonlinear	_	_
model	_	_
fσ2	_	_
i	_	_
can	_	_
be	_	_
learned	_	_
by	_	_
solving	_	_
:	_	_
W∗	_	_
σ2	_	_
=	_	_
argmin	_	_
Wσ2	_	_
||R−Wσ2K||2F	_	_
+	_	_
λσ2	_	_
||Wσ2	_	_
||22	_	_
+λ2||K−WT	_	_
σ2R||2F	_	_
(	_	_
12	_	_
)	_	_
Again	_	_
,	_	_
taking	_	_
derivatives	_	_
and	_	_
setting	_	_
to	_	_
zero	_	_
gives	_	_
RRTWσ2	_	_
+Wσ2	_	_
(	_	_
λ2KKT	_	_
+λσ2	_	_
)	_	_
=	_	_
(	_	_
1+λ2	_	_
)	_	_
RKT	_	_
(	_	_
13	_	_
)	_	_
The	_	_
above	_	_
equation	_	_
is	_	_
also	_	_
in	_	_
the	_	_
form	_	_
of	_	_
AW	_	_
+	_	_
WB	_	_
=	_	_
C	_	_
A	_	_
=	_	_
RRT	_	_
(	_	_
14	_	_
)	_	_
B	_	_
=	_	_
λ2KKT	_	_
+	_	_
λσ2	_	_
(	_	_
15	_	_
)	_	_
C	_	_
=	_	_
(	_	_
1	_	_
+	_	_
λ2	_	_
)	_	_
RKT	_	_
(	_	_
16	_	_
)	_	_
Given	_	_
the	_	_
learned	_	_
parameters	_	_
Wµc	_	_
and	_	_
Wσ2	_	_
c	_	_
,	_	_
the	_	_
parameters	_	_
of	_	_
data	_	_
distribution	_	_
for	_	_
unseen	_	_
classes	_	_
c	_	_
=	_	_
S	_	_
+	_	_
1	_	_
,	_	_
.	_	_

#100
.	_	_

#101
.	_	_

#102
,	_	_
S	_	_
+	_	_
U	_	_
are	_	_
estimated	_	_
as	_	_
:	_	_
µc	_	_
=	_	_
Wµkc	_	_
,	_	_
&	_	_
σ2	_	_
c	_	_
=	_	_
exp	_	_
(	_	_
ρc	_	_
)	_	_
=	_	_
exp	_	_
(	_	_
Wσ2kc	_	_
)	_	_
(	_	_
17	_	_
)	_	_
Where	_	_
kc	_	_
=	_	_
[	_	_
k	_	_
(	_	_
ac	_	_
,	_	_
a1	_	_
)	_	_
,	_	_
...	_	_
,	_	_
k	_	_
(	_	_
ac	_	_
,	_	_
aS	_	_
)	_	_
]	_	_
denotes	_	_
an	_	_
S	_	_
×	_	_
1	_	_
vector	_	_
of	_	_
kernel-based	_	_
similarities	_	_
of	_	_
the	_	_
class	_	_
attribute	_	_
vectors	_	_
of	_	_
the	_	_
unseen	_	_
class	_	_
c	_	_
with	_	_
the	_	_
class	_	_
attribute	_	_
vectors	_	_
of	_	_
all	_	_
the	_	_
seen	_	_
classes	_	_
.	_	_

#103
In	_	_
the	_	_
aforementioned	_	_
procedure	_	_
for	_	_
estimation	_	_
of	_	_
the	_	_
unseen	_	_
class	_	_
distribution	_	_
parameters	_	_
uses	_	_
only	_	_
seen	_	_
class	_	_
labelled	_	_
data	_	_
.	_	_

#104
In	_	_
this	_	_
setting	_	_
,	_	_
the	_	_
unseen	_	_
classes	_	_
unlabeled	_	_
data	_	_
have	_	_
not	_	_
been	_	_
used	_	_
.	_	_

#105
This	_	_
setting	_	_
is	_	_
called	_	_
as	_	_
an	_	_
inductive	_	_
setting	_	_
.	_	_

#106
If	_	_
we	_	_
have	_	_
access	_	_
to	_	_
the	_	_
unseen	_	_
classes	_	_
test	_	_
instances	_	_
at	_	_
the	_	_
training	_	_
time	_	_
,	_	_
we	_	_
can	_	_
use	_	_
these	_	_
to	_	_
improve	_	_
the	_	_
estimation	_	_
of	_	_
distribution	_	_
parameters	_	_
of	_	_
unseen	_	_
classes	_	_
.	_	_

#107
This	_	_
is	_	_
the	_	_
transductive	_	_
setting	_	_
which	_	_
we	_	_
describe	_	_
next	_	_
.	_	_

#108
2.3.	_	_
Transductive	_	_
setting	_	_

#109
One	_	_
of	_	_
the	_	_
unique	_	_
advantages	_	_
of	_	_
the	_	_
proposed	_	_
generative	_	_
approach	_	_
is	_	_
that	_	_
unlabeled	_	_
data	_	_
from	_	_
unseen	_	_
classes	_	_
can	_	_
be	_	_
leveraged	_	_
to	_	_
improve	_	_
the	_	_
parameter	_	_
estimates	_	_
(	_	_
µc	_	_
and	_	_
σc	_	_
)	_	_
.	_	_

#110
In	_	_
zero-shot	_	_
learning	_	_
,	_	_
training	_	_
and	_	_
test	_	_
data	_	_
could	options	_
possibly	_	_
come	_	_
from	_	_
different	_	_
domains	_	_
.	_	_

#111
Therefore	_	_
,	_	_
it	_	_
is	_	_
very	_	_
likely	_	_
that	_	_
parameters	_	_
learned	_	_
in	_	_
the	_	_
training	_	_
,	_	_
will	_	_
not	_	_
work	_	_
well	_	_
for	_	_
the	_	_
test	_	_
data	_	_
.	_	_

#112
This	_	_
phenomenon	_	_
is	_	_
called	_	_
domain	_	_
shift	_	_
.	_	_

#113
An	_	_
illustrative	_	_
view	_	_
of	_	_
the	_	_
domain	_	_
shift	_	_
can	_	_
be	_	_
seen	_	_
in	_	_
Fig.	_	_
2	_	_
.	_	_

#114
One	_	_
way	_	_
to	_	_
overcome	_	_
this	_	_
issue	_	_
is	_	_
to	_	_
use	_	_
unlabeled	_	_
data	_	_
to	_	_
further	_	_
fine-tune	_	_
the	_	_
parameters	_	_
learned	_	_
by	_	_
the	_	_
inductive	_	_
approach	_	_
which	_	_
only	_	_
uses	_	_
the	_	_
labeled	_	_
data	_	_
from	_	_
the	_	_
seen	_	_
action	_	_
classes	_	_
.	_	_

#115
In	_	_
the	_	_
transductive	_	_
setting	_	_
[	_	_
34	_	_
]	_	_
,	_	_
we	_	_
assume	_	_
that	_	_
the	_	_
test	_	_
data	_	_
is	_	_
also	_	_
available	_	_
at	_	_
the	_	_
training	_	_
time	_	_
.	_	_

#116
This	_	_
data	_	_
can	_	_
help	_	_
mitigate	_	_
the	_	_
bias	_	_
towards	_	_
the	_	_
seen	_	_
classes	_	_
.	_	_

#117
In	_	_
this	_	_
work	_	_
,	_	_
we	_	_
handle	_	_
the	_	_
domain	_	_
shift	_	_
problem	_	_
by	_	_
initializing	_	_
the	_	_
parameters	_	_
µc	_	_
,	_	_
σc	_	_
using	_	_
the	_	_
learned	_	_
basis	_	_
vectors	_	_
from	_	_
the	_	_
inductive	_	_
learning	_	_
phase	_	_
,	_	_
which	_	_
are	_	_
then	_	_
fine-tuned	_	_
using	_	_
the	_	_
unlabeled	_	_
test	_	_
data	_	_
from	_	_
the	_	_
unseen	_	_
classes	_	_
using	_	_
the	_	_
an	_	_
Expectation-Maximization	_	_
(	_	_
EM	_	_
)	_	_
algorithm	_	_
.	_	_

#118
Since	_	_
each	_	_
class	_	_
distribution	_	_
is	_	_
assumed	_	_
to	_	_
be	_	_
a	_	_
Gaussian	_	_
,	_	_
this	_	_
EM	_	_
based	_	_
procedure	_	_
is	_	_
equivalent	_	_
to	_	_
a	_	_
Gaussian	_	_
mixture	_	_
model	_	_
(	_	_
GMM	_	_
)	_	_
on	_	_
the	_	_
unlabeled	_	_
test	_	_
data	_	_
(	_	_
xn	_	_
)	_	_
Nun=1	_	_
from	_	_
unseen	_	_
classes	_	_
.	_	_

#119
This	_	_
GMM	_	_
has	_	_
U	_	_
mixture	_	_
components	_	_
,	_	_
with	_	_
each	_	_
corresponding	_	_
to	_	_
an	_	_
unseen	_	_
class	_	_
and	_	_
is	_	_
initialized	_	_
by	_	_
Figure	_	_
2	_	_
.	_	_

#120
Domain	_	_
Adaptation	_	_
illustrative	_	_
example	_	_
:	_	_
Each	_	_
class	_	_
attribute	_	_
is	_	_
projected	_	_
to	_	_
the	_	_
visual	_	_
space	_	_
,	_	_
In	_	_
the	_	_
visual	_	_
space	_	_
each	_	_
class	_	_
are	_	_
represented	_	_
by	_	_
a	_	_
distribution	_	_
.	_	_

#121
Because	_	_
the	_	_
seen	_	_
and	_	_
unseen	_	_
class	_	_
are	_	_
disjoint	_	_
,	_	_
there	_	_
is	_	_
a	_	_
problem	_	_
of	_	_
domain	_	_
shift	_	_
.	_	_

#122
the	_	_
estimated	_	_
parameters	_	_
of	_	_
unseen	_	_
classes	_	_
(	_	_
µc	_	_
,	_	_
σ	_	_
c	_	_
)	_	_
S+Uc=S+1	_	_
in	_	_
the	_	_
inductive	_	_
setting	_	_
.	_	_

#123
The	_	_
procedure	_	_
for	_	_
transductive	_	_
setting	_	_
can	_	_
be	_	_
briefly	_	_
summarized	_	_
as	_	_
follows	_	_
1	_	_
.	_	_

#124
Initialize	_	_
:	_	_
Let	_	_
the	_	_
initial	_	_
estimate	_	_
of	_	_
the	_	_
unseen	_	_
class	_	_
parameters	_	_
be	_	_
Θ	_	_
=	_	_
(	_	_
µc	_	_
,	_	_
σ	_	_
c	_	_
)	_	_
S+Uc=S+1	_	_
where	_	_
µc	_	_
=	_	_
Wµac	_	_
,	_	_
σ2	_	_
c	_	_
=	_	_
exp	_	_
(	_	_
Wσ2ac	_	_
)	_	_
.	_	_

#125
Here	_	_
Wµ	_	_
and	_	_
Wσ2	_	_
are	_	_
estimated	_	_
from	_	_
seen	_	_
class	_	_
data	_	_
using	_	_
equations	_	_
4	_	_
,	_	_
12	_	_
(	_	_
assuming	_	_
we	_	_
have	_	_
used	_	_
the	_	_
nonlinear	_	_
regression	_	_
model	_	_
in	_	_
the	_	_
inductive	_	_
phase	_	_
)	_	_
.	_	_

#126
2	_	_
.	_	_

#127
Expectation	_	_
Step	_	_
:	_	_
Infer	_	_
the	_	_
probabilities	_	_
for	_	_
each	_	_
example	_	_
xn	_	_
belonging	_	_
to	_	_
each	_	_
of	_	_
the	_	_
unseen	_	_
classes	_	_
c	_	_
=	_	_
S	_	_
+	_	_
1	_	_
,	_	_
...	_	_
,	_	_
S	_	_
+	_	_
U	_	_
as	_	_
p	_	_
(	_	_
yn	_	_
=	_	_
c|xn	_	_
,	_	_
θ	_	_
)	_	_
∝	_	_
N	_	_
(	_	_
xn|µc	_	_
,	_	_
σ2	_	_
c	_	_
)	_	_
where	_	_
the	_	_
class	_	_
priors	_	_
p	_	_
(	_	_
c	_	_
)	_	_
are	_	_
assumed	_	_
to	_	_
be	_	_
uniform	_	_
.	_	_

#128
3	_	_
.	_	_

#129
Maximization	_	_
Step	_	_
:	_	_
Use	_	_
the	_	_
inferred	_	_
class	_	_
labels	_	_
to	_	_
re-estimate	_	_
Θ	_	_
=	_	_
(	_	_
µc	_	_
,	_	_
σ	_	_
c	_	_
)	_	_
S+Uc=S+1	_	_
.	_	_

#130
These	_	_
updates	_	_
have	_	_
closed	_	_
form	_	_
solution	_	_
as	_	_
in	_	_
the	_	_
standard	_	_
GMM	_	_
.	_	_

#131
4	_	_
.	_	_

#132
Go	_	_
to	_	_
step	_	_
2	_	_
if	_	_
not	_	_
converged	_	_
.	_	_

#133
2.4	_	_
.	_	_

#134
Few-shot	_	_
Action	_	_
Recognition	_	_
In	_	_
few-shot	_	_
action	_	_
recognition	_	_
,	_	_
we	_	_
have	_	_
a	_	_
small	_	_
number	_	_
of	_	_
labeled	_	_
examples	_	_
for	_	_
each	_	_
of	_	_
the	_	_
unseen	_	_
classes	_	_
.	_	_

#135
Since	_	_
our	_	_
method	_	_
assumes	_	_
a	_	_
Gaussian	_	_
distribution	_	_
for	_	_
each	_	_
class	_	_
,	_	_
we	_	_
can	_	_
easily	_	_
extend	_	_
our	_	_
zero-shot	_	_
action	_	_
recognition	_	_
method	_	_
to	_	_
few-shot	_	_
action	_	_
recognition	_	_
.	_	_

#136
To	_	_
this	_	_
end	_	_
,	_	_
we	_	_
treat	_	_
the	_	_
initial	_	_
estimate	_	_
obtained	_	_
using	_	_
the	_	_
previous	_	_
approach	_	_
as	_	_
the	_	_
prior	_	_
.	_	_

#137
Due	_	_
to	_	_
the	_	_
conjugate	_	_
nature	_	_
of	_	_
the	_	_
Gaussian	_	_
,	_	_
we	_	_
can	_	_
update	_	_
the	_	_
estimates	_	_
(	_	_
µc	_	_
,	_	_
σ	_	_
c	_	_
)	_	_
S+Uc=S+1	_	_
obtained	_	_
from	_	_
zero-shot	_	_
action	_	_
recognition	_	_
method	_	_
in	_	_
a	_	_
straightforward	_	_
manner	_	_
when	_	_
such	_	_
labeled	_	_
data	_	_
for	_	_
unseen	_	_
classes	_	_
is	_	_
provided	_	_
.	_	_

#138
In	_	_
particular	_	_
,	_	_
given	_	_
a	_	_
small	_	_
number	_	_
of	_	_
labeled	_	_
data	_	_
(	_	_
xn	_	_
)	_	_
Ncn=1	_	_
for	_	_
unseen	_	_
class	_	_
c	_	_
the	_	_
parameters	_	_
of	_	_
this	_	_
class	_	_
can	_	_
be	_	_
directly	_	_
updated	_	_
as	_	_
:	_	_
µFSc	_	_
=	_	_
µ	_	_
+	_	_
∑Nc	_	_
n=1	_	_
xn	_	_
1	_	_
+Nc	_	_
(	_	_
18	_	_
)	_	_
σ2	_	_
(	_	_
FS	_	_
)	_	_
c	_	_
=	_	_
(	_	_
σ2	_	_
c	_	_
+	_	_
Nc	_	_
σ2∗	_	_
)	_	_
−1	_	_
(	_	_
19	_	_
)	_	_
where	_	_
σ2∗	_	_
=	_	_
1	_	_
Nc	_	_
∑Nc	_	_
n=1	_	_
(	_	_
xn	_	_
−µc	_	_
)	_	_
2	_	_
denotes	_	_
empirical	_	_
variance	_	_
of	_	_
Nc	_	_
observations	_	_
from	_	_
the	_	_
unseen	_	_
class	_	_
c.	_	_
2.5	_	_
.	_	_

#139
Extension	_	_
to	_	_
Other	_	_
Distributions	_	_
Finally	_	_
,	_	_
we	_	_
would	_	_
like	_	_
to	_	_
emphasize	_	_
that	_	_
although	_	_
we	_	_
have	_	_
consider	_	_
Gaussians	_	_
to	_	_
model	_	_
each	_	_
class	_	_
,	_	_
our	_	_
approach	_	_
applies	_	_
to	_	_
any	_	_
parameteric	_	_
distribution	_	_
p	_	_
(	_	_
x|θc	_	_
)	_	_
as	_	_
it	_	_
essentially	_	_
boils	_	_
down	_	_
to	_	_
learning	_	_
a	_	_
mapping	_	_
from	_	_
the	_	_
class	_	_
attribute	_	_
vectors	_	_
ac	_	_
to	_	_
the	_	_
distribution	_	_
parameters	_	_
θc	_	_
.	_	_

#140
The	_	_
choice	_	_
of	_	_
a	_	_
Gaussian	_	_
or	_	_
an	_	_
exponential	_	_
family	_	_
distribution	_	_
[	_	_
29	_	_
]	_	_
,	_	_
due	_	_
to	_	_
conjugacy	_	_
,	_	_
makes	_	_
our	_	_
estimation	_	_
procedure	_	_
particularly	_	_
simple	_	_
in	_	_
the	_	_
transductive	_	_
and	_	_
few-shot	_	_
settings	_	_
,	_	_
but	_	_
our	_	_
framework	_	_
is	_	_
not	_	_
restricted	_	_
to	_	_
these	_	_
.	_	_

#141
Other	_	_
density	_	_
estimation	_	_
methods	_	_
such	_	_
as	_	_
deep	_	_
generative	_	_
models	_	_
can	_	_
also	_	_
be	_	_
used	_	_
[	_	_
32	_	_
]	_	_
.	_	_

#142
3	_	_
.	_	_

#143
Related	_	_
Work	_	_
ZSL	_	_
can	_	_
be	_	_
viewed	_	_
as	_	_
an	_	_
interplay	_	_
of	_	_
three	_	_
subproblems	_	_
:	_	_
a	_	_
visual	_	_
representation	_	_
of	_	_
data	_	_
instances	_	_
(	_	_
feature	_	_
representation	_	_
)	_	_
,	_	_
semantic	_	_
representation	_	_
of	_	_
all	_	_
classes	_	_
such	_	_
as	_	_
word2vec	_	_
representation	_	_
[	_	_
19	_	_
]	_	_
,	_	_
and	_	_
learning	_	_
a	_	_
function	_	_
which	_	_
establishes	_	_
the	_	_
relationship	_	_
between	_	_
visual	_	_
representations	_	_
and	_	_
semantic	_	_
representations	_	_
of	_	_
each	_	_
class	_	_
[	_	_
13	_	_
,	_	_
14	_	_
]	_	_
.	_	_

#144
For	_	_
visual	_	_
(	_	_
or	_	_
feature	_	_
)	_	_
representation	_	_
of	_	_
class	_	_
instance	_	_
,	_	_
popular	_	_
hand-crafted	_	_
features	_	_
such	_	_
as	_	_
HOG	_	_
[	_	_
3	_	_
]	_	_
,	_	_
HOF	_	_
[	_	_
2	_	_
]	_	_
,	_	_
ITF	_	_
[	_	_
30	_	_
]	_	_
were	_	_
designed	_	_
.	_	_

#145
However	_	_
,	_	_
the	_	_
proven	_	_
utility	_	_
of	_	_
deep	_	_
features	_	_
for	_	_
many	_	_
tasks	_	_
such	_	_
as	_	_
Object	_	_
Recognition	_	_
[	_	_
10	_	_
,	_	_
25	_	_
,	_	_
27	_	_
]	_	_
,	_	_
Object	_	_
Detection	_	_
[	_	_
4	_	_
]	_	_
,	_	_
etc.	_	_
,	_	_
has	_	_
made	_	_
features	_	_
from	_	_
well	_	_
performing	_	_
CNNs	_	_
such	_	_
as	_	_
[	_	_
15	_	_
]	_	_
,	_	_
Two-Stream	_	_
CNN	_	_
[	_	_
18	_	_
]	_	_
,	_	_
3DCNN	_	_
[	_	_
6	_	_
]	_	_
ubiquitous	_	_
for	_	_
Action	_	_
Recognition	_	_
tasks	_	_
including	_	_
the	_	_
zero	_	_
shot	_	_
setting	_	_
.	_	_

#146
By	_	_
using	_	_
3DCNN	_	_
features	_	_
in	_	_
ZSL	_	_
,	_	_
a	_	_
significant	_	_
boost	_	_
in	_	_
accuracy	_	_
has	_	_
been	_	_
observed	_	_
[	_	_
31	_	_
]	_	_
.	_	_

#147
Semantic	_	_
representation	_	_
of	_	_
a	_	_
class	_	_
provides	_	_
additional	_	_
,	_	_
complementary	_	_
information	_	_
to	_	_
the	_	_
visual	_	_
features	_	_
of	_	_
the	_	_
classes	_	_
.	_	_

#148
Typically	_	_
,	_	_
two	_	_
types	_	_
of	_	_
semantic	_	_
representations	_	_
have	_	_
been	_	_
widely	_	_
used	_	_
in	_	_
the	_	_
ZSL	_	_
literature	_	_
:	_	_
attribute	_	_
representations	_	_
[	_	_
12	_	_
]	_	_
and	_	_
word	_	_
vector	_	_
representations	_	_
[	_	_
19	_	_
]	_	_
.	_	_

#149
Attribute	_	_
representations	_	_
are	_	_
manually	_	_
annotated	_	_
vectors	_	_
for	_	_
each	_	_
class	_	_
based	_	_
on	_	_
the	_	_
gesture	_	_
and	_	_
motion	_	_
appearance	_	_
of	_	_
the	_	_
objects	_	_
in	_	_
the	_	_
video	_	_
.	_	_

#150
Word	_	_
Vector	_	_
representations	_	_
are	_	_
automatically	_	_
learned	_	_
from	_	_
a	_	_
large	_	_
amount	_	_
of	_	_
textual	_	_
data	_	_
(	_	_
Wikipedia	_	_
Corpus	_	_
)	_	_
.	_	_

#151
Word2vec	_	_
models	_	_
have	_	_
been	_	_
used	_	_
successfully	_	_
for	_	_
extracting	_	_
semantic	_	_
word	_	_
vectors	_	_
from	_	_
class	_	_
names	_	_
[	_	_
31	_	_
,	_	_
7	_	_
,	_	_
35	_	_
]	_	_
.	_	_

#152
The	_	_
core	_	_
step	_	_
in	_	_
ZSL	_	_
is	_	_
to	_	_
find	_	_
a	_	_
function	_	_
or	_	_
projection	_	_
matrix	_	_
which	_	_
can	_	_
establish	_	_
a	_	_
relationship	_	_
between	_	_
visual	_	_
space	_	_
and	_	_
semantic	_	_
space	_	_
in	_	_
such	_	_
a	_	_
way	_	_
that	_	_
visual	_	_
features	_	_
of	_	_
classes	_	_
map	_	_
close	_	_
to	_	_
their	_	_
semantic	_	_
features	_	_
and	_	_
vice	_	_
versa	_	_
.	_	_

#153
For	_	_
example	_	_
,	_	_
we	_	_
would	_	_
like	_	_
to	_	_
have	_	_
visual	_	_
features	_	_
of	_	_
‘running’	_	_
map	_	_
close	_	_
to	_	_
semantic	_	_
features	_	_
of	_	_
‘running’	_	_
and	_	_
far	_	_
away	_	_
from	_	_
an	_	_
unrelated	_	_
action	_	_
such	_	_
as	_	_
‘eating’	_	_
.	_	_

#154
Note	_	_
that	_	_
our	_	_
framework	_	_
is	_	_
similar	_	_
in	_	_
spirit	_	_
to	_	_
such	_	_
methods	_	_
with	_	_
a	_	_
key	_	_
difference	_	_
:	_	_
Instead	_	_
of	_	_
learning	_	_
a	_	_
mapping	_	_
between	_	_
the	_	_
semantic	_	_
feature	_	_
and	_	_
visual	_	_
features	_	_
,	_	_
we	_	_
learn	_	_
a	_	_
mapping	_	_
from	_	_
the	_	_
semantic	_	_
features	_	_
and	_	_
the	_	_
parameters	_	_
of	_	_
the	_	_
distributions	_	_
representing	_	_
the	_	_
classes	_	_
.	_	_

#155
Most	_	_
methods	_	_
for	_	_
zero-shot	_	_
learning	_	_
are	_	_
evaluated	_	_
on	_	_
image	_	_
classification	_	_
whereas	_	_
only	_	_
a	_	_
few	_	_
methods	_	_
have	_	_
been	_	_
proposed	_	_
for	_	_
zero-shot	_	_
action	_	_
recognition	_	_
in	_	_
the	_	_
literature	_	_
[	_	_
31	_	_
,	_	_
35	_	_
,	_	_
34	_	_
,	_	_
21	_	_
]	_	_
.	_	_

#156
Such	_	_
methods	_	_
typically	_	_
assume	_	_
the	_	_
inductive	_	_
or	_	_
the	_	_
transductive	_	_
setting	_	_
.	_	_

#157
The	_	_
most	_	_
popular	_	_
approach	_	_
to	_	_
ZSL	_	_
is	_	_
learning	_	_
a	_	_
linear	_	_
compatibility	_	_
between	_	_
the	_	_
visual	_	_
and	_	_
semantic	_	_
space	_	_
[	_	_
1	_	_
]	_	_
.	_	_

#158
[	_	_
23	_	_
,	_	_
9	_	_
]	_	_
provide	_	_
novel	_	_
regularizations	_	_
while	_	_
learning	_	_
a	_	_
linear	_	_
compatibility	_	_
function	_	_
.	_	_

#159
ESZSL	_	_
[	_	_
23	_	_
]	_	_
models	_	_
the	_	_
relationship	_	_
between	_	_
features	_	_
and	_	_
attributes	_	_
as	_	_
a	_	_
linear	_	_
compatibility	_	_
function	_	_
while	_	_
explicitly	_	_
regularizing	_	_
the	_	_
objective	_	_
.	_	_

#160
UDA	_	_
[	_	_
8	_	_
]	_	_
uses	_	_
a	_	_
domain	_	_
adaptation	_	_
technique	_	_
by	_	_
using	_	_
unlabeled	_	_
data	_	_
of	_	_
unseen	_	_
classes	_	_
for	_	_
better	_	_
estimation	_	_
of	_	_
the	_	_
parameters	_	_
.	_	_

#161
Our	_	_
model	_	_
is	_	_
inspired	_	_
by	_	_
the	_	_
recently	_	_
proposed	_	_
model	_	_
[	_	_
29	_	_
]	_	_
,	_	_
which	_	_
is	_	_
a	_	_
simple	_	_
generative	_	_
approach	_	_
for	_	_
zero-shot	_	_
learning	_	_
.	_	_

#162
However	_	_
,	_	_
their	_	_
model	_	_
does	_	_
not	_	_
have	_	_
the	_	_
reconstruction	_	_
regularizer	_	_
(	_	_
autoencoder-style	_	_
reverse	_	_
mapping	_	_
)	_	_
from	_	_
visual	_	_
to	_	_
attribute	_	_
space	_	_
and	_	_
their	_	_
focus	_	_
is	_	_
on	_	_
image	_	_
classification	_	_
whereas	_	_
here	_	_
we	_	_
have	_	_
focused	_	_
on	_	_
action	_	_
recognition	_	_
.	_	_

#163
In	_	_
another	_	_
recent	_	_
work	_	_
,	_	_
[	_	_
9	_	_
]	_	_
proposed	_	_
a	_	_
semantic	_	_
auto-encoder	_	_
for	_	_
zero-shot	_	_
learning	_	_
which	_	_
introduced	_	_
the	_	_
reconstructability	_	_
regularizer	_	_
.	_	_

#164
This	_	_
paper	_	_
works	_	_
only	_	_
in	_	_
the	_	_
inductive	_	_
setting	_	_
and	_	_
their	_	_
approach	_	_
is	_	_
not	_	_
generative	_	_
.	_	_

#165
Our	_	_
generative	_	_
approach	_	_
can	_	_
be	_	_
seen	_	_
as	_	_
a	_	_
combination	_	_
of	_	_
the	_	_
generative	_	_
approach	_	_
of	_	_
[	_	_
29	_	_
]	_	_
with	_	_
auto-encoder	_	_
style	_	_
regularizer	_	_
proposed	_	_
by	_	_
[	_	_
9	_	_
]	_	_
.	_	_

#166
Among	_	_
prior	_	_
works	_	_
on	_	_
zero-shot	_	_
action	_	_
recognition	_	_
in	_	_
transductive	_	_
setting	_	_
,	_	_
[	_	_
35	_	_
]	_	_
proposed	_	_
a	_	_
transductive	_	_
framework	_	_
for	_	_
zero-shot	_	_
action	_	_
recognition	_	_
,	_	_
which	_	_
uses	_	_
unlabeled	_	_
unseen	_	_
class	_	_
data	_	_
for	_	_
training	_	_
the	_	_
model	_	_
.	_	_

#167
In	_	_
their	_	_
work	_	_
,	_	_
they	_	_
introduced	_	_
a	_	_
manifold-regularized	_	_
regression	_	_
and	_	_
a	_	_
data	_	_
augmentation	_	_
strategy	_	_
to	_	_
enhance	_	_
the	_	_
performance	_	_
.	_	_

#168
They	_	_
have	_	_
also	_	_
introduced	_	_
a	_	_
multi-task	_	_
visual-semantic	_	_
mapping	_	_
for	_	_
zero-shot	_	_
action	_	_
recognition	_	_
.	_	_

#169
In	_	_
addition	_	_
,	_	_
they	_	_
used	_	_
prioritized	_	_
auxiliary	_	_
data	_	_
augmentation	_	_
for	_	_
domain	_	_
adaptation	_	_
and	_	_
improved	_	_
the	_	_
mapping	_	_
between	_	_
visual	_	_
and	_	_
semantic	_	_
spaces	_	_
.	_	_

#170
Because	_	_
of	_	_
the	_	_
generative	_	_
nature	_	_
of	_	_
our	_	_
proposed	_	_
approach	_	_
,	_	_
we	_	_
can	_	_
synthesize	_	_
the	_	_
data	_	_
from	_	_
unseen	_	_
class	_	_
based	_	_
on	_	_
attribute	_	_
and	_	_
train	_	_
the	_	_
classifier	_	_
.	_	_

#171
This	_	_
approach	_	_
helps	_	_
to	_	_
reduce	_	_
the	_	_
baisness	_	_
in	_	_
the	_	_
case	_	_
of	_	_
Generalize	_	_
Zero-Shot	_	_
Learning	_	_
.	_	_

#172
The	_	_
efficacy	_	_
of	_	_
the	_	_
proposed	_	_
approach	_	_
for	_	_
the	_	_
GZSL	_	_
as	_	_
well	_	_
as	_	_
ZSL	_	_
can	_	_
be	_	_
seen	_	_
from	_	_
the	_	_
experiment	_	_
on	_	_
three	_	_
standard	_	_
datasets	_	_
.	_	_

#173
4	_	_
.	_	_

#174
Experiments	_	_
Datasets	_	_
and	_	_
Settings	_	_
:	_	_
We	_	_
evaluate	_	_
our	_	_
proposed	_	_
method	_	_
in	_	_
three	_	_
of	_	_
the	_	_
most	_	_
challenging	_	_
video	_	_
action	_	_
recognition	_	_
datasets	_	_
,	_	_
UCF101	_	_
[	_	_
26	_	_
]	_	_
,	_	_
HMDB51	_	_
[	_	_
11	_	_
]	_	_
and	_	_
Olympic	_	_
[	_	_
17	_	_
]	_	_
,	_	_
widely	_	_
used	_	_
as	_	_
benchmark	_	_
datasets	_	_
.	_	_

#175
We	_	_
report	_	_
mean	_	_
accuracy	_	_
along	_	_
with	_	_
standard	_	_
deviation	_	_
on	_	_
30	_	_
independent	_	_
test	_	_
runs	_	_
with	_	_
random	_	_
train/test	_	_
class	_	_
splits	_	_
.	_	_

#176
•	_	_
UCF101	_	_
:	_	_
[	_	_
26	_	_
]	_	_
is	_	_
human	_	_
action	_	_
recognition	_	_
data	_	_
set	_	_
with	_	_
101	_	_
different	_	_
classes	_	_
of	_	_
actions	_	_
and	_	_
total	_	_
of	_	_
13320	_	_
video	_	_
clips	_	_
.	_	_

#177
In	_	_
our	_	_
experiments	_	_
,	_	_
we	_	_
split	_	_
the	_	_
classes	_	_
into	_	_
51	_	_
seen	_	_
and	_	_
50	_	_
unseen	_	_
class	_	_
respectively	_	_
.	_	_

#178
‘	_	_
•	_	_
HMDB51	_	_
:	_	_
[	_	_
11	_	_
]	_	_
is	_	_
the	_	_
one	_	_
of	_	_
the	_	_
most	_	_
challenging	_	_
human	_	_
action	_	_
recognition	_	_
dataset	_	_
with	_	_
51	_	_
different	_	_
classes	_	_
of	_	_
human	_	_
actions	_	_
and	_	_
total	_	_
number	_	_
of	_	_
6766	_	_
video	_	_
clips	_	_
.	_	_

#179
Each	_	_
class	_	_
has	_	_
more	_	_
than	_	_
100	_	_
video	_	_
clips	_	_
.	_	_

#180
For	_	_
the	_	_
evaluation	_	_
of	_	_
our	_	_
model	_	_
,	_	_
we	_	_
perform	_	_
a	_	_
26/25	_	_
split	_	_
for	_	_
seen	_	_
and	_	_
unseen	_	_
classes	_	_
respectively	_	_
.	_	_

#181
•	_	_
Olympic	_	_
:	_	_
[	_	_
17	_	_
]	_	_
This	_	_
dataset	_	_
has	_	_
783	_	_
videos	_	_
from	_	_
16	_	_
different	_	_
classes	_	_
with	_	_
seen/unseen	_	_
class	_	_
split	_	_
being	_	_
8/8	_	_
.	_	_

#182
Dataset	_	_
#	_	_
videos	_	_
#	_	_
classes	_	_
seen/unseen	_	_
Attribute	_	_
dim	_	_
UCF101	_	_
13320	_	_
101	_	_
51/50	_	_
115	_	_
HMDB51	_	_
6676	_	_
51	_	_
26/25	_	_
N/A	_	_
Olympic	_	_
783	_	_
16	_	_
8/8	_	_
40	_	_
Table	_	_
1	_	_
.	_	_

#183
Dataset	_	_
details	_	_
and	_	_
their	_	_
train	_	_
test	_	_
split	_	_
on	_	_
all	_	_
the	_	_
three	_	_
dataset	_	_
used	_	_
in	_	_
our	_	_
experiment	_	_
.	_	_

#184
Visual	_	_
features	_	_
:	_	_
The	_	_
quality	_	_
of	_	_
visual	_	_
features	_	_
directly	_	_
affect	_	_
the	_	_
efficacy	_	_
of	_	_
the	_	_
model	_	_
.	_	_

#185
We	_	_
use	_	_
deep	_	_
features	_	_
as	_	_
they	_	_
have	_	_
been	_	_
shown	_	_
to	_	_
be	_	_
successful	_	_
in	_	_
many	_	_
computer	_	_
vision	_	_
tasks	_	_
.	_	_

#186
In	_	_
our	_	_
experiments	_	_
,	_	_
we	_	_
use	_	_
the	_	_
latest	_	_
convolutional	_	_
3D	_	_
(	_	_
C3D	_	_
)	_	_
visual	_	_
features	_	_
provided	_	_
by	_	_
[	_	_
28	_	_
]	_	_
.	_	_

#187
This	_	_
model	_	_
was	_	_
pre-trained	_	_
on	_	_
the	_	_
sports-1M	_	_
dataset	_	_
.	_	_

#188
We	_	_
extract	_	_
the	_	_
outputs	_	_
of	_	_
fc6	_	_
layer	_	_
for	_	_
all	_	_
segments	_	_
similar	_	_
to	_	_
[	_	_
28	_	_
]	_	_
and	_	_
then	_	_
averaged	_	_
over	_	_
the	_	_
segments	_	_
to	_	_
form	_	_
a	_	_
4096-dimensional	_	_
video	_	_
representation	_	_
which	_	_
is	_	_
used	_	_
as	_	_
the	_	_
input	_	_
visual	_	_
features	_	_
.	_	_

#189
Class	_	_
attributes	_	_
:	_	_
Two	_	_
types	_	_
of	_	_
class	_	_
attribute	_	_
vectors	_	_
(	_	_
semantic	_	_
representation	_	_
of	_	_
the	_	_
classes	_	_
)	_	_
are	_	_
widely	_	_
used	_	_
in	_	_
ZSL	_	_
:	_	_
human	_	_
labeled	_	_
attributes	_	_
[	_	_
12	_	_
]	_	_
and	_	_
automatically	_	_
learned	_	_
distributed	_	_
semantic	_	_
representations	_	_
such	_	_
as	_	_
word	_	_
vectors	_	_
[	_	_
19	_	_
]	_	_
.	_	_

#190
Word	_	_
vector	_	_
representation	_	_
is	_	_
learned	_	_
automatically	_	_
by	_	_
a	_	_
skip-gram	_	_
model	_	_
trained	_	_
on	_	_
the	_	_
google	_	_
news	_	_
text	_	_
corpus	_	_
provided	_	_
by	_	_
Google	_	_
.	_	_

#191
Each	_	_
word	_	_
is	_	_
represented	_	_
by	_	_
a	_	_
300	_	_
dimensional	_	_
vector	_	_
.	_	_

#192
We	_	_
experiment	_	_
on	_	_
both	_	_
attribute	_	_
and	_	_
word2vec	_	_
representations	_	_
.	_	_

#193
For	_	_
HMDB51	_	_
dataset	_	_
,	_	_
to	_	_
the	_	_
best	_	_
of	_	_
our	_	_
knowledge	_	_
,	_	_
there	_	_
is	_	_
no	_	_
publicly	_	_
available	_	_
attribute	_	_
representations	_	_
of	_	_
the	_	_
classes	_	_
.	_	_

#194
Hence	_	_
only	_	_
word2vec	_	_
is	_	_
used	_	_
for	_	_
HMDB51	_	_
.	_	_

#195
However	_	_
,	_	_
for	_	_
UCF101	_	_
and	_	_
Olympic	_	_
datasets	_	_
,	_	_
115	_	_
and	_	_
40	_	_
dimensional	_	_
attribute	_	_
vectors	_	_
are	_	_
available	_	_
respectively	_	_
[	_	_
26	_	_
,	_	_
17	_	_
]	_	_
.	_	_

#196
Method	_	_
Embed	_	_
Olympic	_	_
UCF101	_	_
HMDB51	_	_
HAA	_	_
[	_	_
16	_	_
]	_	_
A	_	_
46.1	_	_
±	_	_
12.4	_	_
14.9	_	_
±	_	_
.8	_	_
N/A	_	_
DAP	_	_
[	_	_
13	_	_
]	_	_
A	_	_
45.4	_	_
±	_	_
12.8	_	_
14.3	_	_
±	_	_
1.3	_	_
N/A	_	_
IAP	_	_
[	_	_
14	_	_
]	_	_
A	_	_
42.3±12.5	_	_
12.8	_	_
±	_	_
2	_	_
N/A	_	_
ST	_	_
[	_	_
33	_	_
]	_	_
W	_	_
N/A	_	_
13.0±2.7	_	_
10.9±1.5	_	_
SJE	_	_
[	_	_
1	_	_
]	_	_
W	_	_
28.6±4.9	_	_
9.9±1.4	_	_
13.3±2.4	_	_
SJE	_	_
[	_	_
1	_	_
]	_	_
A	_	_
47.0±14.8	_	_
12.0±1.2	_	_
N/A	_	_
ESZSL	_	_
[	_	_
23	_	_
]	_	_
W	_	_
39.6±9.6	_	_
15.0±1.3	_	_
18.5±2	_	_
UDA	_	_
[	_	_
8	_	_
]	_	_
A	_	_
N/A	_	_
13.2±1.9	_	_
N/A	_	_
Bi-dir	_	_
[	_	_
31	_	_
]	_	_
A	_	_
N/A	_	_
20.5±.5	_	_
N/A	_	_
Bi-dir	_	_
[	_	_
31	_	_
]	_	_
W	_	_
N/A	_	_
18.9±.4	_	_
18.6±.7	_	_
Ours	_	_
A	_	_
50.41±11.2	_	_
22.74±1.2	_	_
N/A	_	_
Ours	_	_
W	_	_
34.12±10.1	_	_
17.33+1.1	_	_
19.28±2.1	_	_
Table	_	_
2	_	_
.	_	_

#197
Results	_	_
on	_	_
inductive	_	_
setting	_	_
for	_	_
standard	_	_
zero	_	_
shot	_	_
learning	_	_
setting	_	_
(	_	_
disjoint	_	_
setting	_	_
)	_	_
for	_	_
the	_	_
action	_	_
recognition	_	_
.	_	_

#198
Here	_	_
A	_	_
represents	_	_
the	_	_
human	_	_
annotated	_	_
attribute	_	_
vectors	_	_
and	_	_
W	_	_
represents	_	_
the	_	_
word2vec	_	_
embedding	_	_
.	_	_

#199
Hyper-parameters	_	_
:	_	_
Our	_	_
model	_	_
consists	_	_
of	_	_
four	_	_
hyperparameters	_	_
:	_	_
λµ	_	_
,	_	_
λ1	_	_
(	_	_
Eq.	_	_
4	_	_
)	_	_
and	_	_
λσ2	_	_
,	_	_
λ2	_	_
(	_	_
Eq.	_	_
12	_	_
)	_	_
for	_	_
estimating	_	_
the	_	_
projection	_	_
matrix	_	_
for	_	_
mean	_	_
and	_	_
variance	_	_
.	_	_

#200
The	_	_
optimal	_	_
values	_	_
of	_	_
hyper-parameters	_	_
are	_	_
chosen	_	_
via	_	_
cross	_	_
validation	_	_
on	_	_
the	_	_
seen	_	_
classes	_	_
.	_	_

#201
For	_	_
cross	_	_
validation	_	_
,	_	_
we	_	_
randomly	_	_
fix	_	_
1/4th	_	_
of	_	_
the	_	_
seen	_	_
classes	_	_
as	_	_
validation	_	_
classes	_	_
and	_	_
conduct	_	_
five	_	_
trials	_	_
on	_	_
30	_	_
random	_	_
splits	_	_
(	_	_
same	_	_
as	_	_
[	_	_
31	_	_
]	_	_
)	_	_
.	_	_

#202
For	_	_
generalized	_	_
ZSL	_	_
setting	_	_
,	_	_
the	_	_
number	_	_
of	_	_
synthesize	_	_
examples	_	_
for	_	_
unseen	_	_
classes	_	_
is	_	_
also	_	_
hyper-parameter	_	_
which	_	_
we	_	_
find	_	_
using	_	_
cross-validation	_	_
and	_	_
observe	_	_
best	_	_
model	_	_
performance	_	_
for	_	_
200	_	_
synthesized	_	_
examples	_	_
.	_	_

#203
4.1	_	_
.	_	_

#204
Inductive	_	_
and	_	_
Transductive	_	_
ZSL	_	_
In	_	_
our	_	_
first	_	_
set	_	_
of	_	_
experiments	_	_
,	_	_
we	_	_
evaluate	_	_
our	_	_
model	_	_
for	_	_
zero-shot	_	_
action	_	_
recognition	_	_
with	_	_
inductive	_	_
and	_	_
transductive	_	_
setting	_	_
and	_	_
compare	_	_
with	_	_
a	_	_
number	_	_
of	_	_
state-of-the-art	_	_
methods	_	_
.	_	_

#205
Evaluation	_	_
Metric	_	_
:	_	_
We	_	_
evaluate	_	_
our	_	_
model	_	_
using	_	_
30	_	_
different	_	_
splits	_	_
into	_	_
seen	_	_
and	_	_
unseen	_	_
classes	_	_
provided	_	_
by	_	_
[	_	_
31	_	_
]	_	_
for	_	_
UCF101	_	_
(	_	_
51/50	_	_
)	_	_
,	_	_
HMDB51	_	_
(	_	_
26/25	_	_
)	_	_
datasets	_	_
.	_	_

#206
For	_	_
Olympic	_	_
dataset	_	_
,	_	_
we	_	_
generate	_	_
30	_	_
random	_	_
splits	_	_
for	_	_
seen	_	_
and	_	_
unseen	_	_
classes	_	_
(	_	_
8/8	_	_
)	_	_
.	_	_

#207
We	_	_
use	_	_
the	_	_
average	_	_
accuracy	_	_
for	_	_
all	_	_
30	_	_
splits	_	_
as	_	_
the	_	_
evaluation	_	_
metric	_	_
.	_	_

#208
For	_	_
fair	_	_
comparison	_	_
,	_	_
we	_	_
run	_	_
five	_	_
such	_	_
trials	_	_
for	_	_
30	_	_
random	_	_
splits	_	_
and	_	_
present	_	_
the	_	_
final	_	_
accuracy	_	_
with	_	_
average	_	_
and	_	_
standard	_	_
deviation	_	_
.	_	_

#209
For	_	_
generalized	_	_
zero-shot	_	_
setting	_	_
we	_	_
have	_	_
evaluated	_	_
for	_	_
30	_	_
different	_	_
splits	_	_
as	_	_
above	_	_
and	_	_
calculated	_	_
the	_	_
average	_	_
accuracy	_	_
for	_	_
seen	_	_
and	_	_
unseen	_	_
classes	_	_
.	_	_

#210
The	_	_
final	_	_
evaluation	_	_
metric	_	_
of	_	_
our	_	_
model	_	_
is	_	_
on	_	_
the	_	_
harmonic	_	_
mean	_	_
of	_	_
the	_	_
average	_	_
accuracy	_	_
of	_	_
seen	_	_
and	_	_
unseen	_	_
classes	_	_
,	_	_
as	_	_
used	_	_
in	_	_
[	_	_
20	_	_
,	_	_
16	_	_
,	_	_
1	_	_
]	_	_
.	_	_

#211
Inductive	_	_
setting	_	_
:	_	_
In	_	_
this	_	_
setting	_	_
,	_	_
it	_	_
is	_	_
assumed	_	_
that	_	_
only	_	_
the	_	_
labeled	_	_
data	_	_
from	_	_
the	_	_
seen	_	_
classes	_	_
is	_	_
available	_	_
during	_	_
training	_	_
.	_	_

#212
Table	_	_
2	_	_
shows	_	_
the	_	_
experimental	_	_
results	_	_
in	_	_
the	_	_
inductive	_	_
setting	_	_
of	_	_
the	_	_
zero-shot	_	_
action	_	_
recognition	_	_
problem	_	_
.	_	_

#213
We	_	_
assume	_	_
that	_	_
the	_	_
train	_	_
and	_	_
test	_	_
classes	_	_
are	_	_
disjoint	_	_
.	_	_

#214
Note	_	_
that	_	_
this	_	_
assumption	_	_
is	_	_
made	_	_
for	_	_
all	_	_
the	_	_
evaluation	_	_
settings	_	_
in	_	_
this	_	_
work	_	_
.	_	_

#215
In	_	_
this	_	_
setting	_	_
,	_	_
we	_	_
obtain	_	_
an	_	_
improvement	_	_
of	_	_
3	_	_
%	_	_
over	_	_
the	_	_
state-of-the-art	_	_
on	_	_
the	_	_
Olympic	_	_
dataset	_	_
.	_	_

#216
On	_	_
UCF-101	_	_
,	_	_
which	_	_
is	_	_
the	_	_
most	_	_
used	_	_
dataset	_	_
for	_	_
zero	_	_
shot	_	_
action	_	_
recognition	_	_
,	_	_
the	_	_
proposed	_	_
model	_	_
outperforms	_	_
state-of-the-art	_	_
on	_	_
attribute-based	_	_
semantic	_	_
representations	_	_
.	_	_

#217
For	_	_
HMDB	_	_
dataset	_	_
,	_	_
the	_	_
attribute	_	_
vectors	_	_
are	_	_
not	_	_
available	_	_
.	_	_

#218
Hence	_	_
,	_	_
we	_	_
present	_	_
results	_	_
only	_	_
on	_	_
word2vec	_	_
embeddings	_	_
.	_	_

#219
Our	_	_
model	_	_
outperforms	_	_
the	_	_
state-of-the-art	_	_
for	_	_
this	_	_
dataset	_	_
as	_	_
well	_	_
.	_	_

#220
We	_	_
believe	_	_
the	_	_
improvements	_	_
can	_	_
be	_	_
attributed	_	_
to	_	_
its	_	_
inherent	_	_
nature	_	_
of	_	_
sharing	_	_
information	_	_
across	_	_
classes	_	_
(	_	_
by	_	_
modeling	_	_
each	_	_
as	_	_
a	_	_
basis	_	_
combination	_	_
of	_	_
prototype	_	_
classes	_	_
)	_	_
and	_	_
its	_	_
simple	_	_
estimation	_	_
procedure	_	_
.	_	_

#221
Method	_	_
Embed	_	_
Olympic	_	_
UCF101	_	_
HMDB51	_	_
PST	_	_
[	_	_
22	_	_
]	_	_
A	_	_
48.6±11	_	_
15.3	_	_
±2.2	_	_
N/A	_	_
ST	_	_
[	_	_
33	_	_
]	_	_
W	_	_
N/A	_	_
15.8±2.3	_	_
15.0±3	_	_
TZWE	_	_
[	_	_
34	_	_
]	_	_
A	_	_
53.5±11.9	_	_
20.2±2.2	_	_
N/A	_	_
TZWE	_	_
[	_	_
34	_	_
]	_	_
W	_	_
38.6±10.6	_	_
18.0±2.7	_	_
19.1	_	_
±3.8	_	_
Bi-dir	_	_
[	_	_
31	_	_
]	_	_
A	_	_
N/A	_	_
28.3±1.0	_	_
N/A	_	_
Bi-dir	_	_
[	_	_
31	_	_
]	_	_
W	_	_
N/A	_	_
21.4±.8	_	_
18.9±1.1	_	_
UDA	_	_
[	_	_
8	_	_
]	_	_
A	_	_
N/A	_	_
13.2±.6	_	_
N/A	_	_
Ours	_	_
A	_	_
57.88±14.1	_	_
24.48±2.9	_	_
N/A	_	_
Ours	_	_
W	_	_
41.27±11.4	_	_
20.25±1.9	_	_
20.67±3.1	_	_
Table	_	_
3	_	_
.	_	_

#222
Results	_	_
on	_	_
transductive	_	_
setting	_	_
for	_	_
the	_	_
standard	_	_
zero	_	_
shot	_	_
action	_	_
recognition	_	_
.	_	_

#223
Here	_	_
A	_	_
represents	_	_
the	_	_
human	_	_
annotated	_	_
attribute	_	_
vectors	_	_
and	_	_
W	_	_
represents	_	_
the	_	_
word2vec	_	_
embedding	_	_
.	_	_

#224
Transductive	_	_
setting	_	_
:	_	_
In	_	_
the	_	_
transductive	_	_
setting	_	_
,	_	_
it	_	_
is	_	_
assumed	_	_
that	_	_
the	_	_
unlabeled	_	_
data	_	_
of	_	_
the	_	_
unseen	_	_
classes	_	_
is	_	_
also	_	_
available	_	_
at	_	_
train	_	_
time	_	_
.	_	_

#225
Table	_	_
3	_	_
shows	_	_
the	_	_
performance	_	_
of	_	_
our	_	_
model	_	_
in	_	_
the	_	_
transductive	_	_
setting	_	_
.	_	_

#226
The	_	_
unlabeled	_	_
data	_	_
from	_	_
unseen	_	_
classes	_	_
helps	_	_
us	_	_
mitigate	_	_
the	_	_
bias	_	_
towards	_	_
the	_	_
seen	_	_
classes	_	_
.	_	_

#227
In	_	_
this	_	_
setting	_	_
,	_	_
our	_	_
model	_	_
outperforms	_	_
the	_	_
state-of-the-art	_	_
in	_	_
the	_	_
Olympic	_	_
and	_	_
HMDB	_	_
datasets	_	_
.	_	_

#228
The	_	_
performance	_	_
on	_	_
the	_	_
UCF-101	_	_
dataset	_	_
is	_	_
slightly	_	_
worse	_	_
,	_	_
where	_	_
[	_	_
31	_	_
]	_	_
has	_	_
the	_	_
best	_	_
performance	_	_
.	_	_

#229
However	_	_
,	_	_
note	_	_
that	_	_
we	_	_
outperform	_	_
[	_	_
31	_	_
]	_	_
in	_	_
the	_	_
inductive	_	_
setting	_	_
.	_	_

#230
Method	_	_
Embed	_	_
Olympic	_	_
UCF101	_	_
HMDB51	_	_
HAA	_	_
[	_	_
16	_	_
]	_	_
A	_	_
49.4	_	_
±	_	_
10.8	_	_
18.7	_	_
±	_	_
2.4	_	_
N/A	_	_
SJE	_	_
[	_	_
1	_	_
]	_	_
W	_	_
32.5±6.7	_	_
8.9±2.2	_	_
10.5±2.4	_	_
ConSE	_	_
[	_	_
20	_	_
]	_	_
W	_	_
37.6	_	_
±	_	_
9.9	_	_
12.7	_	_
±	_	_
2.2	_	_
15.4±	_	_
2.8	_	_
Ours	_	_
A	_	_
52.41±12.2	_	_
23.74±1.2	_	_
N/A	_	_
Ours	_	_
W	_	_
42.23±10.2	_	_
17.45±2.2	_	_
20.10±2.1	_	_
Table	_	_
4	_	_
.	_	_

#231
Results	_	_
on	_	_
the	_	_
transductive	_	_
setting	_	_
for	_	_
generalized	_	_
zero-shot	_	_
learning	_	_
setting	_	_
for	_	_
the	_	_
action	_	_
recognition	_	_
.	_	_

#232
Here	_	_
A	_	_
represents	_	_
the	_	_
human	_	_
annotated	_	_
attribute	_	_
vectors	_	_
and	_	_
W	_	_
represents	_	_
the	_	_
word2vec	_	_
embedding	_	_
.	_	_

#233
4.2.	_	_
Generalized	_	_
ZSL	_	_

#234
In	_	_
this	_	_
setting	_	_
,	_	_
the	_	_
test	_	_
data	_	_
may	options	_
come	_	_
from	_	_
both	_	_
seen	_	_
and	_	_
unseen	_	_
classes	_	_
.	_	_

#235
In	_	_
this	_	_
setting	_	_
,	_	_
from	_	_
the	_	_
seen	_	_
classes	_	_
,	_	_
we	_	_
separate	_	_
20	_	_
%	_	_
of	_	_
the	_	_
data	_	_
for	_	_
testing	_	_
and	_	_
remaining	_	_
80	_	_
%	_	_
data	_	_
is	_	_
used	_	_
as	_	_
training	_	_
data	_	_
for	_	_
calculating	_	_
Wµ	_	_
and	_	_
Wσ2	_	_
which	_	_
is	_	_
used	_	_
to	_	_
predict	_	_
the	_	_
mean	_	_
(	_	_
µc	_	_
)	_	_
and	_	_
variance	_	_
(	_	_
σ2	_	_
c	_	_
)	_	_
for	_	_
the	_	_
unseen	_	_
classes	_	_
.	_	_

#236
One	_	_
way	_	_
to	_	_
handle	_	_
this	_	_
setting	_	_
is	_	_
to	_	_
assign	_	_
each	_	_
test	_	_
data-point	_	_
to	_	_
the	_	_
class	_	_
whose	_	_
estimated	_	_
distribution	_	_
gives	_	_
the	_	_
highest	_	_
score	_	_
.	_	_

#237
However	_	_
,	_	_
we	_	_
notice	_	_
that	_	_
such	_	_
an	_	_
approach	_	_
is	_	_
biased	_	_
towards	_	_
seen	_	_
classes	_	_
since	_	_
the	_	_
model	_	_
has	_	_
not	_	_
seen	_	_
any	_	_
unseen	_	_
class	_	_
examples	_	_
.	_	_

#238
In	_	_
our	_	_
approach	_	_
,	_	_
we	_	_
propose	_	_
the	_	_
following	_	_
solution	_	_
to	_	_
this	_	_
issue	_	_
:	_	_
we	_	_
synthesize	_	_
class	_	_
instances	_	_
of	_	_
unseen	_	_
classes	_	_
using	_	_
the	_	_
µc	_	_
and	_	_
σ2	_	_
c	_	_
which	_	_
are	_	_
obtained	_	_
from	_	_
the	_	_
transductive	_	_
setting	_	_
approach	_	_
;	_	_
these	_	_
class	_	_
instances	_	_
are	_	_
called	_	_
pseudo	_	_
class	_	_
instances	_	_
for	_	_
unseen	_	_
classes	_	_
.	_	_

#239
Here	_	_
we	_	_
generate	_	_
200	_	_
instances	_	_
for	_	_
each	_	_
unseen	_	_
classes	_	_
.	_	_

#240
Since	_	_
we	_	_
now	_	_
have	_	_
labelled	_	_
data	_	_
for	_	_
seen	_	_
classes	_	_
and	_	_
pseudo	_	_
labelled	_	_
data	_	_
for	_	_
unseen	_	_
classes	_	_
,	_	_
we	_	_
train	_	_
SVM	_	_
classifier	_	_
for	_	_
labelled	_	_
seen	_	_
classes	_	_
data	_	_
and	_	_
pseudo	_	_
labelled	_	_
data	_	_
for	_	_
unseen	_	_
classes	_	_
.	_	_

#241
We	_	_
then	_	_
pass	_	_
the	_	_
test	_	_
data	_	_
(	_	_
unseen	_	_
class	_	_
data	_	_
plus	_	_
20	_	_
%	_	_
seen	_	_
class	_	_
data	_	_
)	_	_
to	_	_
the	_	_
trained	_	_
SVM	_	_
classifier	_	_
for	_	_
classification	_	_
.	_	_

#242
Table	_	_
4	_	_
presents	_	_
the	_	_
performance	_	_
of	_	_
our	_	_
model	_	_
in	_	_
the	_	_
generalized	_	_
setting	_	_
for	_	_
zero-shot	_	_
action	_	_
classification	_	_
which	_	_
clearly	_	_
shows	_	_
that	_	_
it	_	_
significantly	_	_
outperforms	_	_
state-of-art	_	_
on	_	_
all	_	_
the	_	_
datasets	_	_
.	_	_

#243
4.3	_	_
.	_	_

#244
Few-shot	_	_
action	_	_
recognition	_	_
Finally	_	_
,	_	_
we	_	_
experiment	_	_
with	_	_
the	_	_
few	_	_
shot	_	_
action	_	_
recognition	_	_
setting	_	_
and	_	_
present	_	_
the	_	_
results	_	_
.	_	_

#245
Here	_	_
only	_	_
a	_	_
small	_	_
number	_	_
of	_	_
examples	_	_
for	_	_
each	_	_
of	_	_
the	_	_
unseen	_	_
classes	_	_
are	_	_
available	_	_
during	_	_
training	_	_
.	_	_

#246
Our	_	_
generative	_	_
model	_	_
provides	_	_
a	_	_
simple	_	_
way	_	_
to	_	_
update	_	_
the	_	_
parameters	_	_
of	_	_
the	_	_
class	_	_
distribution	_	_
using	_	_
equation	_	_
18	_	_
,	_	_
19	_	_
.	_	_

#247
It	_	_
is	_	_
clear	_	_
from	_	_
the	_	_
Table	_	_
5	_	_
that	_	_
availability	_	_
of	_	_
the	_	_
few	_	_
data	_	_
points	_	_
of	_	_
the	_	_
unseen	_	_
classes	_	_
significantly	_	_
improves	_	_
the	_	_
performance	_	_
which	_	_
is	_	_
now	_	_
comparable	_	_
to	_	_
that	_	_
of	_	_
supervised	_	_
learning	_	_
.	_	_

#248
Note	_	_
that	_	_
we	_	_
do	_	_
not	_	_
assume	_	_
any	_	_
un-labeled	_	_
data	_	_
from	_	_
the	_	_
unseen	_	_
classes	_	_
in	_	_
this	_	_
setting	_	_
.	_	_

#249
We	_	_
test	_	_
our	_	_
model	_	_
with	_	_
varying	_	_
number	_	_
of	_	_
examples	_	_
of	_	_
each	_	_
unseen	_	_
classes	_	_
.	_	_

#250
The	_	_
plot	_	_
of	_	_
accuracy	_	_
with	_	_
respect	_	_
to	_	_
the	_	_
number	_	_
of	_	_
samples	_	_
per	_	_
class	_	_
is	_	_
shown	_	_
in	_	_
Figure	_	_
3	_	_
.	_	_

#251
Dataset	_	_
2	_	_
samples	_	_
3	_	_
samples	_	_
4	_	_
samples	_	_
5	_	_
samples	_	_
UCF101	_	_
68.78±3.3	_	_
73.49±2.2	_	_
76.51±2.1	_	_
78.68±1.8	_	_
HMDB51	_	_
42.10±3.6	_	_
47.54±3.3	_	_
50.34±3.4	_	_
52.58±3.1	_	_
Olympic	_	_
73.20±7.4	_	_
75.35±7.3	_	_
80.21±7.24	_	_
83.81±7.11	_	_
Table	_	_
5	_	_
.	_	_

#252
Inductive	_	_
setting	_	_
with	_	_
few-shot	_	_
action	_	_
recognition	_	_
Figure	_	_
3	_	_
.	_	_

#253
Accuracy	_	_
vs	_	_
number	_	_
of	_	_
data	_	_
points	_	_
for	_	_
few-shot	_	_
learning	_	_
5	_	_
.	_	_

#254
Conclusion	_	_
We	_	_
have	_	_
presented	_	_
a	_	_
simple	_	_
,	_	_
probabilistic	_	_
,	_	_
generative	_	_
model	_	_
based	_	_
framework	_	_
for	_	_
zero-shot	_	_
action	_	_
recognition	_	_
.	_	_

#255
The	_	_
proposed	_	_
approach	_	_
performs	_	_
well	_	_
in	_	_
both	_	_
the	_	_
inductive	_	_
and	_	_
transductive	_	_
setting	_	_
for	_	_
the	_	_
standard	_	_
(	_	_
disjoint	_	_
)	_	_
and	_	_
generalized	_	_
zero-shot	_	_
learning	_	_
.	_	_

#256
The	_	_
generative	_	_
aspect	_	_
of	_	_
our	_	_
model	_	_
unables	_	_
synthesizing	_	_
unseen	_	_
class	_	_
examples	_	_
and	_	_
can	_	_
effectively	_	_
work	_	_
in	_	_
the	_	_
generalized	_	_
ZSL	_	_
setting	_	_
.	_	_

#257
In	_	_
addition	_	_
,	_	_
the	_	_
ability	_	_
of	_	_
leverage	_	_
unlabeled	_	_
data	_	_
(	_	_
transductive	_	_
setting	_	_
)	_	_
helps	_	_
address	_	_
the	_	_
domain	_	_
shift	_	_
problem	_	_
between	_	_
seen	_	_
and	_	_
unseen	_	_
classes	_	_
.	_	_

#258
A	_	_
particularly	_	_
appealing	_	_
aspect	_	_
of	_	_
our	_	_
model	_	_
is	_	_
that	_	_
it	_	_
yields	_	_
a	_	_
closed	_	_
form	_	_
solution	_	_
for	_	_
the	_	_
parameters	_	_
to	_	_
make	_	_
it	_	_
fast	_	_
and	_	_
easy	_	_
to	_	_
implement	_	_
.	_	_

#259
Experimental	_	_
results	_	_
are	_	_
shown	_	_
to	_	_
achieve	_	_
state-of-the-art	_	_
performance	_	_
.	_	_

#260
The	_	_
proposed	_	_
method	_	_
also	_	_
generalizes	_	_
to	_	_
few-shot	_	_
action	_	_
recognition	_	_
setting	_	_
,	_	_
achieving	_	_
comparable	_	_
results	_	_
to	_	_
fully	_	_
supervised	_	_
learning	_	_
using	_	_
only	_	_
a	_	_
few	_	_
synthesized	_	_
examples	_	_
from	_	_
each	_	_
unseen	_	_
class	_	_
.	_	_