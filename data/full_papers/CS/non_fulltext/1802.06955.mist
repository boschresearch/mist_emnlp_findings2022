#0
ÔÄ†	_	_
Abstract‚ÄîDeep	_	_
learning	_	_
(	_	_
DL	_	_
)	_	_
based	_	_
semantic	_	_
segmentation	_	_
methods	_	_
have	_	_
been	_	_
providing	_	_
state-of-the-art	_	_
performance	_	_
in	_	_
the	_	_
last	_	_
few	_	_
years	_	_
.	_	_

#1
More	_	_
specifically	_	_
,	_	_
these	_	_
techniques	_	_
have	_	_
been	_	_
successfully	_	_
applied	_	_
to	_	_
medical	_	_
image	_	_
classification	_	_
,	_	_
segmentation	_	_
,	_	_
and	_	_
detection	_	_
tasks	_	_
.	_	_

#2
One	_	_
deep	_	_
learning	_	_
technique	_	_
,	_	_
U-Net	_	_
,	_	_
has	_	_
become	_	_
one	_	_
of	_	_
the	_	_
most	_	_
popular	_	_
for	_	_
these	_	_
applications	_	_
.	_	_

#3
In	_	_
this	_	_
paper	_	_
,	_	_
we	_	_
propose	_	_
a	_	_
Recurrent	_	_
Convolutional	_	_
Neural	_	_
Network	_	_
(	_	_
RCNN	_	_
)	_	_
based	_	_
on	_	_
U-Net	_	_
as	_	_
well	_	_
as	_	_
a	_	_
Recurrent	_	_
Residual	_	_
Convolutional	_	_
Neural	_	_
Network	_	_
(	_	_
RRCNN	_	_
)	_	_
based	_	_
on	_	_
U-Net	_	_
models	_	_
,	_	_
which	_	_
are	_	_
named	_	_
RU-Net	_	_
and	_	_
R2U-Net	_	_
respectively	_	_
.	_	_

#4
The	_	_
proposed	_	_
models	_	_
utilize	_	_
the	_	_
power	_	_
of	_	_
U-Net	_	_
,	_	_
Residual	_	_
Network	_	_
,	_	_
as	_	_
well	_	_
as	_	_
RCNN	_	_
.	_	_

#5
There	_	_
are	_	_
several	_	_
advantages	_	_
of	_	_
these	_	_
proposed	_	_
architectures	_	_
for	_	_
segmentation	_	_
tasks	_	_
.	_	_

#6
First	_	_
,	_	_
a	_	_
residual	_	_
unit	_	_
helps	_	_
when	_	_
training	_	_
deep	_	_
architecture	_	_
.	_	_

#7
Second	_	_
,	_	_
feature	_	_
accumulation	_	_
with	_	_
recurrent	_	_
residual	_	_
convolutional	_	_
layers	_	_
ensures	_	_
better	_	_
feature	_	_
representation	_	_
for	_	_
segmentation	_	_
tasks	_	_
.	_	_

#8
Third	_	_
,	_	_
it	_	_
allows	_	_
us	_	_
to	_	_
design	_	_
better	_	_
U-Net	_	_
architecture	_	_
with	_	_
same	_	_
number	_	_
of	_	_
network	_	_
parameters	_	_
with	_	_
better	_	_
performance	_	_
for	_	_
medical	_	_
image	_	_
segmentation	_	_
.	_	_

#9
The	_	_
proposed	_	_
models	_	_
are	_	_
tested	_	_
on	_	_
three	_	_
benchmark	_	_
datasets	_	_
such	_	_
as	_	_
blood	_	_
vessel	_	_
segmentation	_	_
in	_	_
retina	_	_
images	_	_
,	_	_
skin	_	_
cancer	_	_
segmentation	_	_
,	_	_
and	_	_
lung	_	_
lesion	_	_
segmentation	_	_
.	_	_

#10
The	_	_
experimental	_	_
results	_	_
show	_	_
superior	_	_
performance	_	_
on	_	_
segmentation	_	_
tasks	_	_
compared	_	_
to	_	_
equivalent	_	_
models	_	_
including	_	_
U-Net	_	_
and	_	_
residual	_	_
U-Net	_	_
(	_	_
ResU-Net	_	_
)	_	_
.	_	_

#11
Index	_	_
Terms‚ÄîMedical	_	_
imaging	_	_
,	_	_
Semantic	_	_
segmentation	_	_
,	_	_
Convolutional	_	_
Neural	_	_
Networks	_	_
,	_	_
U-Net	_	_
,	_	_
Residual	_	_
U-Net	_	_
,	_	_
RU-Net	_	_
,	_	_
and	_	_
R2U-Net	_	_
.	_	_

#12
I	_	_
.	_	_

#13
INTRODUCTION	_	_
OWADAYS	_	_
DL	_	_
provides	_	_
state-of-the-art	_	_
performance	_	_
for	_	_
image	_	_
classification	_	_
[	_	_
1	_	_
]	_	_
,	_	_
segmentation	_	_
[	_	_
2	_	_
]	_	_
,	_	_
detection	_	_
and	_	_
tracking	_	_
[	_	_
3	_	_
]	_	_
,	_	_
and	_	_
captioning	_	_
[	_	_
4	_	_
]	_	_
.	_	_

#14
Since	_	_
2012	_	_
,	_	_
several	_	_
Deep	_	_
Convolutional	_	_
Neural	_	_
Network	_	_
(	_	_
DCNN	_	_
)	_	_
models	_	_
have	_	_
been	_	_
proposed	_	_
such	_	_
as	_	_
AlexNet	_	_
[	_	_
1	_	_
]	_	_
,	_	_
VGG	_	_
[	_	_
5	_	_
]	_	_
,	_	_
GoogleNet	_	_
[	_	_
6	_	_
]	_	_
,	_	_
Residual	_	_
Net	_	_
[	_	_
7	_	_
]	_	_
,	_	_
DenseNet	_	_
[	_	_
8	_	_
]	_	_
,	_	_
and	_	_
CapsuleNet	_	_
[	_	_
9	_	_
]	_	_
[	_	_
65	_	_
]	_	_
.	_	_

#15
A	_	_
DL	_	_
based	_	_
approach	_	_
(	_	_
CNN	_	_
in	_	_
particular	_	_
)	_	_
provides	_	_
state-of-the-art	_	_
performance	_	_
for	_	_
classification	_	_
and	_	_
segmentation	_	_
tasks	_	_
for	_	_
several	_	_
reasons	_	_
:	_	_
first	_	_
,	_	_
activation	_	_
functions	_	_
resolve	_	_
training	_	_
problems	_	_
in	_	_
DL	_	_
approaches	_	_
.	_	_

#16
Second	_	_
,	_	_
dropout	_	_
helps	_	_
regularize	_	_
the	_	_
networks	_	_
.	_	_

#17
Third	_	_
,	_	_
several	_	_
efficient	_	_
optimization	_	_
techniques	_	_
Md	_	_
Zahangir	_	_
Alom1*	_	_
,	_	_
Chris	_	_
Yakopcic1	_	_
,	_	_
Tarek	_	_
M.	_	_
Taha1	_	_
,	_	_
and	_	_
Vijayan	_	_
K.	_	_
Asari1	_	_
are	_	_
with	_	_
the	_	_
University	_	_
of	_	_
Dayton	_	_
,	_	_
300	_	_
College	_	_
Park	_	_
,	_	_
Dayton	_	_
,	_	_
OH	_	_
,	_	_
45469	_	_
,	_	_
USA	_	_
.	_	_

#18
(	_	_
e-mail	_	_
:	_	_
{	_	_
alomm1	_	_
,	_	_
cyakopcic1	_	_
,	_	_
ttaha1	_	_
,	_	_
vasari1	_	_
}	_	_
@	_	_
udayton.edu	_	_
)	_	_
.	_	_

#19
are	_	_
available	_	_
for	_	_
training	_	_
CNN	_	_
models	_	_
[	_	_
1	_	_
]	_	_
.	_	_

#20
However	_	_
,	_	_
in	_	_
most	_	_
cases	_	_
,	_	_
models	_	_
are	_	_
explored	_	_
and	_	_
evaluated	_	_
using	_	_
classification	_	_
tasks	_	_
on	_	_
very	_	_
large-scale	_	_
datasets	_	_
like	_	_
ImageNet	_	_
[	_	_
1	_	_
]	_	_
,	_	_
where	_	_
the	_	_
outputs	_	_
of	_	_
the	_	_
classification	_	_
tasks	_	_
are	_	_
single	_	_
label	_	_
or	_	_
probability	_	_
values	_	_
.	_	_

#21
Alternatively	_	_
,	_	_
small	_	_
architecturally	_	_
variant	_	_
models	_	_
are	_	_
used	_	_
for	_	_
semantic	_	_
image	_	_
segmentation	_	_
tasks	_	_
.	_	_

#22
For	_	_
example	_	_
,	_	_
a	_	_
fully-connected	_	_
convolutional	_	_
neural	_	_
network	_	_
(	_	_
FCN	_	_
)	_	_
also	_	_
provides	_	_
state-of-the-art	_	_
results	_	_
for	_	_
image	_	_
segmentation	_	_
tasks	_	_
in	_	_
computer	_	_
vision	_	_
[	_	_
2	_	_
]	_	_
.	_	_

#23
Another	_	_
variant	_	_
of	_	_
FCN	_	_
was	_	_
also	_	_
proposed	_	_
which	_	_
is	_	_
called	_	_
SegNet	_	_
[	_	_
10	_	_
]	_	_
.	_	_

#24
Fig.	_	_
1	_	_
.	_	_

#25
Medical	_	_
image	_	_
segmentation	_	_
:	_	_
retina	_	_
blood	_	_
vessel	_	_
segmentation	_	_
in	_	_
the	_	_
left	_	_
,	_	_
skin	_	_
cancer	_	_
lesion	_	_
segmentation	_	_
,	_	_
and	_	_
lung	_	_
segmentation	_	_
in	_	_
the	_	_
right	_	_
.	_	_

#26
Due	_	_
to	_	_
the	_	_
great	_	_
success	_	_
of	_	_
DCNNs	_	_
in	_	_
the	_	_
field	_	_
of	_	_
computer	_	_
vision	_	_
,	_	_
different	_	_
variants	_	_
of	_	_
this	_	_
approach	_	_
are	_	_
applied	_	_
in	_	_
different	_	_
modalities	_	_
of	_	_
medical	_	_
imaging	_	_
including	_	_
segmentation	_	_
,	_	_
classification	_	_
,	_	_
detection	_	_
,	_	_
registration	_	_
,	_	_
and	_	_
medical	_	_
information	_	_
processing	_	_
.	_	_

#27
The	_	_
medical	_	_
imaging	_	_
comes	_	_
from	_	_
different	_	_
imaging	_	_
techniques	_	_
such	_	_
as	_	_
Computer	_	_
Tomography	_	_
(	_	_
CT	_	_
)	_	_
,	_	_
ultrasound	_	_
,	_	_
X-ray	_	_
,	_	_
and	_	_
Magnetic	_	_
Resonance	_	_
Imaging	_	_
(	_	_
MRI	_	_
)	_	_
.	_	_

#28
The	_	_
goal	_	_
of	_	_
Computer-Aided	_	_
Diagnosis	_	_
(	_	_
CAD	_	_
)	_	_
is	_	_
to	_	_
obtain	_	_
a	_	_
faster	_	_
and	_	_
better	_	_
diagnosis	_	_
to	_	_
ensure	_	_
better	_	_
treatment	_	_
of	_	_
a	_	_
large	_	_
number	_	_
of	_	_
people	_	_
at	_	_
the	_	_
same	_	_
time	_	_
.	_	_

#29
Additionally	_	_
,	_	_
efficient	_	_
automatic	_	_
processing	_	_
without	_	_
human	_	_
involvement	_	_
to	_	_
reduce	_	_
human	_	_
error	_	_
and	_	_
also	_	_
reduces	_	_
overall	_	_
time	_	_
and	_	_
cost	_	_
.	_	_

#30
Due	_	_
to	_	_
the	_	_
slow	_	_
process	_	_
and	_	_
tedious	_	_
nature	_	_
of	_	_
Mahmudul	_	_
Hasan2	_	_
,	_	_
is	_	_
with	_	_
Comcast	_	_
Labs	_	_
,	_	_
Washington	_	_
,	_	_
DC	_	_
,	_	_
USA	_	_
.	_	_

#31
(	_	_
e-mail	_	_
:	_	_
mahmud.ucr	_	_
@	_	_
gmail.com	_	_
)	_	_
.	_	_

#32
Recurrent	_	_
Residual	_	_
Convolutional	_	_
Neural	_	_
Network	_	_
based	_	_
on	_	_
U-Net	_	_
(	_	_
R2U-Net	_	_
)	_	_
for	_	_
Medical	_	_
Image	_	_
Segmentation	_	_
Md	_	_
Zahangir	_	_
Alom1*	_	_
,	_	_
Student	_	_
Member	_	_
,	_	_
IEEE	_	_
,	_	_
Mahmudul	_	_
Hasan2	_	_
,	_	_
Chris	_	_
Yakopcic1	_	_
,	_	_
Member	_	_
,	_	_
IEEE	_	_
,	_	_
Tarek	_	_
M.	_	_
Taha1	_	_
,	_	_
Member	_	_
,	_	_
IEEE	_	_
,	_	_
and	_	_
Vijayan	_	_
K.	_	_
Asari1	_	_
,	_	_
Senior	_	_
Member	_	_
,	_	_
IEEE	_	_
N	_	_
manual	_	_
segmentation	_	_
approaches	_	_
,	_	_
there	_	_
is	_	_
a	_	_
significant	_	_
demand	_	_
for	_	_
computer	_	_
algorithms	_	_
that	_	_
can	_	_
do	_	_
segmentation	_	_
quickly	_	_
and	_	_
accurately	_	_
without	_	_
human	_	_
interaction	_	_
.	_	_

#33
However	_	_
,	_	_
there	_	_
are	_	_
some	_	_
limitations	_	_
of	_	_
medical	_	_
image	_	_
segmentation	_	_
including	_	_
data	_	_
scarcity	_	_
and	_	_
class	_	_
imbalance	_	_
.	_	_

#34
Most	_	_
of	_	_
the	_	_
time	_	_
the	_	_
large	_	_
number	_	_
of	_	_
labels	_	_
(	_	_
often	_	_
in	_	_
the	_	_
thousands	_	_
)	_	_
for	_	_
training	_	_
is	_	_
not	_	_
available	_	_
for	_	_
several	_	_
reasons	_	_
[	_	_
11	_	_
]	_	_
.	_	_

#35
Labeling	_	_
the	_	_
dataset	_	_
requires	_	_
an	_	_
expert	_	_
in	_	_
this	_	_
field	_	_
which	_	_
is	_	_
expensive	_	_
,	_	_
and	_	_
it	_	_
requires	_	_
a	_	_
lot	_	_
of	_	_
effort	_	_
and	_	_
time	_	_
.	_	_

#36
Sometimes	_	_
,	_	_
different	_	_
data	_	_
transformation	_	_
or	_	_
augmentation	_	_
techniques	_	_
(	_	_
data	_	_
whitening	_	_
,	_	_
rotation	_	_
,	_	_
translation	_	_
,	_	_
and	_	_
scaling	_	_
)	_	_
are	_	_
applied	_	_
for	_	_
increasing	_	_
the	_	_
number	_	_
of	_	_
labeled	_	_
samples	_	_
available	_	_
[	_	_
12	_	_
,	_	_
13	_	_
,	_	_
and	_	_
14	_	_
]	_	_
.	_	_

#37
In	_	_
addition	_	_
,	_	_
patch	_	_
based	_	_
approaches	_	_
are	_	_
used	_	_
for	_	_
solving	_	_
class	_	_
imbalance	_	_
problems	_	_
.	_	_

#38
In	_	_
this	_	_
work	_	_
,	_	_
we	_	_
have	_	_
evaluated	_	_
the	_	_
proposed	_	_
approaches	_	_
on	_	_
both	_	_
patch-based	_	_
and	_	_
entire	_	_
image-based	_	_
approaches	_	_
.	_	_

#39
However	_	_
,	_	_
to	_	_
switch	_	_
from	_	_
the	_	_
patch-based	_	_
approach	_	_
to	_	_
the	_	_
pixel-based	_	_
approach	_	_
that	_	_
works	_	_
with	_	_
the	_	_
entire	_	_
image	_	_
,	_	_
we	_	_
must	deontic	_
be	_	_
aware	_	_
of	_	_
the	_	_
class	_	_
imbalance	_	_
problem	_	_
.	_	_

#40
In	_	_
the	_	_
case	_	_
of	_	_
semantic	_	_
segmentation	_	_
,	_	_
the	_	_
image	_	_
backgrounds	_	_
are	_	_
assigned	_	_
a	_	_
label	_	_
and	_	_
the	_	_
foreground	_	_
regions	_	_
are	_	_
assigned	_	_
a	_	_
target	_	_
class	_	_
.	_	_

#41
Therefore	_	_
,	_	_
the	_	_
class	_	_
imbalance	_	_
problem	_	_
is	_	_
resolved	_	_
without	_	_
any	_	_
trouble	_	_
.	_	_

#42
Two	_	_
advanced	_	_
techniques	_	_
including	_	_
cross-entropy	_	_
loss	_	_
and	_	_
dice	_	_
similarity	_	_
are	_	_
introduced	_	_
for	_	_
efficient	_	_
training	_	_
of	_	_
classification	_	_
and	_	_
segmentation	_	_
tasks	_	_
in	_	_
[	_	_
13	_	_
,	_	_
14	_	_
]	_	_
.	_	_

#43
Furthermore	_	_
,	_	_
in	_	_
medical	_	_
image	_	_
processing	_	_
,	_	_
global	_	_
localization	_	_
and	_	_
context	_	_
modulation	_	_
is	_	_
very	_	_
often	_	_
applied	_	_
for	_	_
localization	_	_
tasks	_	_
.	_	_

#44
Each	_	_
pixel	_	_
is	_	_
assigned	_	_
a	_	_
class	_	_
label	_	_
with	_	_
a	_	_
desired	_	_
boundary	_	_
that	_	_
is	_	_
related	_	_
to	_	_
the	_	_
contour	_	_
of	_	_
the	_	_
target	_	_
lesion	_	_
in	_	_
identification	_	_
tasks	_	_
.	_	_

#45
To	_	_
define	_	_
these	_	_
target	_	_
lesion	_	_
boundaries	_	_
,	_	_
we	_	_
must	deontic	_
emphasize	_	_
the	_	_
related	_	_
pixels	_	_
.	_	_

#46
Landmark	_	_
detection	_	_
in	_	_
medical	_	_
imaging	_	_
[	_	_
15	_	_
,	_	_
16	_	_
]	_	_
is	_	_
one	_	_
example	_	_
of	_	_
this	_	_
.	_	_

#47
There	_	_
were	_	_
several	_	_
traditional	_	_
machine	_	_
learning	_	_
and	_	_
image	_	_
processing	_	_
techniques	_	_
available	_	_
for	_	_
medical	_	_
image	_	_
segmentation	_	_
tasks	_	_
before	_	_
the	_	_
DL	_	_
revolution	_	_
,	_	_
including	_	_
amplitude	_	_
segmentation	_	_
based	_	_
on	_	_
histogram	_	_
features	_	_
[	_	_
17	_	_
]	_	_
,	_	_
the	_	_
region	_	_
based	_	_
segmentation	_	_
method	_	_
[	_	_
18	_	_
]	_	_
,	_	_
and	_	_
the	_	_
graph-cut	_	_
approach	_	_
[	_	_
19	_	_
]	_	_
.	_	_

#48
However	_	_
,	_	_
semantic	_	_
segmentation	_	_
approaches	_	_
that	_	_
utilize	_	_
DL	_	_
have	_	_
become	_	_
very	_	_
popular	_	_
in	_	_
recent	_	_
years	_	_
in	_	_
the	_	_
field	_	_
of	_	_
medical	_	_
image	_	_
segmentation	_	_
,	_	_
lesion	_	_
detection	_	_
,	_	_
and	_	_
localization	_	_
[	_	_
20	_	_
]	_	_
.	_	_

#49
In	_	_
addition	_	_
,	_	_
DL	_	_
based	_	_
approaches	_	_
are	_	_
known	_	_
as	_	_
universal	_	_
learning	_	_
approaches	_	_
,	_	_
where	_	_
a	_	_
single	_	_
model	_	_
can	_	_
be	_	_
utilized	_	_
efficiently	_	_
in	_	_
different	_	_
modalities	_	_
of	_	_
medical	_	_
imaging	_	_
such	_	_
as	_	_
MRI	_	_
,	_	_
CT	_	_
,	_	_
and	_	_
X-ray	_	_
.	_	_

#50
According	_	_
to	_	_
a	_	_
recent	_	_
survey	_	_
,	_	_
DL	_	_
approaches	_	_
are	_	_
applied	_	_
to	_	_
almost	_	_
all	_	_
modalities	_	_
of	_	_
medical	_	_
imagining	_	_
[	_	_
20	_	_
,	_	_
21	_	_
]	_	_
.	_	_

#51
Furthermore	_	_
,	_	_
the	_	_
highest	_	_
number	_	_
of	_	_
papers	_	_
have	_	_
been	_	_
published	_	_
on	_	_
segmentation	_	_
tasks	_	_
in	_	_
different	_	_
modalities	_	_
of	_	_
medical	_	_
imaging	_	_
[	_	_
20	_	_
,	_	_
21	_	_
]	_	_
.	_	_

#52
A	_	_
DCNN	_	_
based	_	_
brain	_	_
tumor	_	_
segmentation	_	_
and	_	_
detection	_	_
method	_	_
was	_	_
proposed	_	_
in	_	_
[	_	_
22	_	_
]	_	_
.	_	_

#53
From	_	_
an	_	_
architectural	_	_
point	_	_
of	_	_
view	_	_
,	_	_
the	_	_
CNN	_	_
model	_	_
for	_	_
classification	_	_
tasks	_	_
requires	_	_
an	_	_
encoding	_	_
unit	_	_
and	_	_
provides	_	_
class	_	_
probability	_	_
as	_	_
an	_	_
output	_	_
.	_	_

#54
In	_	_
classification	_	_
tasks	_	_
,	_	_
we	_	_
have	_	_
performed	_	_
convolution	_	_
operations	_	_
with	_	_
activation	_	_
functions	_	_
followed	_	_
by	_	_
sub-sampling	_	_
layers	_	_
which	_	_
reduces	_	_
the	_	_
dimensionality	_	_
of	_	_
the	_	_
feature	_	_
maps	_	_
.	_	_

#55
As	_	_
the	_	_
input	_	_
samples	_	_
traverse	_	_
through	_	_
the	_	_
layers	_	_
of	_	_
the	_	_
network	_	_
,	_	_
the	_	_
number	_	_
of	_	_
feature	_	_
maps	_	_
increases	_	_
but	_	_
the	_	_
dimensionality	_	_
of	_	_
the	_	_
feature	_	_
maps	_	_
decreases	_	_
.	_	_

#56
This	_	_
is	_	_
shown	_	_
in	_	_
the	_	_
first	_	_
part	_	_
of	_	_
the	_	_
model	_	_
(	_	_
in	_	_
green	_	_
)	_	_
in	_	_
Fig.	_	_
2	_	_
.	_	_

#57
Since	_	_
,	_	_
the	_	_
number	_	_
of	_	_
feature	_	_
maps	_	_
increase	_	_
in	_	_
the	_	_
deeper	_	_
layers	_	_
,	_	_
the	_	_
number	_	_
of	_	_
network	_	_
parameters	_	_
increases	_	_
respectively	_	_
.	_	_

#58
Eventually	_	_
,	_	_
the	_	_
Softmax	_	_
operations	_	_
are	_	_
applied	_	_
at	_	_
the	_	_
end	_	_
of	_	_
the	_	_
network	_	_
to	_	_
compute	_	_
the	_	_
probability	_	_
of	_	_
the	_	_
target	_	_
classes	_	_
.	_	_

#59
As	_	_
opposed	_	_
to	_	_
classification	_	_
tasks	_	_
,	_	_
the	_	_
architecture	_	_
of	_	_
segmentation	_	_
tasks	_	_
requires	_	_
both	_	_
convolutional	_	_
encoding	_	_
and	_	_
decoding	_	_
units	_	_
.	_	_

#60
The	_	_
encoding	_	_
unit	_	_
is	_	_
used	_	_
to	_	_
encode	_	_
input	_	_
images	_	_
into	_	_
a	_	_
larger	_	_
number	_	_
of	_	_
maps	_	_
with	_	_
lower	_	_
dimensionality	_	_
.	_	_

#61
The	_	_
decoding	_	_
unit	_	_
is	_	_
used	_	_
to	_	_
perform	_	_
up-convolution	_	_
(	_	_
deconvolution	_	_
)	_	_
operations	_	_
to	_	_
produce	_	_
segmentation	_	_
maps	_	_
with	_	_
the	_	_
same	_	_
dimensionality	_	_
as	_	_
the	_	_
original	_	_
input	_	_
image	_	_
.	_	_

#62
Therefore	_	_
,	_	_
the	_	_
architecture	_	_
for	_	_
segmentation	_	_
tasks	_	_
generally	_	_
requires	_	_
almost	_	_
double	_	_
the	_	_
number	_	_
of	_	_
network	_	_
parameters	_	_
when	_	_
compared	_	_
to	_	_
the	_	_
architecture	_	_
of	_	_
the	_	_
classification	_	_
tasks	_	_
.	_	_

#63
Thus	_	_
,	_	_
it	_	_
is	_	_
important	_	_
to	_	_
design	_	_
efficient	_	_
DCNN	_	_
architectures	_	_
for	_	_
segmentation	_	_
tasks	_	_
which	_	_
can	_	_
ensure	_	_
better	_	_
performance	_	_
with	_	_
less	_	_
number	_	_
of	_	_
network	_	_
parameters	_	_
.	_	_

#64
This	_	_
research	_	_
demonstrates	_	_
two	_	_
modified	_	_
and	_	_
improved	_	_
segmentation	_	_
models	_	_
,	_	_
one	_	_
using	_	_
recurrent	_	_
convolution	_	_
networks	_	_
,	_	_
and	_	_
another	_	_
using	_	_
recurrent	_	_
residual	_	_
convolutional	_	_
networks	_	_
.	_	_

#65
To	_	_
accomplish	_	_
our	_	_
goals	_	_
,	_	_
the	_	_
proposed	_	_
models	_	_
are	_	_
Fig.	_	_
2	_	_
.	_	_

#66
U-Net	_	_
architecture	_	_
consisted	_	_
with	_	_
convolutional	_	_
encoding	_	_
and	_	_
decoding	_	_
units	_	_
that	_	_
take	_	_
image	_	_
as	_	_
input	_	_
and	_	_
produce	_	_
the	_	_
segmentation	_	_
feature	_	_
maps	_	_
with	_	_
respective	_	_
pixel	_	_
classes	_	_
.	_	_

#67
evaluated	_	_
on	_	_
different	_	_
modalities	_	_
of	_	_
medical	_	_
imagining	_	_
as	_	_
shown	_	_
in	_	_
Fig.	_	_
1	_	_
.	_	_

#68
The	_	_
contributions	_	_
of	_	_
this	_	_
work	_	_
can	_	_
be	_	_
summarized	_	_
as	_	_
follows	_	_
:	_	_
1	_	_
)	_	_
Two	_	_
new	_	_
models	_	_
RU-Net	_	_
and	_	_
R2U-Net	_	_
are	_	_
introduced	_	_
for	_	_
medical	_	_
image	_	_
segmentation	_	_
.	_	_

#69
2	_	_
)	_	_
The	_	_
experiments	_	_
are	_	_
conducted	_	_
on	_	_
three	_	_
different	_	_
modalities	_	_
of	_	_
medical	_	_
imaging	_	_
including	_	_
retina	_	_
blood	_	_
vessel	_	_
segmentation	_	_
,	_	_
skin	_	_
cancer	_	_
segmentation	_	_
,	_	_
and	_	_
lung	_	_
segmentation	_	_
.	_	_

#70
3	_	_
)	_	_
Performance	_	_
evaluation	_	_
of	_	_
the	_	_
proposed	_	_
models	_	_
is	_	_
conducted	_	_
for	_	_
the	_	_
patch-based	_	_
method	_	_
for	_	_
retina	_	_
blood	_	_
vessel	_	_
segmentation	_	_
tasks	_	_
and	_	_
the	_	_
end-to-end	_	_
image-based	_	_
approach	_	_
for	_	_
skin	_	_
lesion	_	_
and	_	_
lung	_	_
segmentation	_	_
tasks	_	_
.	_	_

#71
4	_	_
)	_	_
Comparison	_	_
against	_	_
recently	_	_
proposed	_	_
state-of-the-art	_	_
methods	_	_
that	_	_
shows	_	_
superior	_	_
performance	_	_
against	_	_
equivalent	_	_
models	_	_
with	_	_
same	_	_
number	_	_
of	_	_
network	_	_
parameters	_	_
.	_	_

#72
The	_	_
paper	_	_
is	_	_
organized	_	_
as	_	_
follows	_	_
:	_	_
Section	_	_
II	_	_
discusses	_	_
related	_	_
work	_	_
.	_	_

#73
The	_	_
architectures	_	_
of	_	_
the	_	_
proposed	_	_
RU-Net	_	_
and	_	_
R2U-Net	_	_
models	_	_
are	_	_
presented	_	_
in	_	_
Section	_	_
III	_	_
.	_	_

#74
Section	_	_
IV	_	_
,	_	_
explains	_	_
the	_	_
datasets	_	_
,	_	_
experiments	_	_
,	_	_
and	_	_
results	_	_
.	_	_

#75
The	_	_
conclusion	_	_
and	_	_
future	_	_
direction	_	_
are	_	_
discussed	_	_
in	_	_
Section	_	_
V.	_	_
II	_	_
.	_	_

#76
RELATED	_	_
WORK	_	_
Semantic	_	_
segmentation	_	_
is	_	_
an	_	_
active	_	_
research	_	_
area	_	_
where	_	_
DCNNs	_	_
are	_	_
used	_	_
to	_	_
classify	_	_
each	_	_
pixel	_	_
in	_	_
the	_	_
image	_	_
individually	_	_
,	_	_
which	_	_
is	_	_
fueled	_	_
by	_	_
different	_	_
challenging	_	_
datasets	_	_
in	_	_
the	_	_
fields	_	_
of	_	_
computer	_	_
vision	_	_
and	_	_
medical	_	_
imaging	_	_
[	_	_
23	_	_
,	_	_
24	_	_
,	_	_
and	_	_
25	_	_
]	_	_
.	_	_

#77
Before	_	_
the	_	_
deep	_	_
learning	_	_
revolution	_	_
,	_	_
the	_	_
traditional	_	_
machine	_	_
learning	_	_
approach	_	_
mostly	_	_
relied	_	_
on	_	_
hand	_	_
engineered	_	_
features	_	_
that	_	_
were	_	_
used	_	_
for	_	_
classifying	_	_
pixels	_	_
independently	_	_
.	_	_

#78
In	_	_
the	_	_
last	_	_
few	_	_
years	_	_
,	_	_
a	_	_
lot	_	_
of	_	_
models	_	_
have	_	_
been	_	_
proposed	_	_
that	_	_
have	_	_
proved	_	_
that	_	_
deeper	_	_
networks	_	_
are	_	_
better	_	_
for	_	_
recognition	_	_
and	_	_
segmentation	_	_
tasks	_	_
[	_	_
5	_	_
]	_	_
.	_	_

#79
However	_	_
,	_	_
training	_	_
very	_	_
deep	_	_
models	_	_
is	_	_
difficult	_	_
due	_	_
to	_	_
the	_	_
vanishing	_	_
gradient	_	_
problem	_	_
,	_	_
which	_	_
is	_	_
resolved	_	_
by	_	_
implementing	_	_
modern	_	_
activation	_	_
functions	_	_
such	_	_
as	_	_
Rectified	_	_
Linear	_	_
Units	_	_
(	_	_
ReLU	_	_
)	_	_
or	_	_
Exponential	_	_
Linear	_	_
Units	_	_
(	_	_
ELU	_	_
)	_	_
[	_	_
5,6	_	_
]	_	_
.	_	_

#80
Another	_	_
solution	_	_
to	_	_
this	_	_
problem	_	_
is	_	_
proposed	_	_
by	_	_
He	_	_
et	_	_
al.	_	_
,	_	_
a	_	_
deep	_	_
residual	_	_
model	_	_
that	_	_
overcomes	_	_
the	_	_
problem	_	_
utilizing	_	_
an	_	_
identity	_	_
mapping	_	_
to	_	_
facilitate	_	_
the	_	_
training	_	_
process	_	_
[	_	_
26	_	_
]	_	_
.	_	_

#81
In	_	_
addition	_	_
,	_	_
CNNs	_	_
based	_	_
segmentation	_	_
methods	_	_
based	_	_
on	_	_
FCN	_	_
provide	_	_
superior	_	_
performance	_	_
for	_	_
natural	_	_
image	_	_
segmentation	_	_
[	_	_
2	_	_
]	_	_
.	_	_

#82
One	_	_
of	_	_
the	_	_
image	_	_
patch-based	_	_
architectures	_	_
is	_	_
called	_	_
Random	_	_
architecture	_	_
,	_	_
which	_	_
is	_	_
very	_	_
computationally	_	_
intensive	_	_
and	_	_
contains	_	_
around	_	_
134.5M	_	_
network	_	_
parameters	_	_
.	_	_

#83
The	_	_
main	_	_
drawback	_	_
of	_	_
this	_	_
approach	_	_
is	_	_
that	_	_
a	_	_
large	_	_
number	_	_
of	_	_
pixel	_	_
overlap	_	_
and	_	_
the	_	_
same	_	_
convolutions	_	_
are	_	_
performed	_	_
many	_	_
times	_	_
.	_	_

#84
The	_	_
performance	_	_
of	_	_
FCN	_	_
has	_	_
improved	_	_
with	_	_
recurrent	_	_
neural	_	_
networks	_	_
(	_	_
RNN	_	_
)	_	_
,	_	_
which	_	_
are	_	_
fine-tuned	_	_
on	_	_
very	_	_
large	_	_
datasets	_	_
[	_	_
27	_	_
]	_	_
.	_	_

#85
Semantic	_	_
image	_	_
segmentation	_	_
with	_	_
DeepLab	_	_
is	_	_
one	_	_
of	_	_
the	_	_
state-of-the-art	_	_
performing	_	_
methods	_	_
[	_	_
28	_	_
]	_	_
.	_	_

#86
SegNet	_	_
consists	_	_
of	_	_
two	_	_
parts	_	_
,	_	_
one	_	_
is	_	_
the	_	_
encoding	_	_
network	_	_
which	_	_
is	_	_
a	_	_
13-layer	_	_
VGG16	_	_
network	_	_
[	_	_
5	_	_
]	_	_
,	_	_
and	_	_
the	_	_
corresponding	_	_
decoding	_	_
network	_	_
uses	_	_
pixel-wise	_	_
classification	_	_
layers	_	_
.	_	_

#87
The	_	_
main	_	_
contribution	_	_
of	_	_
this	_	_
paper	_	_
is	_	_
the	_	_
way	_	_
in	_	_
which	_	_
the	_	_
decoder	_	_
up-samples	_	_
its	_	_
lower	_	_
resolution	_	_
input	_	_
feature	_	_
maps	_	_
[	_	_
10	_	_
]	_	_
.	_	_

#88
Later	_	_
,	_	_
an	_	_
improved	_	_
version	_	_
of	_	_
SegNet	_	_
,	_	_
which	_	_
is	_	_
called	_	_
Bayesian	_	_
SegNet	_	_
was	_	_
proposed	_	_
in	_	_
2015	_	_
[	_	_
29	_	_
]	_	_
.	_	_

#89
Most	_	_
of	_	_
these	_	_
architectures	_	_
are	_	_
explored	_	_
using	_	_
computer	_	_
vision	_	_
applications	_	_
.	_	_

#90
However	_	_
,	_	_
there	_	_
are	_	_
some	_	_
deep	_	_
learning	_	_
models	_	_
that	_	_
have	_	_
been	_	_
proposed	_	_
specifically	_	_
for	_	_
the	_	_
medical	_	_
image	_	_
segmentation	_	_
,	_	_
as	_	_
they	_	_
consider	_	_
data	_	_
insufficiency	_	_
and	_	_
class	_	_
imbalance	_	_
problems	_	_
.	_	_

#91
One	_	_
of	_	_
the	_	_
very	_	_
first	_	_
and	_	_
most	_	_
popular	_	_
approaches	_	_
for	_	_
semantic	_	_
medical	_	_
image	_	_
segmentation	_	_
is	_	_
called	_	_
‚ÄúU-Net‚Äù	_	_
[	_	_
12	_	_
]	_	_
.	_	_

#92
A	_	_
diagram	_	_
of	_	_
the	_	_
basic	_	_
U-Net	_	_
model	_	_
is	_	_
shown	_	_
in	_	_
Fig.	_	_
2	_	_
.	_	_

#93
According	_	_
to	_	_
the	_	_
structure	_	_
,	_	_
the	_	_
network	_	_
consists	_	_
of	_	_
two	_	_
main	_	_
parts	_	_
:	_	_
the	_	_
convolutional	_	_
encoding	_	_
and	_	_
decoding	_	_
units	_	_
.	_	_

#94
The	_	_
basic	_	_
convolution	_	_
operations	_	_
are	_	_
performed	_	_
followed	_	_
by	_	_
ReLU	_	_
activation	_	_
in	_	_
both	_	_
parts	_	_
of	_	_
the	_	_
network	_	_
.	_	_

#95
For	_	_
down	_	_
sampling	_	_
in	_	_
the	_	_
encoding	_	_
unit	_	_
,	_	_
2√ó2	_	_
max-pooling	_	_
operations	_	_
are	_	_
performed	_	_
.	_	_

#96
In	_	_
the	_	_
decoding	_	_
phase	_	_
,	_	_
the	_	_
convolution	_	_
transpose	_	_
(	_	_
representing	_	_
up-convolution	_	_
,	_	_
or	_	_
de-convolution	_	_
)	_	_
operations	_	_
are	_	_
performed	_	_
to	_	_
up-sample	_	_
the	_	_
feature	_	_
maps	_	_
.	_	_

#97
The	_	_
very	_	_
first	_	_
version	_	_
of	_	_
U-Net	_	_
was	_	_
used	_	_
to	_	_
crop	_	_
and	_	_
copy	_	_
feature	_	_
maps	_	_
from	_	_
the	_	_
encoding	_	_
unit	_	_
to	_	_
the	_	_
decoding	_	_
unit	_	_
.	_	_

#98
The	_	_
U-Net	_	_
model	_	_
provides	_	_
several	_	_
advantages	_	_
for	_	_
segmentation	_	_
tasks	_	_
:	_	_
first	_	_
,	_	_
this	_	_
model	_	_
allows	_	_
for	_	_
the	_	_
use	_	_
of	_	_
global	_	_
location	_	_
and	_	_
context	_	_
at	_	_
the	_	_
same	_	_
time	_	_
.	_	_

#99
Second	_	_
,	_	_
it	_	_
works	_	_
with	_	_
very	_	_
few	_	_
training	_	_
samples	_	_
and	_	_
provides	_	_
better	_	_
performance	_	_
for	_	_
segmentation	_	_
tasks	_	_
[	_	_
12	_	_
]	_	_
.	_	_

#100
Third	_	_
,	_	_
an	_	_
end-to-end	_	_
pipeline	_	_
process	_	_
the	_	_
entire	_	_
image	_	_
in	_	_
the	_	_
forward	_	_
pass	_	_
and	_	_
directly	_	_
produces	_	_
segmentation	_	_
maps	_	_
.	_	_

#101
This	_	_
ensures	_	_
that	_	_
U-Net	_	_
preserves	_	_
the	_	_
full	_	_
context	_	_
of	_	_
the	_	_
input	_	_
images	_	_
,	_	_
which	_	_
is	_	_
a	_	_
major	_	_
advantage	_	_
when	_	_
compared	_	_
to	_	_
patch-based	_	_
segmentation	_	_
approaches	_	_
[	_	_
12	_	_
,	_	_
14	_	_
]	_	_
.	_	_

#102
Fig.	_	_
3	_	_
.	_	_

#103
RU-Net	_	_
architecture	_	_
with	_	_
convolutional	_	_
encoding	_	_
and	_	_
decoding	_	_
units	_	_
using	_	_
recurrent	_	_
convolutional	_	_
layers	_	_
(	_	_
RCL	_	_
)	_	_
based	_	_
U-Net	_	_
architecture	_	_
.	_	_

#104
The	_	_
residual	_	_
units	_	_
are	_	_
used	_	_
with	_	_
RCL	_	_
for	_	_
R2U-Net	_	_
architecture	_	_
.	_	_

#105
However	_	_
,	_	_
U-Net	_	_
is	_	_
not	_	_
only	_	_
limited	_	_
to	_	_
the	_	_
applications	_	_
in	_	_
the	_	_
domain	_	_
of	_	_
medical	_	_
imaging	_	_
,	_	_
nowadays	_	_
this	_	_
model	_	_
is	_	_
massively	_	_
applied	_	_
for	_	_
computer	_	_
vision	_	_
tasks	_	_
as	_	_
well	_	_
[	_	_
30	_	_
,	_	_
31	_	_
]	_	_
.	_	_

#106
Meanwhile	_	_
,	_	_
different	_	_
variants	_	_
of	_	_
U-Net	_	_
models	_	_
have	_	_
been	_	_
proposed	_	_
,	_	_
including	_	_
a	_	_
very	_	_
simple	_	_
variant	_	_
of	_	_
U-Net	_	_
for	_	_
CNN-based	_	_
segmentation	_	_
of	_	_
Medical	_	_
Imaging	_	_
data	_	_
[	_	_
32	_	_
]	_	_
.	_	_

#107
In	_	_
this	_	_
model	_	_
,	_	_
two	_	_
modifications	_	_
are	_	_
made	_	_
to	_	_
the	_	_
original	_	_
design	_	_
of	_	_
U-Net	_	_
:	_	_
first	_	_
,	_	_
a	_	_
combination	_	_
of	_	_
multiple	_	_
segmentation	_	_
maps	_	_
and	_	_
forward	_	_
feature	_	_
maps	_	_
are	_	_
summed	_	_
(	_	_
element-wise	_	_
)	_	_
from	_	_
one	_	_
part	_	_
of	_	_
the	_	_
network	_	_
to	_	_
the	_	_
other	_	_
.	_	_

#108
The	_	_
feature	_	_
maps	_	_
are	_	_
taken	_	_
from	_	_
different	_	_
layers	_	_
of	_	_
encoding	_	_
and	_	_
decoding	_	_
units	_	_
and	_	_
finally	_	_
summation	_	_
(	_	_
element-wise	_	_
)	_	_
is	_	_
performed	_	_
outside	_	_
of	_	_
the	_	_
encoding	_	_
and	_	_
decoding	_	_
units	_	_
.	_	_

#109
The	_	_
authors	_	_
report	_	_
promising	_	_
performance	_	_
improvement	_	_
during	_	_
training	_	_
with	_	_
better	_	_
convergence	_	_
compared	_	_
to	_	_
U-Net	_	_
,	_	_
but	_	_
no	_	_
benefit	_	_
was	_	_
observed	_	_
when	_	_
using	_	_
a	_	_
summation	_	_
of	_	_
features	_	_
during	_	_
the	_	_
testing	_	_
phase	_	_
[	_	_
32	_	_
]	_	_
.	_	_

#110
However	_	_
,	_	_
this	_	_
concept	_	_
proved	_	_
that	_	_
feature	_	_
summation	_	_
impacts	_	_
the	_	_
performance	_	_
of	_	_
a	_	_
network	_	_
.	_	_

#111
The	_	_
importance	_	_
of	_	_
skipped	_	_
connections	_	_
for	_	_
biomedical	_	_
image	_	_
segmentation	_	_
tasks	_	_
have	_	_
been	_	_
empirically	_	_
evaluated	_	_
with	_	_
U-Net	_	_
and	_	_
residual	_	_
networks	_	_
[	_	_
33	_	_
]	_	_
.	_	_

#112
A	_	_
deep	_	_
contour-aware	_	_
network	_	_
called	_	_
Deep	_	_
ContourAware	_	_
Networks	_	_
(	_	_
DCAN	_	_
)	_	_
was	_	_
proposed	_	_
in	_	_
2016	_	_
,	_	_
which	_	_
can	_	_
extract	_	_
multi-level	_	_
contextual	_	_
features	_	_
using	_	_
a	_	_
hierarchical	_	_
architecture	_	_
for	_	_
accurate	_	_
gland	_	_
segmentation	_	_
of	_	_
histology	_	_
images	_	_
and	_	_
shows	_	_
very	_	_
good	_	_
performance	_	_
for	_	_
segmentation	_	_
[	_	_
34	_	_
]	_	_
.	_	_

#113
Furthermore	_	_
,	_	_
Nabla-Net	_	_
:	_	_
a	_	_
deep	_	_
dig-like	_	_
convolutional	_	_
architecture	_	_
was	_	_
proposed	_	_
for	_	_
segmentation	_	_
in	_	_
2017	_	_
[	_	_
35	_	_
]	_	_
.	_	_

#114
Other	_	_
deep	_	_
learning	_	_
approaches	_	_
have	_	_
been	_	_
proposed	_	_
based	_	_
on	_	_
U-Net	_	_
for	_	_
3D	_	_
medical	_	_
image	_	_
segmentation	_	_
tasks	_	_
as	_	_
well	_	_
.	_	_

#115
The	_	_
3D-Unet	_	_
architecture	_	_
for	_	_
volumetric	_	_
segmentation	_	_
learns	_	_
from	_	_
sparsely	_	_
annotated	_	_
volumetric	_	_
images	_	_
[	_	_
13	_	_
]	_	_
.	_	_

#116
A	_	_
powerful	_	_
end-to-end	_	_
3D	_	_
medical	_	_
image	_	_
segmentation	_	_
system	_	_
based	_	_
on	_	_
volumetric	_	_
images	_	_
called	_	_
V-net	_	_
has	_	_
been	_	_
proposed	_	_
,	_	_
which	_	_
consists	_	_
of	_	_
a	_	_
FCN	_	_
with	_	_
residual	_	_
connections	_	_
[	_	_
14	_	_
]	_	_
.	_	_

#117
This	_	_
paper	_	_
also	_	_
introduces	_	_
a	_	_
dice	_	_
loss	_	_
layer	_	_
[	_	_
14	_	_
]	_	_
.	_	_

#118
Furthermore	_	_
,	_	_
a	_	_
3D	_	_
deeply	_	_
supervised	_	_
approach	_	_
for	_	_
automated	_	_
segmentation	_	_
of	_	_
volumetric	_	_
medical	_	_
images	_	_
was	_	_
presented	_	_
in	_	_
[	_	_
36	_	_
]	_	_
.	_	_

#119
High-Res3DNet	_	_
was	_	_
proposed	_	_
using	_	_
residual	_	_
networks	_	_
for	_	_
3D	_	_
segmentation	_	_
tasks	_	_
in	_	_
2016	_	_
[	_	_
37	_	_
]	_	_
.	_	_

#120
In	_	_
2017	_	_
,	_	_
a	_	_
CNN	_	_
based	_	_
brain	_	_
tumor	_	_
segmentation	_	_
approach	_	_
was	_	_
proposed	_	_
using	_	_
a	_	_
3D-CNN	_	_
model	_	_
with	_	_
a	_	_
fully	_	_
connected	_	_
CRF	_	_
[	_	_
38	_	_
]	_	_
.	_	_

#121
Pancreas	_	_
segmentation	_	_
was	_	_
proposed	_	_
in	_	_
[	_	_
39	_	_
]	_	_
,	_	_
and	_	_
Voxresnet	_	_
was	_	_
proposed	_	_
in	_	_
2016	_	_
where	_	_
a	_	_
deep	_	_
voxel	_	_
wise	_	_
residual	_	_
network	_	_
is	_	_
used	_	_
for	_	_
brain	_	_
segmentation	_	_
.	_	_

#122
This	_	_
architecture	_	_
utilizes	_	_
residual	_	_
networks	_	_
and	_	_
summation	_	_
of	_	_
feature	_	_
maps	_	_
from	_	_
different	_	_
layers	_	_
[	_	_
40	_	_
]	_	_
.	_	_

#123
Alternatively	_	_
,	_	_
we	_	_
have	_	_
proposed	_	_
two	_	_
models	_	_
for	_	_
semantic	_	_
segmentation	_	_
based	_	_
on	_	_
the	_	_
architecture	_	_
of	_	_
U-Net	_	_
in	_	_
this	_	_
paper	_	_
.	_	_

#124
The	_	_
proposed	_	_
Recurrent	_	_
Convolutional	_	_
Neural	_	_
Networks	_	_
(	_	_
RCNN	_	_
)	_	_
model	_	_
based	_	_
on	_	_
U-Net	_	_
is	_	_
named	_	_
RU-Net	_	_
,	_	_
which	_	_
is	_	_
shown	_	_
in	_	_
Fig.	_	_
3	_	_
.	_	_

#125
Additionally	_	_
,	_	_
we	_	_
have	_	_
proposed	_	_
a	_	_
residual	_	_
RCNN	_	_
based	_	_
U-Net	_	_
model	_	_
which	_	_
is	_	_
called	_	_
R2U-Net	_	_
.	_	_

#126
The	_	_
following	_	_
section	_	_
provides	_	_
the	_	_
architectural	_	_
details	_	_
of	_	_
both	_	_
models	_	_
.	_	_

#127
III	_	_
.	_	_

#128
RU-NET	_	_
AND	_	_
R2U-NET	_	_
ARCHITECTURES	_	_
Inspired	_	_
by	_	_
the	_	_
deep	_	_
residual	_	_
model	_	_
[	_	_
7	_	_
]	_	_
,	_	_
RCNN	_	_
[	_	_
41	_	_
]	_	_
,	_	_
and	_	_
U-Net	_	_
[	_	_
12	_	_
]	_	_
,	_	_
we	_	_
propose	_	_
two	_	_
models	_	_
for	_	_
segmentation	_	_
tasks	_	_
which	_	_
are	_	_
named	_	_
RU-Net	_	_
and	_	_
R2U-Net	_	_
.	_	_

#129
These	_	_
two	_	_
approaches	_	_
utilize	_	_
the	_	_
strengths	_	_
of	_	_
all	_	_
three	_	_
recently	_	_
developed	_	_
deep	_	_
learning	_	_
models	_	_
.	_	_

#130
RCNN	_	_
and	_	_
its	_	_
variants	_	_
have	_	_
already	_	_
shown	_	_
superior	_	_
performance	_	_
on	_	_
object	_	_
recognition	_	_
tasks	_	_
using	_	_
different	_	_
benchmarks	_	_
[	_	_
42	_	_
,	_	_
43	_	_
]	_	_
.	_	_

#131
The	_	_
recurrent	_	_
residual	_	_
convolutional	_	_
operations	_	_
can	_	_
be	_	_
demonstrated	_	_
mathematically	_	_
according	_	_
to	_	_
the	_	_
improved-residual	_	_
networks	_	_
in	_	_
[	_	_
43	_	_
]	_	_
.	_	_

#132
The	_	_
operations	_	_
of	_	_
the	_	_
Recurrent	_	_
Convolutional	_	_
Layers	_	_
(	_	_
RCL	_	_
)	_	_
are	_	_
performed	_	_
with	_	_
respect	_	_
to	_	_
the	_	_
discrete	_	_
time	_	_
steps	_	_
that	_	_
are	_	_
expressed	_	_
according	_	_
to	_	_
the	_	_
RCNN	_	_
[	_	_
41	_	_
]	_	_
.	_	_

#133
Let‚Äôs	_	_
consider	_	_
the	_	_
ùë•ùëô	_	_
input	_	_
sample	_	_
in	_	_
the	_	_
ùëôùë°‚Ñé	_	_
layer	_	_
of	_	_
the	_	_
residual	_	_
RCNN	_	_
(	_	_
RRCNN	_	_
)	_	_
block	_	_
and	_	_
a	_	_
pixel	_	_
located	_	_
at	_	_
(	_	_
ùëñ	_	_
,	_	_
ùëó	_	_
)	_	_
in	_	_
an	_	_
input	_	_
sample	_	_
on	_	_
the	_	_
kth	_	_
feature	_	_
map	_	_
in	_	_
the	_	_
RCL	_	_
.	_	_

#134
Additionally	_	_
,	_	_
let‚Äôs	_	_
assume	_	_
the	_	_
output	_	_
of	_	_
the	_	_
network	_	_
ùëÇùëñùëóùëò	_	_
ùëô	_	_
(	_	_
ùë°	_	_
)	_	_
is	_	_
at	_	_
the	_	_
time	_	_
step	_	_
t.	_	_
The	_	_
output	_	_
can	_	_
be	_	_
expressed	_	_
as	_	_
follows	_	_
as	_	_
:	_	_
ùëÇùëñùëóùëò	_	_
ùëô	_	_
(	_	_
ùë°	_	_
)	_	_
=	_	_
(	_	_
ùë§ùëò	_	_
ùëì	_	_
)	_	_
ùëá	_	_
‚àó	_	_
ùë•ùëô	_	_
ùëì	_	_
(	_	_
ùëñ	_	_
,	_	_
ùëó	_	_
)	_	_
(	_	_
ùë°	_	_
)	_	_
+	_	_
(	_	_
ùë§ùëò	_	_
ùëü	_	_
)	_	_
ùëá	_	_
‚àó	_	_
ùë•ùëô	_	_
ùëü	_	_
(	_	_
ùëñ	_	_
,	_	_
ùëó	_	_
)	_	_
(	_	_
ùë°	_	_
‚àí	_	_
1	_	_
)	_	_
+	_	_
ùëèùëò	_	_
(	_	_
1	_	_
)	_	_
Here	_	_
ùë•ùëô	_	_
ùëì	_	_
(	_	_
ùëñ	_	_
,	_	_
ùëó	_	_
)	_	_
(	_	_
ùë°	_	_
)	_	_
and	_	_
ùë•ùëô	_	_
ùëü	_	_
(	_	_
ùëñ	_	_
,	_	_
ùëó	_	_
)	_	_
(	_	_
ùë°	_	_
‚àí	_	_
1	_	_
)	_	_
are	_	_
the	_	_
inputs	_	_
to	_	_
the	_	_
standard	_	_
convolution	_	_
layers	_	_
and	_	_
for	_	_
the	_	_
ùëôùë°‚Ñé	_	_
RCL	_	_
respectively	_	_
.	_	_

#135
The	_	_
ùë§ùëò	_	_
ùëì	_	_
and	_	_
ùë§ùëò	_	_
ùëü	_	_
values	_	_
are	_	_
the	_	_
weights	_	_
of	_	_
the	_	_
standard	_	_
convolutional	_	_
layer	_	_
and	_	_
the	_	_
RCL	_	_
of	_	_
the	_	_
kth	_	_
feature	_	_
map	_	_
respectively	_	_
,	_	_
and	_	_
ùëèùëò	_	_
is	_	_
the	_	_
bias	_	_
.	_	_

#136
The	_	_
outputs	_	_
of	_	_
RCL	_	_
are	_	_
fed	_	_
to	_	_
the	_	_
standard	_	_
ReLU	_	_
activation	_	_
function	_	_
ùëì	_	_
and	_	_
are	_	_
expressed	_	_
:	_	_
‚Ñ±	_	_
(	_	_
ùë•ùëô	_	_
,	_	_
ùë§ùëô	_	_
)	_	_
=	_	_
ùëì	_	_
(	_	_
ùëÇùëñùëóùëò	_	_
ùëô	_	_
(	_	_
ùë°	_	_
)	_	_
)	_	_
=	_	_
max	_	_
(	_	_
0	_	_
,	_	_
ùëÇùëñùëóùëò	_	_
ùëô	_	_
(	_	_
ùë°	_	_
)	_	_
)	_	_
(	_	_
2	_	_
)	_	_
‚Ñ±	_	_
(	_	_
ùë•ùëô	_	_
,	_	_
ùë§ùëô	_	_
)	_	_
represents	_	_
the	_	_
outputs	_	_
from	_	_
of	_	_
lth	_	_
layer	_	_
of	_	_
the	_	_
RCNN	_	_
unit	_	_
.	_	_

#137
The	_	_
output	_	_
of	_	_
‚Ñ±	_	_
(	_	_
ùë•ùëô	_	_
,	_	_
ùë§ùëô	_	_
)	_	_
is	_	_
used	_	_
for	_	_
down-sampling	_	_
and	_	_
up-sampling	_	_
layers	_	_
in	_	_
the	_	_
convolutional	_	_
encoding	_	_
and	_	_
decoding	_	_
units	_	_
of	_	_
the	_	_
RU-Net	_	_
model	_	_
respectively	_	_
.	_	_

#138
In	_	_
the	_	_
case	_	_
of	_	_
R2U-Net	_	_
,	_	_
the	_	_
final	_	_
outputs	_	_
of	_	_
the	_	_
RCNN	_	_
unit	_	_
are	_	_
passed	_	_
through	_	_
the	_	_
residual	_	_
unit	_	_
that	_	_
is	_	_
shown	_	_
Fig.	_	_
4	_	_
(	_	_
d	_	_
)	_	_
.	_	_

#139
Let‚Äôs	_	_
consider	_	_
that	_	_
the	_	_
output	_	_
of	_	_
the	_	_
RRCNN-block	_	_
is	_	_
ùë•ùëô+1	_	_
and	_	_
can	_	_
be	_	_
calculated	_	_
as	_	_
follows	_	_
:	_	_
ùë•ùëô+1	_	_
=	_	_
ùë•ùëô	_	_
+	_	_
‚Ñ±	_	_
(	_	_
ùë•ùëô	_	_
,	_	_
ùë§ùëô	_	_
)	_	_
(	_	_
3	_	_
)	_	_
Here	_	_
,	_	_
ùë•ùëô	_	_
represents	_	_
the	_	_
input	_	_
samples	_	_
of	_	_
the	_	_
RRCNN-block	_	_
.	_	_

#140
The	_	_
ùë•ùëô+1	_	_
sample	_	_
is	_	_
used	_	_
the	_	_
input	_	_
for	_	_
the	_	_
immediate	_	_
succeeding	_	_
sub-sampling	_	_
or	_	_
up-sampling	_	_
layers	_	_
in	_	_
the	_	_
encoding	_	_
and	_	_
decoding	_	_
convolutional	_	_
units	_	_
of	_	_
R2U-Net	_	_
.	_	_

#141
However	_	_
,	_	_
the	_	_
number	_	_
of	_	_
feature	_	_
maps	_	_
and	_	_
the	_	_
dimensions	_	_
of	_	_
the	_	_
feature	_	_
maps	_	_
for	_	_
the	_	_
residual	_	_
units	_	_
are	_	_
the	_	_
same	_	_
as	_	_
in	_	_
the	_	_
RRCNN-block	_	_
shown	_	_
in	_	_
Fig.	_	_
4	_	_
(	_	_
d	_	_
)	_	_
.	_	_

#142
Fig.	_	_
4	_	_
.	_	_

#143
Different	_	_
variant	_	_
of	_	_
convolutional	_	_
and	_	_
recurrent	_	_
convolutional	_	_
units	_	_
(	_	_
a	_	_
)	_	_
Forward	_	_
convolutional	_	_
units	_	_
,	_	_
(	_	_
b	_	_
)	_	_
Recurrent	_	_
convolutional	_	_
block	_	_
(	_	_
c	_	_
)	_	_
Residual	_	_
convolutional	_	_
unit	_	_
,	_	_
and	_	_
(	_	_
d	_	_
)	_	_
Recurrent	_	_
Residual	_	_
convolutional	_	_
units	_	_
(	_	_
RRCU	_	_
)	_	_
.	_	_

#144
The	_	_
proposed	_	_
deep	_	_
learning	_	_
models	_	_
are	_	_
the	_	_
building	_	_
blocks	_	_
of	_	_
the	_	_
stacked	_	_
convolutional	_	_
units	_	_
shown	_	_
in	_	_
Fig.	_	_
4	_	_
(	_	_
b	_	_
)	_	_
and	_	_
(	_	_
d	_	_
)	_	_
.	_	_

#145
There	_	_
are	_	_
four	_	_
different	_	_
architectures	_	_
evaluated	_	_
in	_	_
this	_	_
work	_	_
.	_	_

#146
First	_	_
,	_	_
U-Net	_	_
with	_	_
forward	_	_
convolution	_	_
layers	_	_
and	_	_
feature	_	_
concatenation	_	_
is	_	_
applied	_	_
as	_	_
an	_	_
alternative	_	_
to	_	_
the	_	_
crop	_	_
and	_	_
copy	_	_
method	_	_
found	_	_
in	_	_
the	_	_
primary	_	_
version	_	_
of	_	_
U-Net	_	_
[	_	_
12	_	_
]	_	_
.	_	_

#147
The	_	_
basic	_	_
convolutional	_	_
unit	_	_
of	_	_
this	_	_
model	_	_
is	_	_
shown	_	_
in	_	_
Fig.	_	_
4	_	_
(	_	_
a	_	_
)	_	_
.	_	_

#148
Second	_	_
,	_	_
U-Net	_	_
with	_	_
forward	_	_
convolutional	_	_
layers	_	_
with	_	_
residual	_	_
connectivity	_	_
is	_	_
used	_	_
,	_	_
which	_	_
is	_	_
often	_	_
called	_	_
residual	_	_
U-net	_	_
(	_	_
ResU-Net	_	_
)	_	_
and	_	_
is	_	_
shown	_	_
in	_	_
Fig.	_	_
4	_	_
(	_	_
c	_	_
)	_	_
[	_	_
14	_	_
]	_	_
.	_	_

#149
The	_	_
third	_	_
architecture	_	_
is	_	_
U-Net	_	_
with	_	_
forward	_	_
recurrent	_	_
convolutional	_	_
layers	_	_
as	_	_
shown	_	_
in	_	_
Fig.	_	_
4	_	_
(	_	_
b	_	_
)	_	_
,	_	_
which	_	_
is	_	_
named	_	_
RU-Net	_	_
.	_	_

#150
Finally	_	_
,	_	_
the	_	_
last	_	_
architecture	_	_
is	_	_
U-Net	_	_
with	_	_
recurrent	_	_
convolution	_	_
layers	_	_
with	_	_
residual	_	_
connectivity	_	_
as	_	_
shown	_	_
in	_	_
Fig.	_	_
4	_	_
(	_	_
d	_	_
)	_	_
,	_	_
which	_	_
is	_	_
named	_	_
R2U-Net	_	_
.	_	_

#151
The	_	_
pictorial	_	_
representation	_	_
of	_	_
the	_	_
unfolded	_	_
RCL	_	_
layers	_	_
with	_	_
respect	_	_
to	_	_
time-step	_	_
is	_	_
shown	_	_
in	_	_
Fig	_	_
5	_	_
.	_	_

#152
Here	_	_
t=2	_	_
(	_	_
0	_	_
~	_	_
2	_	_
)	_	_
,	_	_
refers	_	_
to	_	_
the	_	_
recurrent	_	_
convolutional	_	_
operation	_	_
that	_	_
includes	_	_
one	_	_
single	_	_
convolution	_	_
layer	_	_
followed	_	_
by	_	_
two	_	_
subsequential	_	_
recurrent	_	_
convolutional	_	_
layers	_	_
.	_	_

#153
In	_	_
this	_	_
implementation	_	_
,	_	_
we	_	_
have	_	_
applied	_	_
concatenation	_	_
to	_	_
the	_	_
feature	_	_
maps	_	_
from	_	_
the	_	_
encoding	_	_
unit	_	_
to	_	_
the	_	_
decoding	_	_
unit	_	_
for	_	_
both	_	_
RU-Net	_	_
and	_	_
R2U-Net	_	_
models	_	_
.	_	_

#154
Fig.	_	_
5	_	_
.	_	_

#155
Unfolded	_	_
recurrent	_	_
convolutional	_	_
units	_	_
for	_	_
t	_	_
=	_	_
2	_	_
(	_	_
left	_	_
)	_	_
and	_	_
t	_	_
=	_	_
3	_	_
(	_	_
right	_	_
)	_	_
.	_	_

#156
The	_	_
differences	_	_
between	_	_
the	_	_
proposed	_	_
models	_	_
with	_	_
respect	_	_
to	_	_
the	_	_
U-Net	_	_
model	_	_
are	_	_
three-fold	_	_
.	_	_

#157
This	_	_
architecture	_	_
consists	_	_
of	_	_
convolutional	_	_
encoding	_	_
and	_	_
decoding	_	_
units	_	_
same	_	_
as	_	_
U-Net	_	_
.	_	_

#158
However	_	_
,	_	_
the	_	_
RCLs	_	_
and	_	_
RCLs	_	_
with	_	_
residual	_	_
units	_	_
are	_	_
used	_	_
instead	_	_
of	_	_
regular	_	_
forward	_	_
convolutional	_	_
layers	_	_
in	_	_
both	_	_
the	_	_
encoding	_	_
and	_	_
decoding	_	_
units	_	_
.	_	_

#159
The	_	_
residual	_	_
unit	_	_
with	_	_
RCLs	_	_
helps	_	_
to	_	_
develop	_	_
a	_	_
more	_	_
efficient	_	_
deeper	_	_
model	_	_
.	_	_

#160
Second	_	_
,	_	_
the	_	_
efficient	_	_
feature	_	_
accumulation	_	_
method	_	_
is	_	_
included	_	_
in	_	_
the	_	_
RCL	_	_
units	_	_
of	_	_
both	_	_
proposed	_	_
models	_	_
.	_	_

#161
The	_	_
effectiveness	_	_
of	_	_
feature	_	_
accumulation	_	_
from	_	_
one	_	_
part	_	_
of	_	_
the	_	_
network	_	_
to	_	_
the	_	_
other	_	_
is	_	_
shown	_	_
in	_	_
the	_	_
CNN-based	_	_
segmentation	_	_
approach	_	_
for	_	_
medical	_	_
imaging	_	_
.	_	_

#162
In	_	_
this	_	_
model	_	_
,	_	_
the	_	_
element-wise	_	_
feature	_	_
summation	_	_
is	_	_
performed	_	_
outside	_	_
of	_	_
the	_	_
U-Net	_	_
model	_	_
[	_	_
32	_	_
]	_	_
.	_	_

#163
This	_	_
model	_	_
only	_	_
shows	_	_
the	_	_
benefit	_	_
during	_	_
the	_	_
training	_	_
process	_	_
in	_	_
the	_	_
form	_	_
of	_	_
better	_	_
convergence	_	_
.	_	_

#164
However	_	_
,	_	_
our	_	_
proposed	_	_
models	_	_
show	_	_
benefits	_	_
for	_	_
both	_	_
training	_	_
and	_	_
testing	_	_
phases	_	_
due	_	_
to	_	_
the	_	_
feature	_	_
accumulation	_	_
inside	_	_
the	_	_
model	_	_
.	_	_

#165
The	_	_
feature	_	_
accumulation	_	_
with	_	_
respect	_	_
to	_	_
different	_	_
time-steps	_	_
ensures	_	_
better	_	_
and	_	_
stronger	_	_
feature	_	_
representation	_	_
.	_	_

#166
Thus	_	_
,	_	_
it	_	_
helps	_	_
extract	_	_
very	_	_
low-level	_	_
features	_	_
which	_	_
are	_	_
essential	_	_
for	_	_
segmentation	_	_
tasks	_	_
for	_	_
different	_	_
modalities	_	_
of	_	_
medical	_	_
imaging	_	_
(	_	_
such	_	_
as	_	_
blood	_	_
vessel	_	_
segmentation	_	_
)	_	_
.	_	_

#167
Third	_	_
,	_	_
we	_	_
have	_	_
removed	_	_
the	_	_
cropping	_	_
and	_	_
copying	_	_
unit	_	_
from	_	_
the	_	_
basic	_	_
U-Net	_	_
model	_	_
and	_	_
use	_	_
only	_	_
concatenation	_	_
operations	_	_
,	_	_
resulting	_	_
a	_	_
much-sophisticated	_	_
architecture	_	_
that	_	_
results	_	_
in	_	_
better	_	_
performance	_	_
.	_	_

#168
Fig.	_	_
6	_	_
.	_	_

#169
Example	_	_
images	_	_
from	_	_
training	_	_
dataset	_	_
:	_	_
left	_	_
column	_	_
from	_	_
DRIVE	_	_
dataset	_	_
,	_	_
middle	_	_
column	_	_
from	_	_
STARE	_	_
dataset	_	_
and	_	_
right	_	_
column	_	_
from	_	_
CHASE-DB1	_	_
dataset	_	_
.	_	_

#170
The	_	_
first	_	_
row	_	_
shows	_	_
the	_	_
original	_	_
images	_	_
,	_	_
second	_	_
row	_	_
shows	_	_
fields	_	_
of	_	_
view	_	_
(	_	_
FOV	_	_
)	_	_
,	_	_
and	_	_
third	_	_
row	_	_
shows	_	_
the	_	_
target	_	_
outputs	_	_
.	_	_

#171
There	_	_
are	_	_
several	_	_
advantages	_	_
of	_	_
using	_	_
the	_	_
proposed	_	_
architectures	_	_
when	_	_
compared	_	_
with	_	_
U-Net	_	_
.	_	_

#172
The	_	_
first	_	_
is	_	_
the	_	_
efficiency	_	_
in	_	_
terms	_	_
of	_	_
the	_	_
number	_	_
of	_	_
network	_	_
parameters	_	_
.	_	_

#173
The	_	_
proposed	_	_
RU-Net	_	_
,	_	_
and	_	_
R2U-Net	_	_
architectures	_	_
are	_	_
designed	_	_
to	_	_
have	_	_
the	_	_
same	_	_
number	_	_
of	_	_
network	_	_
parameters	_	_
when	_	_
compared	_	_
to	_	_
U-Net	_	_
and	_	_
ResU-Net	_	_
,	_	_
and	_	_
RU-Net	_	_
and	_	_
R2U-Net	_	_
show	_	_
better	_	_
performance	_	_
on	_	_
segmentation	_	_
tasks	_	_
.	_	_

#174
The	_	_
recurrent	_	_
and	_	_
residual	_	_
operations	_	_
do	_	_
not	_	_
increase	_	_
the	_	_
number	_	_
of	_	_
network	_	_
parameters	_	_
.	_	_

#175
However	_	_
,	_	_
they	_	_
do	_	_
have	_	_
a	_	_
significant	_	_
impact	_	_
on	_	_
training	_	_
and	_	_
testing	_	_
performance	_	_
.	_	_

#176
This	_	_
is	_	_
shown	_	_
through	_	_
empirical	_	_
evidence	_	_
with	_	_
a	_	_
set	_	_
of	_	_
experiments	_	_
in	_	_
the	_	_
following	_	_
sections	_	_
[	_	_
43	_	_
]	_	_
.	_	_

#177
This	_	_
approach	_	_
is	_	_
also	_	_
generalizable	_	_
,	_	_
as	_	_
it	_	_
easily	_	_
be	_	_
applied	_	_
deep	_	_
learning	_	_
models	_	_
based	_	_
on	_	_
SegNet	_	_
[	_	_
10	_	_
]	_	_
,	_	_
3D-UNet	_	_
[	_	_
13	_	_
]	_	_
,	_	_
and	_	_
VNet	_	_
[	_	_
14	_	_
]	_	_
with	_	_
improved	_	_
performance	_	_
for	_	_
segmentation	_	_
tasks	_	_
.	_	_

#178
IV	_	_
.	_	_

#179
EXPERIMENTAL	_	_
SETUP	_	_
AND	_	_
RESULTS	_	_
To	_	_
demonstrate	_	_
the	_	_
performance	_	_
of	_	_
the	_	_
RU-Net	_	_
and	_	_
R2U-Net	_	_
models	_	_
,	_	_
we	_	_
have	_	_
tested	_	_
them	_	_
on	_	_
three	_	_
different	_	_
medical	_	_
imaging	_	_
datasets	_	_
.	_	_

#180
These	_	_
include	_	_
blood	_	_
vessel	_	_
segmentations	_	_
from	_	_
retina	_	_
images	_	_
(	_	_
DRIVE	_	_
,	_	_
STARE	_	_
,	_	_
and	_	_
CHASE_DB1	_	_
shown	_	_
in	_	_
Fig.	_	_
6	_	_
)	_	_
,	_	_
skin	_	_
cancer	_	_
lesion	_	_
segmentation	_	_
,	_	_
and	_	_
lung	_	_
segmentation	_	_
from	_	_
2D	_	_
images	_	_
.	_	_

#181
For	_	_
this	_	_
implementation	_	_
,	_	_
the	_	_
Keras	_	_
,	_	_
and	_	_
TensorFlow	_	_
frameworks	_	_
are	_	_
used	_	_
on	_	_
a	_	_
single	_	_
GPU	_	_
machine	_	_
with	_	_
56G	_	_
of	_	_
RAM	_	_
and	_	_
an	_	_
NIVIDIA	_	_
GEFORCE	_	_
GTX-980	_	_
Ti	_	_
.	_	_

#182
A	_	_
.	_	_

#183
Database	_	_
Summary	_	_
1	_	_
)	_	_
Blood	_	_
Vessel	_	_
Segmentation	_	_
We	_	_
have	_	_
experimented	_	_
on	_	_
three	_	_
different	_	_
popular	_	_
datasets	_	_
for	_	_
retina	_	_
blood	_	_
vessel	_	_
segmentation	_	_
including	_	_
DRIVE	_	_
,	_	_
STARE	_	_
,	_	_
and	_	_
CHASH_DB1	_	_
.	_	_

#184
The	_	_
DRIVE	_	_
dataset	_	_
is	_	_
consisted	_	_
of	_	_
40	_	_
color	_	_
retinal	_	_
images	_	_
in	_	_
total	_	_
,	_	_
in	_	_
which	_	_
20	_	_
samples	_	_
are	_	_
used	_	_
for	_	_
training	_	_
and	_	_
remaining	_	_
20	_	_
samples	_	_
are	_	_
used	_	_
for	_	_
testing	_	_
.	_	_

#185
The	_	_
size	_	_
of	_	_
each	_	_
original	_	_
image	_	_
is	_	_
565√ó584	_	_
pixels	_	_
[	_	_
44	_	_
]	_	_
.	_	_

#186
To	_	_
develop	_	_
a	_	_
square	_	_
dataset	_	_
,	_	_
the	_	_
images	_	_
are	_	_
cropped	_	_
to	_	_
only	_	_
contain	_	_
the	_	_
data	_	_
from	_	_
columns	_	_
9	_	_
through	_	_
574	_	_
,	_	_
which	_	_
then	_	_
makes	_	_
each	_	_
image	_	_
565√ó565	_	_
pixels	_	_
.	_	_

#187
In	_	_
this	_	_
implementation	_	_
,	_	_
we	_	_
considered	_	_
190,000	_	_
randomly	_	_
selected	_	_
patches	_	_
from	_	_
20	_	_
of	_	_
the	_	_
images	_	_
in	_	_
the	_	_
DRIVE	_	_
dataset	_	_
,	_	_
where	_	_
171,000	_	_
patches	_	_
are	_	_
used	_	_
for	_	_
training	_	_
,	_	_
and	_	_
the	_	_
remaining	_	_
19,000	_	_
patches	_	_
used	_	_
for	_	_
validation	_	_
.	_	_

#188
The	_	_
size	_	_
of	_	_
each	_	_
patch	_	_
is	_	_
48√ó48	_	_
for	_	_
all	_	_
three	_	_
datasets	_	_
shown	_	_
in	_	_
Fig.	_	_
7	_	_
.	_	_

#189
The	_	_
second	_	_
dataset	_	_
,	_	_
STARE	_	_
,	_	_
contains	_	_
20	_	_
color	_	_
images	_	_
,	_	_
and	_	_
each	_	_
image	_	_
has	_	_
a	_	_
size	_	_
of	_	_
700√ó605	_	_
pixels	_	_
[	_	_
45	_	_
,	_	_
46	_	_
]	_	_
.	_	_

#190
Due	_	_
to	_	_
the	_	_
smaller	_	_
number	_	_
of	_	_
samples	_	_
,	_	_
two	_	_
approaches	_	_
are	_	_
applied	_	_
very	_	_
often	_	_
for	_	_
training	_	_
and	_	_
testing	_	_
on	_	_
this	_	_
dataset	_	_
.	_	_

#191
First	_	_
,	_	_
training	_	_
sometimes	_	_
performed	_	_
with	_	_
randomly	_	_
selected	_	_
samples	_	_
from	_	_
all	_	_
20	_	_
images	_	_
[	_	_
53	_	_
]	_	_
.	_	_

#192
Fig.	_	_
7	_	_
.	_	_

#193
Example	_	_
patches	_	_
in	_	_
the	_	_
left	_	_
and	_	_
corresponding	_	_
outputs	_	_
of	_	_
patches	_	_
are	_	_
shown	_	_
in	_	_
the	_	_
right	_	_
.	_	_

#194
Fig.	_	_
8	_	_
.	_	_

#195
Experimental	_	_
outputs	_	_
for	_	_
DRIVE	_	_
dataset	_	_
using	_	_
R2UNet	_	_
:	_	_
first	_	_
row	_	_
shows	_	_
input	_	_
image	_	_
in	_	_
gray	_	_
scale	_	_
,	_	_
second	_	_
row	_	_
show	_	_
ground	_	_
truth	_	_
,	_	_
and	_	_
third	_	_
row	_	_
shows	_	_
the	_	_
experimental	_	_
outputs	_	_
.	_	_

#196
Another	_	_
approach	_	_
is	_	_
the	_	_
‚Äúleave-one-out‚Äù	_	_
method	_	_
,	_	_
in	_	_
which	_	_
each	_	_
image	_	_
is	_	_
tested	_	_
,	_	_
and	_	_
training	_	_
is	_	_
conducted	_	_
on	_	_
the	_	_
remaining	_	_
19	_	_
samples	_	_
[	_	_
47	_	_
]	_	_
.	_	_

#197
Therefore	_	_
,	_	_
there	_	_
is	_	_
no	_	_
overlap	_	_
between	_	_
training	_	_
and	_	_
testing	_	_
samples	_	_
.	_	_

#198
In	_	_
this	_	_
implementation	_	_
,	_	_
we	_	_
used	_	_
the	_	_
‚Äúleaveoneout‚Äù	_	_
approach	_	_
for	_	_
STARE	_	_
dataset	_	_
.	_	_

#199
The	_	_
CHASH_DB1	_	_
dataset	_	_
contains	_	_
28	_	_
color	_	_
retina	_	_
images	_	_
and	_	_
the	_	_
size	_	_
of	_	_
each	_	_
image	_	_
is	_	_
999√ó960	_	_
pixels	_	_
[	_	_
48	_	_
]	_	_
.	_	_

#200
The	_	_
images	_	_
in	_	_
this	_	_
dataset	_	_
were	_	_
collected	_	_
from	_	_
both	_	_
left	_	_
and	_	_
right	_	_
eyes	_	_
of	_	_
14	_	_
school	_	_
children	_	_
.	_	_

#201
The	_	_
dataset	_	_
is	_	_
divided	_	_
into	_	_
two	_	_
sets	_	_
where	_	_
samples	_	_
are	_	_
selected	_	_
randomly	_	_
.	_	_

#202
A	_	_
20-sample	_	_
set	_	_
is	_	_
used	_	_
for	_	_
training	_	_
and	_	_
the	_	_
remaining	_	_
8	_	_
samples	_	_
are	_	_
used	_	_
for	_	_
testing	_	_
.	_	_

#203
As	_	_
the	_	_
dimensionality	_	_
of	_	_
the	_	_
input	_	_
data	_	_
larger	_	_
than	_	_
the	_	_
entire	_	_
DRIVE	_	_
dataset	_	_
,	_	_
we	_	_
have	_	_
considered	_	_
250,000	_	_
patches	_	_
in	_	_
total	_	_
from	_	_
20	_	_
images	_	_
for	_	_
both	_	_
STARE	_	_
and	_	_
CHASE_DB1	_	_
.	_	_

#204
In	_	_
this	_	_
case	_	_
225,000	_	_
patches	_	_
are	_	_
used	_	_
for	_	_
training	_	_
and	_	_
the	_	_
remaining	_	_
25,000	_	_
patches	_	_
are	_	_
used	_	_
for	_	_
validation	_	_
.	_	_

#205
Since	_	_
the	_	_
binary	_	_
FOV	_	_
(	_	_
which	_	_
is	_	_
shown	_	_
in	_	_
second	_	_
row	_	_
in	_	_
Fig.	_	_
6	_	_
)	_	_
is	_	_
not	_	_
available	_	_
for	_	_
the	_	_
STARE	_	_
and	_	_
CHASE_DB1	_	_
datasets	_	_
,	_	_
we	_	_
generated	_	_
FOV	_	_
masks	_	_
using	_	_
a	_	_
similar	_	_
technique	_	_
to	_	_
the	_	_
one	_	_
described	_	_
in	_	_
[	_	_
47	_	_
]	_	_
.	_	_

#206
One	_	_
advantage	_	_
of	_	_
the	_	_
patch-based	_	_
approach	_	_
is	_	_
that	_	_
the	_	_
patches	_	_
give	_	_
the	_	_
network	_	_
access	_	_
to	_	_
local	_	_
information	_	_
about	_	_
the	_	_
pixels	_	_
,	_	_
which	_	_
has	_	_
impact	_	_
on	_	_
overall	_	_
prediction	_	_
.	_	_

#207
Furthermore	_	_
,	_	_
it	_	_
ensures	_	_
that	_	_
the	_	_
classes	_	_
of	_	_
the	_	_
input	_	_
data	_	_
are	_	_
balanced	_	_
.	_	_

#208
The	_	_
input	_	_
patches	_	_
are	_	_
randomly	_	_
sampled	_	_
over	_	_
an	_	_
entire	_	_
image	_	_
,	_	_
which	_	_
also	_	_
includes	_	_
the	_	_
outside	_	_
region	_	_
of	_	_
the	_	_
FOV	_	_
.	_	_

#209
2	_	_
)	_	_
Skin	_	_
Cancer	_	_
Segmentation	_	_
This	_	_
dataset	_	_
is	_	_
taken	_	_
from	_	_
the	_	_
Kaggle	_	_
competition	_	_
on	_	_
skin	_	_
lesion	_	_
segmentation	_	_
that	_	_
occurred	_	_
in	_	_
2017	_	_
[	_	_
49	_	_
]	_	_
.	_	_

#210
This	_	_
dataset	_	_
contains	_	_
2000	_	_
samples	_	_
in	_	_
total	_	_
.	_	_

#211
It	_	_
consists	_	_
of	_	_
1250	_	_
training	_	_
samples	_	_
,	_	_
150	_	_
validation	_	_
samples	_	_
,	_	_
and	_	_
600	_	_
testing	_	_
samples	_	_
.	_	_

#212
The	_	_
original	_	_
size	_	_
of	_	_
each	_	_
sample	_	_
was	_	_
700√ó900	_	_
,	_	_
which	_	_
was	_	_
rescaled	_	_
to	_	_
256√ó256	_	_
for	_	_
this	_	_
implementation	_	_
.	_	_

#213
The	_	_
training	_	_
samples	_	_
include	_	_
the	_	_
original	_	_
images	_	_
,	_	_
as	_	_
well	_	_
as	_	_
corresponding	_	_
target	_	_
binary	_	_
images	_	_
containing	_	_
cancer	_	_
or	_	_
non-cancer	_	_
lesions	_	_
.	_	_

#214
The	_	_
target	_	_
pixels	_	_
are	_	_
represented	_	_
with	_	_
a	_	_
value	_	_
of	_	_
either	_	_
255	_	_
or	_	_
0	_	_
for	_	_
the	_	_
pixels	_	_
outside	_	_
of	_	_
the	_	_
target	_	_
lesion	_	_
.	_	_

#215
3	_	_
)	_	_
Lung	_	_
Segmentation	_	_
The	_	_
Lung	_	_
Nodule	_	_
Analysis	_	_
(	_	_
LUNA	_	_
)	_	_
competition	_	_
at	_	_
the	_	_
Kaggle	_	_
Data	_	_
Science	_	_
Bowl	_	_
in	_	_
2017	_	_
was	_	_
held	_	_
to	_	_
find	_	_
lung	_	_
lesions	_	_
in	_	_
2D	_	_
and	_	_
3D	_	_
CT	_	_
images	_	_
.	_	_

#216
The	_	_
provided	_	_
dataset	_	_
consisted	_	_
of	_	_
534	_	_
2D	_	_
samples	_	_
with	_	_
respective	_	_
label	_	_
images	_	_
for	_	_
lung	_	_
segmentation	_	_
[	_	_
50	_	_
]	_	_
.	_	_

#217
For	_	_
this	_	_
study	_	_
,	_	_
70	_	_
%	_	_
of	_	_
the	_	_
images	_	_
are	_	_
used	_	_
for	_	_
training	_	_
and	_	_
the	_	_
remaining	_	_
30	_	_
%	_	_
are	_	_
used	_	_
for	_	_
testing	_	_
.	_	_

#218
The	_	_
original	_	_
image	_	_
size	_	_
was	_	_
512√ó512	_	_
,	_	_
however	_	_
,	_	_
we	_	_
resized	_	_
the	_	_
images	_	_
to	_	_
256√ó256	_	_
pixels	_	_
in	_	_
this	_	_
implementation	_	_
.	_	_

#219
B.	_	_
Quantitative	_	_
Analysis	_	_
Approaches	_	_
For	_	_
quantitative	_	_
analysis	_	_
of	_	_
the	_	_
experimental	_	_
results	_	_
,	_	_
several	_	_
performance	_	_
metrics	_	_
are	_	_
considered	_	_
,	_	_
including	_	_
accuracy	_	_
(	_	_
AC	_	_
)	_	_
,	_	_
sensitivity	_	_
(	_	_
SE	_	_
)	_	_
,	_	_
specificity	_	_
(	_	_
SP	_	_
)	_	_
,	_	_
F1-score	_	_
,	_	_
Dice	_	_
coefficient	_	_
(	_	_
DC	_	_
)	_	_
,	_	_
and	_	_
Jaccard	_	_
similarity	_	_
(	_	_
JS	_	_
)	_	_
.	_	_

#220
To	_	_
do	_	_
this	_	_
we	_	_
also	_	_
use	_	_
the	_	_
variables	_	_
True	_	_
Positive	_	_
(	_	_
TP	_	_
)	_	_
,	_	_
True	_	_
Negative	_	_
(	_	_
TN	_	_
)	_	_
,	_	_
False	_	_
Positive	_	_
(	_	_
FP	_	_
)	_	_
,	_	_
and	_	_
False	_	_
Negative	_	_
(	_	_
FN	_	_
)	_	_
.	_	_

#221
The	_	_
overall	_	_
accuracy	_	_
is	_	_
calculated	_	_
using	_	_
Eq.	_	_
(	_	_
4	_	_
)	_	_
,	_	_
and	_	_
sensitivity	_	_
is	_	_
calculated	_	_
using	_	_
Eq.	_	_
(	_	_
5	_	_
)	_	_
.	_	_

#222
ùê¥ùê∂	_	_
=	_	_
ùëáùëÉ+ùëáùëÅ	_	_
ùëáùëÉ+ùëáùëÅ+ùêπùëÉ+ùêπùëÅ	_	_
(	_	_
4	_	_
)	_	_
ùëÜùê∏	_	_
=	_	_
ùëáùëÉ	_	_
ùëáùëÉ+ùêπùëÅ	_	_
(	_	_
5	_	_
)	_	_
Furthermore	_	_
,	_	_
specificity	_	_
is	_	_
calculated	_	_
using	_	_
the	_	_
following	_	_
Eq.	_	_
(	_	_
6	_	_
)	_	_
.	_	_

#223
ùëÜùëÉ	_	_
=	_	_
ùëáùëÅ	_	_
ùëáùëÅ+ùêπùëÉ	_	_
(	_	_
6	_	_
)	_	_
The	_	_
DC	_	_
is	_	_
expressed	_	_
as	_	_
in	_	_
Eq.	_	_
(	_	_
7	_	_
)	_	_
according	_	_
to	_	_
[	_	_
51	_	_
]	_	_
.	_	_

#224
Here	_	_
GT	_	_
refers	_	_
to	_	_
the	_	_
ground	_	_
truth	_	_
and	_	_
SR	_	_
refers	_	_
the	_	_
segmentation	_	_
result	_	_
.	_	_

#225
ùê∑ùê∂	_	_
=	_	_
2	_	_
|ùê∫ùëá‚à©ùëÜùëÖ|	_	_
|ùê∫ùëá|+|ùëÜùëÖ|	_	_
(	_	_
7	_	_
)	_	_
The	_	_
JS	_	_
is	_	_
represented	_	_
using	_	_
Eq.	_	_
(	_	_
8	_	_
)	_	_
as	_	_
in	_	_
[	_	_
52	_	_
]	_	_
.	_	_

#226
ùêΩùëÜ	_	_
=	_	_
|ùê∫ùëá‚à©ùëÜùëÖ|	_	_
|ùê∫ùëá‚à™ùëÜùëÖ|	_	_
(	_	_
8	_	_
)	_	_
However	_	_
,	_	_
the	_	_
area	_	_
under	_	_
curve	_	_
(	_	_
AUC	_	_
)	_	_
and	_	_
the	_	_
receiver	_	_
operating	_	_
characteristics	_	_
(	_	_
ROC	_	_
)	_	_
curve	_	_
are	_	_
common	_	_
evaluation	_	_
measures	_	_
for	_	_
medical	_	_
image	_	_
segmentation	_	_
tasks	_	_
.	_	_

#227
In	_	_
this	_	_
experiment	_	_
,	_	_
we	_	_
utilized	_	_
both	_	_
analytical	_	_
methods	_	_
to	_	_
evaluate	_	_
the	_	_
performance	_	_
of	_	_
the	_	_
proposed	_	_
approaches	_	_
considering	_	_
the	_	_
mentioned	_	_
criterions	_	_
against	_	_
existing	_	_
state-of-the-art	_	_
techniques	_	_
.	_	_

#228
Fig.	_	_
9	_	_
.	_	_

#229
Training	_	_
accuracy	_	_
of	_	_
the	_	_
proposed	_	_
models	_	_
of	_	_
RU-Net	_	_
,	_	_
and	_	_
R2U-Net	_	_
against	_	_
ResU-Net	_	_
and	_	_
U-Net	_	_
.	_	_

#230
C.	_	_
Results	_	_
1	_	_
)	_	_
Retina	_	_
Blood	_	_
Vessel	_	_
Segmentation	_	_
Using	_	_
the	_	_
DRIVE	_	_
Dataset	_	_
The	_	_
precise	_	_
segmentation	_	_
results	_	_
achieved	_	_
with	_	_
the	_	_
proposed	_	_
R2U-Net	_	_
model	_	_
are	_	_
shown	_	_
in	_	_
Fig.	_	_
8	_	_
.	_	_

#231
Figs.	_	_
9	_	_
and	_	_
10	_	_
show	_	_
the	_	_
training	_	_
and	_	_
validation	_	_
accuracy	_	_
when	_	_
using	_	_
the	_	_
DRIVE	_	_
dataset	_	_
.	_	_

#232
These	_	_
figures	_	_
show	_	_
that	_	_
the	_	_
proposed	_	_
R2U-Net	_	_
and	_	_
RU-Net	_	_
models	_	_
provide	_	_
better	_	_
performance	_	_
during	_	_
both	_	_
the	_	_
training	_	_
and	_	_
validation	_	_
phase	_	_
when	_	_
compared	_	_
to	_	_
U-Net	_	_
and	_	_
ResU-Net	_	_
.	_	_

#233
Fig.	_	_
10	_	_
.	_	_

#234
Validation	_	_
accuracy	_	_
of	_	_
the	_	_
proposed	_	_
models	_	_
against	_	_
ResU-Net	_	_
and	_	_
UNet	_	_
.	_	_

#235
2	_	_
)	_	_
Retina	_	_
blood	_	_
vessel	_	_
segmentation	_	_
on	_	_
the	_	_
STARE	_	_
dataset	_	_
The	_	_
experimental	_	_
outputs	_	_
of	_	_
R2U-Net	_	_
when	_	_
using	_	_
the	_	_
STARE	_	_
dataset	_	_
are	_	_
shown	_	_
in	_	_
Fig.	_	_
11	_	_
.	_	_

#236
The	_	_
training	_	_
and	_	_
validation	_	_
accuracy	_	_
for	_	_
the	_	_
STARE	_	_
dataset	_	_
is	_	_
shown	_	_
in	_	_
Figs.	_	_
12	_	_
and	_	_
13	_	_
respectively	_	_
.	_	_

#237
R2U-Net	_	_
shows	_	_
a	_	_
better	_	_
performance	_	_
than	_	_
all	_	_
other	_	_
models	_	_
during	_	_
training	_	_
.	_	_

#238
In	_	_
addition	_	_
,	_	_
the	_	_
validation	_	_
accuracy	_	_
in	_	_
Fig.	_	_
13	_	_
demonstrates	_	_
that	_	_
the	_	_
RU-Net	_	_
and	_	_
R2U-Net	_	_
models	_	_
provide	_	_
better	_	_
validation	_	_
accuracy	_	_
when	_	_
compared	_	_
to	_	_
the	_	_
equivalent	_	_
U-Net	_	_
and	_	_
ResU-Net	_	_
models	_	_
.	_	_

#239
Thus	_	_
,	_	_
the	_	_
performance	_	_
demonstrates	_	_
the	_	_
effectiveness	_	_
of	_	_
the	_	_
proposed	_	_
approaches	_	_
for	_	_
segmentation	_	_
tasks	_	_
.	_	_

#240
Fig.	_	_
11	_	_
.	_	_

#241
Experimental	_	_
outputs	_	_
of	_	_
STARE	_	_
dataset	_	_
using	_	_
R2UNet	_	_
:	_	_
first	_	_
row	_	_
shows	_	_
input	_	_
image	_	_
after	_	_
performing	_	_
normalization	_	_
,	_	_
second	_	_
row	_	_
show	_	_
ground	_	_
truth	_	_
,	_	_
and	_	_
third	_	_
row	_	_
shows	_	_
the	_	_
experimental	_	_
outputs	_	_
.	_	_

#242
Fig.	_	_
12	_	_
.	_	_

#243
Training	_	_
accuracy	_	_
in	_	_
STARE	_	_
dataset	_	_
for	_	_
R2U-Net	_	_
,	_	_
RU-Net	_	_
,	_	_
ResU-Net	_	_
,	_	_
and	_	_
U-Net	_	_
.	_	_

#244
Fig.	_	_
13	_	_
.	_	_

#245
Validation	_	_
accuracy	_	_
in	_	_
STARE	_	_
dataset	_	_
for	_	_
R2U-Net	_	_
,	_	_
RU-Net	_	_
,	_	_
ResUNet	_	_
,	_	_
and	_	_
U-Net	_	_
.	_	_

#246
3	_	_
)	_	_
CHASE_DB1	_	_
For	_	_
qualitative	_	_
analysis	_	_
,	_	_
the	_	_
example	_	_
outputs	_	_
of	_	_
R2U-Net	_	_
are	_	_
shown	_	_
in	_	_
Fig.	_	_
14	_	_
.	_	_

#247
For	_	_
quantitative	_	_
analysis	_	_
,	_	_
the	_	_
results	_	_
are	_	_
given	_	_
in	_	_
Table	_	_
I	_	_
.	_	_

#248
From	_	_
the	_	_
table	_	_
,	_	_
it	_	_
can	_	_
be	_	_
concluded	_	_
that	_	_
in	_	_
all	_	_
cases	_	_
,	_	_
the	_	_
proposed	_	_
RU-Net	_	_
and	_	_
R2U-Net	_	_
models	_	_
show	_	_
better	_	_
performance	_	_
in	_	_
terms	_	_
of	_	_
AUC	_	_
and	_	_
accuracy	_	_
.	_	_

#249
The	_	_
ROC	_	_
for	_	_
the	_	_
highest	_	_
AUCs	_	_
for	_	_
the	_	_
R2U-Net	_	_
model	_	_
on	_	_
each	_	_
of	_	_
the	_	_
three	_	_
retina	_	_
blood	_	_
vessel	_	_
segmentation	_	_
datasets	_	_
is	_	_
shown	_	_
in	_	_
Fig.	_	_
15	_	_
.	_	_

#250
Fig.	_	_
14	_	_
.	_	_

#251
Qualitative	_	_
analysis	_	_
for	_	_
CHASE_DB1	_	_
dataset	_	_
.	_	_

#252
The	_	_
segmentation	_	_
outputs	_	_
of	_	_
8	_	_
testing	_	_
samples	_	_
using	_	_
R2U-Net	_	_
.	_	_

#253
First	_	_
row	_	_
shows	_	_
the	_	_
input	_	_
images	_	_
,	_	_
second	_	_
row	_	_
is	_	_
ground	_	_
truth	_	_
,	_	_
and	_	_
third	_	_
row	_	_
shows	_	_
the	_	_
segmentation	_	_
outputs	_	_
using	_	_
R2U-Net	_	_
.	_	_

#254
4	_	_
)	_	_
Skin	_	_
Cancer	_	_
Lesion	_	_
Segmentation	_	_
In	_	_
this	_	_
implementation	_	_
,	_	_
this	_	_
dataset	_	_
is	_	_
preprocessed	_	_
with	_	_
mean	_	_
subtraction	_	_
and	_	_
normalized	_	_
according	_	_
to	_	_
the	_	_
standard	_	_
deviation	_	_
.	_	_

#255
We	_	_
used	_	_
the	_	_
ADAM	_	_
optimization	_	_
technique	_	_
with	_	_
a	_	_
learning	_	_
rate	_	_
of	_	_
2√ó10-4	_	_
and	_	_
binary	_	_
cross	_	_
entropy	_	_
loss	_	_
.	_	_

#256
In	_	_
addition	_	_
,	_	_
we	_	_
also	_	_
calculated	_	_
MSE	_	_
error	_	_
during	_	_
the	_	_
training	_	_
and	_	_
validation	_	_
phase	_	_
.	_	_

#257
In	_	_
this	_	_
case	_	_
10	_	_
%	_	_
of	_	_
the	_	_
samples	_	_
are	_	_
used	_	_
for	_	_
validation	_	_
during	_	_
training	_	_
with	_	_
a	_	_
batch	_	_
size	_	_
of	_	_
32	_	_
and	_	_
150	_	_
epochs	_	_
.	_	_

#258
The	_	_
training	_	_
accuracy	_	_
of	_	_
the	_	_
proposed	_	_
models	_	_
R2U-Net	_	_
and	_	_
RU-Net	_	_
was	_	_
compared	_	_
with	_	_
that	_	_
of	_	_
ResU-Net	_	_
and	_	_
U-Net	_	_
for	_	_
an	_	_
end-to-end	_	_
image	_	_
based	_	_
segmentation	_	_
approach	_	_
.	_	_

#259
The	_	_
result	_	_
is	_	_
shown	_	_
in	_	_
Fig.	_	_
16	_	_
.	_	_

#260
The	_	_
validation	_	_
accuracy	_	_
is	_	_
shown	_	_
in	_	_
Fig.	_	_
17	_	_
.	_	_

#261
In	_	_
both	_	_
cases	_	_
,	_	_
the	_	_
proposed	_	_
models	_	_
show	_	_
better	_	_
performance	_	_
when	_	_
compared	_	_
with	_	_
the	_	_
equivalent	_	_
U-Net	_	_
and	_	_
ResU-Net	_	_
models	_	_
.	_	_

#262
This	_	_
clearly	_	_
demonstrates	_	_
the	_	_
robustness	_	_
of	_	_
the	_	_
proposed	_	_
models	_	_
in	_	_
end-to-end	_	_
image-based	_	_
segmentation	_	_
tasks	_	_
.	_	_

#263
Fig.	_	_
15	_	_
.	_	_

#264
AUC	_	_
for	_	_
retina	_	_
blood	_	_
vessel	_	_
segmentation	_	_
for	_	_
the	_	_
best	_	_
performance	_	_
achieved	_	_
with	_	_
R2U-Net	_	_
.	_	_

#265
TABLE	_	_
I	_	_
.	_	_

#266
EXPERIMENTAL	_	_
RESULTS	_	_
OF	_	_
PROPOSED	_	_
APPROACHES	_	_
FOR	_	_
RETINA	_	_
BLOOD	_	_
VESSEL	_	_
SEGMENTATION	_	_
AND	_	_
COMPARISON	_	_
AGAINST	_	_
OTHER	_	_
TRADITIONAL	_	_
AND	_	_
DEEP	_	_
LEARNING-BASED	_	_
APPROACHES	_	_
.	_	_

#267
Dataset	_	_
Methods	_	_
Year	_	_
F1-score	_	_
SE	_	_
SP	_	_
AC	_	_
AUC	_	_
DRIVE	_	_
Chen	_	_
[	_	_
53	_	_
]	_	_
2014	_	_
-	_	_
o.7252	_	_
0.9798	_	_
0.9474	_	_
0.9648	_	_
Azzopardi	_	_
[	_	_
54	_	_
]	_	_
2015	_	_
-	_	_
0.7655	_	_
0.9704	_	_
0.9442	_	_
0.9614	_	_
Roychowdhury	_	_
[	_	_
55	_	_
]	_	_
2016	_	_
-	_	_
0.7250	_	_
0.9830	_	_
0.9520	_	_
0.9620	_	_
Liskowsk	_	_
[	_	_
56	_	_
]	_	_
2016	_	_
-	_	_
0.7763	_	_
0.9768	_	_
0.9495	_	_
0.9720	_	_
Qiaoliang	_	_
Li	_	_
[	_	_
57	_	_
]	_	_
2016	_	_
-	_	_
0.7569	_	_
0.9816	_	_
0.9527	_	_
0.9738	_	_
U-Net	_	_
2018	_	_
0.8142	_	_
0.7537	_	_
0.9820	_	_
0.9531	_	_
0.9755	_	_
Residual	_	_
U-Net	_	_
2018	_	_
0.8149	_	_
0.7726	_	_
0.9820	_	_
0.9553	_	_
0.9779	_	_
Recurrent	_	_
U-Net	_	_
2018	_	_
0.8155	_	_
0.7751	_	_
0.9816	_	_
0.9556	_	_
0.9782	_	_
R2U-Net	_	_
2018	_	_
0.8171	_	_
0.7792	_	_
0.9813	_	_
0.9556	_	_
0.9784	_	_
STARE	_	_
Marin	_	_
et	_	_
al.	_	_
[	_	_
58	_	_
]	_	_
2011	_	_
-	_	_
0.6940	_	_
0.9770	_	_
0.9520	_	_
0.9820	_	_
Fraz	_	_
[	_	_
59	_	_
]	_	_
2012	_	_
-	_	_
0.7548	_	_
0.9763	_	_
0.9534	_	_
0.9768	_	_
Roychowdhury	_	_
[	_	_
55	_	_
]	_	_
2016	_	_
-	_	_
0.7720	_	_
0.9730	_	_
0.9510	_	_
0.9690	_	_
Liskowsk	_	_
[	_	_
56	_	_
]	_	_
2016	_	_
-	_	_
0.7867	_	_
0.9754	_	_
0.9566	_	_
0.9785	_	_
Qiaoliang	_	_
Li	_	_
[	_	_
57	_	_
]	_	_
2016	_	_
-	_	_
0.7726	_	_
0.9844	_	_
0.9628	_	_
0.9879	_	_
U-Net	_	_
2018	_	_
0.8373	_	_
0.8270	_	_
0.9842	_	_
0.9690	_	_
0.9898	_	_
Residual	_	_
U-Net	_	_
2018	_	_
0.8388	_	_
0.8203	_	_
0.9856	_	_
0.9700	_	_
0.9904	_	_
Recurrent	_	_
U-Net	_	_
2018	_	_
0.8396	_	_
0.8108	_	_
0.9871	_	_
0.9706	_	_
0.9909	_	_
R2U-Net	_	_
2018	_	_
0.8475	_	_
0.8298	_	_
0.9862	_	_
0.9712	_	_
0.9914	_	_
CHASE_DB1	_	_
Fraz	_	_
[	_	_
59	_	_
]	_	_
2012	_	_
-	_	_
0.7224	_	_
0.9711	_	_
0.9469	_	_
0.9712	_	_
Fraz	_	_
[	_	_
60	_	_
]	_	_
2014	_	_
-	_	_
-	_	_
-	_	_
0.9524	_	_
0.9760	_	_
Azzopardi	_	_
[	_	_
54	_	_
]	_	_
2015	_	_
-	_	_
0.7655	_	_
0.9704	_	_
0.9442	_	_
0.9614	_	_
Roychowdhury	_	_
[	_	_
55	_	_
]	_	_
2016	_	_
-	_	_
0.7201	_	_
0.9824	_	_
0.9530	_	_
0.9532	_	_
Qiaoliang	_	_
Li	_	_
[	_	_
57	_	_
]	_	_
2016	_	_
-	_	_
0.7507	_	_
0.9793	_	_
0.9581	_	_
0.9793	_	_
U-Net	_	_
2018	_	_
0.7783	_	_
0.8288	_	_
0.9701	_	_
0.9578	_	_
0.9772	_	_
Residual	_	_
U-Net	_	_
2018	_	_
0.7800	_	_
0.7726	_	_
0.9820	_	_
0.9553	_	_
0.9779	_	_
Recurrent	_	_
U-Net	_	_
2018	_	_
0.7810	_	_
0.7459	_	_
0.9836	_	_
0.9622	_	_
0.9803	_	_
R2U-Net	_	_
2018	_	_
0.7928	_	_
0.7756	_	_
0.9820	_	_
0.9634	_	_
0.9815	_	_
Fig.	_	_
16	_	_
.	_	_

#268
Training	_	_
accuracy	_	_
for	_	_
skin	_	_
lesion	_	_
segmentation	_	_
.	_	_

#269
The	_	_
quantitative	_	_
results	_	_
of	_	_
this	_	_
experiment	_	_
were	_	_
compared	_	_
against	_	_
existing	_	_
methods	_	_
as	_	_
shown	_	_
in	_	_
Table	_	_
II	_	_
.	_	_

#270
Some	_	_
of	_	_
the	_	_
example	_	_
outputs	_	_
from	_	_
the	_	_
testing	_	_
phase	_	_
are	_	_
shown	_	_
in	_	_
Fig.	_	_
18	_	_
.	_	_

#271
The	_	_
first	_	_
column	_	_
shows	_	_
the	_	_
input	_	_
images	_	_
,	_	_
the	_	_
second	_	_
column	_	_
shows	_	_
the	_	_
ground	_	_
truth	_	_
,	_	_
the	_	_
network	_	_
outputs	_	_
are	_	_
shown	_	_
in	_	_
the	_	_
third	_	_
column	_	_
,	_	_
and	_	_
the	_	_
fourth	_	_
column	_	_
demonstrates	_	_
the	_	_
final	_	_
outputs	_	_
after	_	_
performing	_	_
post	_	_
processing	_	_
with	_	_
a	_	_
threshold	_	_
of	_	_
0.5	_	_
.	_	_

#272
Figure	_	_
18	_	_
shows	_	_
promising	_	_
segmentation	_	_
results	_	_
.	_	_

#273
Fig.	_	_
17	_	_
.	_	_

#274
Validation	_	_
accuracy	_	_
for	_	_
skin	_	_
lesion	_	_
segmentation	_	_
.	_	_

#275
In	_	_
most	_	_
cases	_	_
,	_	_
the	_	_
target	_	_
lesions	_	_
are	_	_
segmented	_	_
accurately	_	_
with	_	_
almost	_	_
the	_	_
same	_	_
shape	_	_
of	_	_
ground	_	_
truth	_	_
.	_	_

#276
However	_	_
,	_	_
if	_	_
we	_	_
observe	_	_
the	_	_
second	_	_
and	_	_
third	_	_
rows	_	_
in	_	_
Fig.	_	_
18	_	_
,	_	_
it	_	_
can	_	_
be	_	_
clearly	_	_
seen	_	_
that	_	_
the	_	_
input	_	_
images	_	_
contain	_	_
two	_	_
spots	_	_
,	_	_
one	_	_
is	_	_
a	_	_
target	_	_
lesion	_	_
and	_	_
the	_	_
other	_	_
bright	_	_
spot	_	_
which	_	_
is	_	_
not	_	_
a	_	_
target	_	_
.	_	_

#277
This	_	_
result	_	_
is	_	_
obtained	_	_
even	_	_
though	_	_
the	_	_
non-target	_	_
lesion	_	_
is	_	_
brighter	_	_
than	_	_
the	_	_
target	_	_
lesion	_	_
shown	_	_
in	_	_
the	_	_
third	_	_
row	_	_
in	_	_
Fig.	_	_
18	_	_
.	_	_

#278
The	_	_
R2U-Net	_	_
model	_	_
still	_	_
segments	_	_
the	_	_
desired	_	_
part	_	_
accurately	_	_
,	_	_
which	_	_
clearly	_	_
shows	_	_
the	_	_
robustness	_	_
of	_	_
the	_	_
proposed	_	_
segmentation	_	_
method	_	_
.	_	_

#279
We	_	_
have	_	_
compared	_	_
the	_	_
performance	_	_
of	_	_
the	_	_
proposed	_	_
approaches	_	_
against	_	_
recently	_	_
published	_	_
results	_	_
with	_	_
respect	_	_
to	_	_
sensitivity	_	_
,	_	_
specificity	_	_
,	_	_
accuracy	_	_
,	_	_
AUC	_	_
,	_	_
and	_	_
DC	_	_
.	_	_

#280
The	_	_
proposed	_	_
R2U-Net	_	_
model	_	_
provides	_	_
a	_	_
testing	_	_
accuracy	_	_
0.9424	_	_
with	_	_
a	_	_
higher	_	_
AUC	_	_
,	_	_
which	_	_
is	_	_
0.9419	_	_
.	_	_

#281
The	_	_
average	_	_
AUC	_	_
for	_	_
skin	_	_
lesion	_	_
segmentation	_	_
is	_	_
shown	_	_
in	_	_
Fig.	_	_
19	_	_
.	_	_

#282
In	_	_
addition	_	_
,	_	_
we	_	_
calculated	_	_
the	_	_
average	_	_
DC	_	_
in	_	_
the	_	_
testing	_	_
phase	_	_
and	_	_
achieved	_	_
0.8616	_	_
,	_	_
which	_	_
is	_	_
around	_	_
1.26	_	_
%	_	_
better	_	_
than	_	_
recently	_	_
proposed	_	_
alternatives	_	_
[	_	_
62	_	_
]	_	_
.	_	_

#283
Furthermore	_	_
,	_	_
the	_	_
JSC	_	_
and	_	_
F1	_	_
scores	_	_
are	_	_
calculated	_	_
and	_	_
the	_	_
R2U-Net	_	_
model	_	_
obtains	_	_
0.9421	_	_
for	_	_
JSC	_	_
and	_	_
0.8920	_	_
for	_	_
F1	_	_
score	_	_
for	_	_
skin	_	_
lesion	_	_
segmentation	_	_
with	_	_
t=3	_	_
.	_	_

#284
These	_	_
results	_	_
are	_	_
achieved	_	_
with	_	_
a	_	_
R2U-Net	_	_
model	_	_
that	_	_
only	_	_
contains	_	_
about	_	_
1.037	_	_
million	_	_
(	_	_
M	_	_
)	_	_
network	_	_
parameters	_	_
.	_	_

#285
Contrarily	_	_
,	_	_
the	_	_
work	_	_
presented	_	_
in	_	_
[	_	_
61	_	_
]	_	_
evaluated	_	_
VGG-16	_	_
and	_	_
Incpetion-V3	_	_
models	_	_
for	_	_
skin	_	_
lesion	_	_
segmentation	_	_
,	_	_
but	_	_
those	_	_
networks	_	_
contained	_	_
around	_	_
138M	_	_
and	_	_
23M	_	_
network	_	_
parameters	_	_
respectively	_	_
.	_	_

#286
Fig.	_	_
18	_	_
.	_	_

#287
This	_	_
results	_	_
demonstrates	_	_
qualitative	_	_
assessment	_	_
of	_	_
the	_	_
proposed	_	_
R2U-Net	_	_
for	_	_
skin	_	_
cancer	_	_
segmentation	_	_
task	_	_
with	_	_
t=3	_	_
.	_	_

#288
First	_	_
column	_	_
is	_	_
the	_	_
input	_	_
sample	_	_
,	_	_
second	_	_
column	_	_
is	_	_
ground	_	_
truth	_	_
,	_	_
third	_	_
column	_	_
shows	_	_
the	_	_
outputs	_	_
from	_	_
TABLE	_	_
II	_	_
.	_	_

#289
EXPERIMENTAL	_	_
RESULTS	_	_
OF	_	_
PROPOSED	_	_
APPROACHES	_	_
FOR	_	_
SKIN	_	_
CANCER	_	_
LESION	_	_
SEGMENTATION	_	_
AND	_	_
COMPARISON	_	_
AGAINST	_	_
OTHER	_	_
EXISTING	_	_
APPROACHES	_	_
.	_	_

#290
JACCARD	_	_
SIMILARITY	_	_
SCORE	_	_
(	_	_
JSC	_	_
)	_	_
.	_	_

#291
Methods	_	_
Year	_	_
SE	_	_
SP	_	_
JSC	_	_
F1-score	_	_
AC	_	_
AUC	_	_
DC	_	_
Conv	_	_
.	_	_

#292
classifier	_	_
VGG-16	_	_
[	_	_
61	_	_
]	_	_
2017	_	_
0.533	_	_
-	_	_
-	_	_
-	_	_
0.6130	_	_
0.6420	_	_
Conv	_	_
.	_	_

#293
classifier	_	_
Inception-v3	_	_
[	_	_
61	_	_
]	_	_
2017	_	_
0.760	_	_
-	_	_
-	_	_
-	_	_
0.6930	_	_
0.7390	_	_
Melanoma	_	_
detection	_	_
[	_	_
62	_	_
]	_	_
2017	_	_
-	_	_
-	_	_
-	_	_
-	_	_
o.9340	_	_
-	_	_
0.8490	_	_
Skin	_	_
Lesion	_	_
Analysis	_	_
[	_	_
63	_	_
]	_	_
2017	_	_
0.8250	_	_
0.9750	_	_
-	_	_
-	_	_
0.9340	_	_
-	_	_
UNet	_	_
(	_	_
t=2	_	_
)	_	_
2018	_	_
0.9479	_	_
0.9263	_	_
0.9314	_	_
0.8682	_	_
0.9314	_	_
0.9371	_	_
0.8476	_	_
ResU-Net	_	_
(	_	_
t=2	_	_
)	_	_
2018	_	_
0.9454	_	_
0.9338	_	_
0.9367	_	_
0.8799	_	_
0.9367	_	_
0.9396	_	_
0.8567	_	_
RecU-Net	_	_
(	_	_
t=2	_	_
)	_	_
2018	_	_
0.9334	_	_
0.9395	_	_
0.9380	_	_
0.8841	_	_
0.9380	_	_
0.9364	_	_
0.8592	_	_
R2U-Net	_	_
(	_	_
t=2	_	_
)	_	_
2018	_	_
0.9496	_	_
0.9313	_	_
0.9372	_	_
0.8823	_	_
0.9372	_	_
0.9405	_	_
0.8608	_	_
R2U-Net	_	_
(	_	_
t=3	_	_
)	_	_
2018	_	_
0.9414	_	_
0.9425	_	_
0.9421	_	_
0.8920	_	_
0.9424	_	_
0.9419	_	_
0.8616	_	_
network	_	_
,	_	_
and	_	_
fourth	_	_
column	_	_
show	_	_
the	_	_
final	_	_
resulting	_	_
after	_	_
performing	_	_
thresholding	_	_
with	_	_
0.5	_	_
.	_	_

#294
5	_	_
)	_	_
Lung	_	_
Segmentation	_	_
Lung	_	_
segmentation	_	_
is	_	_
very	_	_
important	_	_
for	_	_
analyzing	_	_
lung	_	_
related	_	_
diseases	_	_
,	_	_
and	_	_
can	_	_
be	_	_
applied	_	_
to	_	_
lung	_	_
cancer	_	_
segmentation	_	_
and	_	_
lung	_	_
pattern	_	_
classification	_	_
for	_	_
identifying	_	_
other	_	_
problems	_	_
.	_	_

#295
In	_	_
this	_	_
experiment	_	_
,	_	_
the	_	_
ADAM	_	_
optimizer	_	_
is	_	_
used	_	_
with	_	_
a	_	_
learning	_	_
rate	_	_
of	_	_
2√ó10-4	_	_
.	_	_

#296
We	_	_
used	_	_
binary	_	_
cross	_	_
entropy	_	_
loss	_	_
,	_	_
and	_	_
also	_	_
calculated	_	_
MSE	_	_
during	_	_
training	_	_
and	_	_
validation	_	_
.	_	_

#297
In	_	_
this	_	_
case	_	_
10	_	_
%	_	_
of	_	_
the	_	_
samples	_	_
were	_	_
used	_	_
for	_	_
validation	_	_
with	_	_
a	_	_
batch	_	_
size	_	_
of	_	_
16	_	_
and	_	_
150	_	_
epochs	_	_
150	_	_
.	_	_

#298
Table	_	_
III	_	_
shows	_	_
the	_	_
summary	_	_
of	_	_
how	_	_
well	_	_
the	_	_
proposed	_	_
models	_	_
performed	_	_
against	_	_
equivalent	_	_
U-Net	_	_
and	_	_
ResU-Net	_	_
models	_	_
.	_	_

#299
The	_	_
experimental	_	_
results	_	_
show	_	_
that	_	_
the	_	_
proposed	_	_
models	_	_
outperform	_	_
the	_	_
U-Net	_	_
and	_	_
ResU-Net	_	_
models	_	_
with	_	_
same	_	_
number	_	_
of	_	_
network	_	_
parameters	_	_
.	_	_

#300
Fig.	_	_
19	_	_
.	_	_

#301
ROC-AUC	_	_
for	_	_
skin	_	_
segmentation	_	_
four	_	_
models	_	_
with	_	_
t=2	_	_
and	_	_
t=3	_	_
.	_	_

#302
Furthermore	_	_
,	_	_
many	_	_
models	_	_
struggle	_	_
to	_	_
define	_	_
the	_	_
class	_	_
boundary	_	_
properly	_	_
during	_	_
segmentation	_	_
tasks	_	_
[	_	_
64	_	_
]	_	_
.	_	_

#303
However	_	_
,	_	_
if	_	_
we	_	_
observe	_	_
the	_	_
experimental	_	_
outputs	_	_
shown	_	_
in	_	_
Fig.	_	_
20	_	_
,	_	_
the	_	_
outputs	_	_
in	_	_
the	_	_
third	_	_
column	_	_
show	_	_
different	_	_
hit	_	_
maps	_	_
on	_	_
the	_	_
border	_	_
,	_	_
which	_	_
can	_	_
be	_	_
used	_	_
to	_	_
define	_	_
the	_	_
boundary	_	_
of	_	_
the	_	_
lung	_	_
region	_	_
,	_	_
while	_	_
the	_	_
ground	_	_
truth	_	_
tends	_	_
to	_	_
have	_	_
a	_	_
smooth	_	_
boundary	_	_
.	_	_

#304
In	_	_
addition	_	_
,	_	_
if	_	_
we	_	_
observe	_	_
the	_	_
input	_	_
,	_	_
ground	_	_
truth	_	_
,	_	_
and	_	_
output	_	_
of	_	_
this	_	_
proposed	_	_
approaches	_	_
in	_	_
the	_	_
second	_	_
row	_	_
,	_	_
it	_	_
can	_	_
be	_	_
observed	_	_
that	_	_
the	_	_
output	_	_
of	_	_
the	_	_
proposed	_	_
approaches	_	_
shows	_	_
better	_	_
segmentation	_	_
with	_	_
appropriate	_	_
contour	_	_
.	_	_

#305
The	_	_
ROC	_	_
with	_	_
AUCs	_	_
are	_	_
shown	_	_
Fig.	_	_
21	_	_
.	_	_

#306
The	_	_
highest	_	_
AUC	_	_
is	_	_
achieved	_	_
with	_	_
the	_	_
proposed	_	_
approach	_	_
of	_	_
R2U-Net	_	_
with	_	_
t=3	_	_
.	_	_

#307
D.	_	_
Evaluation	_	_
Most	_	_
of	_	_
the	_	_
cases	_	_
,	_	_
the	_	_
networks	_	_
are	_	_
evaluated	_	_
for	_	_
different	_	_
segmentation	_	_
tasks	_	_
with	_	_
following	_	_
architectures	_	_
:	_	_
1ÔÉ†64ÔÉ†128ÔÉ†256ÔÉ†512ÔÉ†256	_	_
ÔÉ†	_	_
128ÔÉ†64ÔÉ†1	_	_
that	_	_
require	_	_
4.2M	_	_
network	_	_
parameters	_	_
and	_	_
1ÔÉ†64ÔÉ†128ÔÉ†256ÔÉ†512ÔÉ†256	_	_
ÔÉ†	_	_
128ÔÉ†64ÔÉ†1	_	_
,	_	_
which	_	_
require	_	_
about	_	_
8.5M	_	_
network	_	_
parameters	_	_
respectively	_	_
.	_	_

#308
However	_	_
,	_	_
we	_	_
also	_	_
experimented	_	_
with	_	_
U-Net	_	_
,	_	_
ResU-Net	_	_
,	_	_
RU-Net	_	_
,	_	_
and	_	_
R2U-Net	_	_
models	_	_
with	_	_
following	_	_
structure	_	_
:	_	_
1ÔÉ†16ÔÉ†32ÔÉ†64ÔÉ†128ÔÉ†64	_	_
ÔÉ†	_	_
32ÔÉ†16ÔÉ†1	_	_
.	_	_

#309
In	_	_
this	_	_
case	_	_
we	_	_
used	_	_
a	_	_
time-step	_	_
of	_	_
t=3	_	_
,	_	_
which	_	_
refers	_	_
to	_	_
one	_	_
forward	_	_
convolution	_	_
layer	_	_
followed	_	_
by	_	_
three	_	_
subsequent	_	_
recurrent	_	_
convolutional	_	_
layers	_	_
.	_	_

#310
This	_	_
network	_	_
was	_	_
tested	_	_
on	_	_
skin	_	_
and	_	_
lung	_	_
lesion	_	_
segmentation	_	_
.	_	_

#311
Though	_	_
the	_	_
number	_	_
of	_	_
network	_	_
parameters	_	_
increase	_	_
little	_	_
bit	_	_
with	_	_
respect	_	_
to	_	_
the	_	_
time-step	_	_
in	_	_
the	_	_
recurrent	_	_
convolution	_	_
layer	_	_
,	_	_
further	_	_
improved	_	_
performance	_	_
can	_	_
be	_	_
clearly	_	_
seen	_	_
in	_	_
the	_	_
last	_	_
rows	_	_
of	_	_
Table	_	_
II	_	_
and	_	_
III	_	_
.	_	_

#312
Furthermore	_	_
,	_	_
we	_	_
have	_	_
evaluated	_	_
both	_	_
of	_	_
the	_	_
proposed	_	_
models	_	_
for	_	_
patch-based	_	_
modeling	_	_
on	_	_
retina	_	_
blood	_	_
vessel	_	_
segmentation	_	_
and	_	_
end-to-end	_	_
image-based	_	_
methods	_	_
for	_	_
skin	_	_
and	_	_
lung	_	_
lesion	_	_
segmentation	_	_
.	_	_

#313
In	_	_
both	_	_
cases	_	_
,	_	_
the	_	_
proposed	_	_
models	_	_
outperform	_	_
existing	_	_
state-of-the-art	_	_
methods	_	_
including	_	_
ResU-Net	_	_
and	_	_
U-Net	_	_
in	_	_
terms	_	_
of	_	_
AUC	_	_
and	_	_
accuracy	_	_
on	_	_
all	_	_
three	_	_
datasets	_	_
.	_	_

#314
The	_	_
network	_	_
architectures	_	_
with	_	_
different	_	_
numbers	_	_
of	_	_
network	_	_
parameters	_	_
with	_	_
respect	_	_
to	_	_
the	_	_
different	_	_
time-step	_	_
are	_	_
shown	_	_
in	_	_
Table	_	_
IV	_	_
.	_	_

#315
The	_	_
processing	_	_
times	_	_
during	_	_
the	_	_
testing	_	_
phase	_	_
for	_	_
the	_	_
STARE	_	_
,	_	_
CHASE_DB	_	_
,	_	_
and	_	_
DRIVE	_	_
datasets	_	_
were	_	_
6.42	_	_
,	_	_
8.66	_	_
,	_	_
and	_	_
2.84	_	_
seconds	_	_
per	_	_
sample	_	_
respectively	_	_
.	_	_

#316
In	_	_
addition	_	_
,	_	_
skin	_	_
cancer	_	_
segmentation	_	_
and	_	_
lung	_	_
segmentation	_	_
take	_	_
0.22	_	_
and	_	_
1.145	_	_
seconds	_	_
per	_	_
sample	_	_
respectively	_	_
.	_	_

#317
TABLE	_	_
IV	_	_
.	_	_

#318
ARCHITECTURE	_	_
AND	_	_
NUMBER	_	_
OF	_	_
NETWORK	_	_
PARAMETERS	_	_
.	_	_

#319
t	_	_
Network	_	_
architectures	_	_
Number	_	_
of	_	_
parameters	_	_
(	_	_
million	_	_
)	_	_
2	_	_
1-	_	_
>	_	_
16-	_	_
>	_	_
32-	_	_
>	_	_
64	_	_
>	_	_
128-	_	_
>	_	_
64	_	_
‚Äì	_	_
>	_	_
32	_	_
>	_	_
16	_	_
>	_	_
1	_	_
0.845	_	_
3	_	_
1-	_	_
>	_	_
16-	_	_
>	_	_
32-	_	_
>	_	_
64	_	_
>	_	_
128-	_	_
>	_	_
64	_	_
‚Äì	_	_
>	_	_
32	_	_
>	_	_
16	_	_
>	_	_
1	_	_
1.037	_	_
TABLE	_	_
III	_	_
.	_	_

#320
EXPERIMENTAL	_	_
OUTPUTS	_	_
OF	_	_
PROPOSED	_	_
MODELS	_	_
OF	_	_
RU-NET	_	_
AND	_	_
R2U-NET	_	_
FOR	_	_
LUNG	_	_
SEGMENTATION	_	_
AND	_	_
COMPARISON	_	_
AGAINST	_	_
RESU-NET	_	_
AND	_	_
U-NET	_	_
MODELS	_	_
.	_	_

#321
Methods	_	_
Year	_	_
SE	_	_
SP	_	_
JSC	_	_
F1-Score	_	_
AC	_	_
AUC	_	_
U-Net	_	_
(	_	_
t=2	_	_
)	_	_
2018	_	_
0.9696	_	_
0.9872	_	_
0.9858	_	_
0.9658	_	_
0.9828	_	_
0.9784	_	_
ResU-Net	_	_
(	_	_
t=2	_	_
)	_	_
2018	_	_
0.9555	_	_
0.9945	_	_
0.9850	_	_
0.9690	_	_
0.9849	_	_
0.9750	_	_
RU-Net	_	_
(	_	_
t=2	_	_
)	_	_
2018	_	_
0.9734	_	_
0.9866	_	_
0.9836	_	_
0.9638	_	_
0.9836	_	_
0.9800	_	_
R2U-Net	_	_
(	_	_
t=2	_	_
)	_	_
2018	_	_
0.9826	_	_
0.9918	_	_
0.9897	_	_
0.9780	_	_
0.9897	_	_
0.9872	_	_
R2U-Net	_	_
(	_	_
t=3	_	_
)	_	_
2018	_	_
0.9832	_	_
0.9944	_	_
0.9918	_	_
0.9823	_	_
0.9918	_	_
0.9889	_	_
Fig.	_	_
20	_	_
.	_	_

#322
Qualitative	_	_
assessment	_	_
of	_	_
R2U-Net	_	_
performance	_	_
on	_	_
Lung	_	_
segmentation	_	_
dataset	_	_
:	_	_
first	_	_
column	_	_
input	_	_
images	_	_
,	_	_
second	_	_
column	_	_
ground	_	_
truth	_	_
,	_	_
and	_	_
third	_	_
column	_	_
outputs	_	_
with	_	_
R2U-Net	_	_
.	_	_

#323
E.	_	_
Computational	_	_
time	_	_
The	_	_
computational	_	_
time	_	_
for	_	_
testing	_	_
per	_	_
sample	_	_
is	_	_
shown	_	_
in	_	_
Table	_	_
V	_	_
for	_	_
blood	_	_
vessel	_	_
segmentation	_	_
for	_	_
retina	_	_
images	_	_
,	_	_
skin	_	_
cancer	_	_
,	_	_
and	_	_
lung	_	_
segmentation	_	_
respectively	_	_
.	_	_

#324
TABLE	_	_
V.	_	_
COMPUTATIONAL	_	_
TIME	_	_
FOR	_	_
TESTING	_	_
PHASE	_	_
.	_	_

#325
Dataset	_	_
Time	_	_
(	_	_
Sec	_	_
.	_	_

#326
)	_	_
/	_	_
sample	_	_
Blood	_	_
vessel	_	_
segmentation	_	_
DRIVE	_	_
6.42	_	_
STARE	_	_
8.66	_	_
CHASE_DB1	_	_
2.84	_	_
Skin	_	_
cancer	_	_
segmentation	_	_
0.22	_	_
Lung	_	_
segmentation	_	_
1.15	_	_
V.	_	_
CONCLUSION	_	_
AND	_	_
FUTURE	_	_
WORKS	_	_
In	_	_
this	_	_
paper	_	_
,	_	_
we	_	_
proposed	_	_
an	_	_
extension	_	_
of	_	_
the	_	_
U-Net	_	_
architecture	_	_
using	_	_
Recurrent	_	_
Convolutional	_	_
Neural	_	_
Networks	_	_
and	_	_
Recurrent	_	_
Residual	_	_
Convolutional	_	_
Neural	_	_
Networks	_	_
.	_	_

#327
The	_	_
proposed	_	_
models	_	_
are	_	_
called	_	_
‚ÄúRU-Net‚Äù	_	_
and	_	_
‚ÄúR2U-Net‚Äù	_	_
respectively	_	_
.	_	_

#328
These	_	_
models	_	_
were	_	_
evaluated	_	_
using	_	_
three	_	_
different	_	_
applications	_	_
in	_	_
the	_	_
field	_	_
of	_	_
medical	_	_
imaging	_	_
including	_	_
retina	_	_
blood	_	_
vessel	_	_
segmentation	_	_
,	_	_
skin	_	_
cancer	_	_
lesion	_	_
segmentation	_	_
,	_	_
and	_	_
lung	_	_
segmentation	_	_
.	_	_

#329
The	_	_
experimental	_	_
results	_	_
demonstrate	_	_
that	_	_
the	_	_
proposed	_	_
RU-Net	_	_
,	_	_
and	_	_
R2U-Net	_	_
models	_	_
show	_	_
better	_	_
performance	_	_
in	_	_
segmentation	_	_
tasks	_	_
with	_	_
the	_	_
same	_	_
number	_	_
of	_	_
network	_	_
parameters	_	_
when	_	_
compared	_	_
to	_	_
existing	_	_
methods	_	_
including	_	_
the	_	_
U-Net	_	_
and	_	_
residual	_	_
U-Net	_	_
(	_	_
or	_	_
ResU-Net	_	_
)	_	_
models	_	_
on	_	_
all	_	_
three	_	_
datasets	_	_
.	_	_

#330
In	_	_
addition	_	_
,	_	_
results	_	_
show	_	_
that	_	_
these	_	_
proposed	_	_
models	_	_
not	_	_
only	_	_
ensure	_	_
better	_	_
performance	_	_
during	_	_
the	_	_
training	_	_
but	_	_
also	_	_
in	_	_
testing	_	_
phase	_	_
.	_	_

#331
In	_	_
future	_	_
,	_	_
we	_	_
would	_	_
like	_	_
to	_	_
explore	_	_
the	_	_
same	_	_
architecture	_	_
with	_	_
a	_	_
novel	_	_
feature	_	_
fusion	_	_
strategy	_	_
from	_	_
encoding	_	_
to	_	_
the	_	_
decoding	_	_
units	_	_
.	_	_

#332
Fig.	_	_
21	_	_
.	_	_

#333
ROC	_	_
curve	_	_
for	_	_
lung	_	_
segmentation	_	_
four	_	_
models	_	_
with	_	_
t=2	_	_
and	_	_
t=3	_	_
.	_	_