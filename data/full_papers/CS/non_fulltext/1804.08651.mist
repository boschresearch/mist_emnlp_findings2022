#0
RENDITION	_	_
:	_	_
RECLAIMING	_	_
WHAT	_	_
A	_	_
BLACK	_	_
BOX	_	_
TAKES	_	_
AWAY	_	_
PEYMAN	_	_
MILANFAR	_	_
GOOGLE	_	_
RESEARCH	_	_
Abstract	_	_
.	_	_

#1
The	_	_
premise	_	_
of	_	_
our	_	_
work	_	_
is	_	_
deceptively	_	_
familiar	_	_
:	_	_
A	_	_
black	_	_
box	_	_
f	_	_
(	_	_
·	_	_
)	_	_
has	_	_
altered	_	_
an	_	_
image	_	_
x→	_	_
f	_	_
(	_	_
x	_	_
)	_	_
.	_	_

#2
Recover	_	_
the	_	_
image	_	_
x	_	_
.	_	_

#3
This	_	_
black	_	_
box	_	_
might	options	_
be	_	_
any	_	_
number	_	_
of	_	_
simple	_	_
or	_	_
complicated	_	_
things	_	_
:	_	_
a	_	_
linear	_	_
or	_	_
non-linear	_	_
filter	_	_
,	_	_
some	_	_
app	_	_
on	_	_
your	_	_
phone	_	_
,	_	_
etc	_	_
.	_	_

#4
The	_	_
latter	_	_
is	_	_
a	_	_
good	_	_
canonical	_	_
example	_	_
for	_	_
the	_	_
problem	_	_
we	_	_
address	_	_
:	_	_
Given	_	_
only	_	_
“the	_	_
app”	_	_
and	_	_
an	_	_
image	_	_
produced	_	_
by	_	_
the	_	_
app	_	_
,	_	_
find	_	_
the	_	_
image	_	_
that	_	_
was	_	_
fed	_	_
to	_	_
the	_	_
app	_	_
.	_	_

#5
You	_	_
can	_	_
run	_	_
the	_	_
given	_	_
image	_	_
(	_	_
or	_	_
any	_	_
other	_	_
image	_	_
)	_	_
through	_	_
the	_	_
app	_	_
as	_	_
many	_	_
times	_	_
as	_	_
you	_	_
like	_	_
,	_	_
but	_	_
you	_	_
can	_	_
not	_	_
look	_	_
inside	_	_
the	_	_
(	_	_
code	_	_
for	_	_
the	_	_
)	_	_
app	_	_
to	_	_
see	_	_
how	_	_
it	_	_
works	_	_

#6
At	_	_
first	_	_
blush	_	_
,	_	_
the	_	_
problem	_	_
sounds	_	_
a	_	_
lot	_	_
like	_	_
a	_	_
standard	_	_
inverse	_	_
problem	_	_
[	_	_
14	_	_
,	_	_
17	_	_
]	_	_
,	_	_
but	_	_
it	_	_
is	_	_
not	_	_
in	_	_
the	_	_
following	_	_
sense	_	_
:	_	_
While	_	_
we	_	_
have	_	_
access	_	_
to	_	_
the	_	_
black	_	_
box	_	_
f	_	_
(	_	_
·	_	_
)	_	_
and	_	_
can	_	_
run	_	_
any	_	_
image	_	_
through	_	_
it	_	_
and	_	_
observe	_	_
the	_	_
output	_	_
,	_	_
we	_	_
do	_	_
not	_	_
know	_	_
how	_	_
the	_	_
block	_	_
box	_	_
alters	_	_
the	_	_
image	_	_
.	_	_

#7
Therefore	_	_
we	_	_
have	_	_
no	_	_
explicit	_	_
form	_	_
or	_	_
model	_	_
of	_	_
f	_	_
(	_	_
·	_	_
)	_	_
.	_	_

#8
Nor	_	_
are	_	_
we	_	_
necessarily	_	_
interested	_	_
in	_	_
the	_	_
internal	_	_
workings	_	_
of	_	_
the	_	_
black	_	_
box	_	_
.	_	_

#9
We	_	_
are	_	_
simply	_	_
happy	_	_
to	_	_
reverse	_	_
its	_	_
effect	_	_
on	_	_
a	_	_
particular	_	_
image	_	_
,	_	_
to	_	_
whatver	_	_
extent	_	_
possible	_	_
.	_	_

#10
This	_	_
is	_	_
what	_	_
we	_	_
call	_	_
the	_	_
“rendition”	_	_
(	_	_
rather	_	_
than	_	_
restoration	_	_
)	_	_
problem	_	_
,	_	_
as	_	_
it	_	_
does	_	_
not	_	_
fit	_	_
the	_	_
mold	_	_
of	_	_
an	_	_
inverse	_	_
problem	_	_
(	_	_
blind	_	_
or	_	_
otherwise	_	_
)	_	_
.	_	_

#11
We	_	_
describe	_	_
general	_	_
conditions	_	_
under	_	_
which	_	_
this	_	_
rendition	_	_
is	_	_
possible	_	_
,	_	_
and	_	_
provide	_	_
a	_	_
remarkably	_	_
simple	_	_
algorithm	_	_
that	_	_
works	_	_
for	_	_
both	_	_
contractive	_	_
and	_	_
expansive	_	_
black	_	_
box	_	_
operators	_	_
.	_	_

#12
The	_	_
principal	_	_
and	_	_
novel	_	_
take-away	_	_
message	_	_
from	_	_
our	_	_
work	_	_
is	_	_
this	_	_
surprising	_	_
fact	_	_
:	_	_
One	_	_
simple	_	_
algorithm	_	_
can	_	_
reliably	_	_
undo	_	_
a	_	_
wide	_	_
class	_	_
of	_	_
(	_	_
not	_	_
too	_	_
violent	_	_
)	_	_
image	_	_
distortions	_	_
.	_	_

#13
1	_	_
.	_	_

#14
Introduction	_	_
.	_	_

#15
Let’s	_	_
consider	_	_
an	_	_
image1	_	_
x∗	_	_
that	_	_
has	_	_
been	_	_
transformed	_	_
to	_	_
another	_	_
image	_	_
f	_	_
(	_	_
x∗	_	_
)	_	_
by	_	_
an	_	_
operator	_	_
f	_	_
:	_	_
[	_	_
0	_	_
,	_	_
1	_	_
]	_	_
N	_	_
→	_	_
[	_	_
0	_	_
,	_	_
1	_	_
]	_	_
N	_	_
that	_	_
can	_	_
be	_	_
evaluated	_	_
,	_	_
but	_	_
is	_	_
otherwise	_	_
not	_	_
known	_	_
,	_	_
specified	_	_
parametrically	_	_
,	_	_
or	_	_
otherwise	_	_
.	_	_

#16
The	_	_
problem	_	_
at	_	_
hand	_	_
is	_	_
this	_	_
:	_	_
Given	_	_
f	_	_
(	_	_
x∗	_	_
)	_	_
,	_	_
render	_	_
an	_	_
approximation	_	_
to	_	_
x∗	_	_
.	_	_

#17
A	_	_
general	_	_
approach	_	_
to	_	_
this	_	_
problem	_	_
is	_	_
brute	_	_
force	_	_
learning	_	_
or	_	_
high-dimensional	_	_
regression	_	_
:	_	_
since	_	_
we	_	_
have	_	_
free	_	_
access	_	_
to	_	_
the	_	_
black	_	_
box	_	_
f	_	_
(	_	_
·	_	_
)	_	_
,	_	_
we	_	_
can	_	_
push	_	_
many	_	_
images	_	_
through	_	_
it	_	_
,	_	_
collect	_	_
the	_	_
pairs	_	_
(	_	_
xi	_	_
,	_	_
f	_	_
(	_	_
xi	_	_
)	_	_
)	_	_
,	_	_
and	_	_
build	_	_
a	_	_
(	_	_
possibly	_	_
deep	_	_
)	_	_
model	_	_
that	_	_
is	_	_
sophisiticated	_	_
enough	_	_
to	_	_
generalize	_	_
and	_	_
render	_	_
any	_	_
input	_	_
with	_	_
high	_	_
accuracy	_	_
,	_	_
given	_	_
an	_	_
output	_	_
not	_	_
seen	_	_
before	_	_
.	_	_

#18
This	_	_
approach	_	_
has	_	_
been	_	_
tried	_	_
in	_	_
[	_	_
8	_	_
]	_	_
,	_	_
but	_	_
for	_	_
a	_	_
very	_	_
limited	_	_
use	_	_
case	_	_
of	_	_
restoring	_	_
a	_	_
portrait	_	_
image	_	_
from	_	_
unknown	_	_
global	_	_
operations	_	_
on	_	_
human	_	_
faces	_	_
.	_	_

#19
They	_	_
only	_	_
tackled	_	_
the	_	_
two	_	_
issues	_	_
of	_	_
skin	_	_
smoothing	_	_
and	_	_
skin	_	_
color	_	_
change	_	_
.	_	_

#20
We	_	_
choose	_	_
to	_	_
be	_	_
much	_	_
more	_	_
general	_	_
,	_	_
and	_	_
through	_	_
a	_	_
series	_	_
of	_	_
approximations	_	_
arrive	_	_
at	_	_
a	_	_
simple	_	_
solution	_	_
that	_	_
is	_	_
very	_	_
generally	_	_
applicable	_	_
.	_	_

#21
A	_	_
more	_	_
obvious	_	_
and	_	_
direct	_	_
approach	_	_
to	_	_
this	_	_
problem	_	_
would	_	_
be	_	_
to	_	_
find	_	_
the	_	_
inverse	_	_
function	_	_
f−1	_	_
(	_	_
f	_	_
(	_	_
x∗	_	_
)	_	_
)	_	_
.	_	_

#22
This	_	_
may	_	_
look	_	_
simple	_	_
,	_	_
but	_	_
it	_	_
is	_	_
not	_	_
easy	_	_
for	_	_
several	_	_
reasons	_	_
.	_	_

#23
First	_	_
,	_	_
we	_	_
remind	_	_
the	_	_
reader	_	_
that	_	_
direct	_	_
inversion	_	_
is	_	_
a	_	_
luxury	_	_
we	_	_
do	_	_
not	_	_
enjoy	_	_
since	_	_
we	_	_
do	_	_
not	_	_
have	_	_
an	_	_
explicit	_	_
description	_	_
of	_	_
f	_	_
.	_	_

#24
All	_	_
we	_	_
are	_	_
allowed	_	_
to	_	_
do	_	_
is	_	_
to	_	_
evaluate	_	_
f	_	_
(	_	_
·	_	_
)	_	_
in	_	_
the	_	_
“forward”	_	_
direction	_	_
.	_	_

#25
Second	_	_
,	_	_
it	_	_
is	_	_
far	_	_
from	_	_
clear	_	_
whether	_	_
the	_	_
inverse	_	_
of	_	_
such	_	_
a	_	_
black	_	_
box	_	_
even	_	_
exists	_	_
–	_	_
especially	_	_
,	_	_
one	_	_
that	_	_
alters	_	_
information	_	_
or	_	_
frequency	_	_
content	_	_
(	_	_
e.g.	_	_
blurring	_	_
or	_	_
sharpening	_	_
)	_	_
.	_	_

#26
In	_	_
the	_	_
standard	_	_
literature	_	_
on	_	_
inverse	_	_
problems	_	_
,	_	_
two	_	_
additional	_	_
conditions	_	_
provide	_	_
a	_	_
framework	_	_
that	_	_
makes	_	_
the	_	_
problem	_	_
more	_	_
tractable	_	_
:	_	_
First	_	_
,	_	_
the	_	_
“forward”	_	_
operator	_	_
f	_	_
(	_	_
x	_	_
)	_	_
is	_	_
explicitly	_	_
specified	_	_
(	_	_
with	_	_
perhaps	_	_
some	_	_
unknown	_	_
parameters	_	_
)	_	_
.	_	_

#27
It	_	_
is	_	_
generally	_	_
a	_	_
known	_	_
physical	_	_
model	_	_
,	_	_
or	_	_
a	_	_
filter	_	_
with	_	_
known	_	_
structure	_	_
(	_	_
e.g.	_	_
blind	_	_
or	_	_
non-blind	_	_
blur	_	_
,	_	_
whether	_	_
spatially	_	_
varying	_	_
or	_	_
spatially	_	_
invariant	_	_
)	_	_
.	_	_

#28
And	_	_
second	_	_
,	_	_
prior	_	_
information	_	_
in	_	_
the	_	_
form	_	_
of	_	_
a	_	_
probability	_	_
density	_	_
p	_	_
(	_	_
x	_	_
)	_	_
on	_	_
the	_	_
likely	_	_
class	_	_
of	_	_
input	_	_
images	_	_
is	_	_
assumed	_	_
to	_	_
be	_	_
given	_	_
.	_	_

#29
In	_	_
our	_	_
present	_	_
treatment	_	_
,	_	_
we	_	_
do	_	_
not	_	_
assume	_	_
either	_	_
of	_	_
these	_	_
conditions	_	_
,	_	_
1Lexicographically	_	_
scanned	_	_
into	_	_
a	_	_
vector	_	_
of	_	_
length	_	_
N	_	_
ar	_	_
X	_	_
iv	_	_
:1	_	_
4	_	_
.	_	_

#30
1v	_	_
1	_	_
[	_	_
cs	_	_
.C	_	_
V	_	_
]	_	_
2	_	_
3	_	_
A	_	_
pr	_	_
2	_	_
Fig.	_	_
1	_	_
.	_	_

#31
A	_	_
one	_	_
dimensional	_	_
example	_	_
of	_	_
rendition	_	_
:	_	_
the	_	_
blue	_	_
curve	_	_
is	_	_
the	_	_
underlying	_	_
signal	_	_
x∗	_	_
,	_	_
and	_	_
the	_	_
red	_	_
solid	_	_
line	_	_
is	_	_
the	_	_
distorted	_	_
version	_	_
f	_	_
(	_	_
x∗	_	_
)	_	_
computed	_	_
by	_	_
applying	_	_
a	_	_
bilateral	_	_
filter	_	_
to	_	_
x∗	_	_
.	_	_

#32
The	_	_
dashed	_	_
red	_	_
line	_	_
illustrates	_	_
the	_	_
rendition	_	_
.	_	_

#33
but	_	_
their	_	_
inclusion	_	_
can	_	_
be	_	_
the	_	_
subject	_	_
of	_	_
future	_	_
investigations	_	_
.	_	_

#34
Instead	_	_
,	_	_
we	_	_
will	_	_
specify	_	_
conditions	_	_
under	_	_
which	_	_
we	_	_
can	_	_
render	_	_
a	_	_
solution	_	_
x̂	_	_
≈	_	_
x∗	_	_
with	_	_
only	_	_
access	_	_
to	_	_
“evaluation”	_	_
of	_	_
a	_	_
black	_	_
box	_	_
operator	_	_
f	_	_
(	_	_
x	_	_
)	_	_
.	_	_

#35
Examples	_	_
of	_	_
use	_	_
cases	_	_
that	_	_
fit	_	_
our	_	_
approach	_	_
in	_	_
practice	_	_
are	_	_
common	_	_
and	_	_
numerous	_	_
,	_	_
though	_	_
interestingly	_	_
they	_	_
have	_	_
not	_	_
been	_	_
treated	_	_
widely	_	_
in	_	_
the	_	_
literature	_	_
.	_	_

#36
One	_	_
area	_	_
of	_	_
increasing	_	_
importance	_	_
is	_	_
mobile	_	_
photography	_	_
and	_	_
photo	_	_
editing	_	_
applications	_	_
(	_	_
i.e.	_	_
apps	_	_
)	_	_
.	_	_

#37
Photoshop	_	_
and	_	_
Lightroom	_	_
have	_	_
been	_	_
around	_	_
for	_	_
a	_	_
long	_	_
time	_	_
,	_	_
but	_	_
their	_	_
use	_	_
was	_	_
largely	_	_
limited	_	_
to	_	_
(	_	_
semi-	_	_
)	_	_
professional	_	_
photographers	_	_
and	_	_
enthusiasts	_	_
who	_	_
could	_	_
afford	_	_
expensive	_	_
gear	_	_
and	_	_
post-processing	_	_
software	_	_
packages	_	_
.	_	_

#38
Nowadays	_	_
,	_	_
many	_	_
cheap	_	_
or	_	_
free	_	_
mobile	_	_
apps	_	_
(	_	_
indeed	_	_
the	_	_
camera	_	_
apps	_	_
themselves	_	_
)	_	_
enable	_	_
users	_	_
to	_	_
edit	_	_
images	_	_
in	_	_
non-trivial	_	_
ways	_	_
.	_	_

#39
Both	_	_
the	_	_
users	_	_
themselves	_	_
and	_	_
the	_	_
recipients	_	_
of	_	_
these	_	_
processed	_	_
images	_	_
may	_	_
want	_	_
to	_	_
revert	_	_
at	_	_
least	_	_
some	_	_
of	_	_
these	_	_
effect	_	_
and	_	_
obtain	_	_
a	_	_
rendition	_	_
closer	_	_
to	_	_
the	_	_
original	_	_
.	_	_

#40
In	_	_
some	_	_
applications	_	_
this	_	_
functionality	_	_
is	_	_
enabled	_	_
by	_	_
saving	_	_
multiple	_	_
copies	_	_
of	_	_
the	_	_
image	_	_
(	_	_
the	_	_
original	_	_
and	_	_
the	_	_
processed	_	_
)	_	_
so	_	_
that	_	_
the	_	_
user	_	_
can	_	_
easily	_	_
revert	_	_
back	_	_
.	_	_

#41
Rendition	_	_
provides	_	_
an	_	_
approximate	_	_
(	_	_
but	_	_
storage	_	_
friendly	_	_
)	_	_
alternative	_	_
.	_	_

#42
Another	_	_
possible	_	_
area	_	_
of	_	_
interest	_	_
is	_	_
forensics	_	_
.	_	_

#43
In	_	_
security	_	_
,	_	_
law	_	_
enforcement	_	_
,	_	_
and	_	_
forensic	_	_
investigations	_	_
,	_	_
the	_	_
source	_	_
hardware	_	_
of	_	_
the	_	_
given	_	_
visual	_	_
material	_	_
may	_	_
be	_	_
inaccessible	_	_
directly	_	_
,	_	_
or	_	_
hidden	_	_
from	_	_
the	_	_
analyst	_	_
.	_	_

#44
For	_	_
instance	_	_
,	_	_
a	_	_
blurry	_	_
photo	_	_
of	_	_
a	_	_
scene	_	_
obtained	_	_
from	_	_
a	_	_
remote	_	_
security	_	_
camera	_	_
may	_	_
be	_	_
available	_	_
,	_	_
where	_	_
neither	_	_
the	_	_
make	_	_
nor	_	_
the	_	_
parameters	_	_
of	_	_
the	_	_
camera	_	_
are	_	_
known	_	_
.	_	_

#45
While	_	_
it	_	_
may	_	_
be	_	_
possible	_	_
to	_	_
render	_	_
additional	_	_
images	_	_
from	_	_
the	_	_
sensor	_	_
,	_	_
and	_	_
even	_	_
have	_	_
a	_	_
software	_	_
application	_	_
that	_	_
mimics	_	_
the	_	_
sensor	_	_
,	_	_
the	_	_
operator	_	_
is	_	_
interested	_	_
to	_	_
render	_	_
an	_	_
approximation	_	_
to	_	_
the	_	_
original	_	_
scene	_	_
without	_	_
any	_	_
specific	_	_
knowledge	_	_
of	_	_
the	_	_
camera	_	_
.	_	_

#46
To	_	_
be	_	_
more	_	_
general	_	_
,	_	_
in	_	_
the	_	_
context	_	_
of	_	_
our	_	_
approach	_	_
,	_	_
the	_	_
idea	_	_
is	_	_
that	_	_
given	_	_
any	_	_
accessible	_	_
“forward”	_	_
simulation	_	_
of	_	_
the	_	_
process	_	_
that	_	_
leads	_	_
to	_	_
the	_	_
altered	_	_
image	_	_
,	_	_
we	_	_
can	_	_
render	_	_
an	_	_
approximation	_	_
to	_	_
the	_	_
original	_	_
image	_	_
of	_	_
the	_	_
scene	_	_
.	_	_

#47
To	_	_
afford	_	_
some	_	_
intuition	_	_
,	_	_
we	_	_
present	_	_
a	_	_
one-dimensional	_	_
example	_	_
of	_	_
rendition	_	_
shown	_	_
in	_	_
Fig.	_	_
1	_	_
.	_	_

#48
In	_	_
this	_	_
example	_	_
,	_	_
the	_	_
blue	_	_
curve	_	_
is	_	_
the	_	_
underlying	_	_
signal	_	_
x∗	_	_
,	_	_
and	_	_
the	_	_
red	_	_
solid	_	_
line	_	_
is	_	_
the	_	_
distorted	_	_
version	_	_
f	_	_
(	_	_
x∗	_	_
)	_	_
given	_	_
by	_	_
applying	_	_
a	_	_
non-linear	_	_
edge-preserving	_	_
(	_	_
bilateral	_	_
)	_	_
filter	_	_
to	_	_
x∗	_	_
.	_	_

#49
The	_	_
dashed	_	_
red	_	_
line	_	_
illustrates	_	_
the	_	_
rendition	_	_
,	_	_
which	_	_
amounts	_	_
to	_	_
undoing	_	_
the	_	_
effect	_	_
of	_	_
the	_	_
bilateral	_	_
filter	_	_
.	_	_

#50
2	_	_
.	_	_

#51
Formulation	_	_
of	_	_
A	_	_
Loss	_	_
for	_	_
The	_	_
Rendition	_	_
Problem	_	_
.	_	_

#52
To	_	_
render	_	_
an	_	_
input	_	_
image	_	_
given	_	_
an	_	_
output	_	_
,	_	_
we	_	_
proceed	_	_
by	_	_
defining	_	_
a	_	_
loss	_	_
function	_	_
that	_	_
takes	_	_
advantage	_	_
of	_	_
correlations	_	_
between	_	_
the	_	_
inputs	_	_
x	_	_
,	_	_
the	_	_
outputs	_	_
f	_	_
(	_	_
x	_	_
)	_	_
,	_	_
and	_	_
the	_	_
respective	_	_
residuals	_	_
.	_	_

#53
Let’s	_	_
define	_	_
the	_	_
(	_	_
observable	_	_
)	_	_
residuals	_	_
as	_	_
follows	_	_
:	_	_
(	_	_
2.1	_	_
)	_	_
r	_	_
=	_	_
f	_	_
(	_	_
x	_	_
)	_	_
−	_	_
f	_	_
(	_	_
x∗	_	_
)	_	_
,	_	_
and	_	_
consider	_	_
the	_	_
(	_	_
cross-	_	_
)	_	_
correlation	_	_
function	_	_
(	_	_
2.2	_	_
)	_	_
c	_	_
(	_	_
x	_	_
,	_	_
x∗	_	_
)	_	_
=	_	_
xT	_	_
r	_	_
=	_	_
xT	_	_
(	_	_
f	_	_
(	_	_
x	_	_
)	_	_
−	_	_
f	_	_
(	_	_
x∗	_	_
)	_	_
)	_	_
.	_	_

#54
This	_	_
loss	_	_
function	_	_
on	_	_
its	_	_
own	_	_
is	_	_
not	_	_
powerful	_	_
enough	_	_
to	_	_
give	_	_
a	_	_
reliable	_	_
solution	_	_
because	_	_
there	_	_
are	_	_
at	_	_
least	_	_
three	_	_
ways	_	_
in	_	_
which	_	_
it	_	_
could	_	_
be	_	_
driven	_	_
to	_	_
zero	_	_
:	_	_
•	_	_
If	_	_
x	_	_
=	_	_
0	_	_
.	_	_

#55
This	_	_
is	_	_
a	_	_
degenerate	_	_
and	_	_
undesirable	_	_
solution	_	_
which	_	_
we	_	_
should	_	_
like	_	_
to	_	_
avoid	_	_
.	_	_

#56
•	_	_
If	_	_
the	_	_
residual	_	_
is	_	_
zero	_	_
.	_	_

#57
This	_	_
would	_	_
imply	_	_
that	_	_
we	_	_
are	_	_
at	_	_
a	_	_
solution	_	_
of	_	_
the	_	_
equation	_	_
f	_	_
(	_	_
x	_	_
)	_	_
=	_	_
f	_	_
(	_	_
x∗	_	_
)	_	_
,	_	_
which	_	_
under	_	_
some	_	_
regularity	_	_
conditions	_	_
may	_	_
imply	_	_
that	_	_
x	_	_
is	_	_
near	_	_
x∗	_	_
.	_	_

#58
And	_	_
finally	_	_
,	_	_
•	_	_
If	_	_
the	_	_
residual	_	_
is	_	_
orthogonal	_	_
to	_	_
the	_	_
input	_	_
–	_	_
a	_	_
feature	_	_
that	_	_
implies	_	_
that	_	_
the	_	_
residual	_	_
behaves	_	_
either	_	_
like	_	_
white	_	_
noise	_	_
,	_	_
or	_	_
it	_	_
does	_	_
not	_	_
contain	_	_
elements	_	_
from	_	_
the	_	_
image	_	_
itself	_	_
.	_	_

#59
The	_	_
concept	_	_
of	_	_
orthogonality	_	_
of	_	_
the	_	_
residual	_	_
to	_	_
the	_	_
signal	_	_
is	_	_
well-known	_	_
.	_	_

#60
It	_	_
has	_	_
been	_	_
harnessed	_	_
successfully	_	_
by	_	_
many	_	_
algorithms	_	_
such	_	_
as	_	_
the	_	_
Dantzig	_	_
Selector	_	_
[	_	_
5	_	_
]	_	_
,	_	_
boosting	_	_
techniques	_	_
for	_	_
denoising	_	_
[	_	_
6	_	_
,	_	_
19	_	_
,	_	_
22	_	_
,	_	_
28	_	_
,	_	_
13	_	_
]	_	_
,	_	_
etc	_	_
.	_	_

#61
Indeed	_	_
,	_	_
enforcing	_	_
orthogonality	_	_
between	_	_
the	_	_
signal	_	_
and	_	_
output	_	_
residual	_	_
is	_	_
the	_	_
underlying	_	_
force	_	_
behind	_	_
the	_	_
normal	_	_
equations	_	_
in	_	_
statistical	_	_
estimation	_	_
(	_	_
e.g.	_	_
,	_	_
least	_	_
squares	_	_
and	_	_
Kalman	_	_
filtering	_	_
)	_	_
.	_	_

#62
In	_	_
order	_	_
to	_	_
avoid	_	_
the	_	_
useless	_	_
trivial	_	_
solution	_	_
x	_	_
=	_	_
0	_	_
,	_	_
and	_	_
encourage	_	_
the	_	_
other	_	_
conditions	_	_
,	_	_
we	_	_
formulate	_	_
a	_	_
second	_	_
term	_	_
that	_	_
we	_	_
shall	_	_
attempt	_	_
to	_	_
maximize	_	_
(	_	_
2.3	_	_
)	_	_
a	_	_
(	_	_
x	_	_
)	_	_
=	_	_
xTx	_	_
.	_	_

#63
To	_	_
summarize	_	_
,	_	_
we	_	_
define	_	_
the	_	_
rendition	_	_
loss	_	_
as	_	_
the	_	_
composite	_	_
function	_	_
φ	_	_
(	_	_
x	_	_
)	_	_
=	_	_
c	_	_
(	_	_
x	_	_
,	_	_
x∗	_	_
)	_	_
−	_	_
a	_	_
(	_	_
x	_	_
)	_	_
=	_	_
xT	_	_
(	_	_
f	_	_
(	_	_
x	_	_
)	_	_
−	_	_
f	_	_
(	_	_
x∗	_	_
)	_	_
)	_	_
−	_	_
1	_	_
xTx	_	_
(	_	_
2.4	_	_
)	_	_
We	_	_
will	_	_
hence	_	_
attempt	_	_
to	_	_
solve	_	_
the	_	_
following	_	_
optimization	_	_
problem	_	_
:	_	_
(	_	_
2.5	_	_
)	_	_
min	_	_
x	_	_
φ	_	_
(	_	_
x	_	_
)	_	_
.	_	_

#64
Next	_	_
,	_	_
we	_	_
discuss	_	_
conditions	_	_
under	_	_
which	_	_
this	_	_
loss	_	_
yields	_	_
a	_	_
desired	_	_
result	_	_
,	_	_
and	_	_
give	_	_
an	_	_
iterative	_	_
algorithm	_	_
for	_	_
solving	_	_
the	_	_
rendition	_	_
problem	_	_
.	_	_

#65
As	_	_
a	_	_
preview	_	_
of	_	_
coming	_	_
attractions	_	_
,	_	_
we	_	_
will	_	_
show	_	_
that	_	_
quite	_	_
surprisingly	_	_
,	_	_
the	_	_
above	_	_
optimization	_	_
problem	_	_
can	_	_
be	_	_
addressed	_	_
with	_	_
a	_	_
very	_	_
simple	_	_
and	_	_
convergent	_	_
approximate	_	_
gradient	_	_
descent	_	_
iteration	_	_
as	_	_
long	_	_
as	_	_
the	_	_
operator	_	_
f	_	_
(	_	_
·	_	_
)	_	_
is	_	_
Lipschitz	_	_
continuous	_	_
(	_	_
but	_	_
not	_	_
necessarily	_	_
contractive	_	_
)	_	_
.	_	_

#66
The	_	_
iteration	_	_
furthermore	_	_
involves	_	_
only	_	_
the	_	_
residuals	_	_
as	_	_
follows	_	_
:	_	_
(	_	_
2.6	_	_
)	_	_
xk+1	_	_
=	_	_
βxk	_	_
−	_	_
γ	_	_
[	_	_
f	_	_
(	_	_
xk	_	_
)	_	_
−	_	_
f	_	_
(	_	_
x∗	_	_
)	_	_
]	_	_
This	_	_
solution	_	_
is	_	_
not	_	_
obvious	_	_
;	_	_
its	_	_
derivation	_	_
will	_	_
require	_	_
some	_	_
detailed	_	_
analysis	_	_
which	_	_
we	_	_
provide	_	_
in	_	_
the	_	_
next	_	_
sections	_	_
.	_	_

#67
3	_	_
.	_	_

#68
Solution	_	_
of	_	_
the	_	_
Rendition	_	_
Problem	_	_
.	_	_

#69
Let’s	_	_
for	_	_
the	_	_
moment	_	_
assume	_	_
that	_	_
f	_	_
(	_	_
x	_	_
)	_	_
is	_	_
differentiable	_	_
(	_	_
an	_	_
assumption	_	_
we	_	_
will	_	_
relax	_	_
shortly	_	_
)	_	_
.	_	_

#70
The	_	_
gradient	_	_
of	_	_
the	_	_
proposed	_	_
loss	_	_
is	_	_
:	_	_
∇φ	_	_
(	_	_
x	_	_
)	_	_
=	_	_
∇	_	_
(	_	_
xT	_	_
f	_	_
(	_	_
x	_	_
)	_	_
)	_	_
−	_	_
f	_	_
(	_	_
x∗	_	_
)	_	_
−	_	_
x	_	_
(	_	_
3.1	_	_
)	_	_
=	_	_
f	_	_
(	_	_
x	_	_
)	_	_
+∇f	_	_
(	_	_
x	_	_
)	_	_
T	_	_
·	_	_
x−	_	_
f	_	_
(	_	_
x∗	_	_
)	_	_
−	_	_
x	_	_
(	_	_
3.2	_	_
)	_	_
Remark	_	_
:	_	_
The	_	_
gradient	_	_
∇f	_	_
(	_	_
x	_	_
)	_	_
will	_	_
play	_	_
a	_	_
starring	_	_
role	_	_
in	_	_
the	_	_
rest	_	_
of	_	_
the	_	_
paper	_	_
,	_	_
so	_	_
it	_	_
is	_	_
important	_	_
to	_	_
discuss	_	_
its	_	_
properties	_	_
in	_	_
detail	_	_
here	_	_
.	_	_

#71
Most	_	_
operators	_	_
f	_	_
(	_	_
x	_	_
)	_	_
of	_	_
interest	_	_
are	_	_
a	_	_
combination	_	_
of	_	_
operations	_	_
that	_	_
are	_	_
either	_	_
pointwise	_	_
,	_	_
such	_	_
as	_	_
tone-mappers	_	_
or	_	_
color	_	_
transformations	_	_
;	_	_
or	_	_
pseudo-linear	_	_
,	_	_
such	_	_
as	_	_
the	_	_
bilateral	_	_
or	_	_
non-local	_	_
means	_	_
;	_	_
or	_	_
the	_	_
result	_	_
of	_	_
minimizing	_	_
a	_	_
particular	_	_
(	_	_
implicit	_	_
or	_	_
explicit	_	_
)	_	_
cost	_	_
function	_	_
.	_	_

#72
If	_	_
the	_	_
operator	_	_
f	_	_
(	_	_
x	_	_
)	_	_
acts	_	_
pointwise	_	_
on	_	_
x	_	_
,	_	_
then	_	_
the	_	_
gradient	_	_
∇f	_	_
(	_	_
x	_	_
)	_	_
is	_	_
a	_	_
diagonal	_	_
matrix	_	_
(	_	_
and	_	_
therefore	_	_
also	_	_
symmetric	_	_
.	_	_
)	_	_

#73
When	_	_
the	_	_
operator	_	_
is	_	_
implemented	_	_
in	_	_
pseudo-linear	_	_
form	_	_
f	_	_
(	_	_
x	_	_
)	_	_
=	_	_
W	_	_
(	_	_
x	_	_
)	_	_
x	_	_
,	_	_
the	_	_
weights	_	_
matrix	_	_
W	_	_
can	_	_
be	_	_
closely	_	_
approximated	_	_
by	_	_
a	_	_
symmetric	_	_
matrix	_	_
[	_	_
18	_	_
,	_	_
20	_	_
]	_	_
;	_	_
and	_	_
in	_	_
this	_	_
case	_	_
[	_	_
23	_	_
]	_	_
,	_	_
∇f	_	_
(	_	_
x	_	_
)	_	_
=	_	_
W	_	_
(	_	_
x	_	_
)	_	_
.	_	_

#74
More	_	_
generally	_	_
,	_	_
whenever	_	_
the	_	_
operator	_	_
can	_	_
be	_	_
written	_	_
as	_	_
the	_	_
gradient	_	_
of	_	_
some	_	_
scalar	_	_
loss	_	_
[	_	_
26	_	_
,	_	_
19	_	_
]	_	_
,	_	_
say	_	_
f	_	_
(	_	_
x	_	_
)	_	_
=	_	_
∇Θ	_	_
(	_	_
x	_	_
)	_	_
,	_	_
it	_	_
describes	_	_
a	_	_
conservative	_	_
(	_	_
or	_	_
curl-free	_	_
)	_	_
vector	_	_
field	_	_
.	_	_

#75
This	_	_
,	_	_
in	_	_
turn	_	_
,	_	_
means	_	_
that	_	_
the	_	_
gradient	_	_
∇f	_	_
(	_	_
x	_	_
)	_	_
=	_	_
∇2Θ	_	_
(	_	_
x	_	_
)	_	_
of	_	_
the	_	_
operator	_	_
,	_	_
being	_	_
the	_	_
Hessian	_	_
of	_	_
Θ	_	_
(	_	_
x	_	_
)	_	_
,	_	_
is	_	_
by	_	_
definition	_	_
a	_	_
symmetric	_	_
matrix	_	_
.	_	_

#76
Most	_	_
denoisers	_	_
,	_	_
regularizers	_	_
,	_	_
and	_	_
filters	_	_
built	_	_
upon	_	_
them	_	_
fall	_	_
into	_	_
this	_	_
category	_	_
[	_	_
19	_	_
,	_	_
23	_	_
]	_	_
;	_	_
as	_	_
do	_	_
proximal	_	_
operators	_	_
.	_	_

#77
The	_	_
latter	_	_
case	_	_
is	_	_
instructive	_	_
:	_	_
(	_	_
3.3	_	_
)	_	_
f	_	_
(	_	_
x	_	_
)	_	_
=	_	_
arg	_	_
min	_	_
u	_	_
‖u−	_	_
x‖2	_	_
+	_	_
α	_	_
θ	_	_
(	_	_
u	_	_
)	_	_
.	_	_

#78
We	_	_
can	_	_
compute	_	_
the	_	_
gradient	_	_
of	_	_
the	_	_
right-hand	_	_
side	_	_
,	_	_
solve	_	_
symbolically	_	_
for	_	_
f	_	_
(	_	_
x	_	_
)	_	_
,	_	_
and	_	_
approximate	_	_
for	_	_
small	_	_
α	_	_
(	_	_
i.e.	_	_
consistent	_	_
with	_	_
our	_	_
assumption	_	_
of	_	_
“gentle”	_	_
operators	_	_
)	_	_
:	_	_
f	_	_
(	_	_
x	_	_
)	_	_
=	_	_
(	_	_
I	_	_
+	_	_
α∇θ	_	_
)	_	_
−1	_	_
(	_	_
x	_	_
)	_	_
(	_	_
3.4	_	_
)	_	_
≈	_	_
x−	_	_
α∇θ	_	_
(	_	_
x	_	_
)	_	_
(	_	_
3.5	_	_
)	_	_
=	_	_
∇	_	_
[	_	_
xTx−	_	_
αθ	_	_
(	_	_
x	_	_
)	_	_
]	_	_
.	_	_

#79
(	_	_
3.6	_	_
)	_	_
We	_	_
see	_	_
that	_	_
f	_	_
(	_	_
x	_	_
)	_	_
is	_	_
the	_	_
gradient	_	_
of	_	_
the	_	_
(	_	_
scalar	_	_
)	_	_
term	_	_
inside	_	_
the	_	_
brackets	_	_
,	_	_
which	_	_
means	_	_
that	_	_
∇f	_	_
(	_	_
x	_	_
)	_	_
is	_	_
a	_	_
symmetric	_	_
matrix	_	_
2	_	_
.	_	_

#80
To	_	_
summarize	_	_
,	_	_
in	_	_
the	_	_
remarks	_	_
above	_	_
we’ve	_	_
argued	_	_
that	_	_
for	_	_
all	_	_
practical	_	_
purposes	_	_
,	_	_
we	_	_
can	_	_
assume	_	_
that	_	_
∇f	_	_
(	_	_
x	_	_
)	_	_
T	_	_
=	_	_
∇f	_	_
(	_	_
x	_	_
)	_	_
.	_	_

#81
With	_	_
this	_	_
in	_	_
hand	_	_
,	_	_
we	_	_
write	_	_
∇φ	_	_
(	_	_
x	_	_
)	_	_
=	_	_
f	_	_
(	_	_
x	_	_
)	_	_
+∇f	_	_
(	_	_
x	_	_
)	_	_
·	_	_
x−	_	_
f	_	_
(	_	_
x∗	_	_
)	_	_
−	_	_
x	_	_
(	_	_
3.7	_	_
)	_	_
Next	_	_
,	_	_
at	_	_
least	_	_
in	_	_
theory	_	_
,	_	_
and	_	_
without	_	_
(	_	_
yet	_	_
)	_	_
any	_	_
guarantee	_	_
of	_	_
convergence	_	_
,	_	_
we	_	_
can	_	_
consider	_	_
a	_	_
gradient	_	_
descent	_	_
algorithm	_	_
based	_	_
on	_	_
this	_	_
expression	_	_
as	_	_
follows	_	_
:	_	_
(	_	_
3.8	_	_
)	_	_
xk+1	_	_
=	_	_
xk	_	_
−	_	_
γ∇φ	_	_
(	_	_
xk	_	_
)	_	_
.	_	_

#82
The	_	_
right-hand-side	_	_
still	_	_
includes	_	_
the	_	_
term	_	_
∇f	_	_
(	_	_
x	_	_
)	_	_
·	_	_
x	_	_
,	_	_
which	_	_
contains	_	_
the	_	_
(	_	_
inaccessible	_	_
)	_	_
gradient	_	_
of	_	_
f	_	_
(	_	_
x	_	_
)	_	_
.	_	_

#83
This	_	_
would	_	_
seem	_	_
like	_	_
a	_	_
dead	_	_
end	_	_
.	_	_

#84
However	_	_
,	_	_
while	_	_
we	_	_
do	_	_
not	_	_
have	_	_
access	_	_
to	_	_
the	_	_
gradient	_	_
of	_	_
f	_	_
(	_	_
x	_	_
)	_	_
directly	_	_
,	_	_
we	_	_
can	_	_
approximate	_	_
the	_	_
directional	_	_
derivative	_	_
as	_	_
follows	_	_
[	_	_
23	_	_
]	_	_
:	_	_
(	_	_
3.9	_	_
)	_	_
∇f	_	_
(	_	_
x	_	_
)	_	_
·	_	_
d	_	_
≈	_	_
f	_	_
(	_	_
x	_	_
+	_	_
εd	_	_
)	_	_
−	_	_
f	_	_
(	_	_
x	_	_
)	_	_
ε	_	_
,	_	_
for	_	_
sufficiently	_	_
small	_	_
ε	_	_
.	_	_

#85
In	_	_
particular	_	_
we	_	_
are	_	_
interested	_	_
in	_	_
the	_	_
case	_	_
where	_	_
d	_	_
=	_	_
x	_	_
,	_	_
which	_	_
is	_	_
computable	_	_
with	_	_
two	_	_
activations	_	_
of	_	_
the	_	_
function	_	_
f	_	_
(	_	_
·	_	_
)	_	_
as	_	_
follows	_	_
:	_	_
(	_	_
3.10	_	_
)	_	_
∇f	_	_
(	_	_
x	_	_
)	_	_
·	_	_
x	_	_
≈	_	_
f	_	_
(	_	_
x	_	_
+	_	_
εx	_	_
)	_	_
−	_	_
f	_	_
(	_	_
x	_	_
)	_	_
ε	_	_
=	_	_
f	_	_
(	_	_
(	_	_
1	_	_
+	_	_
ε	_	_
)	_	_
x	_	_
)	_	_
−	_	_
f	_	_
(	_	_
x	_	_
)	_	_
ε	_	_
.	_	_

#86
2Even	_	_
without	_	_
resorting	_	_
to	_	_
approximation	_	_
,	_	_
such	_	_
operators	_	_
can	_	_
be	_	_
written	_	_
exactly	_	_
as	_	_
f	_	_
(	_	_
x	_	_
)	_	_
=	_	_
x−α∇φs	_	_
(	_	_
x	_	_
)	_	_
,	_	_
where	_	_
φs	_	_
is	_	_
a	_	_
smoothed	_	_
version	_	_
of	_	_
φ	_	_
.	_	_

#87
More	_	_
specifically	_	_
,	_	_
φs	_	_
is	_	_
the	_	_
Moreau	_	_
envelope	_	_
[	_	_
21	_	_
]	_	_
of	_	_
φ	_	_
.	_	_

#88
From	_	_
a	_	_
practical	_	_
standpoint	_	_
,	_	_
we	_	_
can	_	_
still	_	_
proceed	_	_
since	_	_
all	_	_
the	_	_
quantities	_	_
in	_	_
the	_	_
gradient	_	_
descent	_	_
equation	_	_
can	_	_
be	_	_
computed	_	_
,	_	_
albeit	_	_
inefficiently	_	_
.	_	_

#89
As	_	_
we	_	_
will	_	_
show	_	_
later	_	_
,	_	_
we	_	_
can	_	_
simplify	_	_
the	_	_
computations	_	_
even	_	_
further	_	_
to	_	_
avoid	_	_
two	_	_
activations	_	_
of	_	_
f	_	_
(	_	_
·	_	_
)	_	_
.	_	_

#90
For	_	_
now	_	_
,	_	_
the	_	_
more	_	_
critical	_	_
question	_	_
is	_	_
whether	_	_
this	_	_
iteration	_	_
converge	_	_
at	_	_
all	_	_
.	_	_

#91
And	_	_
if	_	_
so	_	_
,	_	_
to	_	_
what	_	_
?	_	_

#92
To	_	_
address	_	_
the	_	_
quesiton	_	_
of	_	_
point	_	_
of	_	_
convergence	_	_
,	_	_
let’s	_	_
examine	_	_
where	_	_
the	_	_
gradient	_	_
vanishes	_	_
or	_	_
becomes	_	_
small	_	_
at	_	_
a	_	_
point	_	_
near	_	_
x̂	_	_
:	_	_
∇φ	_	_
(	_	_
x̂	_	_
)	_	_
=	_	_
f	_	_
(	_	_
x̂	_	_
)	_	_
+∇f	_	_
(	_	_
x̂	_	_
)	_	_
·	_	_
x̂−	_	_
f	_	_
(	_	_
x∗	_	_
)	_	_
−	_	_
x̂	_	_
=	_	_
0	_	_
(	_	_
3.11	_	_
)	_	_
=⇒	_	_
f	_	_
(	_	_
x̂	_	_
)	_	_
−	_	_
f	_	_
(	_	_
x∗	_	_
)	_	_
=	_	_
∇f	_	_
(	_	_
x̂	_	_
)	_	_
·	_	_
x̂−	_	_
x̂	_	_
(	_	_
3.12	_	_
)	_	_
=⇒	_	_
f	_	_
(	_	_
x̂	_	_
)	_	_
−	_	_
f	_	_
(	_	_
x∗	_	_
)	_	_
=	_	_
(	_	_
∇f	_	_
(	_	_
x̂	_	_
)	_	_
−	_	_
I	_	_
)	_	_
x̂	_	_
(	_	_
3.13	_	_
)	_	_
Let’s	_	_
look	_	_
at	_	_
the	_	_
spectrum	_	_
of	_	_
the	_	_
operator	_	_
on	_	_
the	_	_
right-hand	_	_
side	_	_
.	_	_

#93
Since	_	_
∇f	_	_
(	_	_
x̂	_	_
)	_	_
is	_	_
assumed	_	_
symmetric	_	_
,	_	_
it	_	_
has	_	_
real	_	_
eigenvalues	_	_
λi	_	_
and	_	_
spectral	_	_
radius	_	_
M	_	_
=	_	_
max	_	_
i	_	_
|λi|	_	_
.	_	_

#94
The	_	_
eigenvalues	_	_
of	_	_
(	_	_
∇f	_	_
(	_	_
x̂	_	_
)	_	_
−	_	_
I	_	_
)	_	_
are	_	_
λi	_	_
−	_	_
1	_	_
and	_	_
its	_	_
spectral	_	_
radius	_	_
is	_	_
M	_	_
′	_	_
=	_	_
max	_	_
i	_	_
|λi	_	_
−	_	_
1|	_	_
.	_	_

#95
This	_	_
can	_	_
help	_	_
us	_	_
see	_	_
how	_	_
far	_	_
from	_	_
the	_	_
solution	_	_
we	_	_
are	_	_
likely	_	_
to	_	_
be	_	_
:	_	_
‖f	_	_
(	_	_
x̂	_	_
)	_	_
−	_	_
f	_	_
(	_	_
x∗	_	_
)	_	_
‖	_	_
=	_	_
‖	_	_
(	_	_
∇f	_	_
(	_	_
x̂	_	_
)	_	_
−	_	_
I	_	_
)	_	_
x̂‖	_	_
(	_	_
3.14	_	_
)	_	_
≤	_	_
‖	_	_
(	_	_
∇f	_	_
(	_	_
x̂	_	_
)	_	_
−	_	_
I	_	_
)	_	_
‖‖x̂‖	_	_
(	_	_
3.15	_	_
)	_	_
≤M	_	_
′	_	_
‖x̂‖	_	_
,	_	_
(	_	_
3.16	_	_
)	_	_
where	_	_
|M	_	_
−	_	_
1|	_	_
≤	_	_
M	_	_
′	_	_
≤	_	_
M	_	_
+	_	_
1	_	_
.	_	_

#96
When	_	_
the	_	_
spectral	_	_
norm	_	_
M	_	_
is	_	_
near	_	_
1	_	_
,	_	_
the	_	_
proposed	_	_
iteration	_	_
will	_	_
not	_	_
drift	_	_
far	_	_
from	_	_
the	_	_
solution	_	_
of	_	_
the	_	_
fixed	_	_
point	_	_
problem3	_	_
.	_	_

#97
As	_	_
M	_	_
gets	_	_
much	_	_
larger	_	_
than	_	_
1	_	_
,	_	_
it	_	_
is	_	_
less	_	_
likely	_	_
that	_	_
the	_	_
solution	_	_
x̂	_	_
will	_	_
be	_	_
near	_	_
the	_	_
desired	_	_
solution	_	_
x∗	_	_
.	_	_

#98
Nevertheless	_	_
,	_	_
if	_	_
M	_	_
is	_	_
sufficiently	_	_
close	_	_
to	_	_
1	_	_
,	_	_
we	_	_
have	_	_
reason	_	_
to	_	_
be	_	_
optimistic	_	_
that	_	_
we	_	_
will	_	_
obtain	_	_
a	_	_
useful	_	_
rendition	_	_
.	_	_

#99
Put	_	_
more	_	_
informally	_	_
,	_	_
one	_	_
can	_	_
imagine	_	_
that	_	_
if	_	_
the	_	_
effect	_	_
of	_	_
f	_	_
(	_	_
·	_	_
)	_	_
is	_	_
severe	_	_
,	_	_
we	_	_
are	_	_
unlikely	_	_
to	_	_
render	_	_
a	_	_
good	_	_
solution	_	_
without	_	_
additional	_	_
constraints	_	_
or	_	_
information	_	_
.	_	_

#100
However	_	_
,	_	_
if	_	_
the	_	_
function	_	_
is	_	_
reasonably	_	_
well-behaved	_	_
in	_	_
the	_	_
vicinity	_	_
of	_	_
x∗	_	_
(	_	_
in	_	_
the	_	_
sense	_	_
of	_	_
M	_	_
≈	_	_
1	_	_
)	_	_
,	_	_
we	_	_
may	_	_
succeed	_	_
.	_	_

#101
Given	_	_
f	_	_
(	_	_
x̂	_	_
)	_	_
,	_	_
the	_	_
ability	_	_
to	_	_
render	_	_
a	_	_
solution	_	_
that	_	_
is	_	_
useful	_	_
in	_	_
the	_	_
sense	_	_
that	_	_
x̂	_	_
≈	_	_
x∗	_	_
hinges	_	_
,	_	_
unsurprisingly	_	_
,	_	_
on	_	_
the	_	_
properties	_	_
of	_	_
f	_	_
.	_	_

#102
First	_	_
,	_	_
and	_	_
at	_	_
a	_	_
basic	_	_
level	_	_
,	_	_
we	_	_
assume	_	_
that	_	_
the	_	_
black	_	_
box	_	_
f	_	_
(	_	_
x	_	_
)	_	_
does	_	_
not	_	_
alter	_	_
a	_	_
null	_	_
image	_	_
.	_	_

#103
That	_	_
is	_	_
to	_	_
say	_	_
,	_	_
we	_	_
assume	_	_
f	_	_
(	_	_
0	_	_
)	_	_
=	_	_
0	_	_
.	_	_

#104
Second	_	_
,	_	_
we	_	_
mentioned	_	_
above	_	_
the	_	_
gradient	_	_
of	_	_
f	_	_
(	_	_
x	_	_
)	_	_
having	_	_
bounded	_	_
spectral	_	_
radius	_	_
.	_	_

#105
Since	_	_
the	_	_
gradient	_	_
may	_	_
not	_	_
strictly	_	_
exist	_	_
everywhere	_	_
for	_	_
all	_	_
filters	_	_
,	_	_
this	_	_
notion	_	_
will	_	_
instead	_	_
be	_	_
invoked	_	_
in	_	_
weaker	_	_
form	_	_
below	_	_
.	_	_

#106
What	_	_
we	_	_
are	_	_
describing	_	_
here	_	_
is	_	_
a	_	_
kind	_	_
of	_	_
local	_	_
“regularity”	_	_
that	_	_
can	_	_
be	_	_
formalized	_	_
using	_	_
the	_	_
concept	_	_
of	_	_
Lipschitz	_	_
continuity	_	_
.	_	_

#107
This	_	_
motivates	_	_
the	_	_
following	_	_
assumption	_	_
on	_	_
the	_	_
black	_	_
box	_	_
f	_	_
(	_	_
·	_	_
)	_	_
:	_	_
Assumption	_	_
1	_	_
:	_	_
f	_	_
(	_	_
x	_	_
)	_	_
is	_	_
Locally	_	_
Lipschitz	_	_
:	_	_
This	_	_
means	_	_
that	_	_
for	_	_
any	_	_
x	_	_
and	_	_
x′	_	_
in	_	_
a	_	_
small	_	_
neighborhood	_	_
N	_	_
(	_	_
x∗	_	_
)	_	_
of	_	_
x∗	_	_
,	_	_
the	_	_
operator	_	_
f	_	_
(	_	_
x	_	_
)	_	_
satisfies	_	_
(	_	_
3.17	_	_
)	_	_
‖f	_	_
(	_	_
x	_	_
)	_	_
−	_	_
f	_	_
(	_	_
x′	_	_
)	_	_
‖	_	_
≤M	_	_
‖x−	_	_
x′‖	_	_
,	_	_
where	_	_
M	_	_
is	_	_
a	_	_
positive	_	_
constant4	_	_
.	_	_

#108
A	_	_
Lipschitz	_	_
function	_	_
is	_	_
limited	_	_
in	_	_
how	_	_
fast	_	_
it	_	_
can	_	_
change	_	_
locally	_	_
(	_	_
as	_	_
dictated	_	_
by	_	_
M	_	_
)	_	_
.	_	_

#109
While	_	_
Lipschitz	_	_
property	_	_
does	_	_
not	_	_
imply	_	_
differentiability	_	_
,	_	_
it	_	_
does	_	_
provide	_	_
(	_	_
through	_	_
Rademacher’s	_	_
Theorem	_	_
[	_	_
11	_	_
]	_	_
)	_	_
,	_	_
a	_	_
guarantee	_	_
that	_	_
the	_	_
function	_	_
will	_	_
be	_	_
almost	_	_
everywhere	_	_
(	_	_
a.e	_	_
.	_	_
)	_	_

#110
differentiable	_	_
;	_	_
that	_	_
is	_	_
,	_	_
if	_	_
not	_	_
at	_	_
x∗	_	_
,	_	_
then	_	_
near	_	_
it	_	_
.	_	_

#111
When	_	_
the	_	_
function	_	_
3As	_	_
shown	_	_
in	_	_
[	_	_
23	_	_
]	_	_
,	_	_
when	_	_
f	_	_
(	_	_
x	_	_
)	_	_
is	_	_
a	_	_
smoothing	_	_
filter	_	_
,	_	_
its	_	_
gradient	_	_
∇f	_	_
(	_	_
x	_	_
)	_	_
has	_	_
spectral	_	_
radius	_	_
M	_	_
≤	_	_
1	_	_
.	_	_

#112
4The	_	_
choice	_	_
of	_	_
norm	_	_
is	_	_
somewhat	_	_
unimportant	_	_
,	_	_
but	_	_
for	_	_
our	_	_
purposes	_	_
we	_	_
will	_	_
use	_	_
the	_	_
`2	_	_
norm	_	_
throughout	_	_
the	_	_
paper	_	_
.	_	_

#113
is	_	_
differentiable	_	_
,	_	_
M	_	_
provides	_	_
a	_	_
bound	_	_
on	_	_
the	_	_
derivative	_	_
.	_	_

#114
More	_	_
intuitively	_	_
,	_	_
the	_	_
Lipschitz	_	_
property	_	_
guarantees	_	_
that	_	_
the	_	_
effect	_	_
of	_	_
the	_	_
operator	_	_
is	_	_
not	_	_
strong	_	_
(	_	_
again	_	_
as	_	_
dictated	_	_
by	_	_
a	_	_
sufficiently	_	_
small	_	_
M	_	_
)	_	_
–	_	_
that	_	_
it	_	_
does	_	_
not	_	_
change	_	_
the	_	_
input	_	_
image	_	_
too	_	_
severely	_	_
.	_	_

#115
As	_	_
a	_	_
result	_	_
of	_	_
this	_	_
guarantee	_	_
,	_	_
as	_	_
we	_	_
shall	_	_
see	_	_
below	_	_
,	_	_
we	_	_
are	_	_
able	_	_
to	_	_
render	_	_
an	_	_
approximation	_	_
to	_	_
the	_	_
unseen	_	_
input	_	_
given	_	_
only	_	_
the	_	_
output	_	_
and	_	_
activations	_	_
of	_	_
the	_	_
function	_	_
f	_	_
(	_	_
·	_	_
)	_	_
.	_	_

#116
Operators	_	_
That	_	_
Satisfy	_	_
Assumption	_	_
1	_	_
:	_	_
The	_	_
approach	_	_
we	_	_
propose	_	_
here	_	_
would	_	_
not	_	_
be	_	_
very	_	_
useful	_	_
if	_	_
it	_	_
could	_	_
only	_	_
be	_	_
applied	_	_
to	_	_
a	_	_
small	_	_
number	_	_
of	_	_
operators	_	_
.	_	_

#117
But	_	_
quite	_	_
the	_	_
contrary	_	_
is	_	_
true	_	_
.	_	_

#118
In	_	_
fact	_	_
,	_	_
nearly	_	_
every	_	_
operation	_	_
on	_	_
images	_	_
one	_	_
can	_	_
conjure	_	_
up	_	_
satisfies	_	_
the	_	_
Lipschitz	_	_
property	_	_
(	_	_
and	_	_
often	_	_
with	_	_
a	_	_
constant	_	_
M	_	_
near	_	_
1	_	_
)	_	_
.	_	_

#119
•	_	_
Smoothing/Blurring	_	_
:	_	_
To	_	_
begin	_	_
,	_	_
we	_	_
note	_	_
that	_	_
in	_	_
[	_	_
23	_	_
]	_	_
it	_	_
was	_	_
shown	_	_
that	_	_
a	_	_
vast	_	_
array	_	_
of	_	_
(	_	_
linear	_	_
and	_	_
nonlinear	_	_
)	_	_
smoothing	_	_
filters	_	_
commonly	_	_
used	_	_
in	_	_
the	_	_
literature	_	_
are	_	_
non-expansive	_	_
.	_	_

#120
That	_	_
is	_	_
,	_	_
they	_	_
are	_	_
Lipschitz	_	_
with	_	_
M	_	_
≤	_	_
1	_	_
.	_	_

#121
These	_	_
include	_	_
linear	_	_
denoisers	_	_
with	_	_
Tikhonov	_	_
regularization	_	_
[	_	_
10	_	_
]	_	_
,	_	_
and	_	_
Wiener	_	_
filtering	_	_
[	_	_
10	_	_
]	_	_
;	_	_
sparsity-based	_	_
methods	_	_
such	_	_
as	_	_
K-SVD	_	_
[	_	_
1	_	_
]	_	_
,	_	_
patch	_	_
based	_	_
methods	_	_
such	_	_
as	_	_
BM3D	_	_
[	_	_
9	_	_
]	_	_
,	_	_
the	_	_
domain	_	_
transform	_	_
filter	_	_
[	_	_
12	_	_
]	_	_
,	_	_
the	_	_
Bilater	_	_
filter	_	_
[	_	_
29	_	_
,	_	_
24	_	_
]	_	_
,	_	_
and	_	_
Non-local	_	_
Means	_	_
(	_	_
NLM	_	_
)	_	_
[	_	_
26	_	_
]	_	_
;	_	_
Gaussian	_	_
mixture	_	_
models	_	_
such	_	_
as	_	_
EPLL	_	_
[	_	_
31	_	_
]	_	_
,	_	_
TNRD	_	_
[	_	_
7	_	_
]	_	_
.	_	_

#122
•	_	_
Sharpening/Deconvolution	_	_
:	_	_
As	_	_
we’ve	_	_
described	_	_
in	_	_
[	_	_
23	_	_
,	_	_
19	_	_
]	_	_
and	_	_
elsewhere	_	_
,	_	_
the	_	_
contractive	_	_
operators	_	_
are	_	_
the	_	_
building	_	_
blocks	_	_
of	_	_
many	_	_
other	_	_
more	_	_
sophisticated	_	_
(	_	_
non-contractive	_	_
)	_	_
operators	_	_
that	_	_
are	_	_
used	_	_
for	_	_
various	_	_
enhancement	_	_
purposes	_	_
including	_	_
sharpening	_	_
,	_	_
deconvolution	_	_
,	_	_
super-resolution	_	_
,	_	_
etc	_	_
.	_	_

#123
Consider	_	_
a	_	_
smoothing	_	_
operator	_	_
f	_	_
(	_	_
x	_	_
)	_	_
(	_	_
say	_	_
the	_	_
bilateral	_	_
filter	_	_
)	_	_
.	_	_

#124
Analogous	_	_
to	_	_
the	_	_
linear	_	_
unsharp	_	_
mask	_	_
,	_	_
we	_	_
can	_	_
construct	_	_
a	_	_
spatially	_	_
adaptive	_	_
sharpening	_	_
filter	_	_
as	_	_
g	_	_
(	_	_
x	_	_
)	_	_
=	_	_
x	_	_
+	_	_
α	_	_
(	_	_
x	_	_
−	_	_
f	_	_
(	_	_
x	_	_
)	_	_
)	_	_
.	_	_

#125
Sum	_	_
of	_	_
two	_	_
Lipschitz	_	_
functions	_	_
with	_	_
constants	_	_
M1	_	_
and	_	_
M2	_	_
is	_	_
also	_	_
Lipschitz	_	_
with	_	_
corresponding	_	_
constant	_	_
M1+M2	_	_
.	_	_

#126
Furthermore	_	_
,	_	_
the	_	_
Lipschitz	_	_
constant	_	_
of	_	_
the	_	_
function	_	_
cf	_	_
(	_	_
x	_	_
)	_	_
is	_	_
|c|M	_	_
.	_	_

#127
Therefore	_	_
the	_	_
“sharpening”	_	_
operator	_	_
g	_	_
(	_	_
x	_	_
)	_	_
has	_	_
Lipschitz	_	_
constant	_	_
Mg	_	_
≤	_	_
(	_	_
1+2|α|	_	_
)	_	_
,	_	_
which	_	_
may	_	_
exceed	_	_
unity	_	_
,	_	_
but	_	_
not	_	_
by	_	_
much	_	_
since	_	_
we	_	_
typically	_	_
choose	_	_
a	_	_
small	_	_
α	_	_
.	_	_

#128
•	_	_
Composite	_	_
Filters	_	_
:	_	_
Generalizing	_	_
the	_	_
last	_	_
group	_	_
of	_	_
filters	_	_
,	_	_
as	_	_
described	_	_
in	_	_
[	_	_
26	_	_
,	_	_
27	_	_
]	_	_
and	_	_
elsewhere	_	_
,	_	_
we	_	_
can	_	_
construct	_	_
a	_	_
variety	_	_
of	_	_
non-linear	_	_
filters	_	_
with	_	_
a	_	_
desirable	_	_
range	_	_
of	_	_
effects	_	_
in	_	_
several	_	_
ways	_	_
.	_	_

#129
The	_	_
simplest	_	_
is	_	_
to	_	_
use	_	_
a	_	_
polynomial	_	_
application	_	_
of	_	_
a	_	_
base	_	_
filter5	_	_
f	_	_
(	_	_
x	_	_
)	_	_
.	_	_

#130
To	_	_
be	_	_
more	_	_
precise	_	_
,	_	_
if	_	_
we	_	_
describe	_	_
f	_	_
(	_	_
x	_	_
)	_	_
=	_	_
W	_	_
(	_	_
x	_	_
)	_	_
x	_	_
,	_	_
then	_	_
we	_	_
can	_	_
generate	_	_
g	_	_
(	_	_
x	_	_
)	_	_
=	_	_
pn	_	_
(	_	_
W	_	_
(	_	_
x	_	_
)	_	_
)	_	_
x	_	_
,	_	_
where	_	_
pn	_	_
(	_	_
λ	_	_
)	_	_
=	_	_
∑n	_	_
j=0	_	_
αjλ	_	_
j	_	_
is	_	_
a	_	_
polynomial	_	_
of	_	_
degree	_	_
n.	_	_
If	_	_
the	_	_
base	_	_
filter	_	_
is	_	_
1-Lipschitz	_	_
,	_	_
then	_	_
the	_	_
filter	_	_
g	_	_
(	_	_
x	_	_
)	_	_
has	_	_
Lipschitz	_	_
constant	_	_
Mg	_	_
≤	_	_
∑n	_	_
j=0	_	_
|αj	_	_
|	_	_
,	_	_
which	_	_
one	_	_
could	_	_
control	_	_
by	_	_
keeping	_	_
the	_	_
αi’s	_	_
small	_	_
in	_	_
magnitude	_	_
.	_	_

#131
•	_	_
Tone-mapping	_	_
and	_	_
Gamma	_	_
Correction	_	_
:	_	_
Tone	_	_
mapping	_	_
functions	_	_
are	_	_
pixel-wise	_	_
operators	_	_
that	_	_
typically	_	_
expand	_	_
or	_	_
compress	_	_
the	_	_
dynamic	_	_
range	_	_
of	_	_
images	_	_
for	_	_
better	_	_
viewing	_	_
.	_	_

#132
For	_	_
instance	_	_
,	_	_
a	_	_
typical	_	_
gamma	_	_
curve6	_	_
acts	_	_
pointwise	_	_
on	_	_
the	_	_
elements	_	_
of	_	_
x	_	_
as	_	_
f	_	_
(	_	_
xi	_	_
)	_	_
=	_	_
xγi	_	_
.	_	_

#133
More	_	_
general	_	_
tone-mapping	_	_
curve	_	_
are	_	_
Sshaped	_	_
curves	_	_
that	_	_
map	_	_
[	_	_
0	_	_
,	_	_
1	_	_
]	_	_
to	_	_
[	_	_
0	_	_
,	_	_
1	_	_
]	_	_
.	_	_

#134
See	_	_
for	_	_
example	_	_
the	_	_
curves	_	_
in	_	_
Fig.	_	_
17	_	_
.	_	_

#135
All	_	_
these	_	_
functions	_	_
are	_	_
Lipschitz	_	_
,	_	_
with	_	_
increasing	_	_
constants	_	_
that	_	_
depend	_	_
on	_	_
the	_	_
sharpness	_	_
of	_	_
the	_	_
transition	_	_
at	_	_
0.5	_	_
.	_	_

#136
•	_	_
Compression	_	_
and	_	_
Compressed	_	_
Sensing	_	_
:	_	_
Classical	_	_
tranform	_	_
coding	_	_
techniques	_	_
(	_	_
such	_	_
as	_	_
the	_	_
jpg	_	_
standard	_	_
)	_	_
apply	_	_
an	_	_
orthogonal	_	_
transform	_	_
(	_	_
e.g.	_	_
DCT	_	_
)	_	_
to	_	_
the	_	_
5More	_	_
generally	_	_
,	_	_
we	_	_
can	_	_
use	_	_
the	_	_
composition	_	_
of	_	_
any	_	_
two	_	_
Lipschitz	_	_
functions	_	_
f1	_	_
(	_	_
f2	_	_
)	_	_
(	_	_
x	_	_
)	_	_
each	_	_
with	_	_
constants	_	_
M1	_	_
,	_	_
M2	_	_
.	_	_

#137
This	_	_
composition	_	_
is	_	_
another	_	_
Lipschitz	_	_
function	_	_
with	_	_
constant	_	_
M1M2	_	_
6For	_	_
γ	_	_
<	_	_
1	_	_
This	_	_
function	_	_
is	_	_
only	_	_
uniformly	_	_
continouous	_	_
,	_	_
but	_	_
is	_	_
Lipschitz	_	_
if	_	_
we	_	_
exclude	_	_
the	_	_
point	_	_
x	_	_
=	_	_
0	_	_
image	_	_
(	_	_
a	_	_
1-Lipschitz	_	_
operator	_	_
)	_	_
,	_	_
then	_	_
shrink	_	_
the	_	_
resulting	_	_
coefficients	_	_
(	_	_
another	_	_
1-Lipschitz	_	_
operator	_	_
)	_	_
,	_	_
and	_	_
finally	_	_
quantize	_	_
these	_	_
coefficients	_	_
(	_	_
an	_	_
M	_	_
-Lipschitz	_	_
operator	_	_
,	_	_
where	_	_
M	_	_
is	_	_
inversely	_	_
proportional	_	_
to	_	_
the	_	_
number	_	_
of	_	_
quantization	_	_
levels	_	_
)	_	_
.	_	_

#138
Overall	_	_
therefore	_	_
,	_	_
compression/decompression	_	_
is	_	_
an	_	_
M	_	_
-Lipschitz	_	_
operator	_	_
with	_	_
M	_	_
possibly	_	_
close	_	_
to	_	_
1	_	_
.	_	_

#139
In	_	_
the	_	_
compressed	_	_
sensing	_	_
literature	_	_
,	_	_
the	_	_
operators	_	_
that	_	_
are	_	_
considered	_	_
are	_	_
random	_	_
matrices	_	_
that	_	_
satisfy	_	_
a	_	_
restricted	_	_
isometry	_	_
property	_	_
[	_	_
4	_	_
]	_	_
(	_	_
1	_	_
−	_	_
δ	_	_
)	_	_
‖x‖22	_	_
≤	_	_
‖Φx‖22	_	_
≤	_	_
(	_	_
1	_	_
+	_	_
δ	_	_
)	_	_
‖x‖22	_	_
.	_	_

#140
This	_	_
condition	_	_
effectively	_	_
guarantees	_	_
with	_	_
high	_	_
probability	_	_
[	_	_
15	_	_
]	_	_
that	_	_
the	_	_
Lipschitz	_	_
constant	_	_
of	_	_
the	_	_
operator	_	_
is	_	_
inside	_	_
the	_	_
range	_	_
1±	_	_
4δ	_	_
•	_	_
Neural	_	_
Networks	_	_
:	_	_
Each	_	_
layer	_	_
of	_	_
a	_	_
convolutional	_	_
neural	_	_
network	_	_
is	_	_
composed	_	_
of	_	_
a	_	_
linear	_	_
smoothing	_	_
filter	_	_
(	_	_
a	_	_
1-Lipschitz	_	_
operator	_	_
)	_	_
followed	_	_
by	_	_
a	_	_
nonlinearity	_	_
.	_	_

#141
If	_	_
the	_	_
nonlinearity	_	_
is	_	_
the	_	_
classical	_	_
sigmoid	_	_
,	_	_
this	_	_
is	_	_
of	_	_
course	_	_
1-Lipschitz	_	_
.	_	_

#142
If	_	_
not	_	_
,	_	_
the	_	_
ReLU	_	_
nonlinearity	_	_
over	_	_
a	_	_
compact	_	_
range	_	_
of	_	_
values	_	_
of	_	_
the	_	_
image	_	_
(	_	_
[	_	_
0	_	_
,	_	_
1	_	_
]	_	_
)	_	_
still	_	_
qualifies	_	_
as	_	_
a	_	_
1-Lipschitz	_	_
operator	_	_
.	_	_

#143
Between	_	_
layers	_	_
,	_	_
various	_	_
pooling	_	_
operators	_	_
can	_	_
be	_	_
employed	_	_
.	_	_

#144
The	_	_
overall	_	_
effect	_	_
of	_	_
these	_	_
and	_	_
the	_	_
corresponding	_	_
effect	_	_
on	_	_
the	_	_
Lipschitz	_	_
constant	_	_
of	_	_
the	_	_
overall	_	_
network	_	_
has	_	_
been	_	_
carefully	_	_
studied	_	_
recently	_	_
in	_	_
[	_	_
3	_	_
]	_	_
.	_	_

#145
Estimates	_	_
of	_	_
the	_	_
Lipschitz	_	_
Constant	_	_
:	_	_
To	_	_
estimate	_	_
the	_	_
Lipschitz	_	_
constant	_	_
for	_	_
a	_	_
given	_	_
filter	_	_
we	_	_
can	_	_
resort	_	_
to	_	_
approximations	_	_
.	_	_

#146
First	_	_
,	_	_
let’s	_	_
recall	_	_
that	_	_
(	_	_
3.18	_	_
)	_	_
M	_	_
=	_	_
max	_	_
x	_	_
,	_	_
x′∈	_	_
[	_	_
0,1	_	_
]	_	_
N	_	_
‖f	_	_
(	_	_
x	_	_
)	_	_
−	_	_
f	_	_
(	_	_
x′	_	_
)	_	_
‖	_	_
‖x−	_	_
x′‖	_	_
In	_	_
order	_	_
to	_	_
estimate	_	_
this	_	_
quantity	_	_
locally	_	_
around	_	_
some	_	_
x	_	_
,	_	_
we	_	_
use	_	_
the	_	_
following	_	_
empirical	_	_
estimate	_	_
(	_	_
3.19	_	_
)	_	_
M̂	_	_
=	_	_
max	_	_
x	_	_
,	_	_
d	_	_
‖f	_	_
(	_	_
x	_	_
+	_	_
d	_	_
)	_	_
−	_	_
f	_	_
(	_	_
x	_	_
)	_	_
‖	_	_
‖d‖	_	_
where	_	_
x	_	_
and	_	_
d	_	_
are	_	_
independent	_	_
random	_	_
vectors	_	_
with	_	_
uniform	_	_
density	_	_
U	_	_
[	_	_
0	_	_
,	_	_
1	_	_
]	_	_
N	_	_
,	_	_
and	_	_
the	_	_
maximum	_	_
is	_	_
computed	_	_
over	_	_
a	_	_
large	_	_
number	_	_
of	_	_
samples	_	_
(	_	_
xi	_	_
,	_	_
di	_	_
)	_	_
.	_	_

#147
For	_	_
now	_	_
,	_	_
consider	_	_
a	_	_
concrete	_	_
example	_	_
where	_	_
an	_	_
image	_	_
is	_	_
adaptively	_	_
sharpened	_	_
through	_	_
a	_	_
bilateral	_	_
filter	_	_
,	_	_
and	_	_
gamma-corrected	_	_
as	_	_
follows	_	_
:	_	_
(	_	_
3.20	_	_
)	_	_
f	_	_
(	_	_
x	_	_
)	_	_
=	_	_
(	_	_
x	_	_
+	_	_
α	_	_
(	_	_
x−	_	_
bilat	_	_
(	_	_
x	_	_
,	_	_
σ1	_	_
,	_	_
σ2	_	_
)	_	_
)	_	_
γ	_	_
With	_	_
α	_	_
=	_	_
1	_	_
,	_	_
[	_	_
σ1	_	_
,	_	_
σ2	_	_
]	_	_
=	_	_
[	_	_
10	_	_
,	_	_
3	_	_
]	_	_
,	_	_
and	_	_
γ	_	_
=	_	_
0.65	_	_
,	_	_
we	_	_
estimate	_	_
M̂	_	_
=	_	_
1.027	_	_
.	_	_

#148
This	_	_
sequence	_	_
of	_	_
nonlinear	_	_
operations	_	_
are	_	_
shown	_	_
in	_	_
Fig.	_	_
2	_	_
for	_	_
an	_	_
example	_	_
image	_	_
.	_	_

#149
In	_	_
Fig.	_	_
12	_	_
,	_	_
we	_	_
will	_	_
illustrate	_	_
the	_	_
rendition	_	_
of	_	_
the	_	_
original	_	_
image	_	_
(	_	_
left	_	_
)	_	_
from	_	_
the	_	_
altered	_	_
one	_	_
on	_	_
the	_	_
right	_	_
.	_	_

#150
In	_	_
the	_	_
appendix	_	_
,	_	_
we	_	_
present	_	_
more	_	_
examples	_	_
of	_	_
these	_	_
estimates	_	_
for	_	_
several	_	_
operators	_	_
.	_	_

#151
We	_	_
verify	_	_
that	_	_
operators	_	_
that	_	_
are	_	_
predominantly	_	_
smoothers	_	_
should	_	_
yields	_	_
values	_	_
of	_	_
M	_	_
smaller	_	_
than	_	_
1	_	_
,	_	_
whereas	_	_
those	_	_
that	_	_
have	_	_
a	_	_
sharpening	_	_
effect	_	_
should	_	_
generally	_	_
yield	_	_
values	_	_
larger	_	_
than	_	_
1	_	_
.	_	_

#152
The	_	_
intuition	_	_
to	_	_
be	_	_
gleaned	_	_
from	_	_
these	_	_
estimates	_	_
and	_	_
how	_	_
well	_	_
the	_	_
proposed	_	_
algorithm	_	_
is	_	_
expected	_	_
to	_	_
work	_	_
is	_	_
as	_	_
follows	_	_
:	_	_
The	_	_
farther	_	_
away	_	_
the	_	_
Lipschitz	_	_
constant	_	_
is	_	_
from	_	_
1	_	_
(	_	_
in	_	_
either	_	_
direction	_	_
)	_	_
,	_	_
the	_	_
less	_	_
likely	_	_
it	_	_
is	_	_
for	_	_
us	_	_
to	_	_
succeed	_	_
in	_	_
rendering	_	_
a	_	_
useful	_	_
result	_	_
.	_	_

#153
When	_	_
M	_	_
is	_	_
much	_	_
smaller	_	_
than	_	_
1	_	_
,	_	_
the	_	_
black	_	_
box	_	_
operator’s	_	_
effect	_	_
is	_	_
too	_	_
severe	_	_
as	_	_
a	_	_
smoother	_	_
and	_	_
therefore	_	_
the	_	_
rendition	_	_
will	_	_
fail	_	_
(	_	_
imagine	_	_
strong	_	_
blurring	_	_
for	_	_
instance	_	_
)	_	_
.	_	_

#154
On	_	_
the	_	_
other	_	_
hand	_	_
,	_	_
if	_	_
M	_	_
is	_	_
much	_	_
bigger	_	_
than	_	_
one	_	_
,	_	_
the	_	_
black	_	_
box	_	_
has	_	_
either	_	_
added	_	_
too	_	_
much	_	_
spurious	_	_
information	_	_
to	_	_
the	_	_
image	_	_
or	_	_
overwhelmed	_	_
parts	_	_
of	_	_
the	_	_
image	_	_
(	_	_
e.g.	_	_
with	_	_
saturation	_	_
in	_	_
an	_	_
HDR	_	_
scene	_	_
)	_	_
that	_	_
rendition	_	_
may	_	_
again	_	_
fail	_	_
.	_	_

#155
These	_	_
remarks	_	_
are	_	_
consistent	_	_
with	_	_
calculations	_	_
of	_	_
Lipschitz	_	_
constants	_	_
for	_	_
various	_	_
operators	_	_
shown	_	_
in	_	_
the	_	_
appendix	_	_
.	_	_

#156
Fig.	_	_
2	_	_
.	_	_

#157
Left	_	_
to	_	_
right	_	_
:	_	_
Input	_	_
image	_	_
,	_	_
Sharpened	_	_
with	_	_
Domain	_	_
(	_	_
Bilateral	_	_
)	_	_
Transform	_	_
,	_	_
tone-mapped	_	_
by	_	_
γ	_	_
correction	_	_
.	_	_

#158
Can	_	_
we	_	_
go	_	_
back	_	_
?	_	_

#159
The	_	_
answer	_	_
is	_	_
yes	_	_
.	_	_

#160
In	_	_
Fig.	_	_
12	_	_
,	_	_
we	_	_
illustrate	_	_
the	_	_
rendition	_	_
of	_	_
the	_	_
original	_	_
image	_	_
(	_	_
left	_	_
)	_	_
from	_	_
the	_	_
altered	_	_
one	_	_
on	_	_
the	_	_
right	_	_
.	_	_

#161
Credit	_	_
:	_	_
Andrzej	_	_
Dragan	_	_
Assumption	_	_
2	_	_
:	_	_
Earlier	_	_
when	_	_
we	_	_
discussed	_	_
the	_	_
directional	_	_
derivative	_	_
of	_	_
f	_	_
(	_	_
x	_	_
)	_	_
and	_	_
its	_	_
approximation	_	_
,	_	_
we	_	_
did	_	_
not	_	_
discuss	_	_
pathologies	_	_
where	_	_
these	_	_
quantities	_	_
may	_	_
not	_	_
even	_	_
exist	_	_
.	_	_

#162
Here	_	_
we	_	_
will	_	_
assume	_	_
that	_	_
f	_	_
(	_	_
x	_	_
)	_	_
has	_	_
a	_	_
non-trivial	_	_
directional	_	_
derivative	_	_
at	_	_
x∗	_	_
.	_	_

#163
This	_	_
assumption	_	_
is	_	_
not	_	_
very	_	_
restrictive	_	_
in	_	_
light	_	_
of	_	_
the	_	_
broader	_	_
definition	_	_
of	_	_
the	_	_
directional	_	_
derivative	_	_
[	_	_
16	_	_
]	_	_
we	_	_
will	_	_
give	_	_
next	_	_
.	_	_

#164
First	_	_
recall	_	_
that	_	_
the	_	_
directional	_	_
derivative	_	_
of	_	_
a	_	_
differentiable	_	_
function	_	_
in	_	_
the	_	_
direction	_	_
d	_	_
is	_	_
defined	_	_
as	_	_
follows	_	_
:	_	_
(	_	_
3.21	_	_
)	_	_
∇f	_	_
(	_	_
x	_	_
)	_	_
·	_	_
d	_	_
=	_	_
lim	_	_
ε→0	_	_
f	_	_
(	_	_
x	_	_
+	_	_
εd	_	_
)	_	_
−	_	_
f	_	_
(	_	_
x	_	_
)	_	_
ε	_	_
When	_	_
f	_	_
is	_	_
only	_	_
Lipschitz	_	_
,	_	_
a	_	_
looser	_	_
definition	_	_
of	_	_
the	_	_
directional	_	_
derivative	_	_
applies	_	_
.	_	_

#165
Following	_	_
[	_	_
16	_	_
]	_	_
,	_	_
we	_	_
think	_	_
of	_	_
the	_	_
directional	_	_
derivative	_	_
as	_	_
a	_	_
set	_	_
∇f	_	_
(	_	_
x	_	_
,	_	_
d	_	_
)	_	_
which	_	_
consists	_	_
of	_	_
all	_	_
points	_	_
z	_	_
that	_	_
are	_	_
the	_	_
limit	_	_
points	_	_
of	_	_
the	_	_
sequence	_	_
(	_	_
3.22	_	_
)	_	_
zk	_	_
=	_	_
f	_	_
(	_	_
xk	_	_
+	_	_
εkd	_	_
)	_	_
−	_	_
f	_	_
(	_	_
xk	_	_
)	_	_
εk	_	_
where	_	_
xk	_	_
→	_	_
x	_	_
and	_	_
εk	_	_
→	_	_
0	_	_
.	_	_

#166
To	_	_
be	_	_
explicit	_	_
,	_	_
this	_	_
assumption	_	_
ensures	_	_
that	_	_
the	_	_
approximation	_	_
to	_	_
the	_	_
directional	_	_
derivative	_	_
is	_	_
well-defined	_	_
in	_	_
the	_	_
neighborhood	_	_
of	_	_
x∗	_	_
.	_	_

#167
In	_	_
the	_	_
scenario	_	_
where	_	_
the	_	_
function	_	_
is	_	_
differentiable	_	_
,	_	_
this	_	_
is	_	_
equivalent	_	_
to	_	_
saying	_	_
that	_	_
the	_	_
Jacobian	_	_
is	_	_
full	_	_
rank	_	_
and	_	_
therefore	_	_
invertible	_	_
.	_	_

#168
And	_	_
when	_	_
this	_	_
is	_	_
true	_	_
,	_	_
the	_	_
Inverse	_	_
Function	_	_
Theorem	_	_
[	_	_
2	_	_
]	_	_
guarantee	_	_
that	_	_
the	_	_
function	_	_
is	_	_
locally	_	_
1-1	_	_
and	_	_
therefore	_	_
locally	_	_
invertible	_	_
.	_	_

#169
If	_	_
instead	_	_
there	_	_
is	_	_
a	_	_
null-space	_	_
to	_	_
the	_	_
Jacobian	_	_
,	_	_
all	_	_
this	_	_
means	_	_
is	_	_
that	_	_
we	_	_
can	_	_
not	_	_
restore	_	_
some	_	_
portions	_	_
of	_	_
the	_	_
original7	_	_
x∗	_	_
.	_	_

#170
More	_	_
to	_	_
the	_	_
point	_	_
,	_	_
in	_	_
[	_	_
16	_	_
]	_	_
,	_	_
a	_	_
generalization	_	_
of	_	_
the	_	_
Inverse	_	_
Function	_	_
Theorem	_	_
guarantees	_	_
the	_	_
function	_	_
is	_	_
locally	_	_
invertible	_	_
when	_	_
it	_	_
is	_	_
only	_	_
Lipschitz	_	_
(	_	_
as	_	_
in	_	_
our	_	_
case	_	_
)	_	_
.	_	_

#171
Operators	_	_
That	_	_
Satisfy	_	_
Assumption	_	_
2	_	_
:	_	_
Let’s	_	_
consider	_	_
the	_	_
simplest	_	_
case	_	_
of	_	_
linear	_	_
filters	_	_
f	_	_
(	_	_
x	_	_
)	_	_
=	_	_
W	_	_
x	_	_
.	_	_

#172
If	_	_
W	_	_
is	_	_
a	_	_
discretization	_	_
of	_	_
a	_	_
simple	_	_
blur	_	_
,	_	_
then	_	_
depending	_	_
on	_	_
the	_	_
structure	_	_
of	_	_
the	_	_
blurring	_	_
kernel	_	_
and	_	_
the	_	_
chosen	_	_
boundary	_	_
condition	_	_
,	_	_
this	_	_
matrix	_	_
can	_	_
certainly	_	_
be	_	_
rank	_	_
deficient	_	_
,	_	_
but	_	_
the	_	_
dimension	_	_
of	_	_
the	_	_
null-space	_	_
would	_	_
be	_	_
small	_	_
.	_	_

#173
For	_	_
instance	_	_
,	_	_
if	_	_
the	_	_
blur	_	_
kernel	_	_
is	_	_
a	_	_
disk	_	_
,	_	_
which	_	_
entirely	_	_
kills	_	_
certain	_	_
spatial	_	_
frequencies	_	_
,	_	_
7In	_	_
such	_	_
a	_	_
scenario	_	_
,	_	_
regularization	_	_
[	_	_
23	_	_
]	_	_
can	_	_
be	_	_
applied	_	_
to	_	_
still	_	_
obtain	_	_
a	_	_
solution	_	_
.	_	_

#174
We	_	_
briefly	_	_
discuss	_	_
this	_	_
notion	_	_
is	_	_
Section	_	_
5.	_	_
then	_	_
W	_	_
would	_	_
be	_	_
rank	_	_
deficient	_	_
against	_	_
components	_	_
of	_	_
the	_	_
image	_	_
at	_	_
those	_	_
spatial	_	_
frequencies	_	_
.	_	_

#175
In	_	_
general	_	_
,	_	_
one	_	_
would	_	_
not	_	_
be	_	_
able	_	_
to	_	_
recover	_	_
such	_	_
frequencies	_	_
unless	_	_
strong	_	_
prior	_	_
information	_	_
was	_	_
available	_	_
.	_	_

#176
In	_	_
other	_	_
cases	_	_
,	_	_
for	_	_
instance	_	_
Gaussian	_	_
blur	_	_
,	_	_
the	_	_
matrix	_	_
is	_	_
generally	_	_
not	_	_
rank	_	_
deficient	_	_
,	_	_
but	_	_
will	_	_
become	_	_
increasingly	_	_
more	_	_
ill-conditioned	_	_
with	_	_
wider	_	_
kernels	_	_
.	_	_

#177
So	_	_
generically	_	_
,	_	_
it	_	_
is	_	_
hard	_	_
to	_	_
construct	_	_
linear	_	_
filters	_	_
that	_	_
completely	_	_
annihilate	_	_
typical	_	_
images	_	_
that	_	_
contain	_	_
a	_	_
wide	_	_
range	_	_
of	_	_
spatial	_	_
frequencies	_	_
.	_	_

#178
At	_	_
worst	_	_
,	_	_
some	_	_
small	_	_
number	_	_
,	_	_
or	_	_
range	_	_
of	_	_
spatial	_	_
frequencies	_	_
are	_	_
knocked	_	_
out	_	_
and	_	_
are	_	_
not	_	_
directly	_	_
recoverable	_	_
by	_	_
rendition	_	_
(	_	_
i.e.	_	_
a	_	_
small	_	_
null-space	_	_
exists	_	_
)	_	_
.	_	_

#179
The	_	_
situation	_	_
for	_	_
non-linear	_	_
filters	_	_
is	_	_
analogous	_	_
.	_	_

#180
Let’s	_	_
consider	_	_
the	_	_
case	_	_
of	_	_
(	_	_
pseudolinear	_	_
)	_	_
filters	_	_
of	_	_
the	_	_
form	_	_
f	_	_
(	_	_
x	_	_
)	_	_
=	_	_
W	_	_
(	_	_
x	_	_
)	_	_
x	_	_
.	_	_

#181
As	_	_
shown	_	_
in	_	_
[	_	_
23	_	_
]	_	_
,	_	_
under	_	_
some	_	_
mild	_	_
regularity	_	_
conditions	_	_
,	_	_
∇f	_	_
(	_	_
x	_	_
)	_	_
=	_	_
W	_	_
(	_	_
x	_	_
)	_	_
.	_	_

#182
The	_	_
matrix	_	_
W	_	_
(	_	_
x	_	_
)	_	_
may	_	_
be	_	_
constructed	_	_
from	_	_
any	_	_
number	_	_
of	_	_
non-linear	_	_
kernels	_	_
such	_	_
as	_	_
bilateral	_	_
or	_	_
non-local	_	_
means	_	_
.	_	_

#183
As	_	_
discussed	_	_
at	_	_
length	_	_
in	_	_
[	_	_
26	_	_
,	_	_
25	_	_
]	_	_
,	_	_
by	_	_
looking	_	_
at	_	_
the	_	_
eigendecomposition	_	_
of	_	_
the	_	_
filter	_	_
matrix	_	_
for	_	_
natural	_	_
images	_	_
,	_	_
we	_	_
can	_	_
see	_	_
that	_	_
these	_	_
nonlinear	_	_
filters	_	_
are	_	_
generally	_	_
full	_	_
rank	_	_
when	_	_
the	_	_
support	_	_
of	_	_
the	_	_
filters	_	_
is	_	_
small	_	_
(	_	_
i.e.	_	_
when	_	_
the	_	_
filters	_	_
are	_	_
local	_	_
)	_	_
.	_	_

#184
When	_	_
the	_	_
filters	_	_
are	_	_
non-local	_	_
(	_	_
or	_	_
even	_	_
truly	_	_
global	_	_
)	_	_
,	_	_
the	_	_
numerical	_	_
rank	_	_
of	_	_
the	_	_
filter	_	_
matrix	_	_
drops	_	_
,	_	_
similarly	_	_
to	_	_
the	_	_
linear	_	_
case	_	_
.	_	_

#185
So	_	_
again	_	_
,	_	_
most	_	_
locally	_	_
operating	_	_
nonlinear	_	_
filters	_	_
also	_	_
do	_	_
not	_	_
annihilate	_	_
most	_	_
images	_	_
completely	_	_
.	_	_

#186
And	_	_
non-local	_	_
filters	_	_
will	_	_
annihilate	_	_
only	_	_
a	_	_
subset	_	_
of	_	_
features	_	_
in	_	_
any	_	_
image	_	_
.	_	_

#187
So	_	_
consistent	_	_
with	_	_
the	_	_
main	_	_
message	_	_
of	_	_
the	_	_
paper	_	_
,	_	_
as	_	_
long	_	_
as	_	_
the	_	_
effect	_	_
of	_	_
the	_	_
black	_	_
box	_	_
is	_	_
not	_	_
severe	_	_
,	_	_
we	_	_
may	_	_
stand	_	_
a	_	_
chance	_	_
of	_	_
obtaining	_	_
a	_	_
useful	_	_
rendition	_	_
.	_	_

#188
With	_	_
the	_	_
two	_	_
assumptions	_	_
above	_	_
in	_	_
place	_	_
,	_	_
we	_	_
now	_	_
have	_	_
the	_	_
key	_	_
result	_	_
that	_	_
enables	_	_
us	_	_
to	_	_
move	_	_
forward	_	_
.	_	_

#189
Theorem	_	_
3.1	_	_
(	_	_
[	_	_
16	_	_
]	_	_
)	_	_
.	_	_

#190
The	_	_
function	_	_
f	_	_
(	_	_
x	_	_
)	_	_
is	_	_
locally	_	_
Lipschitz	_	_
invertible	_	_
at	_	_
x∗	_	_
if	_	_
and	_	_
only	_	_
if	_	_
the	_	_
above	_	_
two	_	_
conditions	_	_
are	_	_
satisfied	_	_
at	_	_
x∗	_	_
.	_	_

#191
The	_	_
implications	_	_
of	_	_
this	_	_
result	_	_
are	_	_
deep	_	_
.	_	_

#192
It	_	_
will	_	_
enable	_	_
us	_	_
to	_	_
invert	_	_
a	_	_
very	_	_
large	_	_
class	_	_
of	_	_
degradations	_	_
as	_	_
long	_	_
as	_	_
their	_	_
effect	_	_
is	_	_
not	_	_
too	_	_
severe	_	_
.	_	_

#193
A	_	_
particularly	_	_
noteworthy	_	_
implication	_	_
is	_	_
that	_	_
the	_	_
local	_	_
inverse	_	_
is	_	_
itself	_	_
guaranteed	_	_
to	_	_
be	_	_
locally	_	_
Lipschitz	_	_
(	_	_
with	_	_
a	_	_
different	_	_
positive	_	_
constant	_	_
m	_	_
)	_	_
.	_	_

#194
That	_	_
is	_	_
,	_	_
the	_	_
function	_	_
is	_	_
locally	_	_
bi-Lipschitz	_	_
near	_	_
x∗	_	_
:	_	_
(	_	_
3.23	_	_
)	_	_
m	_	_
‖x−	_	_
x′‖	_	_
≤	_	_
‖f	_	_
(	_	_
x	_	_
)	_	_
−	_	_
f	_	_
(	_	_
x′	_	_
)	_	_
‖	_	_
≤M	_	_
‖x−	_	_
x′‖	_	_
.	_	_

#195
Now	_	_
let’s	_	_
return	_	_
to	_	_
the	_	_
iterative	_	_
algorithm	_	_
we	_	_
proposed	_	_
earlier	_	_
:	_	_
(	_	_
3.24	_	_
)	_	_
xk+1	_	_
=	_	_
xk	_	_
−	_	_
γ∇φ	_	_
(	_	_
xk	_	_
)	_	_
,	_	_
where	_	_
(	_	_
3.25	_	_
)	_	_
∇φ	_	_
(	_	_
x	_	_
)	_	_
=	_	_
f	_	_
(	_	_
x	_	_
)	_	_
−	_	_
f	_	_
(	_	_
x∗	_	_
)	_	_
+∇f	_	_
(	_	_
x	_	_
)	_	_
x−	_	_
x	_	_
=	_	_
f	_	_
(	_	_
x	_	_
)	_	_
−	_	_
f	_	_
(	_	_
x∗	_	_
)	_	_
+	_	_
(	_	_
∇f	_	_
(	_	_
x	_	_
)	_	_
−	_	_
I	_	_
)	_	_
x	_	_
As	_	_
we	_	_
noted	_	_
before	_	_
,	_	_
the	_	_
directional	_	_
derivative	_	_
∇f	_	_
(	_	_
x	_	_
)	_	_
x	_	_
could	_	_
be	_	_
approximated	_	_
with	_	_
two	_	_
activations	_	_
of	_	_
the	_	_
filter	_	_
f	_	_
(	_	_
x	_	_
)	_	_
.	_	_

#196
We	_	_
wish	_	_
to	_	_
simplify	_	_
even	_	_
further	_	_
to	_	_
avoid	_	_
this	_	_
.	_	_

#197
Therefore	_	_
,	_	_
we	_	_
instead	_	_
appeal	_	_
to	_	_
an	_	_
approximation	_	_
of	_	_
the	_	_
gradient	_	_
of	_	_
the	_	_
loss	_	_
directly	_	_
.	_	_

#198
Namely	_	_
,	_	_
we	_	_
recall	_	_
that	_	_
‖	_	_
(	_	_
∇f	_	_
(	_	_
x	_	_
)	_	_
−	_	_
I	_	_
)	_	_
x‖	_	_
≤M	_	_
′‖x‖	_	_
.	_	_

#199
Therefore	_	_
,	_	_
as	_	_
M	_	_
is	_	_
near	_	_
1	_	_
,	_	_
we	_	_
will	_	_
approximate	_	_
(	_	_
3.26	_	_
)	_	_
(	_	_
∇f	_	_
(	_	_
x	_	_
)	_	_
−	_	_
I	_	_
)	_	_
x	_	_
≈	_	_
µx	_	_
where	_	_
|M	_	_
−	_	_
1|	_	_
≤	_	_
µ	_	_
≤M	_	_
+	_	_
1	_	_
is	_	_
a	_	_
non-negative	_	_
scalar	_	_
.	_	_

#200
Now	_	_
,	_	_
recalling	_	_
the	_	_
definition	_	_
of	_	_
the	_	_
loss	_	_
function	_	_
and	_	_
its	_	_
gradient	_	_
:	_	_
φ	_	_
(	_	_
x	_	_
)	_	_
=	_	_
xT	_	_
(	_	_
f	_	_
(	_	_
x	_	_
)	_	_
−	_	_
f	_	_
(	_	_
x∗	_	_
)	_	_
)	_	_
−	_	_
1	_	_
xTx	_	_
,	_	_
(	_	_
3.27	_	_
)	_	_
∇φ	_	_
(	_	_
x	_	_
)	_	_
=	_	_
f	_	_
(	_	_
x	_	_
)	_	_
−	_	_
f	_	_
(	_	_
x∗	_	_
)	_	_
+	_	_
(	_	_
∇f	_	_
(	_	_
x	_	_
)	_	_
−	_	_
I	_	_
)	_	_
x	_	_
,	_	_
(	_	_
3.28	_	_
)	_	_
we	_	_
have	_	_
the	_	_
approximate	_	_
gradient	_	_
of	_	_
the	_	_
loss	_	_
:	_	_
(	_	_
3.29	_	_
)	_	_
∇̃φ	_	_
(	_	_
x	_	_
)	_	_
=	_	_
f	_	_
(	_	_
x	_	_
)	_	_
−	_	_
f	_	_
(	_	_
x∗	_	_
)	_	_
+	_	_
µ	_	_
x	_	_
This	_	_
gives	_	_
an	_	_
elegantly	_	_
simple	_	_
approximate	_	_
gradient	_	_
descent	_	_
iteration	_	_
:	_	_
xk+1	_	_
=	_	_
xk	_	_
−	_	_
γ∇̃φ	_	_
(	_	_
xk	_	_
)	_	_
(	_	_
3.30	_	_
)	_	_
=⇒	_	_
xk+1	_	_
=	_	_
(	_	_
1−	_	_
γµ	_	_
)	_	_
xk	_	_
−	_	_
γ	_	_
[	_	_
f	_	_
(	_	_
xk	_	_
)	_	_
−	_	_
f	_	_
(	_	_
x∗	_	_
)	_	_
]	_	_
(	_	_
3.31	_	_
)	_	_
With	_	_
a	_	_
sufficiently	_	_
small	_	_
step	_	_
size	_	_
γ	_	_
,	_	_
the	_	_
factor	_	_
(	_	_
1	_	_
−	_	_
γµ	_	_
)	_	_
is	_	_
slightly	_	_
less	_	_
than	_	_
one	_	_
,	_	_
and	_	_
has	_	_
a	_	_
mild	_	_
dampening	_	_
effect	_	_
.	_	_

#201
This	_	_
iteration	_	_
overall	_	_
has	_	_
a	_	_
nice	_	_
intuitive	_	_
interpretation	_	_
:	_	_
dampen	_	_
the	_	_
last	_	_
estimate	_	_
slightly	_	_
,	_	_
and	_	_
move	_	_
repeatedly	_	_
in	_	_
the	_	_
direction	_	_
of	_	_
the	_	_
residual	_	_
.	_	_

#202
This	_	_
interpretation	_	_
is	_	_
reminiscent	_	_
of	_	_
(	_	_
but	_	_
distinct	_	_
from	_	_
)	_	_
the	_	_
concept	_	_
of	_	_
boosting	_	_
described	_	_
in	_	_
several	_	_
recent	_	_
works	_	_
[	_	_
23	_	_
,	_	_
22	_	_
,	_	_
19	_	_
,	_	_
6	_	_
,	_	_
28	_	_
]	_	_
.	_	_

#203
We	_	_
should	_	_
note	_	_
that	_	_
with	_	_
the	_	_
exception	_	_
of	_	_
the	_	_
first	_	_
term	_	_
on	_	_
the	_	_
right-hand	_	_
side	_	_
,	_	_
the	_	_
equation	_	_
(	_	_
3.31	_	_
)	_	_
is	_	_
a	_	_
damped	_	_
fixed	_	_
point	_	_
iteration	_	_
for	_	_
solving	_	_
the	_	_
equation	_	_
f	_	_
(	_	_
xk	_	_
)	_	_
=	_	_
f	_	_
(	_	_
x∗	_	_
)	_	_
.	_	_

#204
We	_	_
hasten	_	_
to	_	_
note	_	_
that	_	_
such	_	_
a	_	_
fixed	_	_
point	_	_
iteration	_	_
would	_	_
only	_	_
converge	_	_
for	_	_
contractive	_	_
operators	_	_
.	_	_

#205
The	_	_
interesting	_	_
property	_	_
of	_	_
the	_	_
proposed	_	_
approach	_	_
is	_	_
that	_	_
this	_	_
simple	_	_
iteration	_	_
works	_	_
toward	_	_
minimizing	_	_
φ	_	_
(	_	_
x	_	_
)	_	_
even	_	_
if	_	_
the	_	_
operator	_	_
f	_	_
(	_	_
x	_	_
)	_	_
is	_	_
expansive	_	_
.	_	_

#206
We	_	_
discuss	_	_
the	_	_
issue	_	_
of	_	_
convergence	_	_
next	_	_
.	_	_

#207
3.1	_	_
.	_	_

#208
Convergence	_	_
.	_	_

#209
Is	_	_
the	_	_
iteration	_	_
(	_	_
3.31	_	_
)	_	_
convergent	_	_
?	_	_

#210
In	_	_
order	_	_
to	_	_
answer	_	_
this	_	_
question	_	_
,	_	_
we	_	_
need	_	_
to	_	_
examine	_	_
when	_	_
the	_	_
operator	_	_
ψ	_	_
(	_	_
x	_	_
)	_	_
=	_	_
x−γ∇̃φ	_	_
(	_	_
x	_	_
)	_	_
on	_	_
the	_	_
right-hand	_	_
side	_	_
is	_	_
contractive	_	_
.	_	_

#211
We	_	_
compute	_	_
its	_	_
gradient	_	_
:	_	_
(	_	_
3.32	_	_
)	_	_
∇ψ	_	_
(	_	_
x	_	_
)	_	_
=	_	_
(	_	_
1−	_	_
γµ	_	_
)	_	_
I−	_	_
γ∇f	_	_
(	_	_
x	_	_
)	_	_

#212
If	_	_
the	_	_
spectral	_	_
radius	_	_
of	_	_
∇ψ	_	_
(	_	_
x	_	_
)	_	_
is	_	_
below	_	_
1	_	_
,	_	_
we	_	_
have	_	_
convergence	_	_
.	_	_

#213
This	_	_
spectal	_	_
radius	_	_
is	_	_
bounded	_	_
above	_	_
as	_	_
:	_	_
(	_	_
3.33	_	_
)	_	_
ρ	_	_
(	_	_
∇ψ	_	_
(	_	_
x	_	_
)	_	_
)	_	_
=	_	_
|1−	_	_
γµ|+	_	_
γM	_	_
which	_	_
must	deontic	_
satisfy	_	_
(	_	_
3.34	_	_
)	_	_
|1−	_	_
γµ|+	_	_
γM	_	_
<	_	_
1	_	_
=⇒	_	_
γ	_	_
<	_	_
µ+M	_	_

#214
This	_	_
is	_	_
a	_	_
sufficient	_	_
condition	_	_
to	_	_
ensure	_	_
the	_	_
convergence	_	_
of	_	_
the	_	_
proposed	_	_
iteration	_	_
to	_	_
a	_	_
local	_	_
optimum	_	_
.	_	_

#215
Remark	_	_
:	_	_
While	_	_
the	_	_
loss	_	_
function	_	_
φ	_	_
(	_	_
x	_	_
)	_	_
is	_	_
not	_	_
convex	_	_
,	_	_
it	_	_
is	_	_
interesting	_	_
to	_	_
note	_	_
that	_	_
it	_	_
is	_	_
locally	_	_
,	_	_
directionally	_	_
convex	_	_
.	_	_

#216
We	_	_
can	_	_
look	_	_
at	_	_
a	_	_
Taylor	_	_
series	_	_
expansion	_	_
around	_	_
the	_	_
optimum	_	_
x̂	_	_
,	_	_
where	_	_
∇φ	_	_
(	_	_
x̂	_	_
)	_	_
=	_	_
0	_	_
.	_	_

#217
Let’s	_	_
consider	_	_
a	_	_
small	_	_
perturbation	_	_
x̂→	_	_
x̂	_	_
+	_	_
εd	_	_
in	_	_
an	_	_
arbitrary	_	_
direction	_	_
d.	_	_
For	_	_
sufficiently	_	_
small	_	_
ε	_	_
,	_	_
we	_	_
have	_	_
φ	_	_
(	_	_
x̂	_	_
+	_	_
εd	_	_
)	_	_
=	_	_
φ	_	_
(	_	_
x̂	_	_
)	_	_
+	_	_
ε∇φ	_	_
(	_	_
x̂	_	_
)	_	_
d	_	_
+	_	_
ε2	_	_
dT∇2φ	_	_
(	_	_
x̂	_	_
)	_	_
d	_	_
(	_	_
3.35	_	_
)	_	_
=	_	_
φ	_	_
(	_	_
x̂	_	_
)	_	_
+	_	_
ε2	_	_
dT∇2φ	_	_
(	_	_
x̂	_	_
)	_	_
d	_	_
(	_	_
3.36	_	_
)	_	_
≈	_	_
φ	_	_
(	_	_
x̂	_	_
)	_	_
+	_	_
ε2	_	_
dT	_	_
∇̃2φ	_	_
(	_	_
x̂	_	_
)	_	_
d	_	_
(	_	_
3.37	_	_
)	_	_
=	_	_
φ	_	_
(	_	_
x̂	_	_
)	_	_
+	_	_
ε2	_	_
dT	_	_
(	_	_
∇f	_	_
(	_	_
x̂	_	_
)	_	_
+	_	_
µI	_	_
)	_	_
d	_	_
(	_	_
3.38	_	_
)	_	_
=	_	_
φ	_	_
(	_	_
x̂	_	_
)	_	_
+	_	_
µε2	_	_
dTd	_	_
+	_	_
ε2	_	_
dT∇f	_	_
(	_	_
x̂	_	_
)	_	_
d	_	_
(	_	_
3.39	_	_
)	_	_
We	_	_
observe	_	_
that	_	_
as	_	_
we	_	_
move	_	_
away	_	_
from	_	_
x∗	_	_
in	_	_
an	_	_
arbitrary	_	_
direction	_	_
d	_	_
,	_	_
the	_	_
loss	_	_
may	_	_
increase	_	_
or	_	_
decrese	_	_
depending	_	_
directly	_	_
on	_	_
whether	_	_
the	_	_
gradient	_	_
∇f	_	_
(	_	_
x̂	_	_
)	_	_
is	_	_
positive	_	_
definite	_	_
(	_	_
and	_	_
therefore	_	_
the	_	_
quadratic	_	_
form	_	_
positive	_	_
or	_	_
negative	_	_
valued	_	_
)	_	_
in	_	_
that	_	_
direction	_	_
.	_	_

#218
When	_	_
the	_	_
filter	_	_
f	_	_
(	_	_
x	_	_
)	_	_
is	_	_
strictly	_	_
of	_	_
denoising/smoothing	_	_
type	_	_
,	_	_
all	_	_
eigenvalues	_	_
of	_	_
the	_	_
filter	_	_
are	_	_
non-negative	_	_
[	_	_
19	_	_
,	_	_
23	_	_
]	_	_
,	_	_
and	_	_
we	_	_
can	_	_
be	_	_
assured	_	_
that	_	_
∇f	_	_
(	_	_
x	_	_
)	_	_
is	_	_
non-negative	_	_
definite	_	_
in	_	_
any	_	_
direction	_	_
.	_	_

#219
However	_	_
,	_	_
for	_	_
more	_	_
general	_	_
filters	_	_
we’ve	_	_
considered	_	_
here	_	_
in	_	_
the	_	_
context	_	_
of	_	_
rendition	_	_
,	_	_
this	_	_
is	_	_
not	_	_
necessarily	_	_
the	_	_
case	_	_
.	_	_

#220
In	_	_
such	_	_
instances	_	_
,	_	_
the	_	_
convergence	_	_
may	_	_
be	_	_
to	_	_
a	_	_
saddle	_	_
point	_	_
.	_	_

#221
When	_	_
the	_	_
perturbation	_	_
is	_	_
small	_	_
,	_	_
this	_	_
solution	_	_
is	_	_
often	_	_
enough	_	_
to	_	_
give	_	_
a	_	_
good	_	_
rendition	_	_
,	_	_
and	_	_
we	_	_
will	_	_
stop	_	_
the	_	_
iterations	_	_
.	_	_

#222
A	_	_
reliable	_	_
approach	_	_
to	_	_
remain	_	_
in	_	_
this	_	_
useful	_	_
local	_	_
critical	_	_
point	_	_
is	_	_
to	_	_
pick	_	_
a	_	_
small	_	_
step	_	_
size	_	_
γ	_	_
,	_	_
and	_	_
iterate	_	_
roughly	_	_
k	_	_
=	_	_
1	_	_
γM	_	_
times	_	_
.	_	_

#223
Alternatively	_	_
,	_	_
we	_	_
can	_	_
stop	_	_
the	_	_
iterations	_	_
when	_	_
the	_	_
relative	_	_
residual	_	_
drops	_	_
below	_	_
a	_	_
threshold	_	_
τ	_	_
.	_	_

#224
We	_	_
define	_	_
this	_	_
stopping	_	_
condition	_	_
as	_	_
follows	_	_
,	_	_
where	_	_
τ	_	_
is	_	_
typically	_	_
on	_	_
the	_	_
order	_	_
of	_	_
10−2	_	_
or	_	_
smaller	_	_
.	_	_

#225
(	_	_
3.40	_	_
)	_	_
‖f	_	_
(	_	_
xk	_	_
)	_	_
−	_	_
f	_	_
(	_	_
x∗	_	_
)	_	_
‖	_	_
‖f	_	_
(	_	_
x∗	_	_
)	_	_
‖	_	_
≤	_	_
τ	_	_
3.2	_	_
.	_	_

#226
The	_	_
Effect	_	_
of	_	_
Noise	_	_
.	_	_

#227
What	_	_
if	_	_
the	_	_
given	_	_
image	_	_
f	_	_
(	_	_
x∗	_	_
)	_	_
is	_	_
available	_	_
not	_	_
exactly	_	_
,	_	_
but	_	_
rather	_	_
with	_	_
uncertainty	_	_
as	_	_
f	_	_
(	_	_
x∗	_	_
)	_	_
+	_	_
error	_	_
?	_	_

#228
This	_	_
error	_	_
may	_	_
be	_	_
due	_	_
to	_	_
noise	_	_
,	_	_
quantization	_	_
,	_	_
or	_	_
some	_	_
other	_	_
source	_	_
of	_	_
error	_	_
with	_	_
bounded	_	_
magnitude	_	_
.	_	_

#229
To	_	_
simplify	_	_
matters	_	_
,	_	_
let’s	_	_
restrict	_	_
our	_	_
attention	_	_
to	_	_
the	_	_
linear	_	_
filter	_	_
case	_	_
where	_	_
f	_	_
(	_	_
x	_	_
)	_	_
=	_	_
Wx	_	_
.	_	_

#230
The	_	_
intuitions	_	_
gained	_	_
from	_	_
this	_	_
analysis	_	_
are	_	_
applicable	_	_
to	_	_
the	_	_
general	_	_
(	_	_
nonlinear	_	_
)	_	_
case	_	_
as	_	_
well	_	_
.	_	_

#231
First	_	_
,	_	_
let’s	_	_
suppose	_	_
f	_	_
(	_	_
x∗	_	_
)	_	_
is	_	_
given	_	_
exactly	_	_
and	_	_
without	_	_
error	_	_
.	_	_

#232
It	_	_
is	_	_
not	_	_
difficult	_	_
to	_	_
show	_	_
that	_	_
the	_	_
rendition	_	_
algorithm	_	_
we	_	_
propose	_	_
boils	_	_
down	_	_
in	_	_
the	_	_
linear	_	_
case	_	_
to	_	_
the	_	_
following	_	_
simple	_	_
expression	_	_
for	_	_
the	_	_
k-th	_	_
iterate	_	_
(	_	_
3.41	_	_
)	_	_
xk	_	_
=	_	_
[	_	_
αI	_	_
+	_	_
γ	_	_
(	_	_
I−W	_	_
)	_	_
]	_	_
k	_	_
x0	_	_
where	_	_
α	_	_
=	_	_
1−	_	_
γµ	_	_
,	_	_
and	_	_
the	_	_
intialization	_	_
is	_	_
x0	_	_
=	_	_
f	_	_
(	_	_
x∗	_	_
)	_	_
.	_	_

#233
Now	_	_
suppose	_	_
that	_	_
we	_	_
perturb	_	_
x0	_	_
as	_	_
x̃0	_	_
=	_	_
x0	_	_
+	_	_
∆x0	_	_
where	_	_
∆x0	_	_
is	_	_
the	_	_
unknown	_	_
perturbation	_	_
.	_	_

#234
This	_	_
in	_	_
turn	_	_
results	_	_
in	_	_
a	_	_
perturbation	_	_
of	_	_
the	_	_
iterates	_	_
as	_	_
follows	_	_
:	_	_
x̃k	_	_
=	_	_
[	_	_
αI	_	_
+	_	_
γ	_	_
(	_	_
I−W	_	_
)	_	_
]	_	_
k	_	_
x̃0	_	_
(	_	_
3.42	_	_
)	_	_
=	_	_
xk	_	_
+	_	_
[	_	_
αI	_	_
+	_	_
γ	_	_
(	_	_
I−W	_	_
)	_	_
]	_	_
k	_	_
∆x0	_	_
(	_	_
3.43	_	_
)	_	_
The	_	_
norm	_	_
of	_	_
the	_	_
error	_	_
after	_	_
k	_	_
iterations	_	_
is	_	_
‖x̃k	_	_
−	_	_
xk‖	_	_
=	_	_
‖	_	_
[	_	_
αI	_	_
+	_	_
γ	_	_
(	_	_
I−W	_	_
)	_	_
]	_	_
k	_	_
∆x0‖	_	_
(	_	_
3.44	_	_
)	_	_
≤	_	_
‖	_	_
[	_	_
αI	_	_
+	_	_
γ	_	_
(	_	_
I−W	_	_
)	_	_
]	_	_
‖k	_	_
‖∆x0‖	_	_
(	_	_
3.45	_	_
)	_	_
≤	_	_
(	_	_
α+	_	_
γ	_	_
(	_	_
1	_	_
+M	_	_
)	_	_
)	_	_
k	_	_
‖∆x0‖	_	_
,	_	_
(	_	_
3.46	_	_
)	_	_
where	_	_
M	_	_
is	_	_
the	_	_
spectral	_	_
radius8	_	_
of	_	_
W.	_	_
Considering	_	_
the	_	_
appropriate	_	_
number	_	_
of	_	_
steps	_	_
8Or	_	_
equivalently	_	_
the	_	_
Lipschitz	_	_
constant	_	_
of	_	_
f	_	_
(	_	_
x	_	_
)	_	_
=	_	_
Wx	_	_
.	_	_

#235
Fig.	_	_
3	_	_
.	_	_

#236
Bound	_	_
on	_	_
the	_	_
distortion	_	_
introduced	_	_
by	_	_
unit	_	_
norm	_	_
error	_	_
in	_	_
measurement	_	_
of	_	_
f	_	_
(	_	_
x∗	_	_
)	_	_
,	_	_
as	_	_
a	_	_
function	_	_
of	_	_
the	_	_
Lipschitz	_	_
constant	_	_
M	_	_
.	_	_

#237
to	_	_
convergence	_	_
,	_	_
we	_	_
have	_	_
γ	_	_
=	_	_
O	_	_
(	_	_
1	_	_
kM	_	_
)	_	_
and	_	_
therefore	_	_
‖x̃k	_	_
−	_	_
xk‖	_	_
≤	_	_
(	_	_
α+	_	_
(	_	_
1	_	_
+M	_	_
)	_	_
kM	_	_
)	_	_
k	_	_
‖∆x0‖	_	_
(	_	_
3.47	_	_
)	_	_
≤	_	_
(	_	_
1	_	_
+	_	_
(	_	_
1	_	_
+M	_	_
)	_	_
kM	_	_
)	_	_
k	_	_
‖∆x0‖	_	_
(	_	_
3.48	_	_
)	_	_
≤	_	_
exp	_	_
(	_	_
1	_	_
+M	_	_
M	_	_
)	_	_
‖∆x0‖	_	_
(	_	_
3.49	_	_
)	_	_
(	_	_
3.50	_	_
)	_	_
The	_	_
exponential	_	_
factor	_	_
(	_	_
see	_	_
Fig.	_	_
3	_	_
)	_	_
grows	_	_
rapidly	_	_
when	_	_
M	_	_
<	_	_
1	_	_
and	_	_
decays	_	_
slowly	_	_
when	_	_
M	_	_
>	_	_
1	_	_
.	_	_

#238
This	_	_
makes	_	_
intuitive	_	_
sense	_	_
:	_	_
strong	_	_
blurring	_	_
operators	_	_
(	_	_
M	_	_
<	_	_
1	_	_
)	_	_
need	_	_
to	_	_
accentuate	_	_
high	_	_
frequencies	_	_
in	_	_
the	_	_
rendition	_	_
,	_	_
and	_	_
this	_	_
will	_	_
amplify	_	_
the	_	_
noise	_	_
.	_	_

#239
On	_	_
the	_	_
other	_	_
hand	_	_
,	_	_
when	_	_
the	_	_
distortions	_	_
are	_	_
strong	_	_
sharpening	_	_
operators	_	_
(	_	_
M	_	_
>	_	_
1	_	_
)	_	_
,	_	_
the	_	_
rendition	_	_
will	_	_
suppress	_	_
high	_	_
frequencies	_	_
,	_	_
which	_	_
in	_	_
turn	_	_
incidentally	_	_
limits	_	_
the	_	_
effect	_	_
of	_	_
noise	_	_
.	_	_

#240
In	_	_
either	_	_
event	_	_
,	_	_
the	_	_
effect	_	_
of	_	_
noise	_	_
is	_	_
bounded	_	_
so	_	_
long	_	_
as	_	_
the	_	_
perturbation	_	_
is	_	_
small	_	_
and	_	_
M	_	_
not	_	_
far	_	_
from	_	_
unity	_	_
.	_	_

#241
Near	_	_
the	_	_
end	_	_
of	_	_
the	_	_
next	_	_
section	_	_
we	_	_
illustrate	_	_
some	_	_
examples	_	_
.	_	_

#242
4	_	_
.	_	_

#243
Experiments	_	_
.	_	_

#244
In	_	_
this	_	_
section	_	_
we	_	_
present	_	_
a	_	_
set	_	_
of	_	_
experiments	_	_
to	_	_
illustrate	_	_
and	_	_
quantify	_	_
the	_	_
ability	_	_
of	_	_
our	_	_
proposed	_	_
method	_	_
to	_	_
recover	_	_
from	_	_
several	_	_
forms	_	_
of	_	_
degradations	_	_
including	_	_
linear	_	_
and	_	_
non-linear	_	_
smoothing	_	_
,	_	_
sharpening	_	_
,	_	_
the	_	_
median	_	_
filter	_	_
,	_	_
tone-mapping	_	_
,	_	_
and	_	_
some	_	_
combinations	_	_
of	_	_
these	_	_
effects	_	_
.	_	_

#245
4.1	_	_
.	_	_

#246
Rendition	_	_
from	_	_
Linear	_	_
and	_	_
Non-linear	_	_
Smoothing	_	_
.	_	_

#247
First	_	_
,	_	_
let’s	_	_
consider	_	_
rendition	_	_
from	_	_
linear	_	_
blur	_	_
.	_	_

#248
In	_	_
Figure	_	_
4	_	_
the	_	_
image	_	_
on	_	_
the	_	_
left	_	_
is	_	_
blurred	_	_
with	_	_
a	_	_
Gaussian	_	_
point	_	_
spread	_	_
function	_	_
of	_	_
radius	_	_
5	_	_
and	_	_
variance	_	_
1	_	_
.	_	_

#249
The	_	_
middle	_	_
image	_	_
shows	_	_
the	_	_
degraded	_	_
image	_	_
.	_	_

#250
The	_	_
image	_	_
on	_	_
the	_	_
right	_	_
hand	_	_
side	_	_
(	_	_
and	_	_
its	_	_
corresponding	_	_
crops	_	_
shown	_	_
)	_	_
are	_	_
recovered	_	_
by	_	_
running	_	_
the	_	_
rendition	_	_
iteration	_	_
for	_	_
35	_	_
steps	_	_
which	_	_
is	_	_
when	_	_
the	_	_
stopping	_	_
criterion	_	_
takes	_	_
effect	_	_
.	_	_

#251
The	_	_
rendition	_	_
has	_	_
improved	_	_
the	_	_
PSNR	_	_
of	_	_
the	_	_
degraded	_	_
image	_	_
signficantly	_	_
from	_	_
23.82dB	_	_
to	_	_
29.92dB	_	_
.	_	_

#252
The	_	_
next	_	_
example	_	_
illustrated	_	_
in	_	_
Figure	_	_
5	_	_
shows	_	_
the	_	_
same	_	_
image	_	_
degraded	_	_
with	_	_
a	_	_
Fig.	_	_
4	_	_
.	_	_

#253
Left	_	_
to	_	_
right	_	_
:	_	_
512×512	_	_
ground	_	_
truth	_	_
image	_	_
;	_	_
blurred	_	_
with	_	_
Gauss	_	_
(	_	_
5,1	_	_
)	_	_
PSNR	_	_
=	_	_
23.82dB	_	_
;	_	_
Rendered	_	_
PSNR	_	_
=	_	_
30.86dB	_	_
.	_	_

#254
35	_	_
iterations	_	_
,	_	_
step	_	_
size	_	_
γ	_	_
=	_	_
0.15.	_	_
Credit	_	_
:	_	_
DxO	_	_
Labs	_	_
disk	_	_
blur	_	_
kernel	_	_
of	_	_
size	_	_
5	_	_
×	_	_
5	_	_
.	_	_

#255
The	_	_
disk	_	_
PSF	_	_
has	_	_
a	_	_
more	_	_
severe	_	_
cutoff	_	_
,	_	_
an	_	_
therefore	_	_
oscillating	_	_
frequency	_	_
response	_	_
which	_	_
destroys	_	_
frequencies	_	_
that	_	_
can	_	_
no	_	_
longer	_	_
be	_	_
recovered	_	_
.	_	_

#256
We	_	_
may	_	_
therefore	_	_
expect	_	_
that	_	_
the	_	_
rendition	_	_
would	_	_
be	_	_
less	_	_
compelling	_	_
than	_	_
the	_	_
Gaussian	_	_
case	_	_
as	_	_
the	_	_
smoothing	_	_
effect	_	_
is	_	_
more	_	_
destructive	_	_
.	_	_

#257
This	_	_
is	_	_
indeed	_	_
the	_	_
observation	_	_
.	_	_

#258
While	_	_
the	_	_
rendition	_	_
converges	_	_
in	_	_
only	_	_
26	_	_
iterations	_	_
,	_	_
the	_	_
final	_	_
result	_	_
has	_	_
improved	_	_
the	_	_
PSNR	_	_
only	_	_
by	_	_
a	_	_
bit	_	_
more	_	_
than	_	_
1dB	_	_
from	_	_
22.46	_	_
to	_	_
23.26dB	_	_
.	_	_

#259
The	_	_
above	_	_
experiments	_	_
illustrate	_	_
that	_	_
we	_	_
can	_	_
recover	_	_
from	_	_
mild	_	_
(	_	_
linear	_	_
)	_	_
blur	_	_
of	_	_
unknown	_	_
nature	_	_
rather	_	_
effectively	_	_
with	_	_
the	_	_
rendition	_	_
algorithm	_	_
.	_	_

#260
The	_	_
next	_	_
set	_	_
of	_	_
experiments	_	_
shows	_	_
what	_	_
is	_	_
a	_	_
more	_	_
surprising	_	_
and	_	_
impressive	_	_
effect	_	_
.	_	_

#261
Namely	_	_
,	_	_
we	_	_
can	_	_
recover	_	_
from	_	_
applying	_	_
a	_	_
non-linear	_	_
filter	_	_
such	_	_
as	_	_
the	_	_
bilateral	_	_
,	_	_
the	_	_
domain	_	_
transform	_	_
,	_	_
or	_	_
even	_	_
the	_	_
median	_	_
filter	_	_
.	_	_

#262
But	_	_
the	_	_
degree	_	_
of	_	_
success	_	_
depends	_	_
upon	_	_
the	_	_
severity	_	_
of	_	_
the	_	_
effect	_	_
and	_	_
the	_	_
type	_	_
of	_	_
distortion	_	_
.	_	_

#263
Let’s	_	_
consider	_	_
the	_	_
bilateral	_	_
filter	_	_
with	_	_
spatial	_	_
and	_	_
range	_	_
parameters	_	_
2	_	_
and	_	_
1.5	_	_
Fig.	_	_
5	_	_
.	_	_

#264
Left	_	_
to	_	_
right	_	_
:	_	_
Left	_	_
to	_	_
right	_	_
:	_	_
512	_	_
×	_	_
512	_	_
ground	_	_
truth	_	_
image	_	_
;	_	_
blurred	_	_
with	_	_
disk	_	_
PSF	_	_
of	_	_
diameter	_	_
5	_	_
PSNR	_	_
=	_	_
22.46dB	_	_
;	_	_
Rendered	_	_
PSNR	_	_
=	_	_
23.64dB	_	_
.	_	_

#265
Converged	_	_
after	_	_
26	_	_
iterations	_	_
,	_	_
step	_	_
size	_	_
γ	_	_
=	_	_
0.15	_	_
respectively	_	_
,	_	_
applied	_	_
to	_	_
the	_	_
image	_	_
in	_	_
Figure	_	_
6	_	_
.	_	_

#266
The	_	_
more	_	_
subtle	_	_
effect	_	_
of	_	_
this	_	_
non-linear	_	_
smoother	_	_
is	_	_
apparent	_	_
in	_	_
removing	_	_
and	_	_
smoothing	_	_
some	_	_
of	_	_
the	_	_
smaller	_	_
scale	_	_
wrinkles	_	_
and	_	_
leaving	_	_
the	_	_
larger	_	_
ones	_	_
mostly	_	_
untouched	_	_
.	_	_

#267
The	_	_
rendition	_	_
after	_	_
22	_	_
iterations	_	_
shows	_	_
many	_	_
of	_	_
the	_	_
small	_	_
scale	_	_
features	_	_
on	_	_
the	_	_
face	_	_
returned	_	_
to	_	_
the	_	_
image	_	_
.	_	_

#268
While	_	_
of	_	_
coure	_	_
the	_	_
rendition	_	_
is	_	_
not	_	_
expected	_	_
to	_	_
be	_	_
perfect	_	_
,	_	_
we	_	_
do	_	_
observe	_	_
an	_	_
impressive	_	_
increase	_	_
in	_	_
PSNR	_	_
of	_	_
more	_	_
than	_	_
8dB	_	_
.	_	_

#269
The	_	_
next	_	_
example	_	_
shown	_	_
in	_	_
Figure	_	_
7	_	_
illustrates	_	_
a	_	_
median	_	_
filter	_	_
of	_	_
support	_	_
2	_	_
×	_	_
2	_	_
applied	_	_
to	_	_
the	_	_
image	_	_
shown	_	_
on	_	_
the	_	_
left	_	_
.	_	_

#270
We	_	_
choose	_	_
this	_	_
image	_	_
in	_	_
particular	_	_
for	_	_
this	_	_
example	_	_
since	_	_
it	_	_
contains	_	_
many	_	_
small	_	_
scale	_	_
features	_	_
that	_	_
stand	_	_
out	_	_
from	_	_
their	_	_
surroundings	_	_
(	_	_
i.e.	_	_
apparent	_	_
outliers	_	_
)	_	_
.	_	_

#271
Removing	_	_
outliers	_	_
is	_	_
something	_	_
the	_	_
median	_	_
filter	_	_
is	_	_
good	_	_
at	_	_
.	_	_

#272
The	_	_
smoothing	_	_
effect	_	_
is	_	_
apparent	_	_
in	_	_
the	_	_
middle	_	_
column	_	_
.	_	_

#273
In	_	_
the	_	_
right	_	_
side	_	_
column	_	_
,	_	_
the	_	_
rendered	_	_
image	_	_
and	_	_
crops	_	_
can	_	_
be	_	_
seen	_	_
.	_	_

#274
We	_	_
note	_	_
that	_	_
while	_	_
the	_	_
effect	_	_
Fig.	_	_
6	_	_
.	_	_

#275
Left	_	_
to	_	_
right	_	_
:	_	_
Ground	_	_
truth	_	_
image	_	_
,	_	_
Smoothed	_	_
with	_	_
Bilateral	_	_
(	_	_
x,2,1.5	_	_
)	_	_
PSNR	_	_
=	_	_
30.00dB	_	_
;	_	_
Rendered	_	_
PSNR	_	_
=	_	_
38.22dB	_	_
,	_	_
22	_	_
iterations	_	_
,	_	_
step	_	_
size	_	_
γ	_	_
=	_	_
0.15	_	_
is	_	_
to	_	_
sharpen	_	_
the	_	_
image	_	_
,	_	_
the	_	_
small	_	_
outliers	_	_
removed	_	_
are	_	_
not	_	_
effectively	_	_
returned	_	_
to	_	_
the	_	_
image	_	_
.	_	_

#276
Even	_	_
so	_	_
,	_	_
the	_	_
PSNR	_	_
has	_	_
improved	_	_
by	_	_
about	_	_
3.5dB	_	_
.	_	_

#277
It	_	_
is	_	_
reasonable	_	_
to	_	_
wonder	_	_
how	_	_
far	_	_
the	_	_
effects	_	_
illustrated	_	_
here	_	_
can	_	_
be	_	_
pushed	_	_
in	_	_
their	_	_
severity	_	_
and	_	_
to	_	_
ask	_	_
whether	_	_
we	_	_
can	_	_
still	_	_
get	_	_
a	_	_
reasonable	_	_
rendition	_	_
.	_	_

#278
To	_	_
answer	_	_
these	_	_
question	_	_
,	_	_
we	_	_
carry	_	_
out	_	_
an	_	_
experiment	_	_
shown	_	_
in	_	_
Fig.	_	_
8	_	_
where	_	_
the	_	_
strength	_	_
of	_	_
the	_	_
bilateral	_	_
filter	_	_
applied	_	_
to	_	_
the	_	_
photo	_	_
of	_	_
flowers	_	_
is	_	_
increased	_	_
exponentially	_	_
in	_	_
each	_	_
row	_	_
.	_	_

#279
Not	_	_
only	_	_
are	_	_
the	_	_
parameters	_	_
of	_	_
the	_	_
bilateral	_	_
filter	_	_
doubled	_	_
each	_	_
time	_	_
,	_	_
but	_	_
the	_	_
resulting	_	_
filter	_	_
is	_	_
also	_	_
applied	_	_
more	_	_
times	_	_
in	_	_
each	_	_
case	_	_
.	_	_

#280
What	_	_
we	_	_
observe	_	_
,	_	_
not	_	_
surprisingly	_	_
,	_	_
is	_	_
that	_	_
the	_	_
effect	_	_
of	_	_
the	_	_
rendition	_	_
is	_	_
less	_	_
impressive	_	_
in	_	_
terms	_	_
of	_	_
recovering	_	_
the	_	_
original	_	_
image	_	_
.	_	_

#281
Still	_	_
,	_	_
it	_	_
must	deontic-rhetorical	_
be	_	_
said	_	_
that	_	_
the	_	_
effect	_	_
is	_	_
not	_	_
without	_	_
merit	_	_
.	_	_

#282
In	_	_
fact	_	_
,	_	_
it	_	_
is	_	_
compelling	_	_
to	_	_
see	_	_
that	_	_
the	_	_
rendition	_	_
does	_	_
provide	_	_
sharper	_	_
images	_	_
with	_	_
more	_	_
well-defined	_	_
features	_	_
,	_	_
even	_	_
when	_	_
the	_	_
filter	_	_
is	_	_
quite	_	_
severe	_	_
.	_	_

#283
4.2.	_	_
Rendition	_	_
from	_	_
Tone-mapping	_	_
,	_	_
Sharpening	_	_
,	_	_
and	_	_
Composite	_	_
Effects	_	_
.	_	_

#284
As	_	_
we	_	_
advertised	_	_
earlier	_	_
in	_	_
the	_	_
paper	_	_
,	_	_
one	_	_
of	_	_
the	_	_
compelling	_	_
reasons	_	_
why	_	_
rendition	_	_
is	_	_
both	_	_
simple	_	_
and	_	_
useful	_	_
is	_	_
that	_	_
it	_	_
is	_	_
effective	_	_
for	_	_
reversing	_	_
non-contractive	_	_
effects	_	_
.	_	_

#285
Let’s	_	_
consider	_	_
a	_	_
common	_	_
operation	_	_
that	_	_
is	_	_
used	_	_
to	_	_
change	_	_
the	_	_
look	_	_
of	_	_
an	_	_
image	_	_
;	_	_
namely	_	_
tone-mapping	_	_
.	_	_

#286
As	_	_
illustrated	_	_
in	_	_
Fig.	_	_
10	_	_
,	_	_
the	_	_
image	_	_
on	_	_
the	_	_
left	_	_
is	_	_
passed	_	_
(	_	_
in	_	_
all	_	_
three	_	_
color	_	_
channels	_	_
)	_	_
through	_	_
a	_	_
nonlinear	_	_
tone-mapping	_	_
transformation	_	_
described	_	_
in	_	_
equation	_	_
(	_	_
A.1	_	_
)	_	_
with	_	_
parameter	_	_
a	_	_
=	_	_
0.2	_	_
.	_	_

#287
The	_	_
shape	_	_
of	_	_
this	_	_
function	_	_
can	_	_
be	_	_
inferred	_	_
in	_	_
Figure	_	_
17	_	_
.	_	_

#288
The	_	_
rendition	_	_
from	_	_
this	_	_
tone-mapped	_	_
image	_	_
is	_	_
seen	_	_
to	_	_
agree	_	_
quite	_	_
well	_	_
with	_	_
the	_	_
ground	_	_
truth	_	_
image	_	_
,	_	_
as	_	_
confirmed	_	_
by	_	_
the	_	_
PSNR	_	_
of	_	_
35.87	_	_
,	_	_
which	_	_
is	_	_
more	_	_
than	_	_
15	_	_
dB	_	_
improvement	_	_
over	_	_
the	_	_
given	_	_
image	_	_
.	_	_

#289
Next	_	_
,	_	_
we	_	_
consider	_	_
the	_	_
case	_	_
where	_	_
the	_	_
image	_	_
in	_	_
Fig.	_	_
11	_	_
is	_	_
sharpened	_	_
using	_	_
a	_	_
(	_	_
nonlinear	_	_
)	_	_
unsharp	_	_
mask	_	_
which	_	_
employs	_	_
the	_	_
bilateral	_	_
filter	_	_
.	_	_

#290
Namely	_	_
,	_	_
f	_	_
(	_	_
x∗	_	_
)	_	_
=	_	_
x∗	_	_
+	_	_
(	_	_
x∗	_	_
−	_	_
Fig.	_	_
11	_	_
.	_	_

#291
Left	_	_
to	_	_
right	_	_
:	_	_
Ground	_	_
truth	_	_
image	_	_
,	_	_
Sharpened	_	_
with	_	_
2x	_	_
-	_	_
Bilat	_	_
(	_	_
x,2,1.5	_	_
)	_	_
PSNR	_	_
=	_	_
30.46dB	_	_
,	_	_
Rendered	_	_
PSNR	_	_
=	_	_
45.60dB	_	_
.	_	_

#292
13	_	_
iterations	_	_
,	_	_
step	_	_
size	_	_
γ	_	_
=	_	_
0.15	_	_
bilat	_	_
(	_	_
x∗	_	_
,	_	_
2	_	_
,	_	_
1.5	_	_
)	_	_
)	_	_
.	_	_

#293
We	_	_
seek	_	_
to	_	_
render	_	_
x∗	_	_
.	_	_

#294
The	_	_
ground	_	_
truth	_	_
x∗	_	_
,	_	_
the	_	_
given	_	_
image	_	_
f	_	_
(	_	_
x∗	_	_
)	_	_
,	_	_
and	_	_
the	_	_
rendered	_	_
solution	_	_
are	_	_
shown	_	_
respectively	_	_
in	_	_
the	_	_
left	_	_
,	_	_
center	_	_
,	_	_
and	_	_
right	_	_
panels	_	_
of	_	_
Fig.	_	_
11	_	_
.	_	_

#295
The	_	_
rendition	_	_
improves	_	_
the	_	_
PSNR	_	_
by	_	_
a	_	_
significant	_	_
15	_	_
dB	_	_
margin	_	_
.	_	_

#296
In	_	_
the	_	_
next	_	_
experiment	_	_
,	_	_
we	_	_
employ	_	_
not	_	_
only	_	_
a	_	_
more	_	_
severe	_	_
sharpening	_	_
,	_	_
but	_	_
also	_	_
apply	_	_
a	_	_
strong	_	_
gamma	_	_
tone	_	_
curve	_	_
to	_	_
produce	_	_
the	_	_
given	_	_
image	_	_
as	_	_
follows	_	_
:	_	_
f	_	_
(	_	_
x∗	_	_
)	_	_
=	_	_
(	_	_
x∗	_	_
+	_	_
(	_	_
x∗	_	_
−	_	_
bilat	_	_
(	_	_
x∗	_	_
,	_	_
10	_	_
,	_	_
3	_	_
)	_	_
)	_	_
0.65	_	_
.	_	_

#297
It	_	_
is	_	_
quite	_	_
encouraging	_	_
to	_	_
observe	_	_
that	_	_
the	_	_
rendition	_	_
is	_	_
a	_	_
very	_	_
close	_	_
visual	_	_
approximation	_	_
of	_	_
the	_	_
ground	_	_
truth	_	_
image	_	_
,	_	_
with	_	_
a	_	_
corresponding	_	_
PSNR	_	_
of	_	_
33.26	_	_
dB	_	_
,	_	_
having	_	_
boosted	_	_
the	_	_
PSNR	_	_
by	_	_
more	_	_
than	_	_
16	_	_
dB	_	_
.	_	_

#298
Fig.	_	_
12	_	_
.	_	_

#299
Left	_	_
to	_	_
right	_	_
:	_	_
Ground	_	_
truth	_	_
image	_	_
,	_	_
Sharpened	_	_
and	_	_
gamma	_	_
corrected	_	_
with	_	_
(	_	_
2x	_	_
−	_	_
Bilat	_	_
(	_	_
x	_	_
,	_	_
10	_	_
,	_	_
3	_	_
)	_	_
)	_	_
0.65	_	_
PSNR	_	_
17.19dB	_	_
.	_	_

#300
Rendered	_	_
PSNR	_	_
33.26dB	_	_
.	_	_

#301
24	_	_
iterations	_	_
,	_	_
step	_	_
size	_	_
γ	_	_
=	_	_
0.15	_	_
Fig.	_	_
13	_	_
.	_	_

#302
An	_	_
example	_	_
of	_	_
an	_	_
expected	_	_
failed	_	_
rendition	_	_
with	_	_
M̂	_	_
=	_	_
0.67	_	_
.	_	_

#303
Left	_	_
:	_	_
Ground	_	_
truth	_	_
,	_	_
Middle	_	_
:	_	_
Cartoonized	_	_
[	_	_
30	_	_
]	_	_
.	_	_

#304
Right	_	_
:	_	_
Best	_	_
possible	_	_
rendition	_	_
shown	_	_
after	_	_
15	_	_
iterations	_	_
.	_	_

#305
Stopped	_	_
manually	_	_
.	_	_

#306
PSNR	_	_
improves	_	_
only	_	_
from	_	_
15.56	_	_
to	_	_
15.84	_	_
dB	_	_
,	_	_
and	_	_
there	_	_
is	_	_
no	_	_
visual	_	_
improvement	_	_
.	_	_

#307
Continuing	_	_
iterations	_	_
results	_	_
in	_	_
worsening	_	_
of	_	_
results	_	_
–	_	_
a	_	_
failed	_	_
rendition	_	_
.	_	_

#308
4.3	_	_
.	_	_

#309
Effect	_	_
of	_	_
strong	_	_
perturbations	_	_
and	_	_
noise	_	_
.	_	_

#310
As	_	_
we	_	_
noted	_	_
in	_	_
earlier	_	_
sections	_	_
,	_	_
there	_	_
are	_	_
two	_	_
scenarios	_	_
in	_	_
which	_	_
one	_	_
can	_	_
expect	_	_
the	_	_
rendition	_	_
results	_	_
to	_	_
either	_	_
fail	_	_
completely	_	_
,	_	_
or	_	_
depart	_	_
visually	_	_
from	_	_
the	_	_
sought-after	_	_
image	_	_
.	_	_

#311
The	_	_
first	_	_
occurs	_	_
if	_	_
the	_	_
perturbation	_	_
is	_	_
very	_	_
strong	_	_
;	_	_
the	_	_
second	_	_
,	_	_
when	_	_
the	_	_
given	_	_
image	_	_
is	_	_
disturbed	_	_
by	_	_
noise	_	_
or	_	_
error	_	_
.	_	_

#312
We	_	_
examine	_	_
these	_	_
scenarios	_	_
here	_	_
with	_	_
a	_	_
few	_	_
experiments	_	_
.	_	_

#313
First	_	_
,	_	_
let’s	_	_
show	_	_
a	_	_
clear	_	_
example	_	_
where	_	_
rendition	_	_
simply	_	_
fails	_	_
to	_	_
improve	_	_
the	_	_
result	_	_
at	_	_
all	_	_
.	_	_

#314
In	_	_
Figure	_	_
13	_	_
we	_	_
illustrate	_	_
a	_	_
cartoonization	_	_
filter	_	_
[	_	_
30	_	_
]	_	_
applied	_	_
to	_	_
the	_	_
flower	_	_
image	_	_
.	_	_

#315
This	_	_
effect	_	_
is	_	_
clearly	_	_
very	_	_
strong	_	_
,	_	_
producing	_	_
large	_	_
areas	_	_
of	_	_
piecewise	_	_
constant	_	_
brightness	_	_
and	_	_
color	_	_
.	_	_

#316
We	_	_
would	_	_
not	_	_
expect	_	_
the	_	_
rendition	_	_
to	_	_
be	_	_
successful	_	_
.	_	_

#317
The	_	_
best	_	_
possible	_	_
rendition	_	_
(	_	_
in	_	_
terms	_	_
of	_	_
PSNR	_	_
)	_	_
is	_	_
shown	_	_
after	_	_
15	_	_
iterations	_	_
,	_	_
where	_	_
the	_	_
process	_	_
was	_	_
terminated	_	_
manually	_	_
.	_	_

#318
The	_	_
PSNR	_	_
improves	_	_
insignificantly	_	_
from	_	_
15.56	_	_
to	_	_
15.84	_	_
dB	_	_
,	_	_
and	_	_
there	_	_
is	_	_
no	_	_
apparent	_	_
visual	_	_
improvement	_	_
.	_	_

#319
Continuing	_	_
iterations	_	_
results	_	_
in	_	_
worsening	_	_
of	_	_
results	_	_
–	_	_
a	_	_
failed	_	_
rendition	_	_
.	_	_

#320
Next	_	_
,	_	_
we	_	_
illustrate	_	_
the	_	_
effect	_	_
of	_	_
noise	_	_
on	_	_
the	_	_
results	_	_
shown	_	_
in	_	_
the	_	_
previous	_	_
experiments	_	_
in	_	_
this	_	_
section	_	_
.	_	_

#321
As	_	_
we	_	_
demonstrated	_	_
in	_	_
eq	_	_
.	_	_

#322
(	_	_
3.47	_	_
)	_	_
,	_	_
with	_	_
adequate	_	_
number	_	_
of	_	_
iterations	_	_
,	_	_
the	_	_
effect	_	_
of	_	_
perturbation	_	_
can	_	_
be	_	_
bounded	_	_
,	_	_
but	_	_
still	_	_
significant	_	_
.	_	_

#323
In	_	_
the	_	_
experiments	_	_
shown	_	_
in	_	_
Fig	_	_
14	_	_
,	_	_
we	_	_
can	_	_
see	_	_
how	_	_
rendition	_	_
from	_	_
(	_	_
Gaussian	_	_
and	_	_
Disk	_	_
)	_	_
blur	_	_
are	_	_
impacted	_	_
by	_	_
noise	_	_
.	_	_

#324
The	_	_
variance	_	_
of	_	_
the	_	_
noise	_	_
here	_	_
is	_	_
moderate	_	_
at	_	_
0.05	_	_
,	_	_
already	_	_
reducing	_	_
the	_	_
PSNR	_	_
of	_	_
the	_	_
starting	_	_
image	_	_
by	_	_
2	_	_
−	_	_
3	_	_
dB	_	_
.	_	_

#325
It	_	_
is	_	_
interesting	_	_
to	_	_
note	_	_
that	_	_
in	_	_
the	_	_
resulting	_	_
renditions	_	_
,	_	_
the	_	_
effect	_	_
of	_	_
the	_	_
black	_	_
box	_	_
appears	_	_
to	_	_
be	_	_
reversed	_	_
,	_	_
but	_	_
remnants	_	_
the	_	_
noise	_	_
survive	_	_
in	_	_
the	_	_
result	_	_
.	_	_

#326
In	_	_
Fig.	_	_
15	_	_
,	_	_
we	_	_
illustrate	_	_
the	_	_
effect	_	_
of	_	_
noise	_	_
on	_	_
rendition	_	_
from	_	_
images	_	_
either	_	_
smoothed	_	_
,	_	_
or	_	_
sharpened	_	_
by	_	_
the	_	_
bilateral	_	_
filter	_	_
,	_	_
and	_	_
in	_	_
the	_	_
latter	_	_
case	_	_
,	_	_
also	_	_
tone	_	_
mapped	_	_
.	_	_

#327
As	_	_
expected	_	_
,	_	_
the	_	_
effect	_	_
of	_	_
noise	_	_
on	_	_
the	_	_
rendition	_	_
is	_	_
milder	_	_
when	_	_
the	_	_
black	_	_
box	_	_
operator	_	_
is	_	_
sharpening	_	_
,	_	_
and	_	_
more	_	_
noticeable	_	_
when	_	_
the	_	_
operator	_	_
is	_	_
purely	_	_
smoothing	_	_
.	_	_

#328
Finally	_	_
,	_	_
in	_	_
Fig.	_	_
16	_	_
we	_	_
show	_	_
the	_	_
effect	_	_
of	_	_
noise	_	_
on	_	_
the	_	_
rendition	_	_
from	_	_
the	_	_
median	_	_
filter	_	_
,	_	_
direct	_	_
tone-mapping	_	_
,	_	_
and	_	_
a	_	_
very	_	_
strong	_	_
bilateral	_	_
filter	_	_
.	_	_

#329
All	_	_
the	_	_
black	_	_
box	_	_
operators	_	_
here	_	_
are	_	_
difficult	_	_
to	_	_
invert	_	_
,	_	_
and	_	_
the	_	_
effect	_	_
of	_	_
noise	_	_
doesn’t	_	_
help	_	_
matters	_	_
.	_	_

#330
In	_	_
particular	_	_
,	_	_
note	_	_
that	_	_
in	_	_
the	_	_
case	_	_
of	_	_
the	_	_
median	_	_
filter	_	_
,	_	_
the	_	_
given	_	_
image	_	_
is	_	_
already	_	_
noisy	_	_
,	_	_
and	_	_
we	_	_
are	_	_
studying	_	_
what	_	_
happens	_	_
when	_	_
we	_	_
add	_	_
even	_	_
more	_	_
noise	_	_
.	_	_

#331
All	_	_
the	_	_
above	_	_
observations	_	_
are	_	_
consistent	_	_
with	_	_
the	_	_
bounds	_	_
in	_	_
(	_	_
3.47	_	_
)	_	_
.	_	_

#332
Fig.	_	_
14	_	_
.	_	_

#333
Effect	_	_
of	_	_
Gaussian	_	_
white	_	_
noise	_	_
with	_	_
standard	_	_
deviation	_	_
0.05	_	_
(	_	_
on	_	_
a	_	_
scale	_	_
of	_	_
0	_	_
to	_	_
1	_	_
)	_	_
on	_	_
rendition	_	_
from	_	_
blurring	_	_
with	_	_
(	_	_
first	_	_
row	_	_
)	_	_
Gaussian	_	_
and	_	_
(	_	_
second	_	_
row	_	_
)	_	_
Disk	_	_
kernels	_	_
,	_	_
respectively	_	_
.	_	_

#334
Fig.	_	_
15	_	_
.	_	_

#335
Effect	_	_
of	_	_
Gaussian	_	_
white	_	_
noise	_	_
with	_	_
standard	_	_
deviation	_	_
0.05	_	_
on	_	_
rendition	_	_
from	_	_
bilateral	_	_
(	_	_
top	_	_
row	_	_
)	_	_
smoothing	_	_
,	_	_
(	_	_
middle	_	_
row	_	_
)	_	_
sharpening	_	_
,	_	_
and	_	_
(	_	_
bottom	_	_
row	_	_
)	_	_
combined	_	_
sharpening	_	_
and	_	_
tonemapping	_	_
.	_	_

#336
Fig.	_	_
16	_	_
.	_	_

#337
Effect	_	_
of	_	_
Gaussian	_	_
white	_	_
noise	_	_
with	_	_
standard	_	_
deviation	_	_
0.05	_	_
on	_	_
rendition	_	_
from	_	_
(	_	_
top	_	_
row	_	_
)	_	_
median	_	_
filter	_	_
,	_	_
(	_	_
middle	_	_
row	_	_
)	_	_
direct	_	_
tone-mapping	_	_
,	_	_
(	_	_
bottom	_	_
row	_	_
)	_	_
strong	_	_
bilateral	_	_
filter	_	_
.	_	_

#338
5	_	_
.	_	_

#339
Remarks	_	_
and	_	_
Conclusions	_	_
.	_	_

#340
In	_	_
this	_	_
final	_	_
section	_	_
,	_	_
we	_	_
summarize	_	_
again	_	_
our	_	_
contributions	_	_
,	_	_
and	_	_
note	_	_
several	_	_
areas	_	_
of	_	_
further	_	_
investigation	_	_
worth	_	_
considering	_	_
.	_	_

#341
•	_	_
As	_	_
we	_	_
described	_	_
in	_	_
the	_	_
introduction	_	_
,	_	_
the	_	_
premise	_	_
of	_	_
the	_	_
rendition	_	_
problem	_	_
is	_	_
very	_	_
familiar	_	_
–	_	_
namely	_	_
,	_	_
we	_	_
wish	_	_
to	_	_
invert	_	_
the	_	_
effect	_	_
of	_	_
an	_	_
incompletely	_	_
known	_	_
process	_	_
.	_	_

#342
The	_	_
problem	_	_
we’ve	_	_
addressed	_	_
here	_	_
is	_	_
quite	_	_
different	_	_
from	_	_
a	_	_
standard	_	_
inverse	_	_
problem	_	_
in	_	_
several	_	_
respects	_	_
.	_	_

#343
First	_	_
,	_	_
we	_	_
have	_	_
not	_	_
assumed	_	_
a	_	_
functional	_	_
form	_	_
(	_	_
e.g.	_	_
model	_	_
)	_	_
for	_	_
the	_	_
degradation	_	_
process	_	_
.	_	_

#344
Second	_	_
,	_	_
we	_	_
are	_	_
not	_	_
addressing	_	_
the	_	_
inversion	_	_
of	_	_
a	_	_
necessarily	_	_
physical	_	_
forward	_	_
process	_	_
.	_	_

#345
Third	_	_
,	_	_
we	_	_
have	_	_
not	_	_
taken	_	_
advantage	_	_
of	_	_
any	_	_
regularization	_	_
which	_	_
would	_	_
implicitly	_	_
bring	_	_
in	_	_
prior	_	_
information	_	_
about	_	_
the	_	_
class	_	_
of	_	_
images	_	_
we	_	_
seek	_	_
to	_	_
reconstruct	_	_
.	_	_

#346
As	_	_
such	_	_
,	_	_
the	_	_
description	_	_
of	_	_
our	_	_
problem	_	_
is	_	_
rather	_	_
bare	_	_
bones	_	_
and	_	_
somewhat	_	_
unorthodox	_	_
;	_	_
as	_	_
is	_	_
the	_	_
solution	_	_
.	_	_

#347
•	_	_
We	_	_
make	_	_
weak	_	_
assumptions	_	_
(	_	_
Lipschitz	_	_
)	_	_
on	_	_
the	_	_
forward	_	_
operator	_	_
that	_	_
distorts	_	_
the	_	_
image	_	_
of	_	_
interest	_	_
,	_	_
and	_	_
assume	_	_
access	_	_
only	_	_
to	_	_
evaluation	_	_
of	_	_
this	_	_
operator	_	_
,	_	_
not	_	_
its	_	_
“insides”	_	_
.	_	_

#348
We	_	_
proved	_	_
that	_	_
as	_	_
long	_	_
as	_	_
the	_	_
damage	_	_
done	_	_
by	_	_
this	_	_
operator	_	_
to	_	_
the	_	_
unobserved	_	_
input	_	_
is	_	_
not	_	_
too	_	_
heavy	_	_
,	_	_
we	_	_
can	_	_
roughly	_	_
undo	_	_
its	_	_
effect	_	_
and	_	_
recover	_	_
a	_	_
good	_	_
rendition	_	_
of	_	_
the	_	_
input	_	_
.	_	_

#349
Notably	_	_
,	_	_
we	_	_
showed	_	_
that	_	_
the	_	_
resulting	_	_
algorithm	_	_
becomes	_	_
very	_	_
simple	_	_
,	_	_
resembling	_	_
a	_	_
fixed	_	_
point	_	_
operation	_	_
.	_	_

#350
However	_	_
,	_	_
this	_	_
algorithm	_	_
is	_	_
shown	_	_
to	_	_
be	_	_
convergent	_	_
for	_	_
a	_	_
far	_	_
wider	_	_
class	_	_
of	_	_
perturbations	_	_
than	_	_
simply	_	_
“contractive”	_	_
ones	_	_
.	_	_

#351
Indeed	_	_
,	_	_
a	_	_
very	_	_
large	_	_
variety	_	_
of	_	_
practical	_	_
operations	_	_
such	_	_
as	_	_
nonlinear	_	_
local	_	_
sharpening	_	_
and	_	_
tone-mapping	_	_
which	_	_
are	_	_
applied	_	_
by	_	_
image	_	_
processing	_	_
pipelines	_	_
are	_	_
non-contractive	_	_
,	_	_
yet	_	_
apparently	_	_
reversible	_	_
so	_	_
long	_	_
as	_	_
these	_	_
effects	_	_
are	_	_
not	_	_
too	_	_
strong	_	_
.	_	_

#352
•	_	_
A	_	_
final	_	_
question	_	_
worth	_	_
asking	_	_
is	_	_
whether	_	_
standard	_	_
approaches	_	_
to	_	_
solving	_	_
inverse	_	_
problems	_	_
such	_	_
as	_	_
regularization	_	_
are	_	_
still	_	_
relevant	_	_
to	_	_
rendition	_	_
.	_	_

#353
Conceptually	_	_
,	_	_
the	_	_
answer	_	_
is	_	_
yes	_	_
;	_	_
but	_	_
it	_	_
is	_	_
less	_	_
clear	_	_
how	_	_
effective	_	_
regularization	_	_
would	_	_
be	_	_
.	_	_

#354
Consider	_	_
a	_	_
regularization	_	_
term	_	_
added	_	_
to	_	_
our	_	_
rendition	_	_
loss	_	_
function	_	_
:	_	_
Jλ	_	_
(	_	_
x	_	_
)	_	_
=	_	_
φ	_	_
(	_	_
x	_	_
)	_	_
+	_	_
λ	_	_
ρ	_	_
(	_	_
x	_	_
)	_	_
(	_	_
5.1	_	_
)	_	_
=	_	_
xT	_	_
(	_	_
f	_	_
(	_	_
x	_	_
)	_	_
−	_	_
f	_	_
(	_	_
x∗	_	_
)	_	_
)	_	_
−	_	_
1	_	_
xTx	_	_
+	_	_
λ	_	_
ρ	_	_
(	_	_
x	_	_
)	_	_
(	_	_
5.2	_	_
)	_	_
The	_	_
regularization	_	_
term	_	_
with	_	_
strength	_	_
λ	_	_
can	_	_
take	_	_
any	_	_
number	_	_
of	_	_
forms	_	_
as	_	_
usual	_	_
.	_	_

#355
A	_	_
particularly	_	_
straightforward	_	_
case	_	_
to	_	_
analyze	_	_
arises	_	_
if	_	_
we	_	_
use	_	_
the	_	_
framework	_	_
of	_	_
regularization	_	_
by	_	_
denoising	_	_
(	_	_
RED	_	_
)	_	_
[	_	_
23	_	_
]	_	_
.	_	_

#356
This	_	_
form	_	_
of	_	_
regularization	_	_
can	_	_
take	_	_
advantage	_	_
of	_	_
any	_	_
denoising	_	_
(	_	_
smoothing	_	_
,	_	_
non-expansive	_	_
)	_	_
function	_	_
s	_	_
(	_	_
x	_	_
)	_	_
.	_	_

#357
The	_	_
RED	_	_
regularizer	_	_
(	_	_
which	_	_
is	_	_
convex	_	_
)	_	_
,	_	_
and	_	_
its	_	_
gradient	_	_
[	_	_
23	_	_
]	_	_
are	_	_
ρ	_	_
(	_	_
x	_	_
)	_	_
=	_	_
xT	_	_
(	_	_
x−	_	_
s	_	_
(	_	_
x	_	_
)	_	_
)	_	_
,	_	_
(	_	_
5.3	_	_
)	_	_
∇ρ	_	_
(	_	_
x	_	_
)	_	_
=	_	_
x−	_	_
s	_	_
(	_	_
x	_	_
)	_	_
.	_	_

#358
(	_	_
5.4	_	_
)	_	_
Therefore	_	_
,	_	_
the	_	_
gradient	_	_
of	_	_
the	_	_
regularized	_	_
loss	_	_
Jλ	_	_
(	_	_
x	_	_
)	_	_
is	_	_
∇Jλ	_	_
(	_	_
x	_	_
)	_	_
=	_	_
∇φ	_	_
(	_	_
x	_	_
)	_	_
+	_	_
λ∇ρ	_	_
(	_	_
x	_	_
)	_	_
(	_	_
5.5	_	_
)	_	_
=	_	_
f	_	_
(	_	_
x	_	_
)	_	_
−	_	_
f	_	_
(	_	_
x∗	_	_
)	_	_
+	_	_
µ	_	_
x	_	_
+	_	_
λ	_	_
(	_	_
x−	_	_
s	_	_
(	_	_
x	_	_
)	_	_
)	_	_
(	_	_
5.6	_	_
)	_	_
And	_	_
hence	_	_
,	_	_
the	_	_
gradient	_	_
descent	_	_
applied	_	_
to	_	_
the	_	_
regularized	_	_
loss	_	_
is	_	_
given	_	_
by	_	_
(	_	_
5.7	_	_
)	_	_
xk+1	_	_
=	_	_
xk	_	_
−	_	_
γ	_	_
[	_	_
f	_	_
(	_	_
xk	_	_
)	_	_
−	_	_
f	_	_
(	_	_
x∗	_	_
)	_	_
+	_	_
µx	_	_
+	_	_
λ	_	_
(	_	_
xk	_	_
−	_	_
s	_	_
(	_	_
xk	_	_
)	_	_
)	_	_
]	_	_
We	_	_
can	_	_
rewrite	_	_
this	_	_
algorithm	_	_
in	_	_
a	_	_
way	_	_
that	_	_
is	_	_
more	_	_
illuminating	_	_
:	_	_
(	_	_
5.8	_	_
)	_	_
xk+1	_	_
=	_	_
(	_	_
1−	_	_
γ	_	_
(	_	_
µ+	_	_
λ	_	_
)	_	_
)	_	_
xk	_	_
+	_	_
γλ	_	_
s	_	_
(	_	_
xk	_	_
)	_	_
−	_	_
γ	_	_
[	_	_
f	_	_
(	_	_
xk	_	_
)	_	_
−	_	_
f	_	_
(	_	_
x∗	_	_
)	_	_
]	_	_
In	_	_
comparison	_	_
to	_	_
the	_	_
un-regularized	_	_
solution	_	_
(	_	_
λ	_	_
=	_	_
0	_	_
)	_	_
originally	_	_
shown	_	_
in	_	_
(	_	_
3.31	_	_
)	_	_
,	_	_
we	_	_
note	_	_
that	_	_
the	_	_
dampening	_	_
in	_	_
the	_	_
first	_	_
term	_	_
(	_	_
xk	_	_
)	_	_
on	_	_
the	_	_
right-hand-side	_	_
has	_	_
been	_	_
strengthened	_	_
,	_	_
and	_	_
a	_	_
second	_	_
smoothing	_	_
term	_	_
γλs	_	_
(	_	_
xk	_	_
)	_	_
has	_	_
been	_	_
added	_	_
.	_	_

#359
The	_	_
residual	_	_
term	_	_
(	_	_
which	_	_
does	_	_
most	_	_
of	_	_
the	_	_
work	_	_
in	_	_
rendition	_	_
)	_	_
meanwhile	_	_
remains	_	_
unaffected	_	_
.	_	_

#360
Therefore	_	_
,	_	_
while	_	_
the	_	_
iterative	_	_
procedure	_	_
is	_	_
expected	_	_
to	_	_
me	_	_
more	_	_
robust	_	_
,	_	_
we	_	_
would	_	_
not	_	_
expect	_	_
this	_	_
change	_	_
to	_	_
have	_	_
a	_	_
big	_	_
impact	_	_
on	_	_
improving	_	_
the	_	_
visual	_	_
quality	_	_
of	_	_
the	_	_
rendition	_	_
.	_	_

#361
Our	_	_
preliminary	_	_
experiments	_	_
confirm	_	_
this	_	_
observation	_	_
.	_	_

#362
Further	_	_
analysis	_	_
of	_	_
convergence	_	_
,	_	_
along	_	_
with	_	_
the	_	_
use	_	_
of	_	_
different	_	_
regularization	_	_
functions	_	_
may	_	_
still	_	_
be	_	_
worth	_	_
investigating	_	_
.	_	_

#363
Appendix	_	_
A	_	_
.	_	_

#364
Example	_	_
computations	_	_
of	_	_
the	_	_
Lipschitz	_	_
constant	_	_
.	_	_

#365
•	_	_
Linear	_	_
Filtering	_	_
:	_	_
–	_	_
Let	_	_
f	_	_
(	_	_
x	_	_
)	_	_
=	_	_
blur	_	_
(	_	_
x	_	_
,	_	_
h	_	_
)	_	_
where	_	_
h	_	_
is	_	_
a	_	_
point-spread	_	_
function	_	_
.	_	_

#366
Using9	_	_
h	_	_
=	_	_
fspecial	_	_
(	_	_
’gaussian’,2,1	_	_
)	_	_
,	_	_
we	_	_
have	_	_
a	_	_
2×2	_	_
box	_	_
filter	_	_
which	_	_
yields	_	_
M̂	_	_
=	_	_
0.867	_	_
.	_	_

#367
Increasing	_	_
the	_	_
blur	_	_
strength	_	_
to	_	_
h	_	_
=	_	_
fspecial	_	_
(	_	_
’gaussian’,5,3	_	_
)	_	_
,	_	_
we	_	_
get	_	_
a	_	_
smaller	_	_
M̂	_	_
=	_	_
0.825	_	_
.	_	_

#368
Increasing	_	_
further	_	_
still	_	_
h	_	_
=	_	_
fspecial	_	_
(	_	_
’gaussian’,15,5	_	_
)	_	_
,	_	_
we	_	_
get	_	_
M̂	_	_
=	_	_
0.818	_	_
–	_	_
Now	_	_
consider	_	_
an	_	_
unsharp	_	_
masking	_	_
operation	_	_
as	_	_
f	_	_
(	_	_
x	_	_
)	_	_
=	_	_
x	_	_
+	_	_
α	_	_
(	_	_
x	_	_
−	_	_
blur	_	_
(	_	_
x	_	_
,	_	_
h	_	_
)	_	_
)	_	_
where	_	_
h	_	_
=	_	_
fspecial	_	_
(	_	_
’gaussian’,5,3	_	_
)	_	_
and	_	_
α	_	_
=	_	_
0.5	_	_
.	_	_

#369
This	_	_
gives	_	_
M̂	_	_
=	_	_
1.05	_	_
.	_	_

#370
Increasing	_	_
the	_	_
blur	_	_
strength	_	_
to	_	_
h	_	_
=	_	_
fspecial	_	_
(	_	_
’gaussian’,15,5	_	_
)	_	_
and	_	_
the	_	_
blending	_	_
strength	_	_
to	_	_
α	_	_
=	_	_
1.0	_	_
gives	_	_
M̂	_	_
=	_	_
1.078	_	_
–	_	_
Next	_	_
,	_	_
let’s	_	_
consider	_	_
downscaling	_	_
and	_	_
then	_	_
upscaling	_	_
a	_	_
given	_	_
image	_	_
by	_	_
some	_	_
integer	_	_
factor	_	_
q.	_	_
Namely	_	_
,	_	_
f	_	_
(	_	_
x	_	_
)	_	_
=	_	_
resize	_	_
(	_	_
resize	_	_
(	_	_
x	_	_
,	_	_
1/q	_	_
)	_	_
,	_	_
q	_	_
)	_	_
.	_	_

#371
Suppose	_	_
we	_	_
use	_	_
bi-cubic	_	_
resampling	_	_
and	_	_
q	_	_
=	_	_
2	_	_
.	_	_

#372
This	_	_
gives	_	_
M̂	_	_
=	_	_
0.841	_	_
.	_	_

#373
With	_	_
Lanczos	_	_
resampling	_	_
the	_	_
result	_	_
is	_	_
a	_	_
bit	_	_
sharper	_	_
so	_	_
the	_	_
estimate	_	_
the	_	_
Lipschitz	_	_
constant	_	_
is	_	_
a	_	_
bit	_	_
higher	_	_
M̂	_	_
=	_	_
0.850	_	_
.	_	_

#374
Keeping	_	_
the	_	_
Lanczos	_	_
resampler	_	_
,	_	_
but	_	_
increasing	_	_
q	_	_
=	_	_
4	_	_
,	_	_
we	_	_
expect	_	_
the	_	_
process	_	_
to	_	_
lose	_	_
more	_	_
high	_	_
frequencies	_	_
and	_	_
therefore	_	_
result	_	_
in	_	_
a	_	_
smaller	_	_
M̂	_	_
=	_	_
0.826	_	_
•	_	_
Nonlinear	_	_
Filtering	_	_
:	_	_
–	_	_
Consider	_	_
the	_	_
domain	_	_
transform	_	_
[	_	_
12	_	_
]	_	_
(	_	_
which	_	_
is	_	_
an	_	_
approximation	_	_
of	_	_
the	_	_
bilateral	_	_
filter	_	_
)	_	_
f	_	_
(	_	_
x	_	_
)	_	_
=	_	_
bilat	_	_
(	_	_
x	_	_
,	_	_
σ1	_	_
,	_	_
σ2	_	_
)	_	_
,	_	_
where	_	_
σ1	_	_
,	_	_
σ2	_	_
are	_	_
the	_	_
spatial	_	_
and	_	_
range	_	_
smoothing	_	_
parameters	_	_
.	_	_

#375
Letting	_	_
[	_	_
σ1	_	_
,	_	_
σ2	_	_
]	_	_
=	_	_
[	_	_
2	_	_
,	_	_
0.5	_	_
]	_	_
,	_	_
we	_	_
estimate	_	_
M̂	_	_
=	_	_
0.981	_	_
.	_	_

#376
Increasing	_	_
the	_	_
smoothing	_	_
level	_	_
to	_	_
[	_	_
σ1	_	_
,	_	_
σ2	_	_
]	_	_
=	_	_
[	_	_
5	_	_
,	_	_
1	_	_
]	_	_
,	_	_
we	_	_
estimate	_	_
M̂	_	_
=	_	_
0.886	_	_
.	_	_

#377
Now	_	_
let’s	_	_
construct	_	_
nonlinear	_	_
unsharp	_	_
masks	_	_
using	_	_
this	_	_
operator	_	_
.	_	_

#378
Analogous	_	_
to	_	_
the	_	_
earlier	_	_
linear	_	_
case	_	_
f	_	_
(	_	_
x	_	_
)	_	_
=	_	_
x+α	_	_
(	_	_
x−bilat	_	_
(	_	_
x	_	_
,	_	_
σ1	_	_
,	_	_
σ2	_	_
)	_	_
)	_	_
.	_	_

#379
Letting	_	_
[	_	_
σ1	_	_
,	_	_
σ2	_	_
]	_	_
=	_	_
[	_	_
5	_	_
,	_	_
1	_	_
]	_	_
,	_	_
and	_	_
α	_	_
=	_	_
0.4	_	_
,	_	_
we	_	_
get	_	_
M̂	_	_
=	_	_
1.02	_	_
;	_	_
where	_	_
as	_	_
[	_	_
σ1	_	_
,	_	_
σ2	_	_
]	_	_
=	_	_
[	_	_
10	_	_
,	_	_
3	_	_
]	_	_
,	_	_
α	_	_
=	_	_
1	_	_
gives	_	_
M̂	_	_
=	_	_
1.083	_	_
.	_	_

#380
–	_	_
Next	_	_
consider	_	_
the	_	_
median	_	_
filter	_	_
f	_	_
(	_	_
x	_	_
)	_	_
=	_	_
median	_	_
(	_	_
x	_	_
,	_	_
w	_	_
)	_	_
where	_	_
w	_	_
denotes	_	_
the	_	_
dimensions	_	_
of	_	_
the	_	_
filter	_	_
footprint	_	_
.	_	_

#381
Letting	_	_
w	_	_
=	_	_
[	_	_
3	_	_
,	_	_
3	_	_
]	_	_
gives	_	_
a	_	_
3	_	_
×	_	_
3	_	_
median	_	_
filter	_	_
and	_	_
M̂	_	_
=	_	_
1.11	_	_
.	_	_

#382
It	_	_
is	_	_
interesting	_	_
to	_	_
note	_	_
that	_	_
since	_	_
the	_	_
median	_	_
filter	_	_
tends	_	_
to	_	_
produce	_	_
very	_	_
sharp	_	_
edges	_	_
,	_	_
it	_	_
is	_	_
not	_	_
a	_	_
contractive	_	_
filter	_	_
even	_	_
for	_	_
small	_	_
window	_	_
sizes	_	_
.	_	_

#383
A	_	_
larger	_	_
window	_	_
size	_	_
w	_	_
=	_	_
[	_	_
7	_	_
,	_	_
7	_	_
]	_	_
gives	_	_
an	_	_
even	_	_
larger	_	_
M̂	_	_
=	_	_
1.162	_	_
.	_	_

#384
The	_	_
relatively	_	_
large	_	_
values	_	_
of	_	_
M	_	_
estimated	_	_
9Matlab	_	_
notation	_	_
Fig.	_	_
17	_	_
.	_	_

#385
Examples	_	_
of	_	_
tone-mapping	_	_
functions	_	_
for	_	_
the	_	_
median	_	_
filter	_	_
indicate	_	_
that	_	_
this	_	_
is	_	_
a	_	_
rather	_	_
difficult	_	_
effect	_	_
to	_	_
undo	_	_
.	_	_

#386
We	_	_
will	_	_
verify	_	_
this	_	_
in	_	_
the	_	_
experimental	_	_
section	_	_
.	_	_

#387
•	_	_
Tone-mapping	_	_
and	_	_
Gamma	_	_
Correction	_	_
:	_	_
We	_	_
often	_	_
use	_	_
these	_	_
pointwise	_	_
nonlinear	_	_
operators	_	_
f	_	_
(	_	_
xi	_	_
)	_	_
=	_	_
T	_	_
(	_	_
xi	_	_
)	_	_
to	_	_
contract	_	_
or	_	_
expand	_	_
the	_	_
dynamic	_	_
range	_	_
of	_	_
the	_	_
image	_	_
,	_	_
while	_	_
remaining	_	_
still	_	_
in	_	_
the	_	_
range	_	_
[	_	_
0	_	_
,	_	_
1	_	_
]	_	_
,	_	_
or	_	_
to	_	_
do	_	_
histogram	_	_
equalization	_	_
or	_	_
modification	_	_
.	_	_

#388
–	_	_
Let’s	_	_
consider	_	_
the	_	_
sigmoid-type	_	_
operator	_	_
that	_	_
rescales	_	_
the	_	_
brightness	_	_
levels	_	_
of	_	_
an	_	_
image	_	_
,	_	_
but	_	_
maps	_	_
0.5	_	_
to	_	_
itself	_	_
:	_	_
(	_	_
A.1	_	_
)	_	_
f	_	_
(	_	_
xi	_	_
)	_	_
=	_	_
σ	_	_
(	_	_
xi	_	_
,	_	_
a	_	_
)	_	_
=	_	_
atan	_	_
(	_	_
1/2a	_	_
)	_	_
+	_	_
atan	_	_
(	_	_
(	_	_
xi	_	_
−	_	_
0.5	_	_
)	_	_
/a	_	_
)	_	_
2atan	_	_
(	_	_
1/2a	_	_
)	_	_
With	_	_
a	_	_
=	_	_
0.1	_	_
we	_	_
estimate	_	_
M̂	_	_
=	_	_
1.239	_	_
,	_	_
whereas	_	_
with	_	_
a	_	_
=	_	_
0.25	_	_
we	_	_
get	_	_
M̂	_	_
=	_	_
1.12	_	_
,	_	_
and	_	_
with	_	_
a	_	_
=	_	_
0.5	_	_
we	_	_
get	_	_
M̂	_	_
=	_	_
1.049	_	_
.	_	_

#389
The	_	_
respective	_	_
tone-mapping	_	_
curves	_	_
are	_	_
shown	_	_
in	_	_
Fig.	_	_
17	_	_
.	_	_

#390
•	_	_
Compression	_	_
:	_	_
Here	_	_
we	_	_
consider	_	_
applying	_	_
jpg	_	_
compression	_	_
to	_	_
an	_	_
image	_	_
.	_	_

#391
Namely	_	_
f	_	_
(	_	_
x	_	_
)	_	_
=	_	_
jpeg	_	_
(	_	_
x	_	_
,	_	_
q	_	_
)	_	_
where	_	_
1	_	_
≤	_	_
q	_	_
≤	_	_
100	_	_
is	_	_
the	_	_
quality	_	_
factor	_	_
.	_	_

#392
We	_	_
have	_	_
M̂	_	_
(	_	_
[	_	_
10:10:100	_	_
]	_	_
)	_	_
=	_	_
[	_	_
0.891	_	_
,	_	_
0.911	_	_
,	_	_
0.924	_	_
,	_	_
0.923	_	_
,	_	_
0.92	_	_
,	_	_
0.92	_	_
,	_	_
0.916	_	_
,	_	_
0.91	_	_
,	_	_
0.904	_	_
,	_	_
0.901	_	_
,	_	_
0.90	_	_
]	_	_
.	_	_

#393
We	_	_
observe	_	_
that	_	_
interestingly	_	_
,	_	_
while	_	_
jpeg	_	_
compression	_	_
is	_	_
always	_	_
a	_	_
contractive	_	_
operator	_	_
,	_	_
the	_	_
Lipschitz	_	_
constant	_	_
may	_	_
not	_	_
be	_	_
a	_	_
monotonic	_	_
function	_	_
of	_	_
the	_	_
quality	_	_
factor	_	_
.	_	_