#0
Real-time	_	_
Progressive	_	_
3D	_	_
Semantic	_	_
Segmentation	_	_
for	_	_
Indoor	_	_
Scenes	_	_
Quang-Hieu	_	_
Pham1	_	_
Binh-Son	_	_
Hua2	_	_
Duc	_	_
Thanh	_	_
Nguyen3	_	_
Sai-Kit	_	_
Yeung4	_	_
1Singapore	_	_
University	_	_
of	_	_
Technology	_	_
and	_	_
Design	_	_
2The	_	_
University	_	_
of	_	_
Tokyo	_	_
3Deakin	_	_
University	_	_
4Hong	_	_
Kong	_	_
University	_	_
of	_	_
Science	_	_
and	_	_
Technology	_	_

#1
Abstract	_	_

#2
The	_	_
widespread	_	_
adoption	_	_
of	_	_
autonomous	_	_
systems	_	_
such	_	_
as	_	_
drones	_	_
and	_	_
assistant	_	_
robots	_	_
has	_	_
created	_	_
a	_	_
need	_	_
for	_	_
real-time	_	_
high-quality	_	_
semantic	_	_
scene	_	_
segmentation	_	_
.	_	_

#3
In	_	_
this	_	_
paper	_	_
,	_	_
we	_	_
propose	_	_
an	_	_
efficient	_	_
yet	_	_
robust	_	_
technique	_	_
for	_	_
on-the-fly	_	_
dense	_	_
reconstruction	_	_
and	_	_
semantic	_	_
segmentation	_	_
of	_	_
3D	_	_
indoor	_	_
scenes	_	_
.	_	_

#4
To	_	_
guarantee	_	_
(	_	_
near	_	_
)	_	_
real-time	_	_
performance	_	_
,	_	_
our	_	_
method	_	_
is	_	_
built	_	_
atop	_	_
an	_	_
efficient	_	_
super-voxel	_	_
clustering	_	_
method	_	_
and	_	_
a	_	_
conditional	_	_
random	_	_
field	_	_
with	_	_
higher-order	_	_
constraints	_	_
from	_	_
structural	_	_
and	_	_
object	_	_
cues	_	_
,	_	_
enabling	_	_
progressive	_	_
dense	_	_
semantic	_	_
segmentation	_	_
without	_	_
any	_	_
precomputation	_	_
.	_	_

#5
We	_	_
extensively	_	_
evaluate	_	_
our	_	_
method	_	_
on	_	_
different	_	_
indoor	_	_
scenes	_	_
including	_	_
kitchens	_	_
,	_	_
offices	_	_
,	_	_
and	_	_
bedrooms	_	_
in	_	_
the	_	_
SceneNN	_	_
and	_	_
ScanNet	_	_
datasets	_	_
and	_	_
show	_	_
that	_	_
our	_	_
technique	_	_
consistently	_	_
produces	_	_
state-of-the-art	_	_
segmentation	_	_
results	_	_
in	_	_
both	_	_
qualitative	_	_
and	_	_
quantitative	_	_
experiments	_	_
.	_	_

#6
1	_	_
.	_	_

#7
Introduction	_	_
Recent	_	_
hardware	_	_
advances	_	_
in	_	_
consumer-grade	_	_
depth	_	_
cameras	_	_
have	_	_
made	_	_
high-quality	_	_
reconstruction	_	_
of	_	_
indoor	_	_
scenes	_	_
feasible	_	_
.	_	_

#8
RGB-D	_	_
images	_	_
have	_	_
been	_	_
used	_	_
to	_	_
boost	_	_
the	_	_
robustness	_	_
of	_	_
numerous	_	_
scene	_	_
understanding	_	_
tasks	_	_
in	_	_
computer	_	_
vision	_	_
,	_	_
such	_	_
as	_	_
object	_	_
recognition	_	_
,	_	_
object	_	_
detection	_	_
,	_	_
and	_	_
semantic	_	_
segmentation	_	_
.	_	_

#9
While	_	_
scene	_	_
understanding	_	_
using	_	_
color	_	_
or	_	_
RGB-D	_	_
images	_	_
is	_	_
a	_	_
well	_	_
explored	_	_
topic	_	_
[	_	_
41	_	_
,	_	_
13	_	_
,	_	_
30	_	_
]	_	_
,	_	_
good	_	_
solutions	_	_
for	_	_
the	_	_
same	_	_
task	_	_
in	_	_
the	_	_
3D	_	_
domain	_	_
have	_	_
been	_	_
highly	_	_
sought	_	_
after	_	_
,	_	_
particularly	_	_
,	_	_
those	_	_
can	_	_
produce	_	_
accurate	_	_
and	_	_
high-quality	_	_
semantic	_	_
segmentation	_	_
.	_	_

#10
In	_	_
this	_	_
work	_	_
,	_	_
we	_	_
propose	_	_
a	_	_
(	_	_
near	_	_
)	_	_
real-time	_	_
method	_	_
for	_	_
high-quality	_	_
dense	_	_
semantic	_	_
segmentation	_	_
of	_	_
3D	_	_
indoor	_	_
scene	_	_
.	_	_

#11
The	_	_
backbone	_	_
of	_	_
our	_	_
work	_	_
is	_	_
a	_	_
higher-order	_	_
conditional	_	_
random	_	_
field	_	_
(	_	_
CRF	_	_
)	_	_
designed	_	_
to	_	_
infer	_	_
optimal	_	_
segmentation	_	_
labels	_	_
from	_	_
the	_	_
predictions	_	_
of	_	_
a	_	_
deep	_	_
neural	_	_
network	_	_
.	_	_

#12
The	_	_
CRF	_	_
runs	_	_
in	_	_
tandem	_	_
with	_	_
a	_	_
revised	_	_
pipeline	_	_
for	_	_
real-time	_	_
3D	_	_
reconstruction	_	_
using	_	_
RGB-D	_	_
images	_	_
as	_	_
input	_	_
.	_	_

#13
In	_	_
contrast	_	_
to	_	_
traditional	_	_
dense	_	_
model	_	_
,	_	_
our	_	_
CRF	_	_
accepts	_	_
additional	_	_
higher-order	_	_
constraints	_	_
from	_	_
unsupervised	_	_
object	_	_
analysis	_	_
,	_	_
resulting	_	_
in	_	_
high-quality	_	_
segmentation	_	_
.	_	_

#14
An	_	_
example	_	_
output	_	_
from	_	_
our	_	_
proposed	_	_
method	_	_
is	_	_
shown	_	_
in	_	_
Figure	_	_
1	_	_
.	_	_

#15
Frame	_	_
8500	_	_
Groundtruth	_	_
Frame	_	_
7100Frame	_	_
5100	_	_
Frame	_	_
100	_	_
Frame	_	_
1100	_	_
Frame	_	_
3100	_	_
Frame	_	_
9500	_	_
Direct	_	_
Figure	_	_
1	_	_
:	_	_
Progressive	_	_
semantic	_	_
segmentation	_	_
of	_	_
a	_	_
10K-frame	_	_
bedroom	_	_
scene	_	_
in	_	_
real	_	_
time	_	_
.	_	_

#16
Our	_	_
method	_	_
can	_	_
resolve	_	_
errors	_	_
in	_	_
segmentation	_	_
while	_	_
scanning	_	_
.	_	_

#17
Note	_	_
the	_	_
segmentation	_	_
error	_	_
on	_	_
the	_	_
bed	_	_
being	_	_
gradually	_	_
fixed	_	_
as	_	_
the	_	_
user	_	_
scans	_	_
the	_	_
scene	_	_
.	_	_

#18
Experiments	_	_
proved	_	_
that	_	_
our	_	_
method	_	_
is	_	_
capable	_	_
of	_	_
producing	_	_
high-quality	_	_
semantic	_	_
segmentation	_	_
and	_	_
achieve	_	_
adequate	_	_
temporal	_	_
consistency	_	_
.	_	_

#19
In	_	_
summary	_	_
,	_	_
our	_	_
contributions	_	_
are	_	_
:	_	_
•	_	_
A	_	_
higher-order	_	_
conditional	_	_
random	_	_
field	_	_
that	_	_
can	_	_
resolve	_	_
noisy	_	_
predictions	_	_
from	_	_
a	_	_
deep	_	_
neural	_	_
network	_	_
into	_	_
a	_	_
coherent	_	_
3D	_	_
dense	_	_
segmentation	_	_
,	_	_
using	_	_
additional	_	_
object-level	_	_
information	_	_
.	_	_

#20
•	_	_
An	_	_
extended	_	_
reconstruction	_	_
pipeline	_	_
,	_	_
including	_	_
an	_	_
efficient	_	_
voxel	_	_
clustering	_	_
technique	_	_
,	_	_
for	_	_
efficient	_	_
(	_	_
near	_	_
)	_	_
real-time	_	_
full-scene	_	_
inference	_	_
while	_	_
scanning	_	_
.	_	_

#21
•	_	_
A	_	_
thorough	_	_
evaluation	_	_
of	_	_
state-of-the-art	_	_
real-time	_	_
semantic	_	_
segmentation	_	_
algorithms	_	_
on	_	_
two	_	_
large	_	_
scale	_	_
indoor	_	_
datasets	_	_
,	_	_
namely	_	_
SceneNN	_	_
[	_	_
17	_	_
]	_	_
and	_	_
ScanNet	_	_
[	_	_
8	_	_
]	_	_
.	_	_

#22
•	_	_
Beyond	_	_
category-based	_	_
semantic	_	_
segmentation	_	_
,	_	_
we	_	_
also	_	_
extend	_	_
our	_	_
method	_	_
to	_	_
instance-based	_	_
semantic	_	_
segmentation	_	_
,	_	_
and	_	_
provide	_	_
the	_	_
first	_	_
evaluation	_	_
of	_	_
real-time	_	_
instance	_	_
segmentation	_	_
on	_	_
SceneNN	_	_
dataset	_	_
.	_	_

#23
ar	_	_
X	_	_
iv	_	_
:1	_	_
4	_	_
.	_	_

#24
7v	_	_
5	_	_
[	_	_
cs	_	_
.C	_	_
V	_	_
]	_	_
5	_	_
A	_	_
pr	_	_
2	_	_
2	_	_
.	_	_

#25
Related	_	_
Work	_	_
Indoor	_	_
semantic	_	_
segmentation	_	_
.	_	_

#26
In	_	_
their	_	_
seminal	_	_
work	_	_
,	_	_
Silberman	_	_
et	_	_
al.	_	_
[	_	_
41	_	_
]	_	_
proposed	_	_
a	_	_
technique	_	_
to	_	_
segment	_	_
cluttered	_	_
indoor	_	_
scenes	_	_
into	_	_
floor	_	_
,	_	_
walls	_	_
,	_	_
objects	_	_
and	_	_
their	_	_
support	_	_
relationships	_	_
.	_	_

#27
Their	_	_
well-known	_	_
NYUv2	_	_
dataset	_	_
has	_	_
since	_	_
sparked	_	_
new	_	_
research	_	_
interests	_	_
in	_	_
semantic	_	_
segmentation	_	_
using	_	_
RGB-D	_	_
images	_	_
.	_	_

#28
Long	_	_
et	_	_
al.	_	_
[	_	_
30	_	_
]	_	_
adapted	_	_
neural	_	_
networks	_	_
originally	_	_
trained	_	_
for	_	_
classification	_	_
to	_	_
solve	_	_
semantic	_	_
segmentation	_	_
by	_	_
appending	_	_
a	_	_
fully	_	_
connected	_	_
layer	_	_
to	_	_
the	_	_
existing	_	_
architecture	_	_
.	_	_

#29
This	_	_
method	_	_
,	_	_
however	_	_
,	_	_
tends	_	_
to	_	_
produce	_	_
inaccuracies	_	_
along	_	_
object	_	_
boundaries	_	_
.	_	_

#30
Since	_	_
then	_	_
,	_	_
different	_	_
techniques	_	_
[	_	_
52	_	_
,	_	_
4	_	_
]	_	_
has	_	_
been	_	_
proposed	_	_
to	_	_
address	_	_
this	_	_
issue	_	_
.	_	_

#31
Some	_	_
recent	_	_
works	_	_
also	_	_
explored	_	_
instance	_	_
segmentation	_	_
[	_	_
14	_	_
,	_	_
5	_	_
]	_	_
,	_	_
but	_	_
such	_	_
techniques	_	_
only	_	_
work	_	_
in	_	_
2D	_	_
.	_	_

#32
In	_	_
the	_	_
3D	_	_
domain	_	_
,	_	_
a	_	_
few	_	_
datasets	_	_
for	_	_
3D	_	_
scene	_	_
segmentation	_	_
have	_	_
also	_	_
been	_	_
proposed	_	_
[	_	_
17	_	_
,	_	_
8	_	_
,	_	_
2	_	_
]	_	_
.	_	_

#33
Early	_	_
techniques	_	_
focused	_	_
on	_	_
solving	_	_
the	_	_
problem	_	_
by	_	_
exploiting	_	_
3D	_	_
volumes	_	_
.	_	_

#34
For	_	_
example	_	_
,	_	_
Song	_	_
et	_	_
al.	_	_
[	_	_
42	_	_
]	_	_
and	_	_
Dai	_	_
et	_	_
al.	_	_
[	_	_
10	_	_
]	_	_
proposed	_	_
a	_	_
network	_	_
architecture	_	_
for	_	_
semantic	_	_
scene	_	_
segmentation	_	_
and	_	_
completion	_	_
at	_	_
the	_	_
same	_	_
time	_	_
.	_	_

#35
Point-based	_	_
deep	_	_
learning	_	_
[	_	_
37	_	_
,	_	_
28	_	_
,	_	_
18	_	_
,	_	_
47	_	_
,	_	_
19	_	_
]	_	_
took	_	_
another	_	_
direction	_	_
and	_	_
attempted	_	_
to	_	_
learn	_	_
point	_	_
representation	_	_
for	_	_
segmentation	_	_
directly	_	_
from	_	_
unordered	_	_
point	_	_
clouds	_	_
.	_	_

#36
While	_	_
the	_	_
results	_	_
from	_	_
these	_	_
neural	_	_
networks	_	_
are	_	_
impressive	_	_
,	_	_
they	_	_
only	_	_
take	_	_
as	_	_
input	_	_
a	_	_
small	_	_
point	_	_
cloud	_	_
of	_	_
a	_	_
few	_	_
thousand	_	_
points	_	_
.	_	_

#37
To	_	_
address	_	_
large-scale	_	_
or	_	_
structural	_	_
point	_	_
cloud	_	_
,	_	_
clustering	_	_
techniques	_	_
such	_	_
as	_	_
superpoints	_	_
[	_	_
25	_	_
]	_	_
or	_	_
hierarchical	_	_
data	_	_
structures	_	_
such	_	_
as	_	_
octree	_	_
[	_	_
39	_	_
]	_	_
and	_	_
kd-tree	_	_
[	_	_
22	_	_
]	_	_
have	_	_
been	_	_
proposed	_	_
.	_	_

#38
Hybrid	_	_
methods	_	_
such	_	_
as	_	_
SEGCloud	_	_
[	_	_
43	_	_
]	_	_
turns	_	_
the	_	_
point	_	_
clouds	_	_
into	_	_
volumes	_	_
for	_	_
prediction	_	_
with	_	_
a	_	_
neural	_	_
network	_	_
and	_	_
then	_	_
propagates	_	_
the	_	_
results	_	_
back	_	_
to	_	_
the	_	_
original	_	_
point	_	_
cloud	_	_
.	_	_

#39
Instead	_	_
of	_	_
directly	_	_
processing	_	_
in	_	_
3D	_	_
,	_	_
multiple	_	_
view	_	_
techniques	_	_
[	_	_
24	_	_
,	_	_
26	_	_
,	_	_
31	_	_
,	_	_
38	_	_
,	_	_
9	_	_
]	_	_
focused	_	_
on	_	_
transferring	_	_
2D	_	_
segmentation	_	_
to	_	_
3D	_	_
.	_	_

#40
Other	_	_
methods	_	_
further	_	_
exploit	_	_
object	_	_
cues	_	_
such	_	_
as	_	_
spatial	_	_
context	_	_
[	_	_
11	_	_
]	_	_
.	_	_

#41
Our	_	_
method	_	_
is	_	_
based	_	_
on	_	_
multi-view	_	_
segmentation	_	_
as	_	_
such	_	_
techniques	_	_
scale	_	_
better	_	_
to	_	_
large-scale	_	_
scenes	_	_
.	_	_

#42
Concurrently	_	_
,	_	_
we	_	_
also	_	_
aim	_	_
to	_	_
achieve	_	_
real-time	_	_
performance	_	_
with	_	_
progressive	_	_
scene	_	_
reconstruction	_	_
.	_	_

#43
We	_	_
would	_	_
focus	_	_
our	_	_
discussion	_	_
to	_	_
the	_	_
most	_	_
relevant	_	_
interactive	_	_
and	_	_
real-time	_	_
techniques	_	_
.	_	_

#44
Real-time	_	_
semantic	_	_
segmentation	_	_
.	_	_

#45
Our	_	_
real-time	_	_
semantic	_	_
segmentation	_	_
system	_	_
requires	_	_
an	_	_
online	_	_
dense	_	_
3D	_	_
reconstruction	_	_
system	_	_
.	_	_

#46
KinectFusion	_	_
[	_	_
33	_	_
]	_	_
showed	_	_
us	_	_
how	_	_
to	_	_
construct	_	_
such	_	_
system	_	_
.	_	_

#47
To	_	_
overcome	_	_
the	_	_
spatial	_	_
constraints	_	_
in	_	_
the	_	_
original	_	_
KinectFusion	_	_
implementation	_	_
,	_	_
which	_	_
prohibits	_	_
large-scale	_	_
3D	_	_
scanning	_	_
,	_	_
Nießner	_	_
et	_	_
al.	_	_
[	_	_
34	_	_
]	_	_
used	_	_
voxel	_	_
hashing	_	_
to	_	_
reduce	_	_
the	_	_
memory	_	_
footprint	_	_
.	_	_

#48
Valentin	_	_
et	_	_
al.	_	_
[	_	_
45	_	_
]	_	_
proposed	_	_
an	_	_
interactive	_	_
scanning	_	_
system	_	_
where	_	_
the	_	_
segmentation	_	_
is	_	_
learnt	_	_
from	_	_
user	_	_
inputs	_	_
.	_	_

#49
Unlike	_	_
them	_	_
,	_	_
our	_	_
method	_	_
is	_	_
completely	_	_
automatic	_	_
without	_	_
the	_	_
need	_	_
of	_	_
user	_	_
interaction	_	_
,	_	_
and	_	_
thus	_	_
more	_	_
suitable	_	_
for	_	_
robotics	_	_
applications	_	_
.	_	_

#50
Our	_	_
method	_	_
is	_	_
based	_	_
on	_	_
a	_	_
segmentation	_	_
prediction	_	_
with	_	_
2D	_	_
deep	_	_
neural	_	_
networks	_	_
,	_	_
a	_	_
2D-3D	_	_
label	_	_
transfer	_	_
and	_	_
optimization	_	_
with	_	_
a	_	_
conditional	_	_
random	_	_
field	_	_
(	_	_
CRF	_	_
)	_	_
.	_	_

#51
To	_	_
our	_	_
knowledge	_	_
,	_	_
the	_	_
closest	_	_
works	_	_
to	_	_
ours	_	_
in	_	_
this	_	_
aspect	_	_
is	_	_
from	_	_
the	_	_
robotics	_	_
community	_	_
[	_	_
16	_	_
,	_	_
48	_	_
,	_	_
46	_	_
,	_	_
32	_	_
,	_	_
15	_	_
,	_	_
50	_	_
]	_	_
.	_	_

#52
Early	_	_
methods	_	_
[	_	_
16	_	_
,	_	_
48	_	_
,	_	_
46	_	_
]	_	_
utilized	_	_
random	_	_
forest	_	_
classifiers	_	_
to	_	_
initialize	_	_
the	_	_
CRF	_	_
but	_	_
their	_	_
end-to-end	_	_
pipeline	_	_
performance	_	_
was	_	_
far	_	_
from	_	_
real	_	_
time	_	_
.	_	_

#53
Similar	_	_
to	_	_
our	_	_
approach	_	_
,	_	_
McCormac	_	_
et	_	_
al.	_	_
[	_	_
32	_	_
]	_	_
utilized	_	_
segmentation	_	_
predictions	_	_
from	_	_
a	_	_
deep	_	_
neural	_	_
network	_	_
and	_	_
achieved	_	_
real-time	_	_
performance	_	_
on	_	_
sparse	_	_
point	_	_
cloud	_	_
.	_	_

#54
In	_	_
comparison	_	_
,	_	_
our	_	_
method	_	_
preserves	_	_
surface	_	_
information	_	_
completely	_	_
by	_	_
working	_	_
with	_	_
an	_	_
on-the-fly	_	_
sparse	_	_
volume	_	_
representation	_	_
from	_	_
Voxel	_	_
Hashing	_	_
[	_	_
34	_	_
]	_	_
,	_	_
and	_	_
introduce	_	_
a	_	_
higher-order	_	_
conditional	_	_
random	_	_
field	_	_
model	_	_
to	_	_
refine	_	_
3D	_	_
segmentation	_	_
.	_	_

#55
Conditional	_	_
random	_	_
field	_	_
.	_	_

#56
The	_	_
CRF	_	_
model	_	_
,	_	_
often	_	_
containing	_	_
unary	_	_
and	_	_
pairwise	_	_
terms	_	_
,	_	_
is	_	_
commonly	_	_
used	_	_
as	_	_
post-processing	_	_
step	_	_
[	_	_
7	_	_
]	_	_
to	_	_
address	_	_
noise	_	_
in	_	_
semantic	_	_
segmentation	_	_
.	_	_

#57
Krähenbühl	_	_
and	_	_
Koltun	_	_
[	_	_
23	_	_
]	_	_
proposed	_	_
an	_	_
efficient	_	_
message	_	_
passing	_	_
method	_	_
to	_	_
perform	_	_
inference	_	_
on	_	_
a	_	_
fully-connected	_	_
model	_	_
.	_	_

#58
Recently	_	_
,	_	_
with	_	_
the	_	_
immense	_	_
advances	_	_
in	_	_
deep	_	_
learning	_	_
,	_	_
it	_	_
is	_	_
possible	_	_
to	_	_
embed	_	_
CRF	_	_
into	_	_
neural	_	_
networks	_	_
[	_	_
56	_	_
,	_	_
3	_	_
]	_	_
and	_	_
its	_	_
parameters	_	_
can	_	_
be	_	_
learnt	_	_
jointly	_	_
with	_	_
the	_	_
network	_	_
via	_	_
back-propagation	_	_
.	_	_

#59
While	_	_
representing	_	_
CRF	_	_
by	_	_
a	_	_
recurrent	_	_
neural	_	_
network	_	_
[	_	_
56	_	_
,	_	_
3	_	_
]	_	_
is	_	_
advantageous	_	_
,	_	_
applying	_	_
such	_	_
end-to-end	_	_
framework	_	_
to	_	_
our	_	_
problem	_	_
poses	_	_
some	_	_
challenges	_	_
.	_	_

#60
First	_	_
in	_	_
the	_	_
context	_	_
of	_	_
progressive	_	_
3D	_	_
reconstruction	_	_
and	_	_
segmentation	_	_
,	_	_
2D	_	_
predictions	_	_
from	_	_
multiple	_	_
views	_	_
have	_	_
to	_	_
be	_	_
combined	_	_
to	_	_
produce	_	_
the	_	_
labeling	_	_
of	_	_
3D	_	_
model	_	_
,	_	_
which	_	_
is	_	_
not	_	_
supported	_	_
in	_	_
the	_	_
previous	_	_
method	_	_
where	_	_
only	_	_
the	_	_
segmentation	_	_
of	_	_
one	_	_
single	_	_
image	_	_
is	_	_
predicted	_	_
.	_	_

#61
Second	_	_
,	_	_
their	_	_
methods	_	_
is	_	_
computationally	_	_
demanding	_	_
which	_	_
does	_	_
not	_	_
fit	_	_
our	_	_
real-time	_	_
requirement	_	_
.	_	_

#62
Third	_	_
,	_	_
the	_	_
number	_	_
of	_	_
2D	_	_
images	_	_
used	_	_
to	_	_
calculate	_	_
the	_	_
unaries	_	_
is	_	_
not	_	_
fixed	_	_
,	_	_
compared	_	_
to	_	_
using	_	_
only	_	_
one	_	_
input	_	_
image	_	_
as	_	_
in	_	_
previous	_	_
approaches	_	_
.	_	_

#63
In	_	_
this	_	_
work	_	_
,	_	_
we	_	_
instead	_	_
run	_	_
the	_	_
CRF	_	_
separately	_	_
on	_	_
3D	_	_
after	_	_
processing	_	_
2D	_	_
semantic	_	_
predictions	_	_
from	_	_
a	_	_
convolutional	_	_
neural	_	_
network	_	_
.	_	_

#64
CRF	_	_
is	_	_
also	_	_
extended	_	_
with	_	_
high-order	_	_
potentials	_	_
to	_	_
further	_	_
improve	_	_
coherency	_	_
in	_	_
the	_	_
label	_	_
prediction	_	_
.	_	_

#65
For	_	_
example	_	_
,	_	_
Zhu	_	_
et	_	_
al.	_	_
[	_	_
57	_	_
]	_	_
explored	_	_
high-order	_	_
CRF	_	_
for	_	_
co-segmentation	_	_
on	_	_
images	_	_
.	_	_

#66
Yang	_	_
et	_	_
al.	_	_
[	_	_
50	_	_
]	_	_
uses	_	_
a	_	_
hierarchical	_	_
CRF	_	_
with	_	_
potentials	_	_
from	_	_
super-pixels	_	_
on	_	_
images	_	_
for	_	_
fast	_	_
outdoor	_	_
scene	_	_
segmentation	_	_
.	_	_

#67
The	_	_
CRF	_	_
model	_	_
we	_	_
propose	_	_
in	_	_
this	_	_
work	_	_
is	_	_
a	_	_
higher-order	_	_
CRF	_	_
that	_	_
includes	_	_
object	_	_
cues	_	_
for	_	_
indoor	_	_
scenes	_	_
and	_	_
works	_	_
in	_	_
tandem	_	_
with	_	_
the	_	_
geometry	_	_
reconstruction	_	_
.	_	_

#68
Our	_	_
idea	_	_
is	_	_
that	_	_
to	_	_
obtain	_	_
a	_	_
coherent	_	_
,	_	_
high-quality	_	_
segmentation	_	_
,	_	_
vertices	_	_
in	_	_
the	_	_
same	_	_
object	_	_
should	_	_
be	_	_
consider	_	_
as	_	_
a	_	_
whole	_	_
in	_	_
the	_	_
model	_	_
.	_	_

#69
Moreover	_	_
,	_	_
noises	_	_
and	_	_
inconsistencies	_	_
should	_	_
be	_	_
fixed	_	_
regularly	_	_
as	_	_
the	_	_
user	_	_
scans	_	_
through	_	_
the	_	_
scene	_	_
.	_	_

#70
xi	_	_
Non-object	_	_
Object	_	_
Final	_	_
Segmentation	_	_
Higher-order	_	_
CRF	_	_
Initial	_	_
Segmentation	_	_
3D	_	_
Reconstruction	_	_
2D	_	_
Semantic	_	_
Predictions	_	_
Voxel	_	_
Hashing	_	_
CNN	_	_
+	_	_
Previous	_	_
Segmentation	_	_
Figure	_	_
2	_	_
:	_	_
Overview	_	_
of	_	_
our	_	_
progressive	_	_
indoor	_	_
scene	_	_
segmentation	_	_
method	_	_
.	_	_

#71
From	_	_
continuous	_	_
frames	_	_
of	_	_
an	_	_
RGB-D	_	_
sensor	_	_
,	_	_
our	_	_
system	_	_
performs	_	_
on-the-fly	_	_
reconstruction	_	_
and	_	_
semantic	_	_
segmentation	_	_
.	_	_

#72
All	_	_
of	_	_
our	_	_
processing	_	_
is	_	_
performed	_	_
on	_	_
a	_	_
frame-by-frame	_	_
basis	_	_
in	_	_
an	_	_
online	_	_
fashion	_	_
,	_	_
thus	_	_
useful	_	_
for	_	_
real-time	_	_
applications	_	_
.	_	_

#73
3	_	_
.	_	_

#74
Real-time	_	_
RGB-D	_	_
Reconstruction	_	_
We	_	_
now	_	_
introduce	_	_
our	_	_
proposed	_	_
method	_	_
for	_	_
the	_	_
progressive	_	_
dense	_	_
semantic	_	_
segmentation	_	_
problem	_	_
.	_	_

#75
An	_	_
overview	_	_
of	_	_
our	_	_
framework	_	_
is	_	_
shown	_	_
in	_	_
Figure	_	_
2	_	_
.	_	_

#76
3.1.	_	_
Semantic	_	_
label	_	_
fusion	_	_

#77
Our	_	_
online	_	_
scanning	_	_
system	_	_
is	_	_
built	_	_
on	_	_
top	_	_
of	_	_
the	_	_
Voxel	_	_
Hashing	_	_
[	_	_
34	_	_
]	_	_
pipeline	_	_
,	_	_
reconstructing	_	_
both	_	_
geometric	_	_
and	_	_
semantic	_	_
information	_	_
of	_	_
the	_	_
scene	_	_
in	_	_
real	_	_
time	_	_
.	_	_

#78
In	_	_
principle	_	_
,	_	_
given	_	_
an	_	_
incoming	_	_
frame	_	_
prediction	_	_
from	_	_
CNN	_	_
,	_	_
we	_	_
must	deontic	_
update	_	_
the	_	_
semantic	_	_
label	_	_
for	_	_
each	_	_
active	_	_
voxel	_	_
accordingly	_	_
,	_	_
using	_	_
the	_	_
same	_	_
integration	_	_
process	_	_
as	_	_
described	_	_
in	_	_
KinectFusion	_	_
[	_	_
33	_	_
]	_	_
.	_	_

#79
For	_	_
this	_	_
problem	_	_
,	_	_
McCormac	_	_
et	_	_
al.	_	_
[	_	_
32	_	_
]	_	_
store	_	_
a	_	_
full	_	_
discrete	_	_
probability	_	_
distribution	_	_
in	_	_
each	_	_
voxel	_	_
,	_	_
and	_	_
update	_	_
it	_	_
by	_	_
using	_	_
recursive	_	_
Bayesian	_	_
rule	_	_
.	_	_

#80
However	_	_
,	_	_
doing	_	_
so	_	_
requires	_	_
a	_	_
large	_	_
amount	_	_
of	_	_
memory	_	_
and	_	_
does	_	_
not	_	_
scale	_	_
well	_	_
with	_	_
large	_	_
number	_	_
of	_	_
semantic	_	_
classes	_	_
.	_	_

#81
We	_	_
employ	_	_
the	_	_
update	_	_
process	_	_
proposed	_	_
by	_	_
Cavallari	_	_
and	_	_
Di	_	_
Stefano	_	_
[	_	_
6	_	_
]	_	_
,	_	_
where	_	_
each	_	_
voxel	_	_
only	_	_
stores	_	_
the	_	_
current	_	_
best	_	_
label	_	_
and	_	_
its	_	_
confidence	_	_
.	_	_

#82
3.2	_	_
.	_	_

#83
Progressive	_	_
super-voxel	_	_
clustering	_	_
Now	_	_
we	_	_
explain	_	_
in	_	_
details	_	_
our	_	_
super-voxel	_	_
clustering	_	_
method	_	_
,	_	_
which	_	_
will	_	_
provide	_	_
a	_	_
new	_	_
domain	_	_
to	_	_
define	_	_
our	_	_
CRF	_	_
with	_	_
higher-order	_	_
constraints	_	_
.	_	_

#84
Our	_	_
super-voxel	_	_
clustering	_	_
method	_	_
resembles	_	_
previous	_	_
local	_	_
k-means	_	_
clustering	_	_
techniques	_	_
such	_	_
as	_	_
VCCS	_	_
[	_	_
35	_	_
]	_	_
or	_	_
SLIC	_	_
[	_	_
1	_	_
]	_	_
.	_	_

#85
The	_	_
main	_	_
difference	_	_
in	_	_
our	_	_
super-voxel	_	_
clustering	_	_
method	_	_
is	_	_
that	_	_
,	_	_
to	_	_
amortize	_	_
the	_	_
computation	_	_
cost	_	_
,	_	_
we	_	_
create	_	_
super-voxels	_	_
in	_	_
a	_	_
progressive	_	_
manner	_	_
,	_	_
performing	_	_
one	_	_
clustering	_	_
iteration	_	_
at	_	_
a	_	_
time	_	_
,	_	_
which	_	_
will	_	_
adapt	_	_
better	_	_
to	_	_
the	_	_
changes	_	_
in	_	_
the	_	_
current	_	_
reconstructed	_	_
scene	_	_
.	_	_

#86
In	_	_
our	_	_
system	_	_
,	_	_
we	_	_
consider	_	_
common	_	_
features	_	_
such	_	_
as	_	_
voxel	_	_
color	_	_
and	_	_
position	_	_
to	_	_
define	_	_
the	_	_
distance	_	_
measure	_	_
D	_	_
:	_	_
D	_	_
=	_	_
√	_	_
αDc	_	_
nc	_	_
+	_	_
βDs	_	_
ns	_	_
(	_	_
1	_	_
)	_	_
where	_	_
Dc	_	_
and	_	_
Ds	_	_
are	_	_
the	_	_
color	_	_
and	_	_
spatial	_	_
distances	_	_
,	_	_
with	_	_
nc	_	_
and	_	_
ns	_	_
act	_	_
as	_	_
the	_	_
normalizers	_	_
;	_	_
α	_	_
and	_	_
β	_	_
control	_	_
the	_	_
relative	_	_
weighting	_	_
of	_	_
color	_	_
and	_	_
spatial	_	_
distances	_	_
.	_	_

#87
In	_	_
all	_	_
of	_	_
our	_	_
experiments	_	_
,	_	_
we	_	_
set	_	_
α	_	_
and	_	_
β	_	_
to	_	_
1	_	_
;	_	_
the	_	_
normalization	_	_
values	_	_
nc	_	_
and	_	_
ns	_	_
are	_	_
based	_	_
on	_	_
the	_	_
chosen	_	_
voxel	_	_
size	_	_
which	_	_
is	_	_
0.008m	_	_
and	_	_
the	_	_
CIELab	_	_
color	_	_
space	_	_
.	_	_

#88
Here	_	_
one	_	_
can	_	_
further	_	_
utilize	_	_
voxel	_	_
normals	_	_
for	_	_
the	_	_
distance	_	_
measure	_	_
but	_	_
we	_	_
found	_	_
that	_	_
the	_	_
quality	_	_
of	_	_
the	_	_
clustering	_	_
does	_	_
not	_	_
improve	_	_
much	_	_
despite	_	_
of	_	_
the	_	_
expensive	_	_
cost	_	_
to	_	_
compute	_	_
normals	_	_
per	_	_
voxel	_	_
.	_	_

#89
Another	_	_
possible	_	_
extension	_	_
is	_	_
to	_	_
consider	_	_
features	_	_
provided	_	_
by	_	_
the	_	_
2D	_	_
semantic	_	_
segmentation	_	_
network	_	_
in	_	_
the	_	_
distance	_	_
measure	_	_
.	_	_

#90
However	_	_
,	_	_
the	_	_
memory	_	_
storage	_	_
per	_	_
voxel	_	_
would	_	_
be	_	_
very	_	_
costly	_	_
because	_	_
each	_	_
feature	_	_
vector	_	_
often	_	_
has	_	_
at	_	_
least	_	_
tens	_	_
of	_	_
floating	_	_
point	_	_
numbers	_	_
.	_	_

#91
Some	_	_
compressions	_	_
might	capability-speculation	_
help	_	_
in	_	_
this	_	_
case	_	_
.	_	_

#92
Suppose	_	_
that	_	_
an	_	_
existing	_	_
set	_	_
of	_	_
super-voxels	_	_
are	_	_
already	_	_
provided	_	_
.	_	_

#93
For	_	_
an	_	_
incoming	_	_
RGB-D	_	_
frame	_	_
at	_	_
time	_	_
t	_	_
,	_	_
after	_	_
camera	_	_
pose	_	_
estimation	_	_
,	_	_
we	_	_
can	_	_
find	_	_
out	_	_
the	_	_
current	_	_
active	_	_
set	_	_
Vt	_	_
of	_	_
voxels	_	_
using	_	_
an	_	_
inside/outside	_	_
check	_	_
on	_	_
the	_	_
current	_	_
camera	_	_
frustum	_	_
.	_	_

#94
Our	_	_
goal	_	_
is	_	_
to	_	_
assign	_	_
each	_	_
of	_	_
these	_	_
voxels	_	_
into	_	_
a	_	_
super-voxel	_	_
(	_	_
or	_	_
cluster	_	_
)	_	_
.	_	_

#95
This	_	_
process	_	_
is	_	_
as	_	_
follows	_	_
:	_	_
first	_	_
new	_	_
seeds	_	_
are	_	_
sampled	_	_
on	_	_
uninitialized	_	_
regions	_	_
,	_	_
based	_	_
on	_	_
a	_	_
chosen	_	_
spatial	_	_
interval	_	_
S.	_	_
For	_	_
each	_	_
active	_	_
voxel	_	_
,	_	_
we	_	_
assign	_	_
it	_	_
to	_	_
the	_	_
nearest	_	_
cluster	_	_
according	_	_
to	_	_
the	_	_
distance	_	_
in	_	_
Equation	_	_
1	_	_
.	_	_

#96
Next	_	_
,	_	_
we	_	_
update	_	_
the	_	_
centers	_	_
information	_	_
based	_	_
on	_	_
the	_	_
new	_	_
cluster	_	_
assignment	_	_
.	_	_

#97
This	_	_
process	_	_
is	_	_
repeated	_	_
for	_	_
every	_	_
incoming	_	_
RGB-D	_	_
frame	_	_
,	_	_
providing	_	_
a	_	_
“live”	_	_
unsupervised	_	_
over-segmentation	_	_
of	_	_
the	_	_
scene	_	_
.	_	_

#98
Our	_	_
progressive	_	_
super-voxel	_	_
building	_	_
scheme	_	_
fits	_	_
well	_	_
into	_	_
the	_	_
common	_	_
dense	_	_
RGB-D	_	_
reconstruction	_	_
pipelines	_	_
such	_	_
as	_	_
KinectFusion	_	_
[	_	_
33	_	_
]	_	_
or	_	_
Voxel	_	_
Hashing	_	_
[	_	_
34	_	_
]	_	_
,	_	_
and	_	_
can	_	_
be	_	_
implemented	_	_
efficiently	_	_
on	_	_
the	_	_
GPU	_	_
.	_	_

#99
In	_	_
practice	_	_
,	_	_
we	_	_
only	_	_
consider	_	_
voxels	_	_
close	_	_
to	_	_
the	_	_
surface	_	_
,	_	_
based	_	_
on	_	_
their	_	_
distance-to-surface	_	_
values	_	_
.	_	_

#100
Performing	_	_
inference	_	_
on	_	_
these	_	_
super-voxels	_	_
significantly	_	_
reduces	_	_
the	_	_
domain	_	_
size	_	_
of	_	_
our	_	_
CRF	_	_
,	_	_
and	_	_
thus	_	_
paves	_	_
the	_	_
way	_	_
for	_	_
real-time	_	_
semantic	_	_
segmentation	_	_
.	_	_

#101
3.3	_	_
.	_	_

#102
Real-time	_	_
object	_	_
proposal	_	_
For	_	_
3D	_	_
object	_	_
proposal	_	_
,	_	_
Karpathy	_	_
et	_	_
al.	_	_
[	_	_
21	_	_
]	_	_
presented	_	_
a	_	_
method	_	_
for	_	_
discovering	_	_
object	_	_
models	_	_
from	_	_
3D	_	_
meshes	_	_
of	_	_
indoor	_	_
environments	_	_
.	_	_

#103
Their	_	_
method	_	_
first	_	_
generates	_	_
object	_	_
candidates	_	_
by	_	_
over-segmenting	_	_
the	_	_
scene	_	_
on	_	_
different	_	_
thresholds	_	_
.	_	_

#104
The	_	_
candidates	_	_
are	_	_
then	_	_
evaluated	_	_
and	_	_
suppressed	_	_
based	_	_
on	_	_
geometric	_	_
metrics	_	_
to	_	_
produce	_	_
the	_	_
final	_	_
proposals	_	_
.	_	_

#105
Kanezaki	_	_
[	_	_
20	_	_
]	_	_
proposed	_	_
an	_	_
extension	_	_
of	_	_
selective	_	_
search	_	_
for	_	_
object	_	_
proposal	_	_
on	_	_
3D	_	_
point	_	_
cloud	_	_
.	_	_

#106
One	_	_
common	_	_
drawback	_	_
of	_	_
these	_	_
methods	_	_
is	_	_
their	_	_
high	_	_
computation	_	_
cost	_	_
,	_	_
since	_	_
they	_	_
require	_	_
a	_	_
costly	_	_
object	_	_
analysis	_	_
on	_	_
different	_	_
scales	_	_
.	_	_

#107
This	_	_
process	_	_
has	_	_
to	_	_
be	_	_
done	_	_
for	_	_
every	_	_
update	_	_
,	_	_
which	_	_
hinders	_	_
real-time	_	_
performance	_	_
.	_	_

#108
In	_	_
this	_	_
work	_	_
,	_	_
we	_	_
explore	_	_
on	_	_
a	_	_
new	_	_
direction	_	_
for	_	_
object	_	_
proposal	_	_
,	_	_
in	_	_
which	_	_
we	_	_
propose	_	_
object	_	_
based	_	_
on	_	_
statistical	_	_
evidences	_	_
.	_	_

#109
Our	_	_
object	_	_
proposal	_	_
is	_	_
come	_	_
from	_	_
a	_	_
simple	_	_
observation	_	_
:	_	_
given	_	_
an	_	_
object	_	_
and	_	_
multiple	_	_
observations	_	_
,	_	_
it	_	_
should	_	_
be	_	_
identified	_	_
as	_	_
an	_	_
object	_	_
in	_	_
most	_	_
of	_	_
the	_	_
corresponding	_	_
2D	_	_
semantic	_	_
predictions	_	_
.	_	_

#110
Hence	_	_
,	_	_
for	_	_
each	_	_
incoming	_	_
RGB-D	_	_
frame	_	_
,	_	_
we	_	_
update	_	_
the	_	_
objectness	_	_
score	_	_
of	_	_
a	_	_
voxel	_	_
given	_	_
its	_	_
current	_	_
predicted	_	_
label	_	_
.	_	_

#111
Specifically	_	_
,	_	_
we	_	_
decrease	_	_
the	_	_
objectness	_	_
score	_	_
if	_	_
the	_	_
prediction	_	_
is	_	_
a	_	_
non-object	_	_
label	_	_
,	_	_
i.e.	_	_
wall	_	_
,	_	_
floor	_	_
,	_	_
or	_	_
ceiling	_	_
;	_	_
and	_	_
increase	_	_
it	_	_
otherwise	_	_
.	_	_

#112
To	_	_
perform	_	_
object	_	_
proposal	_	_
,	_	_
we	_	_
employ	_	_
an	_	_
efficient	_	_
graph-based	_	_
segmentation	_	_
algorithm	_	_
from	_	_
Felzenszwalb	_	_
and	_	_
Huttenlocher	_	_
[	_	_
12	_	_
]	_	_
.	_	_

#113
The	_	_
edge	_	_
weight	_	_
between	_	_
two	_	_
super-voxels	_	_
i	_	_
and	_	_
j	_	_
is	_	_
defined	_	_
as	_	_
wi	_	_
,	_	_
j	_	_
=	_	_
wαi	_	_
,	_	_
j	_	_
+wηi	_	_
,	_	_
j	_	_
+wωi	_	_
,	_	_
j	_	_
where	_	_
wαi	_	_
,	_	_
j	_	_
,	_	_
w	_	_
η	_	_
i	_	_
,	_	_
j	_	_
,	_	_
and	_	_
wωi	_	_
,	_	_
j	_	_
are	_	_
the	_	_
edge	_	_
weight	_	_
for	_	_
voxel	_	_
color	_	_
,	_	_
normal	_	_
,	_	_
and	_	_
objectness	_	_
,	_	_
respectively	_	_
.	_	_

#114
We	_	_
normalize	_	_
the	_	_
each	_	_
of	_	_
the	_	_
weights	_	_
accordingly	_	_
.	_	_

#115
To	_	_
reduce	_	_
computation	_	_
cost	_	_
,	_	_
we	_	_
only	_	_
compute	_	_
the	_	_
terms	_	_
using	_	_
representative	_	_
values	_	_
from	_	_
super-voxel	_	_
centroids	_	_
.	_	_

#116
4.	_	_
Higher-order	_	_
CRF	_	_
Refinement	_	_

#117
Using	_	_
CRF	_	_
as	_	_
a	_	_
post-processing	_	_
step	_	_
is	_	_
a	_	_
common	_	_
technique	_	_
in	_	_
semantic	_	_
segmentation	_	_
.	_	_

#118
However	_	_
,	_	_
for	_	_
real-time	_	_
applications	_	_
,	_	_
there	_	_
are	_	_
two	_	_
limitations	_	_
that	_	_
we	_	_
must	deontic	_
address	_	_
.	_	_

#119
First	_	_
is	_	_
the	_	_
classification	_	_
errors	_	_
caused	_	_
by	_	_
inconsistencies	_	_
,	_	_
sometimes	_	_
known	_	_
as	_	_
“bleeding”	_	_
,	_	_
that	_	_
is	_	_
also	_	_
reported	_	_
by	_	_
Valentin	_	_
et	_	_
al.	_	_
[	_	_
44	_	_
]	_	_
.	_	_

#120
The	_	_
second	_	_
issue	_	_
is	_	_
scalability	_	_
,	_	_
since	_	_
the	_	_
number	_	_
of	_	_
vertices	_	_
in	_	_
the	_	_
graph	_	_
grows	_	_
to	_	_
millions	_	_
during	_	_
scanning	_	_
,	_	_
causing	_	_
CRF	_	_
optimizations	_	_
to	_	_
become	_	_
much	_	_
slower	_	_
over	_	_
time	_	_
.	_	_

#121
In	_	_
this	_	_
work	_	_
,	_	_
we	_	_
address	_	_
both	_	_
limitations	_	_
by	_	_
introducing	_	_
a	_	_
CRF	_	_
model	_	_
with	_	_
higher-order	_	_
constraints	_	_
on	_	_
super-voxels	_	_
to	_	_
perform	_	_
online	_	_
segmentation	_	_
.	_	_

#122
This	_	_
model	_	_
is	_	_
lightweight	_	_
and	_	_
very	_	_
easy	_	_
to	_	_
compute	_	_
,	_	_
allowing	_	_
it	_	_
to	_	_
work	_	_
on	_	_
a	_	_
wide	_	_
range	_	_
of	_	_
indoor	_	_
scenes	_	_
,	_	_
while	_	_
remaining	_	_
computationally	_	_
efficient	_	_
for	_	_
real-time	_	_
use	_	_
.	_	_

#123
Let	_	_
Mt	_	_
be	_	_
the	_	_
3D	_	_
geometry	_	_
at	_	_
time	_	_
t	_	_
with	_	_
N	_	_
t	_	_
supervoxels	_	_
.	_	_

#124
In	_	_
a	_	_
semantic	_	_
segmentation	_	_
problem	_	_
,	_	_
we	_	_
attempt	_	_
to	_	_
assign	_	_
every	_	_
super-voxel	_	_
with	_	_
a	_	_
label	_	_
from	_	_
a	_	_
discrete	_	_
label	_	_
space	_	_
,	_	_
denoted	_	_
L	_	_
=	_	_
{	_	_
l1	_	_
,	_	_
l2	_	_
,	_	_
.	_	_

#125
.	_	_

#126
.	_	_

#127
,	_	_
lL	_	_
}	_	_
.	_	_

#128
Let	_	_
Xt	_	_
=	_	_
{	_	_
xt1	_	_
,	_	_
.	_	_

#129
.	_	_

#130
.	_	_

#131
,	_	_
xtN	_	_
}	_	_
define	_	_
a	_	_
set	_	_
of	_	_
random	_	_
variables	_	_
,	_	_
one	_	_
for	_	_
each	_	_
super-voxel	_	_
,	_	_
where	_	_
xti	_	_
∈	_	_
L.	_	_
An	_	_
assignment	_	_
of	_	_
every	_	_
xti	_	_
will	_	_
be	_	_
a	_	_
solution	_	_
to	_	_
the	_	_
segmentation	_	_
problem	_	_
at	_	_
time	_	_
t.	_	_
For	_	_
shorter	_	_
notation	_	_
,	_	_
we	_	_
will	_	_
drop	_	_
the	_	_
superscript	_	_
time	_	_
notation	_	_
from	_	_
now	_	_
on	_	_
.	_	_

#132
Given	_	_
the	_	_
above	_	_
definitions	_	_
,	_	_
we	_	_
define	_	_
a	_	_
graph	_	_
G	_	_
where	_	_
each	_	_
vertex	_	_
is	_	_
from	_	_
X	_	_
.	_	_

#133
In	_	_
addition	_	_
,	_	_
let	_	_
C	_	_
be	_	_
the	_	_
set	_	_
of	_	_
cliques	_	_
in	_	_
G	_	_
,	_	_
given	_	_
by	_	_
an	_	_
object	_	_
proposal	_	_
method	_	_
.	_	_

#134
For	_	_
every	_	_
clique	_	_
r	_	_
∈	_	_
C	_	_
,	_	_
we	_	_
can	_	_
select	_	_
a	_	_
corresponding	_	_
set	_	_
of	_	_
random	_	_
variables	_	_
xr	_	_
that	_	_
belongs	_	_
to	_	_
r.	_	_
Our	_	_
CRF	_	_
model	_	_
introduces	_	_
three	_	_
new	_	_
types	_	_
of	_	_
higher-order	_	_
potential	_	_
,	_	_
namely	_	_
objectness	_	_
potential	_	_
ψO	_	_
,	_	_
consistency	_	_
potential	_	_
ψC	_	_
and	_	_
object	_	_
relationship	_	_
potential	_	_
ψR	_	_
.	_	_

#135
These	_	_
terms	_	_
are	_	_
later	_	_
explained	_	_
in	_	_
Section	_	_
4.1	_	_
,	_	_
4.2	_	_
,	_	_
and	_	_
4.3	_	_
,	_	_
respectively	_	_
.	_	_

#136
Our	_	_
complete	_	_
CRF	_	_
model	_	_
is	_	_
then	_	_
defined	_	_
as	_	_
E	_	_
(	_	_
X	_	_
)	_	_
=	_	_
∑	_	_
i	_	_
ϕ	_	_
(	_	_
xi	_	_
)	_	_
+	_	_
∑	_	_
i	_	_
<	_	_
j	_	_
ψP	_	_
(	_	_
xi	_	_
,	_	_
xj	_	_
)	_	_
+	_	_
∑	_	_
r∈C	_	_
ψO	_	_
(	_	_
xr	_	_
)	_	_
+	_	_
∑	_	_
r∈C	_	_
ψC	_	_
(	_	_
xr	_	_
)	_	_
+	_	_
∑	_	_
r	_	_
,	_	_
q∈E	_	_
(	_	_
C	_	_
)	_	_
ψR	_	_
(	_	_
xr	_	_
,	_	_
xq	_	_
)	_	_
(	_	_
2	_	_
)	_	_
where	_	_
ϕ	_	_
(	_	_
xi	_	_
)	_	_
and	_	_
ψP	_	_
(	_	_
xi	_	_
,	_	_
xj	_	_
)	_	_
are	_	_
the	_	_
unary	_	_
and	_	_
pairwise	_	_
terms	_	_
used	_	_
in	_	_
the	_	_
traditional	_	_
dense	_	_
CRF	_	_
model	_	_
.	_	_

#137
The	_	_
unary	_	_
term	_	_
represent	_	_
the	_	_
prediction	_	_
from	_	_
a	_	_
local	_	_
classifier	_	_
.	_	_

#138
In	_	_
our	_	_
case	_	_
,	_	_
it	_	_
is	_	_
obtained	_	_
from	_	_
fusing	_	_
CNN	_	_
predictions	_	_
during	_	_
reconstruction	_	_
.	_	_

#139
The	_	_
pairwise	_	_
(	_	_
smoothness	_	_
)	_	_
potential	_	_
ψP	_	_
(	_	_
xi	_	_
,	_	_
xj	_	_
)	_	_
is	_	_
parameterized	_	_
by	_	_
a	_	_
Gaussian	_	_
kernel	_	_
ψP	_	_
(	_	_
xi	_	_
,	_	_
xj	_	_
)	_	_
=	_	_
µij	_	_
exp	_	_
(	_	_
−|	_	_
pi	_	_
−	_	_
pj	_	_
|	_	_
2θ2α	_	_
−	_	_
|	_	_
ni	_	_
−	_	_
nj	_	_
|	_	_
2θ2β	_	_
)	_	_
(	_	_
3	_	_
)	_	_
where	_	_
µij	_	_
is	_	_
the	_	_
label	_	_
compatibility	_	_
function	_	_
between	_	_
xi	_	_
and	_	_
xj	_	_
given	_	_
by	_	_
the	_	_
Potts	_	_
model	_	_
;	_	_
pi	_	_
and	_	_
ni	_	_
are	_	_
the	_	_
location	_	_
and	_	_
normal	_	_
of	_	_
the	_	_
ith	_	_
super-voxel	_	_
;	_	_
θα	_	_
and	_	_
θβ	_	_
are	_	_
standard	_	_
deviations	_	_
of	_	_
the	_	_
kernel	_	_
.	_	_

#140
4.1	_	_
.	_	_

#141
Objectness	_	_
potential	_	_
The	_	_
term	_	_
ψO	_	_
(	_	_
xr	_	_
)	_	_
captures	_	_
the	_	_
mutual	_	_
agreement	_	_
between	_	_
the	_	_
objectness	_	_
score	_	_
of	_	_
a	_	_
clique	_	_
and	_	_
its	_	_
semantic	_	_
label	_	_
.	_	_

#142
Ideally	_	_
,	_	_
we	_	_
would	_	_
want	_	_
a	_	_
clique	_	_
with	_	_
low	_	_
objectness	_	_
score	_	_
to	_	_
take	_	_
a	_	_
non-object	_	_
label	_	_
,	_	_
i.e.	_	_
wall	_	_
,	_	_
floor	_	_
,	_	_
or	_	_
ceiling	_	_
;	_	_
and	_	_
inversely	_	_
.	_	_

#143
To	_	_
model	_	_
the	_	_
objectness	_	_
potential	_	_
of	_	_
a	_	_
clique	_	_
,	_	_
we	_	_
first	_	_
introduce	_	_
latent	_	_
binary	_	_
random	_	_
variables	_	_
y1	_	_
,	_	_
.	_	_

#144
.	_	_

#145
.	_	_

#146
,	_	_
y|C|	_	_
.	_	_

#147
yk	_	_
can	_	_
be	_	_
interpreted	_	_
as	_	_
follows	_	_
:	_	_
if	_	_
the	_	_
kth	_	_
proposal	_	_
has	_	_
been	_	_
found	_	_
to	_	_
be	_	_
an	_	_
object	_	_
,	_	_
then	_	_
yk	_	_
is	_	_
1	_	_
,	_	_
otherwise	_	_
it	_	_
will	_	_
be	_	_
0	_	_
.	_	_

#148
Let	_	_
O	_	_
be	_	_
the	_	_
subset	_	_
of	_	_
L	_	_
,	_	_
which	_	_
comprises	_	_
of	_	_
object	_	_
classes	_	_
in	_	_
the	_	_
label	_	_
space	_	_
.	_	_

#149
We	_	_
can	_	_
then	_	_
define	_	_
our	_	_
objectness	_	_
potential	_	_
ψO	_	_
(	_	_
xr	_	_
)	_	_
=	_	_
{	_	_
|xr|	_	_
∑	_	_
i∈xr	_	_
[	_	_
xi	_	_
/∈	_	_
O	_	_
]	_	_
,	_	_
if	_	_
yr	_	_
=	_	_
1	_	_
,	_	_
|xr|	_	_
∑	_	_
i∈xr	_	_
[	_	_
xi	_	_
∈	_	_
O	_	_
]	_	_
,	_	_
if	_	_
yr	_	_
=	_	_
0	_	_
,	_	_
(	_	_
4	_	_
)	_	_
where	_	_
[	_	_
·	_	_
]	_	_
is	_	_
a	_	_
function	_	_
that	_	_
converts	_	_
a	_	_
logical	_	_
proposition	_	_
into	_	_
1	_	_
if	_	_
the	_	_
condition	_	_
is	_	_
satisfied	_	_
,	_	_
otherwise	_	_
it	_	_
would	_	_
be	_	_
0	_	_
.	_	_

#150
The	_	_
purpose	_	_
of	_	_
this	_	_
term	_	_
is	_	_
to	_	_
correct	_	_
misclassification	_	_
errors	_	_
in	_	_
the	_	_
local	_	_
classifier	_	_
,	_	_
based	_	_
on	_	_
external	_	_
unsupervised	_	_
information	_	_
from	_	_
object	_	_
proposal	_	_
.	_	_

#151
4.2	_	_
.	_	_

#152
Label	_	_
consistency	_	_
The	_	_
term	_	_
ψC	_	_
(	_	_
xr	_	_
)	_	_
enforces	_	_
regional	_	_
consistency	_	_
in	_	_
semantic	_	_
segmentation	_	_
.	_	_

#153
Since	_	_
we	_	_
want	_	_
vertex	_	_
labels	_	_
in	_	_
the	_	_
same	_	_
clique	_	_
to	_	_
be	_	_
homogeneous	_	_
,	_	_
the	_	_
cost	_	_
function	_	_
penalizes	_	_
label	_	_
based	_	_
on	_	_
its	_	_
frequency	_	_
in	_	_
the	_	_
clique	_	_
.	_	_

#154
Let	_	_
fr	_	_
(	_	_
lk	_	_
)	_	_
be	_	_
the	_	_
normalized	_	_
frequency	_	_
of	_	_
label	_	_
lk	_	_
∈	_	_
L	_	_
inside	_	_
the	_	_
rth	_	_
clique	_	_
,	_	_
which	_	_
is	_	_
of	_	_
the	_	_
range	_	_
between	_	_
0	_	_
and	_	_
1	_	_
.	_	_

#155
The	_	_
consistency	_	_
cost	_	_
will	_	_
be	_	_
the	_	_
entropy	_	_
of	_	_
the	_	_
underlying	_	_
distribution	_	_
:	_	_
ψC	_	_
(	_	_
xr	_	_
)	_	_
=	_	_
−	_	_
∑	_	_
lk∈L	_	_
fr	_	_
(	_	_
lk	_	_
)	_	_
log	_	_
fr	_	_
(	_	_
lk	_	_
)	_	_
(	_	_
5	_	_
)	_	_
This	_	_
term	_	_
dampens	_	_
infrequent	_	_
labels	_	_
in	_	_
a	_	_
clique	_	_
.	_	_

#156
In	_	_
experiments	_	_
,	_	_
We	_	_
observed	_	_
that	_	_
the	_	_
label	_	_
consistency	_	_
cost	_	_
helps	_	_
fixing	_	_
low	_	_
frequency	_	_
errors	_	_
in	_	_
the	_	_
output	_	_
segmentation	_	_
.	_	_

#157
4.3	_	_
.	_	_

#158
Region	_	_
relationship	_	_
The	_	_
relationship	_	_
potential	_	_
ψR	_	_
encodes	_	_
the	_	_
relation	_	_
between	_	_
two	_	_
regions	_	_
(	_	_
cliques	_	_
)	_	_
and	_	_
their	_	_
semantic	_	_
labels	_	_
.	_	_

#159
This	_	_
cost	_	_
is	_	_
applied	_	_
on	_	_
neighboring	_	_
regions	_	_
,	_	_
based	_	_
on	_	_
super-voxel	_	_
connectivity	_	_
.	_	_

#160
In	_	_
our	_	_
model	_	_
,	_	_
the	_	_
term	_	_
ψR	_	_
(	_	_
xr	_	_
,	_	_
xq	_	_
)	_	_
is	_	_
defined	_	_
based	_	_
on	_	_
the	_	_
co-occurrence	_	_
of	_	_
class	_	_
labels	_	_
in	_	_
the	_	_
regions	_	_
.	_	_

#161
Specifically	_	_
,	_	_
let	_	_
E	_	_
(	_	_
C	_	_
)	_	_
⊂	_	_
C	_	_
×	_	_
C	_	_
be	_	_
the	_	_
edges	_	_
between	_	_
connected	_	_
cliques	_	_
.	_	_

#162
The	_	_
object	_	_
relationship	_	_
cost	_	_
between	_	_
xr	_	_
and	_	_
xq	_	_
is	_	_
defined	_	_
as	_	_
follows	_	_
,	_	_
ψR	_	_
(	_	_
xr	_	_
,	_	_
xq	_	_
)	_	_
=	_	_
−	_	_
∑	_	_
li∈L	_	_
∑	_	_
lj∈L	_	_
log	_	_
(	_	_
fr	_	_
(	_	_
li	_	_
)	_	_
fq	_	_
(	_	_
lj	_	_
)	_	_
Λli	_	_
,	_	_
lj	_	_
)	_	_
(	_	_
6	_	_
)	_	_
where	_	_
Λli	_	_
,	_	_
lj	_	_
is	_	_
the	_	_
co-occurrence	_	_
cost	_	_
based	_	_
on	_	_
the	_	_
class	_	_
labels	_	_
li	_	_
and	_	_
lj	_	_
and	_	_
designed	_	_
such	_	_
that	_	_
the	_	_
more	_	_
often	_	_
li	_	_
and	_	_
lj	_	_
co-occur	_	_
,	_	_
the	_	_
greater	_	_
Λli	_	_
,	_	_
lj	_	_
is	_	_
.	_	_

#163
This	_	_
cost	_	_
acts	_	_
like	_	_
a	_	_
prior	_	_
to	_	_
prevent	_	_
uncommon	_	_
label	_	_
transition	_	_
,	_	_
e.g.	_	_
chair	_	_
to	_	_
ceiling	_	_
,	_	_
ceiling	_	_
to	_	_
floor	_	_
,	_	_
etc	_	_
;	_	_
and	_	_
can	_	_
be	_	_
learnt	_	_
beforehand	_	_
.	_	_

#164
fr	_	_
and	_	_
fq	_	_
are	_	_
the	_	_
label	_	_
frequencies	_	_
,	_	_
as	_	_
presented	_	_
in	_	_
(	_	_
5	_	_
)	_	_
.	_	_

#165
In	_	_
our	_	_
CRF	_	_
model	_	_
,	_	_
each	_	_
term	_	_
is	_	_
accompanied	_	_
with	_	_
a	_	_
weight	_	_
to	_	_
balance	_	_
their	_	_
values	_	_
that	_	_
we	_	_
omit	_	_
them	_	_
in	_	_
our	_	_
formulas	_	_
for	_	_
better	_	_
clarity	_	_
.	_	_

#166
We	_	_
learn	_	_
these	_	_
weights	_	_
by	_	_
grid	_	_
search	_	_
,	_	_
and	_	_
keep	_	_
them	_	_
unchanged	_	_
in	_	_
all	_	_
of	_	_
the	_	_
experiments	_	_
.	_	_

#167
Finally	_	_
,	_	_
semantic	_	_
segmentation	_	_
can	_	_
be	_	_
done	_	_
by	_	_
minimizing	_	_
the	_	_
energy	_	_
function	_	_
E	_	_
(	_	_
X	_	_
)	_	_
defined	_	_
in	_	_
(	_	_
2	_	_
)	_	_
.	_	_

#168
In	_	_
this	_	_
paper	_	_
,	_	_
we	_	_
adopt	_	_
the	_	_
variational	_	_
mean	_	_
field	_	_
method	_	_
[	_	_
23	_	_
]	_	_
for	_	_
efficiently	_	_
optimizing	_	_
E	_	_
(	_	_
X	_	_
)	_	_
.	_	_

#169
Details	_	_
of	_	_
the	_	_
inference	_	_
process	_	_
can	_	_
be	_	_
found	_	_
in	_	_
the	_	_
supplementary	_	_
material	_	_
.	_	_

#170
4.4	_	_
.	_	_

#171
Temporal	_	_
consistency	_	_
We	_	_
support	_	_
temporal	_	_
consistency	_	_
with	_	_
a	_	_
simple	_	_
modification	_	_
of	_	_
the	_	_
unary	_	_
term	_	_
as	_	_
follows	_	_
.	_	_

#172
To	_	_
minimize	_	_
storage	_	_
,	_	_
let	_	_
us	_	_
only	_	_
consider	_	_
time	_	_
t−	_	_
1	_	_
and	_	_
time	_	_
t.	_	_
The	_	_
unary	_	_
term	_	_
becomes	_	_
a	_	_
weighted	_	_
sum	_	_
that	_	_
takes	_	_
as	_	_
input	_	_
the	_	_
final	_	_
labels	_	_
at	_	_
time	_	_
t	_	_
−	_	_
1	_	_
(	_	_
XCRF	_	_
,	_	_
after	_	_
CRF	_	_
of	_	_
time	_	_
t	_	_
−	_	_
1	_	_
)	_	_
and	_	_
the	_	_
CNN	_	_
predicted	_	_
labels	_	_
at	_	_
the	_	_
time	_	_
t	_	_
(	_	_
Xpredicted	_	_
,	_	_
before	_	_
CRF	_	_
)	_	_
:	_	_
Xt	_	_
unary	_	_
=	_	_
τXt	_	_
predicted	_	_
+	_	_
(	_	_
1	_	_
−	_	_
τ	_	_
)	_	_
Xt−1	_	_
CRF	_	_
where	_	_
X	_	_
are	_	_
the	_	_
label	_	_
probabilities	_	_
,	_	_
and	_	_
τ	_	_
∈	_	_
[	_	_
0	_	_
,	_	_
1	_	_
]	_	_
is	_	_
a	_	_
scalar	_	_
value	_	_
.	_	_

#173
Smaller	_	_
τ	_	_
favors	_	_
temporal	_	_
consistency	_	_
.	_	_

#174
We	_	_
set	_	_
τ	_	_
empirically	_	_
by	_	_
plotting	_	_
the	_	_
segmentation	_	_
accuracy	_	_
with	_	_
multiple	_	_
τ	_	_
.	_	_

#175
Our	_	_
experiment	_	_
(	_	_
see	_	_
supplementary	_	_
)	_	_
shows	_	_
that	_	_
τ	_	_
=	_	_
0.5	_	_
strikes	_	_
a	_	_
balance	_	_
between	_	_
accuracy	_	_
and	_	_
temporal	_	_
consistency	_	_
.	_	_

#176
4.5	_	_
.	_	_

#177
Instance	_	_
segmentation	_	_
Beyond	_	_
category-based	_	_
semantic	_	_
segmentation	_	_
,	_	_
we	_	_
extend	_	_
our	_	_
technique	_	_
to	_	_
support	_	_
instance-based	_	_
semantic	_	_
segmentation	_	_
in	_	_
real	_	_
time	_	_
,	_	_
which	_	_
we	_	_
refer	_	_
to	_	_
as	_	_
instance	_	_
segmentation	_	_
for	_	_
brevity	_	_
.	_	_

#178
The	_	_
key	_	_
change	_	_
is	_	_
that	_	_
CRF	_	_
model	_	_
now	_	_
outputs	_	_
instance	_	_
IDs	_	_
instead	_	_
of	_	_
class	_	_
segmentation	_	_
labels	_	_
.	_	_

#179
Other	_	_
terms	_	_
and	_	_
the	_	_
optimization	_	_
process	_	_
are	_	_
kept	_	_
unchanged	_	_
.	_	_

#180
A	_	_
straightforward	_	_
approach	_	_
for	_	_
instance	_	_
segmentation	_	_
would	_	_
be	_	_
utilizing	_	_
a	_	_
deep	_	_
neural	_	_
network	_	_
that	_	_
can	_	_
perform	_	_
instance-based	_	_
segmentation	_	_
in	_	_
2D	_	_
,	_	_
and	_	_
then	_	_
propagate	_	_
the	_	_
predictions	_	_
from	_	_
2D	_	_
to	_	_
3D	_	_
as	_	_
in	_	_
the	_	_
category-based	_	_
semantic	_	_
segmentation	_	_
case	_	_
.	_	_

#181
However	_	_
,	_	_
this	_	_
approach	_	_
requires	_	_
us	_	_
to	_	_
track	_	_
the	_	_
instance	_	_
IDs	_	_
over	_	_
time	_	_
,	_	_
which	_	_
is	_	_
in	_	_
fact	_	_
a	_	_
challenging	_	_
problem	_	_
,	_	_
since	_	_
the	_	_
networks	_	_
,	_	_
e.g.	_	_
,	_	_
[	_	_
14	_	_
]	_	_
,	_	_
can	_	_
only	_	_
predict	_	_
one	_	_
frame	_	_
at	_	_
a	_	_
time	_	_
.	_	_

#182
Our	_	_
solution	_	_
is	_	_
to	_	_
combine	_	_
category-based	_	_
semantic	_	_
segmentation	_	_
network	_	_
with	_	_
the	_	_
following	_	_
instance-based	_	_
segmentation	_	_
to	_	_
yield	_	_
instance	_	_
IDs	_	_
.	_	_

#183
For	_	_
each	_	_
vertex	_	_
xi	_	_
in	_	_
the	_	_
CRF	_	_
,	_	_
we	_	_
have	_	_
to	_	_
define	_	_
probabilities	_	_
over	_	_
every	_	_
possible	_	_
instance	_	_
IDs	_	_
.	_	_

#184
The	_	_
label	_	_
space	_	_
,	_	_
L	_	_
=	_	_
{	_	_
l1	_	_
,	_	_
l2	_	_
,	_	_
.	_	_

#185
.	_	_

#186
.	_	_

#187
,	_	_
lL	_	_
}	_	_
,	_	_
would	_	_
be	_	_
the	_	_
set	_	_
of	_	_
all	_	_
instance	_	_
IDs	_	_
in	_	_
the	_	_
current	_	_
3D	_	_
reconstruction	_	_
.	_	_

#188
Performing	_	_
CRF	_	_
inference	_	_
on	_	_
the	_	_
entire	_	_
set	_	_
of	_	_
instance	_	_
IDs	_	_
would	_	_
be	_	_
infeasible	_	_
.	_	_

#189
Here	_	_
we	_	_
reduce	_	_
the	_	_
problem	_	_
size	_	_
by	_	_
first	_	_
filtering	_	_
out	_	_
the	_	_
instance	_	_
IDs	_	_
that	_	_
are	_	_
not	_	_
in	_	_
the	_	_
current	_	_
camera	_	_
frustum	_	_
at	_	_
time	_	_
t	_	_
,	_	_
giving	_	_
a	_	_
reduced	_	_
label	_	_
space	_	_
Lt.	_	_
Our	_	_
higher-order	_	_
CRF	_	_
will	_	_
only	_	_
optimize	_	_
instance	_	_
labels	_	_
of	_	_
super-voxels	_	_
in	_	_
the	_	_
camera	_	_
frustum	_	_
,	_	_
instead	_	_
of	_	_
the	_	_
entire	_	_
scene	_	_
as	_	_
before	_	_
.	_	_

#190
The	_	_
result	_	_
is	_	_
then	_	_
fused	_	_
into	_	_
the	_	_
current	_	_
model	_	_
.	_	_

#191
Another	_	_
issue	_	_
in	_	_
progressive	_	_
instance	_	_
segmentation	_	_
is	_	_
how	_	_
to	_	_
update	_	_
the	_	_
label	_	_
space	_	_
L	_	_
,	_	_
since	_	_
online	_	_
scanning	_	_
will	_	_
continuously	_	_
introduce	_	_
new	_	_
instances	_	_
to	_	_
our	_	_
model	_	_
.	_	_

#192
We	_	_
tackle	_	_
this	_	_
problem	_	_
by	_	_
creating	_	_
a	_	_
special	_	_
unknown	_	_
instance	_	_
ID	_	_
.	_	_

#193
All	_	_
of	_	_
the	_	_
newly	_	_
scanned	_	_
voxels	_	_
will	_	_
be	_	_
initialized	_	_
with	_	_
unknown	_	_
.	_	_

#194
After	_	_
each	_	_
CRF	_	_
inference	_	_
step	_	_
,	_	_
the	_	_
largest	_	_
connected	_	_
component	_	_
,	_	_
which	_	_
is	_	_
based	_	_
on	_	_
category	_	_
,	_	_
belongs	_	_
to	_	_
the	_	_
unknown	_	_
instance	_	_
will	_	_
be	_	_
spawned	_	_
as	_	_
a	_	_
new	_	_
instance	_	_
.	_	_

#195
We	_	_
also	_	_
update	_	_
the	_	_
set	_	_
of	_	_
instance	_	_
IDs	_	_
accordingly	_	_
.	_	_

#196
5	_	_
.	_	_

#197
Experiments	_	_
Experiment	_	_
setup	_	_
.	_	_

#198
In	_	_
SemanticFusion	_	_
[	_	_
32	_	_
]	_	_
,	_	_
the	_	_
authors	_	_
chose	_	_
to	_	_
evaluate	_	_
on	_	_
NYUv2	_	_
dataset	_	_
,	_	_
a	_	_
popular	_	_
2D	_	_
dataset	_	_
for	_	_
semantic	_	_
segmentation	_	_
task	_	_
.	_	_

#199
However	_	_
,	_	_
evaluation	_	_
in	_	_
2D	_	_
by	_	_
projecting	_	_
labels	_	_
from	_	_
3D	_	_
model	_	_
to	_	_
2D	_	_
image	_	_
is	_	_
not	_	_
completely	_	_
sound	_	_
;	_	_
since	_	_
2D	_	_
images	_	_
can	_	_
not	_	_
cover	_	_
the	_	_
entire	_	_
scene	_	_
,	_	_
and	_	_
there	_	_
are	_	_
potential	_	_
ambiguities	_	_
when	_	_
doing	_	_
2D-3D	_	_
projection	_	_
.	_	_

#200
To	_	_
tackle	_	_
this	_	_
problem	_	_
,	_	_
we	_	_
perform	_	_
our	_	_
evaluation	_	_
on	_	_
SceneNN	_	_
[	_	_
17	_	_
]	_	_
and	_	_
ScanNet	_	_
[	_	_
8	_	_
]	_	_
,	_	_
which	_	_
are	_	_
two	_	_
3D	_	_
mesh	_	_
datasets	_	_
with	_	_
dense	_	_
annotations	_	_
.	_	_

#201
Our	_	_
evaluation	_	_
can	_	_
act	_	_
as	_	_
a	_	_
reference	_	_
benchmark	_	_
for	_	_
real-time	_	_
3D	_	_
scene	_	_
segmentation	_	_
systems	_	_
.	_	_

#202
ID	_	_
Direct	_	_
SF	_	_
Ours	_	_
Class	_	_
Class	_	_
Class	_	_
Instance	_	_
011	_	_
0.770	_	_
0.776	_	_
0.800	_	_
0.521	_	_
016	_	_
0.607	_	_
0.625	_	_
0.680	_	_
0.342	_	_
030	_	_
0.584	_	_
0.597	_	_
0.658	_	_
0.568	_	_
061	_	_
0.751	_	_
0.777	_	_
0.809	_	_
0.591	_	_
078	_	_
0.497	_	_
0.515	_	_
0.535	_	_
0.349	_	_
086	_	_
0.622	_	_
0.646	_	_
0.668	_	_
0.350	_	_
096	_	_
0.659	_	_
0.668	_	_
0.666	_	_
0.265	_	_
206	_	_
0.766	_	_
0.778	_	_
0.775	_	_
0.417	_	_
223	_	_
0.669	_	_
0.689	_	_
0.729	_	_
0.409	_	_
255	_	_
0.423	_	_
0.439	_	_
0.558	_	_
0.486	_	_
Table	_	_
1	_	_
:	_	_
Comparison	_	_
of	_	_
category-based	_	_
semantic	_	_
segmentation	_	_
accuracy	_	_
on	_	_
typical	_	_
scenes	_	_
in	_	_
SceneNN	_	_
dataset	_	_
.	_	_

#203
We	_	_
report	_	_
performances	_	_
on	_	_
office	_	_
,	_	_
kitchen	_	_
,	_	_
bedroom	_	_
,	_	_
and	_	_
other	_	_
scenes	_	_
.	_	_

#204
Our	_	_
proposed	_	_
CRF	_	_
model	_	_
consistently	_	_
outperforms	_	_
the	_	_
naive	_	_
approach	_	_
that	_	_
directly	_	_
fuses	_	_
neural	_	_
network	_	_
predictions	_	_
to	_	_
3D	_	_
(	_	_
Direct	_	_
)	_	_
[	_	_
6	_	_
]	_	_
,	_	_
and	_	_
SemanticFusion	_	_
(	_	_
SF	_	_
)	_	_
[	_	_
32	_	_
]	_	_
.	_	_

#205
Please	_	_
also	_	_
refer	_	_
to	_	_
the	_	_
supplementary	_	_
document	_	_
for	_	_
weighted	_	_
IoU	_	_
scores	_	_
.	_	_

#206
The	_	_
final	_	_
column	_	_
reports	_	_
the	_	_
average	_	_
precision	_	_
scores	_	_
of	_	_
our	_	_
instance-based	_	_
segmentation	_	_
results	_	_
.	_	_

#207
Acc	_	_
.	_	_

#208
SegNet	_	_
FCN-8s	_	_
SSCNet	_	_
ID	_	_
Base	_	_
Ours	_	_
Base	_	_
Ours	_	_
Base	_	_
Ours	_	_
011	_	_
0.747	_	_
0.837	_	_
0.667	_	_
0.743	_	_
0.475	_	_
0.497	_	_
016	_	_
0.556	_	_
0.714	_	_
0.580	_	_
0.623	_	_
0.648	_	_
0.798	_	_
030	_	_
0.554	_	_
0.668	_	_
0.584	_	_
0.704	_	_
0.505	_	_
0.510	_	_
061	_	_
0.549	_	_
0.841	_	_
0.324	_	_
0.457	_	_
0.700	_	_
0.693	_	_
078	_	_
0.542	_	_
0.666	_	_
0.551	_	_
0.663	_	_
0.515	_	_
0.588	_	_
086	_	_
0.587	_	_
0.686	_	_
0.491	_	_
0.631	_	_
0.543	_	_
0.517	_	_
096	_	_
0.615	_	_
0.683	_	_
0.577	_	_
0.619	_	_
0.631	_	_
0.658	_	_
206	_	_
0.659	_	_
0.812	_	_
0.626	_	_
0.828	_	_
0.861	_	_
0.834	_	_
223	_	_
0.648	_	_
0.758	_	_
0.693	_	_
0.760	_	_
0.644	_	_
0.639	_	_
255	_	_
0.521	_	_
0.654	_	_
0.577	_	_
0.718	_	_
0.547	_	_
0.661	_	_
Table	_	_
2	_	_
:	_	_
Accuracy	_	_
scores	_	_
of	_	_
offline	_	_
semantic	_	_
segmentation	_	_
task	_	_
on	_	_
SceneNN	_	_
[	_	_
17	_	_
]	_	_
.	_	_

#209
Our	_	_
proposed	_	_
CRF	_	_
model	_	_
consistently	_	_
improves	_	_
the	_	_
accuracy	_	_
of	_	_
the	_	_
initial	_	_
predictions	_	_
from	_	_
SegNet	_	_
,	_	_
FCN-8s	_	_
[	_	_
30	_	_
]	_	_
and	_	_
SSCNet	_	_
[	_	_
42	_	_
]	_	_
.	_	_

#210
Please	_	_
refer	_	_
to	_	_
the	_	_
supplementary	_	_
document	_	_
for	_	_
weighted	_	_
IoU	_	_
scores	_	_
and	_	_
more	_	_
results	_	_
on	_	_
ScanNet	_	_
[	_	_
8	_	_
]	_	_
.	_	_

#211
We	_	_
adopt	_	_
two	_	_
common	_	_
metrics	_	_
from	_	_
2D	_	_
semantic	_	_
segmentation	_	_
for	_	_
our	_	_
3D	_	_
evaluation	_	_
,	_	_
namely	_	_
vertex	_	_
accuracy	_	_
(	_	_
A	_	_
)	_	_
and	_	_
frequency	_	_
weighted	_	_
intersection	_	_
over	_	_
union	_	_
(	_	_
wIoU	_	_
)	_	_
.	_	_

#212
Due	_	_
to	_	_
space	_	_
constraint	_	_
,	_	_
we	_	_
only	_	_
show	_	_
our	_	_
accuracy	_	_
evaluation	_	_
in	_	_
this	_	_
section	_	_
.	_	_

#213
Please	_	_
refer	_	_
to	_	_
our	_	_
supplementary	_	_
document	_	_
for	_	_
the	_	_
wIoU	_	_
evaluation	_	_
.	_	_

#214
Implementation	_	_
details	_	_
.	_	_

#215
To	_	_
get	_	_
the	_	_
2D	_	_
segmentation	_	_
predictions	_	_
,	_	_
we	_	_
use	_	_
SegNet	_	_
[	_	_
4	_	_
]	_	_
trained	_	_
on	_	_
SUN	_	_
RGB-D	_	_
dataset	_	_
.	_	_

#216
We	_	_
chose	_	_
SegNet	_	_
as	_	_
it	_	_
has	_	_
better	_	_
accuracy	_	_
for	_	_
indoor	_	_
scenes	_	_
but	_	_
more	_	_
compact	_	_
and	_	_
faster	_	_
alternatives	_	_
[	_	_
36	_	_
,	_	_
49	_	_
,	_	_
27	_	_
,	_	_
40	_	_
,	_	_
55	_	_
,	_	_
51	_	_
,	_	_
54	_	_
]	_	_
could	_	_
<	_	_
capability-feasibility-uncertainty	_	_
>	_	_
be	_	_
used	_	_
.	_	_

#217
The	_	_
CRF	_	_
inference	_	_
is	_	_
the	_	_
work	_	_
by	_	_
Krähenbühl	_	_
and	_	_
Koltun	_	_
[	_	_
23	_	_
]	_	_
.	_	_

#218
For	_	_
the	_	_
best	_	_
performance	_	_
and	_	_
responsiveness	_	_
for	_	_
real	_	_
time	_	_
use	_	_
,	_	_
we	_	_
run	_	_
one	_	_
iteration	_	_
of	_	_
the	_	_
CRF	_	_
inference	_	_
in	_	_
each	_	_
frame	_	_
,	_	_
and	_	_
the	_	_
CNN	_	_
predictions	_	_
every	_	_
K	_	_
frames	_	_
(	_	_
with	_	_
K	_	_
=	_	_
10	_	_
in	_	_
our	_	_
experiment	_	_
)	_	_
.	_	_

#219
This	_	_
aligns	_	_
with	_	_
the	_	_
fact	_	_
that	_	_
the	_	_
geometry	_	_
change	_	_
is	_	_
usually	_	_
subtle	_	_
in	_	_
each	_	_
frame	_	_
,	_	_
and	_	_
label	_	_
propagation	_	_
with	_	_
CRF	_	_
per	_	_
frame	_	_
is	_	_
sufficient	_	_
for	_	_
a	_	_
good	_	_
prediction	_	_
while	_	_
maximizing	_	_
responsiveness	_	_
.	_	_

#220
After	_	_
K	_	_
frames	_	_
when	_	_
geometry	_	_
changes	_	_
more	_	_
significantly	_	_
,	_	_
we	_	_
update	_	_
the	_	_
segmentation	_	_
with	_	_
the	_	_
more	_	_
accurate	_	_
but	_	_
costly	_	_
CNN	_	_
predictions	_	_
.	_	_

#221
Online	_	_
semantic	_	_
segmentation	_	_
.	_	_

#222
We	_	_
compare	_	_
our	_	_
approach	_	_
to	_	_
the	_	_
following	_	_
methods	_	_
:	_	_
(	_	_
1	_	_
)	_	_
Direct	_	_
label	_	_
fusion	_	_
[	_	_
6	_	_
]	_	_
;	_	_
and	_	_
(	_	_
2	_	_
)	_	_
SemanticFusion	_	_
[	_	_
32	_	_
]	_	_
.	_	_

#223
To	_	_
give	_	_
a	_	_
fair	_	_
comparison	_	_
,	_	_
all	_	_
of	_	_
our	_	_
online	_	_
results	_	_
are	_	_
reconstructed	_	_
using	_	_
the	_	_
same	_	_
camera	_	_
trajectories	_	_
and	_	_
semantic	_	_
predictions	_	_
from	_	_
SegNet	_	_
.	_	_

#224
We	_	_
present	_	_
the	_	_
performance	_	_
comparison	_	_
of	_	_
our	_	_
algorithm	_	_
in	_	_
various	_	_
indoor	_	_
settings	_	_
.	_	_

#225
Results	_	_
are	_	_
shown	_	_
in	_	_
Table	_	_
1	_	_
.	_	_

#226
Our	_	_
method	_	_
outperforms	_	_
SemanticFusion	_	_
and	_	_
the	_	_
direct	_	_
fusion	_	_
approach	_	_
in	_	_
almost	_	_
all	_	_
of	_	_
the	_	_
scenes	_	_
.	_	_

#227
Qualitative	_	_
results	_	_
also	_	_
show	_	_
that	_	_
our	_	_
method	_	_
is	_	_
less	_	_
subjective	_	_
to	_	_
noise	_	_
and	_	_
inconsistencies	_	_
in	_	_
segmentation	_	_
compared	_	_
to	_	_
other	_	_
approaches	_	_
,	_	_
especially	_	_
on	_	_
object	_	_
boundaries	_	_
.	_	_

#228
Offline	_	_
semantic	_	_
segmentation	_	_
.	_	_

#229
We	_	_
further	_	_
investigate	_	_
our	_	_
model	_	_
robustness	_	_
subject	_	_
to	_	_
different	_	_
types	_	_
of	_	_
initial	_	_
segmentation	_	_
.	_	_

#230
We	_	_
perform	_	_
the	_	_
experiment	_	_
in	_	_
offline	_	_
setting	_	_
,	_	_
taking	_	_
unary	_	_
predictions	_	_
from	_	_
different	_	_
neural	_	_
networks	_	_
and	_	_
refine	_	_
them	_	_
using	_	_
our	_	_
proposed	_	_
higher-order	_	_
CRF	_	_
.	_	_

#231
For	_	_
the	_	_
offline	_	_
experiment	_	_
,	_	_
since	_	_
the	_	_
meshes	_	_
are	_	_
already	_	_
provided	_	_
,	_	_
we	_	_
run	_	_
CRF	_	_
inference	_	_
directly	_	_
on	_	_
a	_	_
per-vertex	_	_
level	_	_
to	_	_
produce	_	_
highest	_	_
segmentation	_	_
quality	_	_
.	_	_

#232
All	_	_
of	_	_
the	_	_
neural	_	_
networks	_	_
are	_	_
trained	_	_
on	_	_
the	_	_
NYUv2	_	_
dataset	_	_
[	_	_
41	_	_
]	_	_
.	_	_

#233
Results	_	_
from	_	_
SegNet	_	_
[	_	_
4	_	_
]	_	_
,	_	_
SSCNet	_	_
[	_	_
42	_	_
]	_	_
,	_	_
and	_	_
FCN-8s	_	_
[	_	_
30	_	_
]	_	_
are	_	_
shown	_	_
in	_	_
Table	_	_
2	_	_
.	_	_

#234
Note	_	_
that	_	_
SSCNet	_	_
produces	_	_
a	_	_
60×	_	_
36×	_	_
60	_	_
volume	_	_
low	_	_
resolution	_	_
segmentation	_	_
for	_	_
entire	_	_
scene	_	_
due	_	_
to	_	_
memory	_	_
constraints	_	_
,	_	_
so	_	_
we	_	_
need	_	_
to	_	_
re-sample	_	_
to	_	_
a	_	_
higher	_	_
resolution	_	_
.	_	_

#235
In	_	_
contrast	_	_
,	_	_
our	_	_
2D-to-3D	_	_
approach	_	_
can	_	_
achieve	_	_
segmentation	_	_
on	_	_
high	_	_
resolution	_	_
meshes	_	_
at	_	_
almost	_	_
real-time	_	_
rate	_	_
.	_	_

#236
Again	_	_
,	_	_
our	_	_
method	_	_
improves	_	_
SegNet	_	_
by	_	_
10	_	_
%	_	_
in	_	_
accuracy	_	_
,	_	_
SSCNet	_	_
by	_	_
8	_	_
%	_	_
,	_	_
and	_	_
FCN	_	_
by	_	_
9	_	_
%	_	_
.	_	_

#237
This	_	_
shows	_	_
that	_	_
our	_	_
proposed	_	_
CRF	_	_
performs	_	_
robustly	_	_
to	_	_
different	_	_
kinds	_	_
of	_	_
unary	_	_
.	_	_

#238
See	_	_
Figure	_	_
6	_	_
for	_	_
more	_	_
detailed	_	_
qualitative	_	_
comparisons	_	_
.	_	_

#239
Per-class	_	_
accuracy	_	_
.	_	_

#240
We	_	_
measured	_	_
per-class	_	_
accuracy	_	_
of	_	_
our	_	_
method	_	_
and	_	_
SemanticFusion	_	_
[	_	_
32	_	_
]	_	_
(	_	_
see	_	_
Table	_	_
3	_	_
below	_	_
)	_	_
.	_	_

#241
The	_	_
results	_	_
show	_	_
that	_	_
our	_	_
method	_	_
consistently	_	_
outperforms	_	_
SemanticFusion	_	_
.	_	_

#242
On	_	_
average	_	_
,	_	_
we	_	_
increase	_	_
accuracy	_	_
by	_	_
6	_	_
%	_	_
compared	_	_
to	_	_
SemanticFusion	_	_
and	_	_
11	_	_
%	_	_
compared	_	_
to	_	_
the	_	_
direct	_	_
fusion	_	_
method	_	_
.	_	_

#243
Runtime	_	_
analysis	_	_
.	_	_

#244
Runtime	_	_
analysis	_	_
is	_	_
performed	_	_
on	_	_
a	_	_
desktop	_	_
with	_	_
an	_	_
Intel	_	_
Core	_	_
i7-5820K	_	_
3.30GHz	_	_
CPU	_	_
,	_	_
32GB	_	_
RAM	_	_
,	_	_
and	_	_
an	_	_
NVIDIA	_	_
Titan	_	_
X	_	_
GPU	_	_
.	_	_

#245
The	_	_
average	_	_
runtime	_	_
breakdown	_	_
of	_	_
each	_	_
step	_	_
in	_	_
the	_	_
pipeline	_	_
is	_	_
demonstrated	_	_
in	_	_
Figure	_	_
4	_	_
.	_	_

#246
Specifically	_	_
,	_	_
it	_	_
takes	_	_
309.3ms	_	_
on	_	_
average	_	_
to	_	_
run	_	_
a	_	_
single	_	_
forward	_	_
pass	_	_
of	_	_
neural	_	_
network	_	_
.	_	_

#247
Building	_	_
super-voxels	_	_
takes	_	_
34.1ms	_	_
.	_	_

#248
CRF	_	_
with	_	_
higher-order	_	_
constraints	_	_
requires	_	_
additional	_	_
57.9	_	_
ms.	_	_
As	_	_
can	_	_
be	_	_
seen	_	_
,	_	_
over	_	_
time	_	_
when	_	_
wall	_	_
floor	_	_
cabinet	_	_
bed	_	_
chair	_	_
sofa	_	_
table	_	_
door	_	_
Direct	_	_
0.710	_	_
0.914	_	_
0.471	_	_
0.309	_	_
0.430	_	_
0.555	_	_
0.557	_	_
0.313	_	_
SF	_	_
0.728	_	_
0.944	_	_
0.570	_	_
0.343	_	_
0.463	_	_
0.578	_	_
0.701	_	_
0.386	_	_
Ours	_	_
0.750	_	_
0.965	_	_
0.620	_	_
0.375	_	_
0.649	_	_
0.661	_	_
0.698	_	_
0.513	_	_
window	_	_
bookshelf	_	_
picture	_	_
counter	_	_
blinds	_	_
desk	_	_
curtain	_	_
pillow	_	_
Direct	_	_
0.252	_	_
0.839	_	_
0.202	_	_
0.266	_	_
0.215	_	_
0.236	_	_
0.643	_	_
0.268	_	_
SF	_	_
0.315	_	_
0.940	_	_
0.225	_	_
0.371	_	_
0.210	_	_
0.281	_	_
0.830	_	_
0.294	_	_
Ours	_	_
0.425	_	_
0.947	_	_
0.121	_	_
0.551	_	_
0.231	_	_
0.408	_	_
1.000	_	_
0.253	_	_
clothes	_	_
ceiling	_	_
books	_	_
fridge	_	_
television	_	_
paper	_	_
nightstand	_	_
sink	_	_
Direct	_	_
0.197	_	_
0.705	_	_
0.426	_	_
0.700	_	_
0.212	_	_
0.119	_	_
0.076	_	_
0.380	_	_
SF	_	_
0.236	_	_
0.800	_	_
0.524	_	_
0.803	_	_
0.277	_	_
0.320	_	_
0.090	_	_
0.388	_	_
Ours	_	_
0.290	_	_
0.858	_	_
0.603	_	_
0.823	_	_
0.643	_	_
0.097	_	_
0.145	_	_
0.342	_	_
lamp	_	_
shelves	_	_
bag	_	_
structure	_	_
furniture	_	_
prop	_	_
Average	_	_
Direct	_	_
0.284	_	_
0.000	_	_
0.226	_	_
0.121	_	_
0.110	_	_
0.275	_	_
0.367	_	_
SF	_	_
0.391	_	_
0.000	_	_
0.214	_	_
0.169	_	_
0.016	_	_
0.291	_	_
0.423	_	_
Ours	_	_
0.583	_	_
0.000	_	_
0.364	_	_
0.262	_	_
0.018	_	_
0.312	_	_
0.484	_	_
Table	_	_
3	_	_
:	_	_
Per-class	_	_
accuracy	_	_
of	_	_
40	_	_
NYUDv2	_	_
classes	_	_
on	_	_
SceneNN	_	_
dataset	_	_
from	_	_
direct	_	_
fusion	_	_
,	_	_
SemanticFusion	_	_
(	_	_
SF	_	_
)	_	_
and	_	_
ours	_	_
.	_	_

#249
Note	_	_
that	_	_
some	_	_
of	_	_
the	_	_
classes	_	_
are	_	_
missing	_	_
from	_	_
the	_	_
evaluation	_	_
data	_	_
.	_	_

#250
Best	_	_
view	_	_
in	_	_
color	_	_
.	_	_

#251
Prediction	_	_
Ground	_	_
truth	_	_
Prediction	_	_
Ground	_	_
truth	_	_
Figure	_	_
3	_	_
:	_	_
Instance-based	_	_
semantic	_	_
segmentation	_	_
on	_	_
SceneNN	_	_
dataset	_	_
[	_	_
17	_	_
]	_	_
.	_	_

#252
more	_	_
regions	_	_
in	_	_
the	_	_
scene	_	_
are	_	_
reconstructed	_	_
,	_	_
our	_	_
semantic	_	_
segmentation	_	_
still	_	_
takes	_	_
constant	_	_
running	_	_
time	_	_
on	_	_
average	_	_
.	_	_

#253
We	_	_
compared	_	_
our	_	_
online	_	_
approach	_	_
to	_	_
the	_	_
reference	_	_
offline	_	_
approach	_	_
that	_	_
runs	_	_
CNN	_	_
prediction	_	_
every	_	_
frame	_	_
(	_	_
Table	_	_
2	_	_
)	_	_
.	_	_

#254
We	_	_
see	_	_
that	_	_
the	_	_
accuracy	_	_
of	_	_
our	_	_
online	_	_
method	_	_
(	_	_
Table	_	_
1	_	_
)	_	_
is	_	_
about	_	_
5	_	_
%	_	_
lower	_	_
on	_	_
average	_	_
,	_	_
but	_	_
the	_	_
speed	_	_
gain	_	_
is	_	_
more	_	_
than	_	_
8	_	_
times	_	_
.	_	_

#255
Our	_	_
system	_	_
runs	_	_
at	_	_
10-15Hz	_	_
.	_	_

#256
With	_	_
the	_	_
same	_	_
CNN	_	_
predictions	_	_
,	_	_
direct	_	_
fusion	_	_
method	_	_
[	_	_
6	_	_
]	_	_
runs	_	_
at	_	_
17-20Hz	_	_
,	_	_
and	_	_
SemanticFusion	_	_
[	_	_
32	_	_
]	_	_
runs	_	_
at	_	_
14-16Hz	_	_
.	_	_

#257
Note	_	_
that	_	_
such	_	_
methods	_	_
do	_	_
not	_	_
constrain	_	_
label	_	_
consistency	_	_
.	_	_

#258
500	_	_
1000	_	_
1500	_	_
2000	_	_
2500	_	_
3000	_	_
3500	_	_
Frame	_	_
Ru	_	_
nt	_	_
im	_	_
e	_	_
(	_	_
m	_	_
s	_	_
)	_	_
SegNet	_	_
Reconstruction	_	_
Supervoxel	_	_
Proposal	_	_
CRF	_	_
Figure	_	_
4	_	_
:	_	_
Runtime	_	_
analysis	_	_
of	_	_
our	_	_
progressive	_	_
semantic	_	_
segmentation	_	_
system	_	_
.	_	_

#259
Temporal	_	_
accuracy	_	_
.	_	_

#260
Since	_	_
our	_	_
method	_	_
can	_	_
be	_	_
run	_	_
in	_	_
real	_	_
time	_	_
,	_	_
we	_	_
evaluate	_	_
the	_	_
segmentation	_	_
accuracy	_	_
over	_	_
time	_	_
.	_	_

#261
For	_	_
every	_	_
scene	_	_
,	_	_
we	_	_
measure	_	_
the	_	_
accuracy	_	_
every	_	_
100	_	_
frames	_	_
.	_	_

#262
The	_	_
progressive	_	_
segmentation	_	_
results	_	_
are	_	_
shown	_	_
in	_	_
Figure	_	_
6	_	_
.	_	_

#263
The	_	_
results	_	_
suggest	_	_
that	_	_
our	_	_
method	_	_
consistently	_	_
outperforms	_	_
other	_	_
methods	_	_
in	_	_
a	_	_
long	_	_
run	_	_
,	_	_
not	_	_
just	_	_
only	_	_
at	_	_
a	_	_
certain	_	_
time	_	_
period	_	_
.	_	_

#264
In	_	_
addition	_	_
,	_	_
we	_	_
observe	_	_
that	_	_
the	_	_
accuracy	_	_
over	_	_
time	_	_
sometimes	_	_
still	_	_
fluctuates	_	_
slightly	_	_
due	_	_
to	_	_
the	_	_
lack	_	_
of	_	_
full	_	_
temporal	_	_
constraints	_	_
among	_	_
the	_	_
CNN	_	_
predictions	_	_
.	_	_

#265
Addressing	_	_
this	_	_
issue	_	_
could	speculation	_
be	_	_
an	_	_
interesting	_	_
future	_	_
work	_	_
.	_	_

#266
Ablation	_	_
study	_	_
.	_	_

#267
To	_	_
further	_	_
understand	_	_
the	_	_
performance	_	_
of	_	_
our	_	_
CRF	_	_
model	_	_
,	_	_
we	_	_
carry	_	_
out	_	_
an	_	_
ablation	_	_
study	_	_
to	_	_
evaluate	_	_
the	_	_
effects	_	_
of	_	_
each	_	_
CRF	_	_
term	_	_
on	_	_
the	_	_
result	_	_
segmentation	_	_
.	_	_

#268
We	_	_
execute	_	_
three	_	_
runs	_	_
on	_	_
10	_	_
scenes	_	_
,	_	_
each	_	_
run	_	_
enables	_	_
only	_	_
one	_	_
term	_	_
in	_	_
our	_	_
CRF	_	_
model	_	_
,	_	_
and	_	_
record	_	_
their	_	_
performances	_	_
.	_	_

#269
Figure	_	_
5	_	_
visualizes	_	_
the	_	_
results	_	_
on	_	_
these	_	_
10	_	_
scenes	_	_
.	_	_

#270
In	_	_
general	_	_
,	_	_
running	_	_
full	_	_
higher-order	_	_
model	_	_
achieves	_	_
the	_	_
best	_	_
performance	_	_
.	_	_

#271
Enabling	_	_
individual	_	_
term	_	_
is	_	_
able	_	_
to	_	_
outperform	_	_
the	_	_
base	_	_
dense	_	_
CRF	_	_
model	_	_
.	_	_

#272
The	_	_
consistency	_	_
term	_	_
contributes	_	_
the	_	_
most	_	_
in	_	_
the	_	_
performance	_	_
boost	_	_
,	_	_
which	_	_
validates	_	_
our	_	_
initial	_	_
hypothesis	_	_
that	_	_
object-level	_	_
information	_	_
is	_	_
crucial	_	_
when	_	_
performing	_	_
dense	_	_
semantic	_	_
segmentation	_	_
.	_	_

#273
Instance	_	_
segmentation	_	_
.	_	_

#274
To	_	_
evaluate	_	_
our	_	_
instance	_	_
segmentation	_	_
results	_	_
,	_	_
We	_	_
use	_	_
the	_	_
average	_	_
precision	_	_
metric	_	_
[	_	_
29	_	_
]	_	_
with	_	_
minimal	_	_
50	_	_
%	_	_
overlap	_	_
.	_	_

#275
The	_	_
results	_	_
are	_	_
shown	_	_
in	_	_
Table	_	_
1	_	_
.	_	_

#276
Figure	_	_
3	_	_
visualizes	_	_
the	_	_
instance	_	_
segmentation	_	_
in	_	_
two	_	_
indoor	_	_
scenes	_	_
using	_	_
our	_	_
approach	_	_
.	_	_

#277
Such	_	_
results	_	_
could	capability-speculation	_
serve	_	_
as	_	_
a	_	_
baseline	_	_
to	_	_
compare	_	_
with	_	_
more	_	_
sophisticated	_	_
real-time	_	_
3D	_	_
instance	_	_
segmentation	_	_
technique	_	_
in	_	_
the	_	_
future	_	_
.	_	_

#278
6.	_	_
Conclusion	_	_

#279
Our	_	_
proposed	_	_
system	_	_
demonstrates	_	_
the	_	_
capability	_	_
to	_	_
integrate	_	_
semantic	_	_
segmentation	_	_
into	_	_
real-time	_	_
indoor	_	_
scanning	_	_
by	_	_
optimizing	_	_
the	_	_
predictions	_	_
from	_	_
a	_	_
2D	_	_
neural	_	_
network	_	_
with	_	_
a	_	_
novel	_	_
higher-order	_	_
CRF	_	_
model	_	_
.	_	_

#280
The	_	_
results	_	_
and	_	_
ground	_	_
truth	_	_
category-based	_	_
and	_	_
instance-based	_	_
semantic	_	_
segmentation	_	_
will	_	_
be	_	_
made	_	_
publicly	_	_
available	_	_
.	_	_

#281
The	_	_
results	_	_
from	_	_
our	_	_
system	_	_
can	_	_
further	_	_
be	_	_
used	_	_
in	_	_
other	_	_
interactive	_	_
or	_	_
real-time	_	_
applications	_	_
,	_	_
e.g.	_	_
,	_	_
furniture	_	_
arrangement	_	_
[	_	_
53	_	_
]	_	_
,	_	_
or	_	_
object	_	_
manipulation	_	_
and	_	_
picking	_	_
in	_	_
robotics	_	_
.	_	_

#282
Acknowledgment	_	_
.	_	_

#283
This	_	_
research	_	_
project	_	_
is	_	_
partially	_	_
supported	_	_
by	_	_
an	_	_
internal	_	_
grant	_	_
from	_	_
HKUST	_	_
(	_	_
R9429	_	_
)	_	_
.	_	_