#0
A	_	_
Zero-Shot	_	_
Framework	_	_
for	_	_
Sketch	_	_
based	_	_
Image	_	_
Retrieval	_	_
Sasi	_	_
Kiran	_	_
Yelamarthi1	_	_
,	_	_
Shiva	_	_
Krishna	_	_
Reddy1	_	_
,	_	_
Ashish	_	_
Mishra	_	_
,	_	_
and	_	_
Anurag	_	_
Mittal	_	_
Indian	_	_
Institute	_	_
of	_	_
Technology	_	_
Madras	_	_
,	_	_
India	_	_
{	_	_
sasikiran1996	_	_
,	_	_
shivakrishnam912	_	_
}	_	_
@	_	_
gmail.com	_	_
,	_	_
{	_	_
mishra	_	_
,	_	_
amittal	_	_
}	_	_
@	_	_
cse.iitm.ac.in	_	_
Abstract	_	_
.	_	_

#1
Sketch-based	_	_
image	_	_
retrieval	_	_
(	_	_
SBIR	_	_
)	_	_
is	_	_
the	_	_
task	_	_
of	_	_
retrieving	_	_
images	_	_
from	_	_
a	_	_
natural	_	_
image	_	_
database	_	_
that	_	_
correspond	_	_
to	_	_
a	_	_
given	_	_
hand-drawn	_	_
sketch	_	_
.	_	_

#2
Ideally	_	_
,	_	_
an	_	_
SBIR	_	_
model	_	_
should	_	_
learn	_	_
to	_	_
associate	_	_
components	_	_
in	_	_
the	_	_
sketch	_	_
(	_	_
say	_	_
,	_	_
feet	_	_
,	_	_
tail	_	_
,	_	_
etc	_	_
.	_	_
)	_	_

#3
with	_	_
the	_	_
corresponding	_	_
components	_	_
in	_	_
the	_	_
image	_	_
having	_	_
similar	_	_
shape	_	_
characteristics	_	_
.	_	_

#4
However	_	_
,	_	_
current	_	_
evaluation	_	_
methods	_	_
simply	_	_
focus	_	_
only	_	_
on	_	_
coarse-grained	_	_
evaluation	_	_
where	_	_
the	_	_
focus	_	_
is	_	_
on	_	_
retrieving	_	_
images	_	_
which	_	_
belong	_	_
to	_	_
the	_	_
same	_	_
class	_	_
as	_	_
the	_	_
sketch	_	_
but	_	_
not	_	_
necessarily	_	_
having	_	_
the	_	_
same	_	_
shape	_	_
characteristics	_	_
as	_	_
in	_	_
the	_	_
sketch	_	_
.	_	_

#5
As	_	_
a	_	_
result	_	_
,	_	_
existing	_	_
methods	_	_
simply	_	_
learn	_	_
to	_	_
associate	_	_
sketches	_	_
with	_	_
classes	_	_
seen	_	_
during	_	_
training	_	_
and	_	_
hence	_	_
fail	_	_
to	_	_
generalize	_	_
to	_	_
unseen	_	_
classes	_	_
.	_	_

#6
In	_	_
this	_	_
paper	_	_
,	_	_
we	_	_
propose	_	_
a	_	_
new	_	_
benchmark	_	_
for	_	_
zero-shot	_	_
SBIR	_	_
where	_	_
the	_	_
model	_	_
is	_	_
evaluated	_	_
on	_	_
novel	_	_
classes	_	_
that	_	_
are	_	_
not	_	_
seen	_	_
during	_	_
training	_	_
.	_	_

#7
We	_	_
show	_	_
through	_	_
extensive	_	_
experiments	_	_
that	_	_
existing	_	_
models	_	_
for	_	_
SBIR	_	_
that	_	_
are	_	_
trained	_	_
in	_	_
a	_	_
discriminative	_	_
setting	_	_
learn	_	_
only	_	_
class	_	_
specific	_	_
mappings	_	_
and	_	_
fail	_	_
to	_	_
generalize	_	_
to	_	_
the	_	_
proposed	_	_
zero-shot	_	_
setting	_	_
.	_	_

#8
To	_	_
circumvent	_	_
this	_	_
,	_	_
we	_	_
propose	_	_
a	_	_
generative	_	_
approach	_	_
for	_	_
the	_	_
SBIR	_	_
task	_	_
by	_	_
proposing	_	_
deep	_	_
conditional	_	_
generative	_	_
models	_	_
that	_	_
take	_	_
the	_	_
sketch	_	_
as	_	_
an	_	_
input	_	_
and	_	_
fill	_	_
the	_	_
missing	_	_
information	_	_
stochastically	_	_
.	_	_

#9
Experiments	_	_
on	_	_
this	_	_
new	_	_
benchmark	_	_
created	_	_
from	_	_
the	_	_
”Sketchy”	_	_
dataset	_	_
,	_	_
which	_	_
is	_	_
a	_	_
large-scale	_	_
database	_	_
of	_	_
sketch-photo	_	_
pairs	_	_
demonstrate	_	_
that	_	_
the	_	_
performance	_	_
of	_	_
these	_	_
generative	_	_
models	_	_
is	_	_
significantly	_	_
better	_	_
than	_	_
several	_	_
state-of-the-art	_	_
approaches	_	_
in	_	_
the	_	_
proposed	_	_
zero-shot	_	_
framework	_	_
of	_	_
the	_	_
coarse-grained	_	_
SBIR	_	_
task	_	_
.	_	_

#10
Keywords	_	_
:	_	_
Image	_	_
Retrieval	_	_
,	_	_
Zero-Shot	_	_
Learning	_	_

#11
1	_	_
Introduction	_	_

#12
The	_	_
rise	_	_
in	_	_
the	_	_
number	_	_
of	_	_
internet	_	_
users	_	_
coupled	_	_
with	_	_
increased	_	_
storage	_	_
capacity	_	_
,	_	_
better	_	_
internet	_	_
connectivity	_	_
and	_	_
higher	_	_
bandwidths	_	_
has	_	_
resulted	_	_
in	_	_
an	_	_
exponential	_	_
growth	_	_
in	_	_
multimedia	_	_
content	_	_
on	_	_
the	_	_
Web	_	_
.	_	_

#13
In	_	_
particular	_	_
,	_	_
image	_	_
content	_	_
has	_	_
become	_	_
ubiquitous	_	_
and	_	_
plays	_	_
an	_	_
important	_	_
role	_	_
in	_	_
engaging	_	_
users	_	_
on	_	_
social	_	_
media	_	_
as	_	_
well	_	_
as	_	_
customers	_	_
on	_	_
various	_	_
e-commerce	_	_
sites	_	_
.	_	_

#14
With	_	_
this	_	_
growth	_	_
in	_	_
image	_	_
content	_	_
,	_	_
the	_	_
information	_	_
needs	_	_
and	_	_
search	_	_
patterns	_	_
of	_	_
users	_	_
have	_	_
also	_	_
evolved	_	_
.	_	_

#15
Specifically	_	_
,	_	_
it	_	_
is	_	_
now	_	_
common	_	_
for	_	_
users	_	_

#16
1	_	_
Equal	_	_
Contribution	_	_

#17
ar	_	_
X	_	_
iv	_	_
:1	_	_
7	_	_
.	_	_

#18
4v	_	_
1	_	_
[	_	_
cs	_	_
.C	_	_
V	_	_
]	_	_
3	_	_
1	_	_
Ju	_	_
l	_	_
2	_	_

#19
2	_	_
Sasi	_	_
Kiran	_	_
Yelamarthi	_	_
et	_	_
al	_	_

#20
to	_	_
search	_	_
for	_	_
images	_	_
(	_	_
instead	_	_
of	_	_
documents	_	_
)	_	_
either	_	_
by	_	_
providing	_	_
a	_	_
textual	_	_
description	_	_
of	_	_
the	_	_
image	_	_
or	_	_
by	_	_
providing	_	_
another	_	_
image	_	_
which	_	_
is	_	_
similar	_	_
to	_	_
the	_	_
desired	_	_
image	_	_
(	_	_
for	_	_
example	_	_
,	_	_
retrieve	_	_
all	_	_
shirts	_	_
which	_	_
look	_	_
similar	_	_
to	_	_
the	_	_
shirt	_	_
in	_	_
the	_	_
query	_	_
image	_	_
)	_	_
.	_	_

#21
The	_	_
former	_	_
is	_	_
known	_	_
as	_	_
text	_	_
based	_	_
image	_	_
retrieval	_	_
and	_	_
the	_	_
latter	_	_
as	_	_
content	_	_
based	_	_
image	_	_
retrieval	_	_
[	_	_
1	_	_
]	_	_
.	_	_

#22
The	_	_
motivation	_	_
for	_	_
content	_	_
based	_	_
image	_	_
retrieval	_	_
can	_	_
be	_	_
easily	_	_
understood	_	_
by	_	_
taking	_	_
an	_	_
example	_	_
from	_	_
online	_	_
fashion	_	_
.	_	_

#23
Here	_	_
,	_	_
it	_	_
is	_	_
often	_	_
hard	_	_
to	_	_
provide	_	_
a	_	_
textual	_	_
description	_	_
of	_	_
the	_	_
desired	_	_
product	_	_
but	_	_
easier	_	_
to	_	_
provide	_	_
a	_	_
visual	_	_
description	_	_
in	_	_
the	_	_
form	_	_
of	_	_
a	_	_
matching	_	_
image	_	_
.	_	_

#24
The	_	_
visual	_	_
description/query	_	_
need	_	_
not	_	_
necessarily	_	_
be	_	_
an	_	_
image	_	_
but	_	_
can	_	_
also	_	_
be	_	_
a	_	_
sketch	_	_
of	_	_
the	_	_
desired	_	_
product	_	_
,	_	_
if	_	_
no	_	_
image	_	_
is	_	_
available	_	_
.	_	_

#25
The	_	_
user	_	_
can	_	_
simply	_	_
draw	_	_
the	_	_
sketch	_	_
on-the-fly	_	_
on	_	_
touch	_	_
based	_	_
devices	_	_
.	_	_

#26
This	_	_
convenience	_	_
in	_	_
expressing	_	_
a	_	_
visual	_	_
query	_	_
has	_	_
led	_	_
to	_	_
the	_	_
emergence	_	_
of	_	_
Sketch-based	_	_
image	_	_
retrieval	_	_
(	_	_
SBIR	_	_
)	_	_
as	_	_
an	_	_
active	_	_
area	_	_
of	_	_
research	_	_
[	_	_
2,3,4,5,6,7,8,9,10,11,12,13,14,15,16	_	_
]	_	_
.	_	_

#27
The	_	_
primary	_	_
challenge	_	_
here	_	_
is	_	_
the	_	_
domain	_	_
gap	_	_
between	_	_
images	_	_
and	_	_
sketches	_	_
wherein	_	_
sketches	_	_
contain	_	_
only	_	_
an	_	_
outline	_	_
of	_	_
the	_	_
object	_	_
and	_	_
hence	_	_
have	_	_
less	_	_
information	_	_
compared	_	_
to	_	_
images	_	_
.	_	_

#28
The	_	_
second	_	_
challenge	_	_
is	_	_
the	_	_
large	_	_
intra-class	_	_
variance	_	_
present	_	_
in	_	_
sketches	_	_
due	_	_
to	_	_
the	_	_
fact	_	_
that	_	_
humans	_	_
tend	_	_
to	_	_
draw	_	_
sketches	_	_
with	_	_
varied	_	_
levels	_	_
of	_	_
abstraction	_	_
.	_	_

#29
Ideally	_	_
,	_	_
for	_	_
better	_	_
generalization	_	_
,	_	_
a	_	_
model	_	_
for	_	_
SBIR	_	_
must	deontic	_
learn	_	_
to	_	_
discover	_	_
the	_	_
alignments	_	_
between	_	_
the	_	_
components	_	_
of	_	_
the	_	_
sketch	_	_
and	_	_
the	_	_
corresponding	_	_
image	_	_
.	_	_

#30
For	_	_
example	_	_
,	_	_
in	_	_
Figure-1	_	_
,	_	_
we	_	_
would	_	_
want	_	_
the	_	_
model	_	_
to	_	_
associate	_	_
the	_	_
head	_	_
of	_	_
the	_	_
cow	_	_
in	_	_
the	_	_
sketch	_	_
to	_	_
that	_	_
in	_	_
the	_	_
image	_	_
.	_	_

#31
However	_	_
,	_	_
current	_	_
evaluation	_	_
methodology	_	_
[	_	_
17,18,19	_	_
]	_	_
that	_	_
focuses	_	_
only	_	_
on	_	_
class-based	_	_
retrieval	_	_
rather	_	_
than	_	_
shape	_	_
or	_	_
attribute-based	_	_
retrieval	_	_
does	_	_
not	_	_
explicitly	_	_
evaluate	_	_
whether	_	_
such	_	_
associations	_	_
are	_	_
being	_	_
learned	_	_
by	_	_
the	_	_
model	_	_
.	_	_

#32
Specifically	_	_
,	_	_
during	_	_
evaluation	_	_
,	_	_
the	_	_
model	_	_
is	_	_
given	_	_
credit	_	_
if	_	_
it	_	_
simply	_	_
fetches	_	_
an	_	_
image	_	_
which	_	_
belongs	_	_
to	_	_
the	_	_
same	_	_
class	_	_
as	_	_
the	_	_
sketch	_	_
.	_	_

#33
The	_	_
object	_	_
in	_	_
the	_	_
image	_	_
need	_	_
not	_	_
have	_	_
the	_	_
same	_	_
outline	_	_
,	_	_
etc	_	_
as	_	_
in	_	_
the	_	_
sketch	_	_
.	_	_

#34
For	_	_
example	_	_
,	_	_
for	_	_
the	_	_
query	_	_
(	_	_
sketch	_	_
)	_	_
shown	_	_
in	_	_
Figure-1	_	_
,	_	_
there	_	_
is	_	_
no	_	_
guarantee	_	_
that	_	_
the	_	_
model	_	_
fetches	_	_
the	_	_
image	_	_
of	_	_
the	_	_
cow	_	_
with	_	_
the	_	_
same	_	_
number	_	_
of	_	_
feet	_	_
visible	_	_
or	_	_
the	_	_
tail	_	_
visible	_	_
,	_	_
even	_	_
if	_	_
it	_	_
has	_	_
high	_	_
evaluation	_	_
score	_	_
.	_	_

#35
ECCV-18	_	_
submission	_	_
ID	_	_
2152	_	_
3	_	_
Thus	_	_
,	_	_
a	_	_
model	_	_
could	_	_
possibly	_	_
achieve	_	_
good	_	_
performance	_	_
by	_	_
simply	_	_
learning	_	_
a	_	_
class	_	_
specific	_	_
mapping	_	_
from	_	_
sketches	_	_
to	_	_
class	_	_
labels	_	_
and	_	_
retrieve	_	_
all	_	_
the	_	_
images	_	_
from	_	_
the	_	_
same	_	_
class	_	_
as	_	_
that	_	_
of	_	_
the	_	_
query	_	_
sketch	_	_
.	_	_

#36
This	_	_
is	_	_
especially	_	_
so	_	_
,	_	_
when	_	_
the	_	_
unseen	_	_
sketches	_	_
seen	_	_
at	_	_
test	_	_
time	_	_
belong	_	_
to	_	_
the	_	_
same	_	_
set	_	_
of	_	_
classes	_	_
as	_	_
seen	_	_
during	_	_
training	_	_
.	_	_

#37
Furthermore	_	_
,	_	_
existing	_	_
methods	_	_
evaluate	_	_
their	_	_
models	_	_
on	_	_
a	_	_
set	_	_
of	_	_
randomly	_	_
selected	_	_
sketches	_	_
that	_	_
are	_	_
withheld	_	_
during	_	_
training	_	_
.	_	_

#38
However	_	_
,	_	_
the	_	_
images	_	_
corresponding	_	_
to	_	_
the	_	_
withheld	_	_
sketches	_	_
could	_	_
still	_	_
occur	_	_
in	_	_
the	_	_
training	_	_
set	_	_
,	_	_
and	_	_
that	_	_
would	_	_
make	_	_
the	_	_
task	_	_
easier	_	_
.	_	_

#39
One	_	_
way	_	_
to	_	_
discourage	_	_
such	_	_
class	_	_
specific	_	_
learning	_	_
is	_	_
to	_	_
employ	_	_
a	_	_
fine-grained	_	_
evaluation	_	_
.	_	_

#40
For	_	_
a	_	_
given	_	_
sketch	_	_
,	_	_
the	_	_
retrieved	_	_
results	_	_
are	_	_
evaluated	_	_
by	_	_
comparing	_	_
the	_	_
estimated	_	_
ranking	_	_
of	_	_
images	_	_
in	_	_
the	_	_
database	_	_
with	_	_
a	_	_
human	_	_
annotated	_	_
rank	_	_
list	_	_
.	_	_

#41
However	_	_
,	_	_
creating	_	_
such	_	_
annotations	_	_
for	_	_
large	_	_
datasets	_	_
such	_	_
as	_	_
”Sketchy”	_	_
[	_	_
19	_	_
]	_	_
requires	_	_
extensive	_	_
human	_	_
labor	_	_
.	_	_

#42
Also	_	_
,	_	_
such	_	_
evaluation	_	_
metrics	_	_
are	_	_
subject	_	_
to	_	_
human	_	_
biases	_	_
.	_	_

#43
Indeed	_	_
,	_	_
this	_	_
approach	_	_
was	_	_
employed	_	_
in	_	_
several	_	_
prior	_	_
works	_	_
such	_	_
as	_	_
[	_	_
15,9	_	_
]	_	_
In	_	_
this	_	_
work	_	_
,	_	_
we	_	_
propose	_	_
coarse-grained	_	_
evaluation	_	_
in	_	_
the	_	_
zero-shot	_	_
setting	_	_
as	_	_
a	_	_
surrogate	_	_
to	_	_
fine-grained	_	_
evaluation	_	_
to	_	_
circumvent	_	_
both	_	_
these	_	_
drawbacks	_	_
.	_	_

#44
The	_	_
idea	_	_
is	_	_
to	_	_
test	_	_
the	_	_
retrieval	_	_
on	_	_
sketches	_	_
of	_	_
unseen	_	_
classes	_	_
to	_	_
discourage	_	_
class-specific	_	_
learning	_	_
during	_	_
training	_	_
.	_	_

#45
The	_	_
evaluation	_	_
is	_	_
automatic	_	_
,	_	_
i.e.	_	_
,	_	_
it	_	_
requires	_	_
no	_	_
human	_	_
labor	_	_
for	_	_
each	_	_
retrieval	_	_
,	_	_
apart	_	_
from	_	_
having	_	_
no	_	_
biases	_	_
.	_	_

#46
The	_	_
model	_	_
has	_	_
to	_	_
learn	_	_
to	_	_
associate	_	_
the	_	_
latent	_	_
alignments	_	_
in	_	_
the	_	_
sketch	_	_
and	_	_
the	_	_
image	_	_
in	_	_
order	_	_
to	_	_
perform	_	_
well	_	_
.	_	_

#47
This	_	_
is	_	_
also	_	_
important	_	_
from	_	_
a	_	_
practical	_	_
standpoint	_	_
wherein	_	_
,	_	_
in	_	_
some	_	_
domains	_	_
,	_	_
all	_	_
possible	_	_
classes	_	_
many	_	_
not	_	_
be	_	_
available	_	_
at	_	_
training	_	_
time	_	_
.	_	_

#48
For	_	_
example	_	_
,	_	_
new	_	_
product	_	_
classes	_	_
emerge	_	_
every	_	_
day	_	_
in	_	_
the	_	_
fashion	_	_
industry	_	_
.	_	_

#49
Thus	_	_
,	_	_
the	_	_
Zero-Shot	_	_
Sketch	_	_
Based	_	_
Image	_	_
Retrieval	_	_
(	_	_
ZS-SBIR	_	_
)	_	_
task	_	_
introduced	_	_
in	_	_
this	_	_
paper	_	_
provides	_	_
a	_	_
more	_	_
realistic	_	_
setup	_	_
for	_	_
the	_	_
sketch-based	_	_
retrieval	_	_
task	_	_
.	_	_

#50
Towards	_	_
this	_	_
end	_	_
,	_	_
we	_	_
propose	_	_
a	_	_
new	_	_
benchmark	_	_
for	_	_
the	_	_
ZS-SBIR	_	_
task	_	_
by	_	_
creating	_	_
a	_	_
careful	_	_
split	_	_
of	_	_
the	_	_
Sketchy	_	_
database	_	_
(	_	_
as	_	_
explained	_	_
later	_	_
in	_	_
the	_	_
experiments	_	_
section	_	_
)	_	_
.	_	_

#51
We	_	_
first	_	_
evaluate	_	_
several	_	_
existing	_	_
SBIR	_	_
models	_	_
on	_	_
this	_	_
task	_	_
and	_	_
observe	_	_
that	_	_
the	_	_
performance	_	_
of	_	_
these	_	_
models	_	_
drops	_	_
significantly	_	_
in	_	_
the	_	_
zero-shot	_	_
setting	_	_
thereby	_	_
pointing	_	_
to	_	_
class-specific	_	_
learning	_	_
occurring	_	_
in	_	_
these	_	_
models	_	_
.	_	_

#52
We	_	_
hypothesize	_	_
that	_	_
one	_	_
reason	_	_
for	_	_
this	_	_
could	_	_
be	_	_
that	_	_
the	_	_
existing	_	_
methods	_	_
are	_	_
essentially	_	_
formulated	_	_
in	_	_
the	_	_
discriminative	_	_
setup	_	_
,	_	_
which	_	_
encourages	_	_
class	_	_
specific	_	_
learning	_	_
.	_	_

#53
To	_	_
circumvent	_	_
the	_	_
problems	_	_
in	_	_
these	_	_
existing	_	_
models	_	_
,	_	_
we	_	_
approach	_	_
the	_	_
problem	_	_
from	_	_
the	_	_
point	_	_
of	_	_
view	_	_
of	_	_
a	_	_
generative	_	_
model	_	_
.	_	_

#54
Specifically	_	_
,	_	_
ZS-SBIR	_	_
can	_	_
be	_	_
considered	_	_
as	_	_
the	_	_
task	_	_
of	_	_
generating	_	_
additional	_	_
information	_	_
that	_	_
is	_	_
absent	_	_
in	_	_
the	_	_
sketch	_	_
in	_	_
order	_	_
to	_	_
retrieve	_	_
similar	_	_
images	_	_
.	_	_

#55
We	_	_
propose	_	_
Deep	_	_
Conditional	_	_
Generative	_	_
Models	_	_
based	_	_
on	_	_
Adversarial	_	_
Autoencoders	_	_
and	_	_
Variational	_	_
Autoencoders	_	_
for	_	_
the	_	_
ZS-SBIR	_	_
task	_	_
.	_	_

#56
Essentially	_	_
,	_	_
our	_	_
model	_	_
takes	_	_
the	_	_
sketch	_	_
feature	_	_
vector	_	_
as	_	_
an	_	_
input	_	_
and	_	_
generates	_	_
a	_	_
number	_	_
of	_	_
possible	_	_
image	_	_
vectors	_	_
by	_	_
filling	_	_
the	_	_
missing	_	_
information	_	_
stochastically	_	_
using	_	_
generative	_	_
models	_	_
.	_	_

#57
We	_	_
make	_	_
use	_	_
of	_	_
these	_	_
generated	_	_
image	_	_
feature	_	_
vectors	_	_
to	_	_
retrieve	_	_
images	_	_
from	_	_
the	_	_
database	_	_
.	_	_

#58
Our	_	_
experiments	_	_
show	_	_
that	_	_
the	_	_
proposed	_	_
generative	_	_
approach	_	_
performs	_	_
better	_	_
than	_	_
all	_	_
existing	_	_
state-of-the-art	_	_
SBIR	_	_
models	_	_
in	_	_
the	_	_
zero-shot	_	_
setting	_	_
.	_	_

#59
In	_	_
summary	_	_
,	_	_
our	_	_
main	_	_
contributions	_	_
are	_	_
as	_	_
follows	_	_
:	_	_
–	_	_
We	_	_
propose	_	_
the	_	_
task	_	_
of	_	_
Zero-Shot	_	_
Sketch	_	_
Based	_	_
Image	_	_
Retrieval	_	_
(	_	_
ZS-SBIR	_	_
)	_	_
,	_	_
which	_	_
to	_	_
the	_	_
best	_	_
of	_	_
our	_	_
knowledge	_	_
has	_	_
not	_	_
been	_	_
explored	_	_
before	_	_
.	_	_

#60
We	_	_
argue	_	_
that	_	_
this	_	_
task	_	_
provides	_	_
a	_	_
convenient	_	_
way	_	_
to	_	_
evaluate	_	_
sketch	_	_
based	_	_
retrieval	_	_
models	_	_
as	_	_
a	_	_
substitute	_	_
for	_	_
fine-grained	_	_
evaluation	_	_
,	_	_
while	_	_
discouraging	_	_
class	_	_
specific	_	_
learning	_	_
.	_	_

#61
4	_	_
Sasi	_	_
Kiran	_	_
Yelamarthi	_	_
et	_	_
al	_	_

#62
–	_	_
We	_	_
provide	_	_
a	_	_
benchmark	_	_
for	_	_
the	_	_
proposed	_	_
problem	_	_
by	_	_
creating	_	_
a	_	_
careful	_	_
split	_	_
of	_	_
the	_	_
Sketchy	_	_
dataset	_	_
,	_	_
ensuring	_	_
that	_	_
the	_	_
test	_	_
classes	_	_
do	_	_
not	_	_
overlap	_	_
with	_	_
the	_	_
1000	_	_
classes	_	_
of	_	_
Imagenet	_	_
[	_	_
20	_	_
]	_	_
.	_	_

#63
–	_	_
We	_	_
propose	_	_
a	_	_
novel	_	_
generative	_	_
approach	_	_
to	_	_
the	_	_
ZS-SBIR	_	_
task	_	_
that	_	_
achieves	_	_
better	_	_
performance	_	_
in	_	_
the	_	_
proposed	_	_
setting	_	_
compared	_	_
to	_	_
the	_	_
state-of-the	_	_
art	_	_
SBIR	_	_
models	_	_
as	_	_
well	_	_
as	_	_
three	_	_
popular	_	_
zero-shot	_	_
image	_	_
classification	_	_
algorithms	_	_
adapted	_	_
to	_	_
the	_	_
ZS-SBIR	_	_
task	_	_
.	_	_

#64
The	_	_
paper	_	_
is	_	_
organized	_	_
as	_	_
follows	_	_
:	_	_
In	_	_
Section-2	_	_
,	_	_
we	_	_
give	_	_
a	_	_
brief	_	_
overview	_	_
of	_	_
the	_	_
state-of-the-art	_	_
techniques	_	_
in	_	_
SBIR	_	_
and	_	_
ZSL	_	_
.	_	_

#65
Subsequently	_	_
,	_	_
in	_	_
Section-3	_	_
,	_	_
we	_	_
introduce	_	_
the	_	_
proposed	_	_
zero-shot	_	_
framework	_	_
and	_	_
describe	_	_
the	_	_
proposed	_	_
dataset	_	_
split	_	_
.	_	_

#66
Section-4	_	_
shows	_	_
the	_	_
evaluation	_	_
of	_	_
existing	_	_
state-of-the-art	_	_
SBIR	_	_
models	_	_
in	_	_
this	_	_
proposed	_	_
setting	_	_
.	_	_

#67
Section-5	_	_
introduces	_	_
our	_	_
proposed	_	_
generative	_	_
modeling	_	_
of	_	_
ZS-SBIR	_	_
and	_	_
adaptations	_	_
of	_	_
three	_	_
popular	_	_
ZSL	_	_
models	_	_
to	_	_
this	_	_
setting	_	_
.	_	_

#68
Finally	_	_
,	_	_
in	_	_
Sections-6	_	_
,	_	_
we	_	_
present	_	_
an	_	_
empirical	_	_
evaluation	_	_
of	_	_
these	_	_
models	_	_
on	_	_
the	_	_
proposed	_	_
zero	_	_
shot	_	_
splits	_	_
on	_	_
the	_	_
Sketchy	_	_
dataset	_	_
.	_	_

#69
2	_	_
Related	_	_
Work	_	_

#70
Since	_	_
we	_	_
propose	_	_
a	_	_
zero-shot	_	_
framework	_	_
for	_	_
the	_	_
SBIR	_	_
task	_	_
,	_	_
we	_	_
briefly	_	_
review	_	_
the	_	_
literature	_	_
from	_	_
both	_	_
sketch-based	_	_
image	_	_
retrieval	_	_
as	_	_
well	_	_
as	_	_
zero-shot	_	_
learning	_	_
in	_	_
this	_	_
section	_	_
.	_	_

#71
Conventional	_	_
pipeline	_	_
in	_	_
SBIR	_	_
involves	_	_
projecting	_	_
images	_	_
and	_	_
sketches	_	_
into	_	_
a	_	_
common	_	_
feature	_	_
space	_	_
.	_	_

#72
These	_	_
features	_	_
or	_	_
binary	_	_
codes	_	_
extracted	_	_
from	_	_
them	_	_
are	_	_
used	_	_
for	_	_
the	_	_
retrieval	_	_
task	_	_
.	_	_

#73
Hand-crafted	_	_
feature	_	_
based	_	_
models	_	_
include	_	_
the	_	_
gradient	_	_
field	_	_
HOG	_	_
descriptor	_	_
proposed	_	_
by	_	_
Hu	_	_
and	_	_
Collomose	_	_
[	_	_
21	_	_
]	_	_
,	_	_
the	_	_
histogram	_	_
of	_	_
edge	_	_
orientations	_	_
(	_	_
HELO	_	_
)	_	_
proposed	_	_
by	_	_
Saavendra	_	_
[	_	_
22	_	_
]	_	_
,	_	_
the	_	_
learned	_	_
key	_	_
shapes	_	_
(	_	_
LKS	_	_
)	_	_
proposed	_	_
by	_	_
Saavendra	_	_
et.al	_	_
[	_	_
23	_	_
]	_	_
which	_	_
are	_	_
used	_	_
in	_	_
Bag	_	_
of	_	_
Visual	_	_
Words	_	_
(	_	_
BoVW	_	_
)	_	_
framework	_	_
as	_	_
feature	_	_
extractors	_	_
for	_	_
SBIR	_	_
.	_	_

#74
Yu	_	_
et.al	_	_
[	_	_
24	_	_
]	_	_
were	_	_
the	_	_
first	_	_
to	_	_
use	_	_
Convolutional	_	_
Neural	_	_
Networks	_	_
(	_	_
CNN	_	_
)	_	_
for	_	_
the	_	_
sketch	_	_
classification	_	_
task	_	_
.	_	_

#75
Qi	_	_
et.al	_	_
[	_	_
18	_	_
]	_	_
introduced	_	_
the	_	_
use	_	_
of	_	_
siamese	_	_
architecture	_	_
for	_	_
coarse-grained	_	_
SBIR	_	_
.	_	_

#76
Sangkloy	_	_
et.al	_	_
[	_	_
19	_	_
]	_	_
used	_	_
triplet	_	_
ranking	_	_
loss	_	_
for	_	_
training	_	_
the	_	_
features	_	_
for	_	_
coarse-grained	_	_
SBIR	_	_
.	_	_

#77
Yu	_	_
et.al	_	_
[	_	_
15	_	_
]	_	_
used	_	_
triplet	_	_
network	_	_
for	_	_
instance	_	_
level	_	_
SBIR	_	_
evaluating	_	_
the	_	_
performance	_	_
on	_	_
shoe	_	_
and	_	_
chair	_	_
dataset	_	_
.	_	_

#78
They	_	_
use	_	_
a	_	_
pseudo	_	_
fine-grained	_	_
evaluation	_	_
where	_	_
they	_	_
only	_	_
look	_	_
at	_	_
the	_	_
position	_	_
of	_	_
the	_	_
correct	_	_
image	_	_
for	_	_
a	_	_
sketch	_	_
in	_	_
the	_	_
retrieved	_	_
images	_	_
.	_	_

#79
Liu	_	_
et.al	_	_
[	_	_
17	_	_
]	_	_
propose	_	_
a	_	_
semi-heterogeneous	_	_
deep	_	_
architecture	_	_
for	_	_
extracting	_	_
binary	_	_
codes	_	_
from	_	_
sketches	_	_
and	_	_
images	_	_
that	_	_
can	_	_
be	_	_
trained	_	_
in	_	_
an	_	_
end-to-end	_	_
fashion	_	_
for	_	_
coarse-grained	_	_
SBIR	_	_
task	_	_
.	_	_

#80
We	_	_
now	_	_
review	_	_
the	_	_
zero-shot	_	_
literature	_	_
.	_	_

#81
Zero-shot	_	_
learning	_	_
in	_	_
Image	_	_
Classification	_	_
[	_	_
25,26,27,28	_	_
]	_	_
refers	_	_
to	_	_
learning	_	_
to	_	_
recognize	_	_
images	_	_
of	_	_
novel	_	_
classes	_	_
although	_	_
no	_	_
examples	_	_
from	_	_
these	_	_
classes	_	_
are	_	_
present	_	_
in	_	_
the	_	_
training	_	_
set	_	_
.	_	_

#82
Due	_	_
to	_	_
the	_	_
difficulty	_	_
in	_	_
collecting	_	_
examples	_	_
of	_	_
every	_	_
class	_	_
in	_	_
order	_	_
to	_	_
train	_	_
supervised	_	_
models	_	_
,	_	_
zero-shot	_	_
learning	_	_
has	_	_
received	_	_
significant	_	_
interest	_	_
from	_	_
the	_	_
research	_	_
community	_	_
recently	_	_
[	_	_
25,29,30,31,32,33,34,35	_	_
]	_	_
.	_	_

#83
We	_	_
refer	_	_
the	_	_
reader	_	_
to	_	_
[	_	_
36	_	_
]	_	_
for	_	_
a	_	_
comprehensive	_	_
survey	_	_
on	_	_
the	_	_
subject	_	_
.	_	_

#84
Recently	_	_
,	_	_
zero	_	_
shot	_	_
learning	_	_
has	_	_
been	_	_
gaining	_	_
increasing	_	_
attention	_	_
for	_	_
a	_	_
number	_	_
of	_	_
other	_	_
computer	_	_
vision	_	_
tasks	_	_
such	_	_
as	_	_
image	_	_
tagging	_	_
[	_	_
37,38	_	_
]	_	_
,	_	_
visual	_	_
question	_	_
answering	_	_
[	_	_
39,40	_	_
]	_	_
action	_	_
recognition	_	_
[	_	_
41	_	_
]	_	_
etc	_	_
.	_	_

#85
To	_	_
the	_	_
best	_	_
of	_	_
our	_	_
knowledge	_	_
,	_	_
the	_	_
zero-shot	_	_
framework	_	_
has	_	_
not	_	_
been	_	_
previously	_	_
explored	_	_
in	_	_
the	_	_
SBIR	_	_
task	_	_
.	_	_

#86
ECCV-18	_	_
submission	_	_
ID	_	_
2152	_	_
5	_	_

#87
3	_	_
Zero	_	_
shot	_	_
setting	_	_
for	_	_
SBIR	_	_

#88
We	_	_
now	_	_
provide	_	_
a	_	_
formal	_	_
definition	_	_
of	_	_
the	_	_
zero	_	_
shot	_	_
setting	_	_
in	_	_
SBIR	_	_
.	_	_

#89
Let	_	_
S	_	_
=	_	_
{	_	_
(	_	_
xsketchi	_	_
,	_	_
ximgi	_	_
,	_	_
yi	_	_
)	_	_
|yi	_	_
∈	_	_
Y	_	_
}	_	_
be	_	_
the	_	_
triplets	_	_
of	_	_
sketch	_	_
,	_	_
image	_	_
and	_	_
class	_	_
label	_	_
where	_	_
Y	_	_
is	_	_
the	_	_
set	_	_
of	_	_
all	_	_
class	_	_
labels	_	_
in	_	_
S.	_	_
We	_	_
partition	_	_
the	_	_
class	_	_
labels	_	_
in	_	_
the	_	_
data	_	_
into	_	_
Ytrain	_	_
and	_	_
Ytest	_	_
data	_	_
respectively	_	_
.	_	_

#90
Correspondingly	_	_
,	_	_
let	_	_
Str	_	_
=	_	_
{	_	_
(	_	_
xsketchi	_	_
,	_	_
ximgi	_	_
)	_	_
|yi	_	_
∈	_	_
Ytrain	_	_
}	_	_
and	_	_
Ste	_	_
=	_	_
{	_	_
(	_	_
xsketchi	_	_
,	_	_
ximgi	_	_
)	_	_
|yi	_	_
∈	_	_
Ytest	_	_
}	_	_
be	_	_
the	_	_
partition	_	_
of	_	_
S	_	_
into	_	_
train	_	_
and	_	_
test	_	_
sets	_	_
.	_	_

#91
This	_	_
way	_	_
,	_	_
we	_	_
partition	_	_
the	_	_
paired	_	_
data	_	_
into	_	_
train	_	_
and	_	_
test	_	_
set	_	_
such	_	_
that	_	_
none	_	_
of	_	_
the	_	_
sketches	_	_
from	_	_
the	_	_
test	_	_
classes	_	_
occur	_	_
in	_	_
the	_	_
train	_	_
set	_	_
.	_	_

#92
Since	_	_
the	_	_
model	_	_
has	_	_
no	_	_
access	_	_
to	_	_
class	_	_
labels	_	_
,	_	_
the	_	_
model	_	_
needs	_	_
to	_	_
learn	_	_
latent	_	_
alignments	_	_
between	_	_
the	_	_
sketches	_	_
and	_	_
the	_	_
corresponding	_	_
images	_	_
to	_	_
perform	_	_
well	_	_
on	_	_
the	_	_
test	_	_
data	_	_
.	_	_

#93
Let	_	_
D	_	_
be	_	_
the	_	_
database	_	_
of	_	_
all	_	_
images	_	_
and	_	_
gI	_	_
be	_	_
the	_	_
mapping	_	_
from	_	_
images	_	_
to	_	_
class	_	_
labels	_	_
.	_	_

#94
We	_	_
split	_	_
D	_	_
into	_	_
Dtr	_	_
=	_	_
{	_	_
ximgi	_	_
∈	_	_
D|gI	_	_
(	_	_
ximgi	_	_
)	_	_
∈	_	_
Ytrain	_	_
}	_	_
and	_	_
Dte	_	_
=	_	_
{	_	_
ximgi	_	_
∈	_	_
D|gI	_	_
(	_	_
ximgi	_	_
)	_	_
∈	_	_
Ytest	_	_
}	_	_
.	_	_

#95
This	_	_
is	_	_
similar	_	_
to	_	_
other	_	_
zero-shot	_	_
literature	_	_
[	_	_
25	_	_
]	_	_
in	_	_
image	_	_
classification	_	_
.	_	_

#96
The	_	_
retrieval	_	_
model	_	_
in	_	_
this	_	_
framework	_	_
can	_	_
only	_	_
be	_	_
trained	_	_
on	_	_
Str	_	_
.	_	_

#97
The	_	_
database	_	_
Dtr	_	_
may	_	_
be	_	_
used	_	_
for	_	_
validating	_	_
the	_	_
retrieval	_	_
results	_	_
in	_	_
order	_	_
to	_	_
tune	_	_
the	_	_
hyper-parameters	_	_
.	_	_

#98
Given	_	_
an	_	_
xsketch	_	_
taken	_	_
from	_	_
sketches	_	_
of	_	_
Ste	_	_
,	_	_
the	_	_
objective	_	_
of	_	_
zero	_	_
shot	_	_
setting	_	_
in	_	_
SBIR	_	_
is	_	_
to	_	_
retrieve	_	_
images	_	_
fromDte	_	_
that	_	_
belong	_	_
to	_	_
same	_	_
class	_	_
as	_	_
that	_	_
of	_	_
the	_	_
query	_	_
sketch	_	_
.	_	_

#99
This	_	_
evaluation	_	_
setting	_	_
ensures	_	_
that	_	_
the	_	_
model	_	_
can	_	_
not	_	_
just	_	_
learn	_	_
the	_	_
mapping	_	_
from	_	_
sketches	_	_
to	_	_
class	_	_
labels	_	_
and	_	_
retrieve	_	_
all	_	_
the	_	_
images	_	_
using	_	_
the	_	_
label	_	_
information	_	_
.	_	_

#100
The	_	_
model	_	_
now	_	_
has	_	_
to	_	_
learn	_	_
the	_	_
salient	_	_
common	_	_
features	_	_
between	_	_
sketches	_	_
and	_	_
images	_	_
and	_	_
use	_	_
this	_	_
to	_	_
retrieve	_	_
images	_	_
for	_	_
the	_	_
query	_	_
that	_	_
are	_	_
from	_	_
the	_	_
unseen	_	_
classes	_	_
.	_	_

#101
3.1	_	_
Benchmark	_	_

#102
Since	_	_
we	_	_
are	_	_
introducing	_	_
the	_	_
task	_	_
of	_	_
zero-shot	_	_
sketch	_	_
based	_	_
retrieval	_	_
,	_	_
there	_	_
is	_	_
no	_	_
existing	_	_
benchmark	_	_
for	_	_
evaluating	_	_
this	_	_
setting	_	_
.	_	_

#103
Hence	_	_
,	_	_
we	_	_
first	_	_
propose	_	_
a	_	_
new	_	_
benchmark	_	_
for	_	_
evaluation	_	_
by	_	_
making	_	_
a	_	_
careful	_	_
split	_	_
of	_	_
the	_	_
”Sketchy”	_	_
dataset	_	_
[	_	_
19	_	_
]	_	_
.	_	_

#104
Sketchy	_	_
is	_	_
a	_	_
dataset	_	_
consisting	_	_
of	_	_
75,471	_	_
hand-drawn	_	_
sketches	_	_
and	_	_
12,500	_	_
images	_	_
belonging	_	_
to	_	_
125	_	_
classes	_	_
collected	_	_
by	_	_
Sangkloy	_	_
et.al	_	_
[	_	_
19	_	_
]	_	_
.	_	_

#105
Each	_	_
image	_	_
has	_	_
approximately	_	_
6	_	_
hand-drawn	_	_
sketches	_	_
.	_	_

#106
The	_	_
original	_	_
Sketchy	_	_
dataset	_	_
uses	_	_
the	_	_
same	_	_
12,500	_	_
images	_	_
as	_	_
the	_	_
database	_	_
.	_	_

#107
Liu	_	_
et.al	_	_
[	_	_
17	_	_
]	_	_
augment	_	_
the	_	_
database	_	_
with	_	_
60,502	_	_
images	_	_
from	_	_
Imagenet	_	_
to	_	_
create	_	_
a	_	_
retrieval	_	_
database	_	_
with	_	_
a	_	_
total	_	_
of	_	_
73,002	_	_
images	_	_
.	_	_

#108
We	_	_
use	_	_
the	_	_
augmented	_	_
dataset	_	_
provided	_	_
by	_	_
Liu	_	_
et.al	_	_
[	_	_
17	_	_
]	_	_
in	_	_
this	_	_
work	_	_
.	_	_

#109
Next	_	_
,	_	_
we	_	_
partition	_	_
the	_	_
125	_	_
classes	_	_
into	_	_
104	_	_
train	_	_
classes	_	_
and	_	_
21	_	_
test	_	_
classes	_	_
.	_	_

#110
This	_	_
peculiar	_	_
split	_	_
is	_	_
not	_	_
arbitrary	_	_
.	_	_

#111
We	_	_
make	_	_
sure	_	_
that	_	_
the	_	_
21	_	_
test	_	_
classes	_	_
are	_	_
not	_	_
present	_	_
in	_	_
the	_	_
1000	_	_
classes	_	_
of	_	_
Imagenet	_	_
[	_	_
20	_	_
]	_	_
.	_	_

#112
This	_	_
is	_	_
done	_	_
to	_	_
ensure	_	_
that	_	_
researchers	_	_
can	_	_
still	_	_
pre-train	_	_
their	_	_
models	_	_
on	_	_
the	_	_
1000	_	_
classes	_	_
of	_	_
Imagenet	_	_
without	_	_
violating	_	_
the	_	_
zero-shot	_	_
assumption	_	_
.	_	_

#113
Such	_	_
a	_	_
split	_	_
was	_	_
motivated	_	_
by	_	_
the	_	_
recently	_	_
proposed	_	_
benchmark	_	_
for	_	_
standard	_	_
datasets	_	_
used	_	_
in	_	_
the	_	_
zero	_	_
shot	_	_
image	_	_
classification	_	_
task	_	_
by	_	_
Xian	_	_
et.al	_	_
[	_	_
36	_	_
]	_	_
.	_	_

#114
The	_	_
details	_	_
of	_	_
the	_	_
proposed	_	_
dataset	_	_
split	_	_
are	_	_
summarized	_	_
in	_	_
Table	_	_
1	_	_
.	_	_

#115
6	_	_
Sasi	_	_
Kiran	_	_
Yelamarthi	_	_
et	_	_
al	_	_

#116
Table	_	_
1	_	_
.	_	_

#117
Statistics	_	_
of	_	_
the	_	_
proposed	_	_
dataset	_	_
split	_	_
of	_	_
Sketchy	_	_
database	_	_
for	_	_
ZS-SBIR	_	_
task	_	_
Dataset	_	_
Statistics	_	_
#	_	_
Train	_	_
classes	_	_
104	_	_
Test	_	_
classes	_	_
21	_	_
Train	_	_
Images	_	_
10400	_	_
Train	_	_
Sketches	_	_
62787	_	_
Avg	_	_
.	_	_

#118
sketches	_	_
per	_	_
image	_	_
6.03848	_	_
Test	_	_
Sketches	_	_
12694	_	_
DB	_	_
images	_	_
for	_	_
training	_	_
62549	_	_
DB	_	_
images	_	_
for	_	_
testing	_	_
10453	_	_

#119
4	_	_
Limitations	_	_
of	_	_
existing	_	_
SBIR	_	_
methods	_	_

#120
Next	_	_
we	_	_
evaluate	_	_
whether	_	_
the	_	_
existing	_	_
approaches	_	_
to	_	_
the	_	_
sketch-based	_	_
image	_	_
retrival	_	_
task	_	_
generalize	_	_
well	_	_
to	_	_
the	_	_
proposed	_	_
zero-shot	_	_
setting	_	_
.	_	_

#121
To	_	_
this	_	_
end	_	_
,	_	_
we	_	_
evaluate	_	_
three	_	_
state-of-the-art	_	_
SBIR	_	_
methods	_	_
described	_	_
below	_	_
on	_	_
the	_	_
above	_	_
proposed	_	_
benchmark	_	_
.	_	_

#122
4.1	_	_
A	_	_
Siamese	_	_
Network	_	_

#123
The	_	_
Siamese	_	_
network	_	_
proposed	_	_
by	_	_
Hadsell	_	_
et.al	_	_
[	_	_
42	_	_
]	_	_
maps	_	_
both	_	_
the	_	_
sketches	_	_
and	_	_
images	_	_
into	_	_
a	_	_
common	_	_
space	_	_
where	_	_
the	_	_
semantic	_	_
distance	_	_
is	_	_
preserved	_	_
.	_	_

#124
Let	_	_
(	_	_
S	_	_
,	_	_
I	_	_
,	_	_
Y	_	_
=	_	_
1	_	_
)	_	_
and	_	_
(	_	_
S	_	_
,	_	_
I	_	_
,	_	_
Y	_	_
=	_	_
0	_	_
)	_	_
be	_	_
the	_	_
pairs	_	_
of	_	_
images	_	_
and	_	_
sketches	_	_
that	_	_
belong	_	_
to	_	_
same	_	_
and	_	_
different	_	_
class	_	_
respectively	_	_
and	_	_
Dθ	_	_
(	_	_
S	_	_
,	_	_
I	_	_
)	_	_
be	_	_
the	_	_
l2	_	_
distance	_	_
between	_	_
the	_	_
image	_	_
and	_	_
sketch	_	_
features	_	_
where	_	_
θ	_	_
are	_	_
the	_	_
parameters	_	_
of	_	_
the	_	_
mapping	_	_
function	_	_
.	_	_

#125
The	_	_
loss	_	_
function	_	_
L	_	_
(	_	_
θ	_	_
)	_	_
for	_	_
training	_	_
is	_	_
given	_	_
by	_	_
:	_	_
L	_	_
(	_	_
θ	_	_
)	_	_
=	_	_
(	_	_
Y	_	_
)	_	_
(	_	_
Dθ	_	_
)	_	_
2	_	_
+	_	_
(	_	_
1−	_	_
Y	_	_
)	_	_
{	_	_
max	_	_
(	_	_
0	_	_
,	_	_
m−Dθ	_	_
)	_	_
}	_	_
2	_	_
(	_	_
1	_	_
)	_	_
where	_	_
m	_	_
is	_	_
the	_	_
margin	_	_
.	_	_

#126
Chopra	_	_
et.al	_	_
[	_	_
18	_	_
]	_	_
and	_	_
Qi	_	_
et.al	_	_
[	_	_
43	_	_
]	_	_
use	_	_
a	_	_
modified	_	_
version	_	_
of	_	_
the	_	_
above	_	_
loss	_	_
function	_	_
for	_	_
training	_	_
the	_	_
Siamese	_	_
network	_	_
for	_	_
the	_	_
tasks	_	_
of	_	_
face	_	_
verification	_	_
and	_	_
SBIR	_	_
respectively	_	_
,	_	_
which	_	_
is	_	_
given	_	_
below	_	_
:	_	_
L	_	_
(	_	_
θ	_	_
)	_	_
=	_	_
(	_	_
Y	_	_
)	_	_
αD2	_	_
θ	_	_
+	_	_
(	_	_
1−	_	_
Y	_	_
)	_	_
βeγDθ	_	_
(	_	_
2	_	_
)	_	_
where	_	_
α	_	_
=	_	_
Q	_	_
,	_	_
β	_	_
=	_	_
2Q	_	_
,	_	_
γ	_	_
=	_	_
−2.77	_	_
Q	_	_
and	_	_
constant	_	_
Q	_	_
is	_	_
set	_	_
to	_	_
the	_	_
upper	_	_
bound	_	_
on	_	_
Dθ	_	_
estimated	_	_
from	_	_
the	_	_
data	_	_
.	_	_

#127
We	_	_
explore	_	_
both	_	_
these	_	_
formulations	_	_
in	_	_
the	_	_
proposed	_	_
zero-shot	_	_
setting	_	_
.	_	_

#128
We	_	_
call	_	_
the	_	_
former	_	_
setting	_	_
as	_	_
Siamese-1	_	_
and	_	_
the	_	_
latter	_	_
as	_	_
Siamese-2	_	_
.	_	_

#129
4.2	_	_
A	_	_
Triplet	_	_
Network	_	_

#130
Triplet	_	_
loss	_	_
[	_	_
44,19	_	_
]	_	_
is	_	_
defined	_	_
in	_	_
a	_	_
max-margin	_	_
framework	_	_
,	_	_
where	_	_
,	_	_
the	_	_
objective	_	_
is	_	_
to	_	_
minimize	_	_
the	_	_
distance	_	_
between	_	_
sketch	_	_
and	_	_
positive	_	_
image	_	_
that	_	_
belong	_	_
to	_	_
the	_	_
same	_	_
class	_	_
and	_	_
simultaneously	_	_
maximize	_	_
the	_	_
distance	_	_
between	_	_
the	_	_
sketch	_	_
and	_	_
negative	_	_
image	_	_
ECCV-18	_	_
submission	_	_
ID	_	_
2152	_	_
7	_	_
which	_	_
belong	_	_
to	_	_
different	_	_
classes	_	_
.	_	_

#131
The	_	_
triplet	_	_
training	_	_
loss	_	_
for	_	_
a	_	_
given	_	_
triplet	_	_
t	_	_
(	_	_
s	_	_
,	_	_
p+	_	_
,	_	_
p−	_	_
)	_	_
is	_	_
given	_	_
by	_	_
:	_	_
Lθ	_	_
(	_	_
t	_	_
)	_	_
=	_	_
max	_	_
(	_	_
0	_	_
,	_	_
m+Dθ	_	_
(	_	_
s	_	_
,	_	_
p	_	_
+	_	_
)	_	_
−Dθ	_	_
(	_	_
s	_	_
,	_	_
p	_	_
−	_	_
)	_	_
)	_	_
(	_	_
3	_	_
)	_	_
where	_	_
m	_	_
is	_	_
the	_	_
margin	_	_
and	_	_
Dθ	_	_
is	_	_
the	_	_
distance	_	_
measure	_	_
used	_	_
.	_	_

#132
To	_	_
sample	_	_
the	_	_
negative	_	_
images	_	_
during	_	_
training	_	_
,	_	_
we	_	_
follow	_	_
two	_	_
strategies	_	_
(	_	_
i	_	_
)	_	_
we	_	_
consider	_	_
only	_	_
images	_	_
from	_	_
different	_	_
class	_	_
and	_	_
(	_	_
ii	_	_
)	_	_
we	_	_
consider	_	_
all	_	_
the	_	_
images	_	_
that	_	_
do	_	_
not	_	_
directly	_	_
correspond	_	_
to	_	_
the	_	_
sketch	_	_
,	_	_
resulting	_	_
in	_	_
coarse-grained	_	_
and	_	_
fine-grained	_	_
training	_	_
of	_	_
triplet	_	_
network	_	_
respectively	_	_
.	_	_

#133
We	_	_
explore	_	_
both	_	_
these	_	_
training	_	_
methods	_	_
in	_	_
the	_	_
proposed	_	_
zero-shot	_	_
setting	_	_
for	_	_
SBIR	_	_
.	_	_

#134
Table	_	_
2	_	_
.	_	_

#135
Precision	_	_
and	_	_
mAP	_	_
are	_	_
estimated	_	_
by	_	_
retrieving	_	_
200	_	_
images	_	_
.	_	_

#136
-	_	_
indicates	_	_
that	_	_
the	_	_
authors	_	_
do	_	_
not	_	_
present	_	_
results	_	_
on	_	_
that	_	_
metric	_	_
.	_	_

#137
1	_	_
:	_	_
Using	_	_
128	_	_
bit	_	_
hash	_	_
codes	_	_
Method	_	_
Precision	_	_
@	_	_
200	_	_
mAP	_	_
@	_	_
200	_	_
Traditional	_	_
Zero-Shot	_	_
Traditional	_	_
Zero-Shot	_	_
Baseline	_	_
-	_	_
0.106	_	_
-	_	_
0.054	_	_
Siamese-1	_	_
-	_	_
0.243	_	_
-	_	_
0.134	_	_
Siamese-2	_	_
0.690	_	_
0.251	_	_
0.518	_	_
0.149	_	_
Coarse-grained	_	_
triplet	_	_
0.761	_	_
0.169	_	_
0.573	_	_
0.083	_	_
Fine-grained	_	_
triplet	_	_
-	_	_
0.155	_	_
-	_	_
0.081	_	_
DSH1	_	_
0.866	_	_
0.153	_	_
0.783	_	_
0.059	_	_

#138
4.3	_	_
Deep	_	_
Sketch	_	_
Hashing	_	_

#139
Liu	_	_
et.al	_	_
[	_	_
17	_	_
]	_	_
propose	_	_
an	_	_
end-to-end	_	_
framework	_	_
for	_	_
learning	_	_
binary	_	_
codes	_	_
of	_	_
sketches	_	_
and	_	_
images	_	_
which	_	_
is	_	_
the	_	_
current	_	_
state-of-the-art	_	_
in	_	_
SBIR	_	_
.	_	_

#140
The	_	_
objective	_	_
function	_	_
consists	_	_
of	_	_
the	_	_
following	_	_
three	_	_
terms	_	_
:	_	_
(	_	_
i	_	_
)	_	_
cross-view	_	_
pairwise	_	_
loss	_	_
which	_	_
tries	_	_
to	_	_
bring	_	_
binary	_	_
codes	_	_
of	_	_
images	_	_
and	_	_
sketches	_	_
of	_	_
the	_	_
same	_	_
class	_	_
to	_	_
be	_	_
close	_	_
(	_	_
ii	_	_
)	_	_
semantic	_	_
factorization	_	_
loss	_	_
which	_	_
tries	_	_
to	_	_
preserve	_	_
the	_	_
semantic	_	_
relationship	_	_
between	_	_
classes	_	_
in	_	_
the	_	_
binary	_	_
codes	_	_
and	_	_
(	_	_
iii	_	_
)	_	_
the	_	_
quantization	_	_
loss	_	_
.	_	_

#141
The	_	_
overall	_	_
loss	_	_
function	_	_
can	_	_
be	_	_
written	_	_
as	_	_
L	_	_
=	_	_
|W	_	_
m−BTI	_	_
BS	_	_
|2+	_	_
λ	_	_
(	_	_
|Φ	_	_
(	_	_
YI	_	_
)	_	_
−DBI	_	_
|2	_	_
+	_	_
|Φ	_	_
(	_	_
YS	_	_
)	_	_
−DBS	_	_
|2	_	_
)	_	_
+	_	_
γ	_	_
(	_	_
|FI	_	_
(	_	_
θI	_	_
)	_	_
−BI	_	_
|2	_	_
+	_	_
|FS	_	_
(	_	_
θS	_	_
)	_	_
−BS	_	_
|2	_	_
)	_	_
s.t	_	_
.	_	_

#142
BI	_	_
∈	_	_
{	_	_
−1	_	_
,	_	_
1	_	_
}	_	_
m×n1	_	_
,	_	_
BS	_	_
∈	_	_
{	_	_
−1	_	_
,	_	_
1	_	_
}	_	_
m×n2	_	_
(	_	_
4	_	_
)	_	_
where	_	_
BI	_	_
and	_	_
BS	_	_
are	_	_
binary	_	_
codes	_	_
for	_	_
images	_	_
and	_	_
sketches	_	_
,	_	_
W	_	_
is	_	_
the	_	_
cross-view	_	_
similarity	_	_
matrix	_	_
,	_	_
Φ	_	_
(	_	_
YI	_	_
)	_	_
,	_	_
Φ	_	_
(	_	_
YS	_	_
)	_	_
are	_	_
the	_	_
word	_	_
embeddings	_	_
for	_	_
image	_	_
and	_	_
sketch	_	_
classes	_	_
respectively	_	_
,	_	_
D	_	_
is	_	_
the	_	_
shared	_	_
basis	_	_
for	_	_
semantic	_	_
embeddings	_	_
and	_	_
FI	_	_
(	_	_
θI	_	_
)	_	_
and	_	_
FS	_	_
(	_	_
θS	_	_
)	_	_
are	_	_
CNNs	_	_
for	_	_
image	_	_
and	_	_
sketch	_	_
respectively	_	_
.	_	_

#143
8	_	_
Sasi	_	_
Kiran	_	_
Yelamarthi	_	_
et	_	_
al	_	_

#144
4.4	_	_
Experiments	_	_

#145
We	_	_
now	_	_
present	_	_
the	_	_
results	_	_
of	_	_
the	_	_
above	_	_
described	_	_
models	_	_
on	_	_
our	_	_
proposed	_	_
partitions	_	_
of	_	_
the	_	_
”Sketchy”	_	_
dataset	_	_
[	_	_
19	_	_
]	_	_
in	_	_
order	_	_
to	_	_
evaluate	_	_
them	_	_
in	_	_
the	_	_
zero-shot	_	_
setting	_	_
.	_	_

#146
While	_	_
evaluating	_	_
each	_	_
model	_	_
,	_	_
for	_	_
a	_	_
given	_	_
test	_	_
sketch	_	_
,	_	_
we	_	_
retrieve	_	_
the	_	_
top	_	_
K	_	_
=	_	_
200	_	_
images	_	_
from	_	_
the	_	_
database	_	_
that	_	_
are	_	_
closest	_	_
to	_	_
the	_	_
sketch	_	_
in	_	_
the	_	_
learned	_	_
feature	_	_
space	_	_
.	_	_

#147
We	_	_
use	_	_
inverse	_	_
of	_	_
the	_	_
cosine	_	_
similarity	_	_
as	_	_
the	_	_
distance	_	_
metric	_	_
.	_	_

#148
We	_	_
present	_	_
the	_	_
experimental	_	_
details	_	_
for	_	_
the	_	_
evaluated	_	_
methods	_	_
below	_	_
.	_	_

#149
Baseline	_	_
:	_	_
We	_	_
take	_	_
a	_	_
VGG-16	_	_
network	_	_
[	_	_
45	_	_
]	_	_
trained	_	_
on	_	_
image	_	_
classification	_	_
task	_	_
on	_	_
ImageNet-1K	_	_
[	_	_
20	_	_
]	_	_
as	_	_
the	_	_
baseline	_	_
.	_	_

#150
The	_	_
score	_	_
for	_	_
a	_	_
given	_	_
sketch-image	_	_
pair	_	_
is	_	_
given	_	_
by	_	_
the	_	_
cosine	_	_
similarity	_	_
between	_	_
their	_	_
VGG	_	_
features	_	_
.	_	_

#151
Training	_	_
:	_	_
We	_	_
re-implement	_	_
the	_	_
above	_	_
described	_	_
models	_	_
to	_	_
evaluate	_	_
them	_	_
for	_	_
the	_	_
ZS-SBIR	_	_
task	_	_
.	_	_

#152
For	_	_
sanity	_	_
check	_	_
,	_	_
we	_	_
first	_	_
reproduce	_	_
the	_	_
results	_	_
on	_	_
the	_	_
traditional	_	_
SBIR	_	_
task	_	_
reported	_	_
in	_	_
[	_	_
17	_	_
]	_	_
successfully	_	_
.	_	_

#153
We	_	_
follow	_	_
the	_	_
training	_	_
methodology	_	_
described	_	_
in	_	_
[	_	_
19,18,17	_	_
]	_	_
closely	_	_
.	_	_

#154
We	_	_
observe	_	_
that	_	_
the	_	_
validation	_	_
performance	_	_
saturates	_	_
after	_	_
20	_	_
epochs	_	_
in	_	_
case	_	_
of	_	_
Siamese	_	_
network	_	_
and	_	_
after	_	_
80	_	_
epochs	_	_
for	_	_
the	_	_
Triplet	_	_
network	_	_
.	_	_

#155
We	_	_
also	_	_
employ	_	_
data	_	_
augmentation	_	_
for	_	_
training	_	_
the	_	_
Triplet	_	_
network	_	_
because	_	_
the	_	_
available	_	_
training	_	_
data	_	_
is	_	_
insufficient	_	_
for	_	_
proper	_	_
training	_	_
.	_	_

#156
We	_	_
explore	_	_
the	_	_
hyper-parameters	_	_
via	_	_
grid	_	_
search	_	_
.	_	_

#157
In	_	_
the	_	_
case	_	_
of	_	_
DSH	_	_
,	_	_
we	_	_
use	_	_
the	_	_
CNNs	_	_
proposed	_	_
by	_	_
Liu	_	_
et.al	_	_
[	_	_
17	_	_
]	_	_
for	_	_
feature	_	_
extraction	_	_
.	_	_

#158
We	_	_
train	_	_
the	_	_
network	_	_
for	_	_
500	_	_
epochs	_	_
,	_	_
validating	_	_
on	_	_
the	_	_
train	_	_
database	_	_
after	_	_
every	_	_
10	_	_
epochs	_	_
.	_	_

#159
We	_	_
explored	_	_
the	_	_
hyper-parameters	_	_
and	_	_
found	_	_
that	_	_
λ	_	_
=	_	_
0.01	_	_
and	_	_
γ	_	_
=	_	_
10−5	_	_
give	_	_
the	_	_
best	_	_
results	_	_
similar	_	_
to	_	_
the	_	_
original	_	_
SBIR	_	_
training	_	_
.	_	_

#160
The	_	_
performance	_	_
of	_	_
these	_	_
models	_	_
on	_	_
the	_	_
ZS-SBIR	_	_
task	_	_
are	_	_
shown	_	_
in	_	_
Table	_	_
2	_	_
.	_	_

#161
For	_	_
comparative	_	_
purposes	_	_
,	_	_
we	_	_
also	_	_
present	_	_
the	_	_
performance	_	_
in	_	_
the	_	_
traditional	_	_
SBIR	_	_
setting	_	_
[	_	_
17	_	_
]	_	_
where	_	_
the	_	_
models	_	_
are	_	_
trained	_	_
on	_	_
the	_	_
sketch-image	_	_
pairs	_	_
of	_	_
all	_	_
the	_	_
classes	_	_
.	_	_

#162
We	_	_
observe	_	_
that	_	_
the	_	_
performance	_	_
of	_	_
these	_	_
models	_	_
dips	_	_
significantly	_	_
,	_	_
indicating	_	_
the	_	_
nongeneralizability	_	_
of	_	_
existing	_	_
approaches	_	_
to	_	_
SBIR	_	_
.	_	_

#163
This	_	_
performance	_	_
drop	_	_
of	_	_
more	_	_
than	_	_
50	_	_
%	_	_
in	_	_
the	_	_
zero-shot	_	_
setting	_	_
may	_	_
be	_	_
due	_	_
to	_	_
the	_	_
fact	_	_
that	_	_
these	_	_
models	_	_
trained	_	_
in	_	_
a	_	_
discriminative	_	_
setting	_	_
may	_	_
learn	_	_
to	_	_
associate	_	_
the	_	_
sketches	_	_
and	_	_
images	_	_
to	_	_
class	_	_
labels	_	_
.	_	_

#164
Among	_	_
the	_	_
compared	_	_
methods	_	_
we	_	_
notice	_	_
that	_	_
the	_	_
Siamese	_	_
network	_	_
preforms	_	_
the	_	_
best	_	_
among	_	_
the	_	_
existing	_	_
SBIR	_	_
methods	_	_
in	_	_
the	_	_
zero-shot	_	_
setting	_	_
.	_	_

#165
We	_	_
also	_	_
observe	_	_
that	_	_
the	_	_
Triplet	_	_
loss	_	_
gives	_	_
poorer	_	_
performance	_	_
compared	_	_
to	_	_
the	_	_
Siamese	_	_
network	_	_
.	_	_

#166
This	_	_
can	_	_
be	_	_
attributed	_	_
to	_	_
the	_	_
presence	_	_
of	_	_
only	_	_
about	_	_
60	_	_
,	_	_
000	_	_
images	_	_
during	_	_
training	_	_
,	_	_
which	_	_
is	_	_
not	_	_
sufficient	_	_
for	_	_
properly	_	_
training	_	_
a	_	_
triplet	_	_
network	_	_
as	_	_
observed	_	_
by	_	_
Schroff	_	_
et.al	_	_
[	_	_
44	_	_
]	_	_
.	_	_

#167
We	_	_
also	_	_
observe	_	_
that	_	_
the	_	_
coarse-grained	_	_
training	_	_
of	_	_
triplet	_	_
performs	_	_
better	_	_
compared	_	_
to	_	_
fine-grained	_	_
triplet	_	_
.	_	_

#168
This	_	_
may	_	_
be	_	_
because	_	_
the	_	_
fine-grained	_	_
training	_	_
considers	_	_
all	_	_
the	_	_
images	_	_
other	_	_
than	_	_
those	_	_
that	_	_
correspond	_	_
directly	_	_
to	_	_
the	_	_
sketch	_	_
as	_	_
negative	_	_
samples	_	_
making	_	_
the	_	_
training	_	_
harder	_	_
.	_	_

#169
Our	_	_
next	_	_
observation	_	_
is	_	_
that	_	_
DSH	_	_
,	_	_
which	_	_
is	_	_
the	_	_
state-of-the-art	_	_
model	_	_
in	_	_
SBIR	_	_
does	_	_
not	_	_
perform	_	_
well	_	_
compared	_	_
to	_	_
either	_	_
Siamese	_	_
or	_	_
Triplet	_	_
networks	_	_
in	_	_
ZS-SBIR	_	_
task	_	_
.	_	_

#170
This	_	_
may	_	_
be	_	_
due	_	_
to	_	_
the	_	_
fact	_	_
that	_	_
the	_	_
semantic	_	_
factorization	_	_
loss	_	_
in	_	_
DSH	_	_
takes	_	_
only	_	_
the	_	_
training	_	_
class	_	_
embeddings	_	_
into	_	_
account	_	_
and	_	_
does	_	_
not	_	_
reduce	_	_
the	_	_
semantic	_	_
gap	_	_
for	_	_
the	_	_
test	_	_
classes	_	_
.	_	_

#171
Thus	_	_
,	_	_
one	_	_
can	_	_
claim	_	_
that	_	_
there	_	_
exists	_	_
a	_	_
problem	_	_
of	_	_
class-based	_	_
learning	_	_
inherent	_	_
in	_	_
the	_	_
existing	_	_
models	_	_
,	_	_
which	_	_
leads	_	_
to	_	_
inferior	_	_
performance	_	_
in	_	_
the	_	_
ZS-SBIR	_	_
task	_	_
.	_	_

#172
ECCV-18	_	_
submission	_	_
ID	_	_
2152	_	_
9	_	_

#173
5	_	_
Generative	_	_
Models	_	_
for	_	_
ZS-SBIR	_	_

#174
Having	_	_
noticed	_	_
that	_	_
the	_	_
existing	_	_
approaches	_	_
do	_	_
not	_	_
generalize	_	_
well	_	_
to	_	_
the	_	_
ZS-SBIR	_	_
task	_	_
,	_	_
we	_	_
now	_	_
propose	_	_
the	_	_
use	_	_
of	_	_
generative	_	_
models	_	_
for	_	_
the	_	_
ZS-SBIR	_	_
task	_	_
.	_	_

#175
The	_	_
motivation	_	_
for	_	_
such	_	_
an	_	_
approach	_	_
is	_	_
that	_	_
while	_	_
a	_	_
sketch	_	_
gives	_	_
a	_	_
basic	_	_
outline	_	_
of	_	_
the	_	_
image	_	_
,	_	_
additional	_	_
details	_	_
could	_	_
possibly	_	_
be	_	_
generated	_	_
from	_	_
the	_	_
latent	_	_
prior	_	_
vector	_	_
via	_	_
a	_	_
generative	_	_
model	_	_
.	_	_

#176
This	_	_
is	_	_
inline	_	_
with	_	_
the	_	_
recent	_	_
work	_	_
on	_	_
similar	_	_
image	_	_
translation	_	_
tasks	_	_
[	_	_
46,47,48	_	_
]	_	_
in	_	_
computer	_	_
vision	_	_
.	_	_

#177
Let	_	_
Gθ	_	_
model	_	_
the	_	_
probability	_	_
distribution	_	_
of	_	_
the	_	_
image	_	_
features	_	_
(	_	_
ximg	_	_
)	_	_
conditioned	_	_
on	_	_
the	_	_
sketch	_	_
features	_	_
(	_	_
xsketch	_	_
)	_	_
and	_	_
parameterized	_	_
by	_	_
θ	_	_
,	_	_
i.e	_	_
P	_	_
(	_	_
ximg|xsketch	_	_
;	_	_
θ	_	_
)	_	_
.	_	_

#178
Gθ	_	_
is	_	_
trained	_	_
using	_	_
paired	_	_
data	_	_
of	_	_
sketch-image	_	_
pairs	_	_
from	_	_
the	_	_
training	_	_
classes	_	_
.	_	_

#179
Since	_	_
we	_	_
do	_	_
not	_	_
provide	_	_
the	_	_
model	_	_
with	_	_
class	_	_
label	_	_
information	_	_
,	_	_
it	_	_
is	_	_
hoped	_	_
that	_	_
the	_	_
model	_	_
learns	_	_
to	_	_
associate	_	_
the	_	_
characteristics	_	_
of	_	_
the	_	_
sketch	_	_
such	_	_
as	_	_
the	_	_
general	_	_
outline	_	_
,	_	_
local	_	_
shape	_	_
,	_	_
etc	_	_
with	_	_
that	_	_
of	_	_
the	_	_
image	_	_
.	_	_

#180
We	_	_
would	_	_
like	_	_
to	_	_
emphasize	_	_
here	_	_
that	_	_
Gθ	_	_
is	_	_
trained	_	_
to	_	_
generate	_	_
image	_	_
features	_	_
but	_	_
not	_	_
the	_	_
images	_	_
themselves	_	_
using	_	_
the	_	_
sketch	_	_
.	_	_

#181
We	_	_
consider	_	_
two	_	_
popular	_	_
generative	_	_
models	_	_
:	_	_
Variational	_	_
Autoencoders	_	_
[	_	_
49,50	_	_
]	_	_
and	_	_
Adversarial	_	_
Autoencoders	_	_
[	_	_
51	_	_
]	_	_
as	_	_
described	_	_
below	_	_
:	_	_
Fig.	_	_
2	_	_
.	_	_

#182
The	_	_
architectures	_	_
of	_	_
CVAE	_	_
and	_	_
CAAE	_	_
are	_	_
illustrated	_	_
in	_	_
the	_	_
left	_	_
and	_	_
right	_	_
diagrams	_	_
respectively	_	_

#183
5.1	_	_
Variational	_	_
Autoencoders	_	_

#184
The	_	_
Variational	_	_
Autoencoders	_	_
(	_	_
VAE	_	_
)	_	_
[	_	_
49	_	_
]	_	_
map	_	_
a	_	_
prior	_	_
distribution	_	_
on	_	_
a	_	_
hidden	_	_
latent	_	_
variable	_	_
p	_	_
(	_	_
z	_	_
)	_	_
to	_	_
the	_	_
data	_	_
distribution	_	_
p	_	_
(	_	_
x	_	_
)	_	_
.	_	_

#185
The	_	_
intractable	_	_
posterior	_	_
p	_	_
(	_	_
z|x	_	_
)	_	_
is	_	_
approximated	_	_
by	_	_
the	_	_
variational	_	_
distribution	_	_
q	_	_
(	_	_
z|x	_	_
)	_	_
which	_	_
is	_	_
assumed	_	_
to	_	_
be	_	_
Gaussian	_	_
in	_	_
this	_	_
work	_	_
.	_	_

#186
The	_	_
parameters	_	_
of	_	_
the	_	_
variational	_	_
distribution	_	_
are	_	_
estimated	_	_
from	_	_
x	_	_
via	_	_
the	_	_
encoder	_	_
which	_	_
is	_	_
a	_	_
neural	_	_
network	_	_
parameterized	_	_
by	_	_
φ	_	_
.	_	_

#187
The	_	_
conditional	_	_
distribution	_	_
p	_	_
(	_	_
x|z	_	_
)	_	_
is	_	_
modeled	_	_
by	_	_
the	_	_
decoder	_	_
network	_	_
parameterized	_	_
by	_	_
θ	_	_
.	_	_

#188
Following	_	_
the	_	_
notation	_	_
in	_	_
[	_	_
49	_	_
]	_	_
,	_	_
the	_	_
variational	_	_
lower	_	_
bound	_	_
for	_	_
p	_	_
(	_	_
x	_	_
)	_	_
can	_	_
be	_	_
written	_	_
as	_	_
:	_	_
p	_	_
(	_	_
x	_	_
)	_	_
≥	_	_
L	_	_
(	_	_
φ	_	_
,	_	_
θ	_	_
;	_	_
x	_	_
)	_	_
=	_	_
−DKL	_	_
(	_	_
qφ	_	_
(	_	_
z|x	_	_
)	_	_
||pθ	_	_
(	_	_
z	_	_
)	_	_
)	_	_
+	_	_
Eqφ	_	_
(	_	_
z|x	_	_
)	_	_
[	_	_
log	_	_
pθ	_	_
(	_	_
x|z	_	_
)	_	_
]	_	_
(	_	_
5	_	_
)	_	_

#189
10	_	_
Sasi	_	_
Kiran	_	_
Yelamarthi	_	_
et	_	_
al	_	_

#190
Similarly	_	_
,	_	_
it	_	_
is	_	_
possible	_	_
to	_	_
model	_	_
the	_	_
conditional	_	_
probability	_	_
p	_	_
(	_	_
x|y	_	_
)	_	_
as	_	_
proposed	_	_
by	_	_
[	_	_
50	_	_
]	_	_
.	_	_

#191
In	_	_
this	_	_
work	_	_
,	_	_
we	_	_
model	_	_
the	_	_
probability	_	_
distribution	_	_
over	_	_
images	_	_
conditioned	_	_
on	_	_
the	_	_
sketch	_	_
i.e	_	_
P	_	_
(	_	_
ximg|xsketch	_	_
)	_	_
.	_	_

#192
The	_	_
bound	_	_
now	_	_
becomes	_	_
:	_	_
L	_	_
(	_	_
φ	_	_
,	_	_
θ	_	_
;	_	_
ximg	_	_
,	_	_
xsketch	_	_
)	_	_
=	_	_
−DKL	_	_
(	_	_
qφ	_	_
(	_	_
z|ximg	_	_
,	_	_
xsketch	_	_
)	_	_
||pθ	_	_
(	_	_
z|xsketch	_	_
)	_	_
)	_	_
+	_	_
(	_	_
6	_	_
)	_	_
E	_	_
[	_	_
log	_	_
pθ	_	_
(	_	_
ximg|z	_	_
,	_	_
xsketch	_	_
)	_	_
]	_	_
Furthermore	_	_
,	_	_
to	_	_
encourage	_	_
the	_	_
model	_	_
to	_	_
preserve	_	_
the	_	_
latent	_	_
alignments	_	_
of	_	_
the	_	_
sketch	_	_
,	_	_
we	_	_
add	_	_
the	_	_
reconstruction	_	_
regularization	_	_
to	_	_
the	_	_
objective	_	_
.	_	_

#193
In	_	_
other	_	_
words	_	_
,	_	_
we	_	_
force	_	_
the	_	_
reconstructibility	_	_
of	_	_
the	_	_
sketch	_	_
features	_	_
from	_	_
the	_	_
generated	_	_
image	_	_
features	_	_
via	_	_
a	_	_
one-layer	_	_
neural	_	_
network	_	_
fNN	_	_
with	_	_
parameters	_	_
ψ	_	_
.	_	_

#194
All	_	_
the	_	_
parameters	_	_
θ	_	_
,	_	_
ψ	_	_
&	_	_
φ	_	_
are	_	_
trained	_	_
end-to-end	_	_
.	_	_

#195
The	_	_
regularization	_	_
loss	_	_
can	_	_
be	_	_
expressed	_	_
as	_	_
Lrecons	_	_
=	_	_
λ	_	_
.	_	_

#196
||fNN	_	_
(	_	_
x̂img	_	_
)	_	_
−	_	_
xsketch||22	_	_
(	_	_
7	_	_
)	_	_
Here	_	_
,	_	_
λ	_	_
is	_	_
a	_	_
hyper-parameter	_	_
which	_	_
is	_	_
to	_	_
be	_	_
tuned	_	_
.	_	_

#197
The	_	_
architecture	_	_
of	_	_
the	_	_
conditional	_	_
variational	_	_
autoencoder	_	_
used	_	_
is	_	_
shown	_	_
in	_	_
Figure	_	_
2	_	_
.	_	_

#198
We	_	_
call	_	_
this	_	_
CVAE	_	_
from	_	_
here	_	_
on	_	_
.	_	_

#199
5.2	_	_
Adversarial	_	_
Autoencoders	_	_

#200
Adversarial	_	_
Autoencoders	_	_
[	_	_
51	_	_
]	_	_
are	_	_
similar	_	_
to	_	_
the	_	_
variational	_	_
autoencoder	_	_
,	_	_
where	_	_
the	_	_
KL-Divergence	_	_
term	_	_
is	_	_
replaced	_	_
with	_	_
an	_	_
adversarial	_	_
training	_	_
procedure	_	_
.	_	_

#201
LetE	_	_
,	_	_
D	_	_
be	_	_
the	_	_
encoder	_	_
and	_	_
decoder	_	_
of	_	_
the	_	_
autoencoder	_	_
respectively	_	_
.	_	_

#202
E	_	_
maps	_	_
input	_	_
ximg	_	_
to	_	_
the	_	_
parameters	_	_
of	_	_
the	_	_
hidden	_	_
latent	_	_
vector	_	_
distribution	_	_
P	_	_
(	_	_
z|ximg	_	_
)	_	_
,	_	_
whereas	_	_
,	_	_
D	_	_
maps	_	_
the	_	_
sampled	_	_
z	_	_
to	_	_
ximg	_	_
(	_	_
both	_	_
are	_	_
conditioned	_	_
on	_	_
the	_	_
sketch	_	_
vector	_	_
xsketch	_	_
)	_	_
.	_	_

#203
We	_	_
have	_	_
an	_	_
additional	_	_
network	_	_
D	_	_
:	_	_
the	_	_
discriminator	_	_
.	_	_

#204
The	_	_
networks	_	_
E	_	_
&	_	_
D	_	_
try	_	_
to	_	_
minimize	_	_
the	_	_
following	_	_
loss	_	_
:	_	_
Ez	_	_
[	_	_
log	_	_
pθ	_	_
(	_	_
ximg|z	_	_
,	_	_
xsketch	_	_
)	_	_
]	_	_
+	_	_
Eximg	_	_
[	_	_
log	_	_
(	_	_
1−D	_	_
(	_	_
E	_	_
(	_	_
ximg	_	_
)	_	_
)	_	_
)	_	_
]	_	_
(	_	_
8	_	_
)	_	_
The	_	_
discriminator	_	_
D	_	_
tries	_	_
to	_	_
maximize	_	_
the	_	_
following	_	_
similar	_	_
to	_	_
the	_	_
original	_	_
GAN	_	_
formulation	_	_
[	_	_
52	_	_
]	_	_
:	_	_
Ez	_	_
[	_	_
log	_	_
[	_	_
D	_	_
(	_	_
z	_	_
)	_	_
]	_	_
]	_	_
+	_	_
Eximg	_	_
[	_	_
log	_	_
[	_	_
1−D	_	_
(	_	_
E	_	_
(	_	_
ximg	_	_
)	_	_
)	_	_
]	_	_
]	_	_
(	_	_
9	_	_
)	_	_
We	_	_
add	_	_
the	_	_
reconstructibility	_	_
regularization	_	_
described	_	_
in	_	_
the	_	_
above	_	_
section	_	_
to	_	_
the	_	_
loss	_	_
of	_	_
the	_	_
encoder	_	_
.	_	_

#205
The	_	_
architecture	_	_
of	_	_
the	_	_
adversarial	_	_
autoencoder	_	_
used	_	_
is	_	_
shown	_	_
in	_	_
Figure	_	_
2	_	_
.	_	_

#206
We	_	_
call	_	_
this	_	_
CAAE	_	_
from	_	_
here	_	_
on	_	_
.	_	_

#207
5.3	_	_
Retrieval	_	_
Methodology	_	_

#208
Gθ	_	_
is	_	_
trained	_	_
on	_	_
the	_	_
sketch-image	_	_
feature	_	_
pairs	_	_
from	_	_
the	_	_
seen	_	_
classes	_	_
.	_	_

#209
During	_	_
test	_	_
time	_	_
,	_	_
the	_	_
decoder	_	_
part	_	_
of	_	_
the	_	_
network	_	_
is	_	_
used	_	_
to	_	_
generate	_	_
a	_	_
number	_	_
of	_	_
image	_	_
feature	_	_
vectors	_	_
xIgen	_	_
conditioned	_	_
on	_	_
the	_	_
test	_	_
sketch	_	_
by	_	_
sampling	_	_
latent	_	_
vectors	_	_
from	_	_
the	_	_
prior	_	_
distribution	_	_
p	_	_
(	_	_
z	_	_
)	_	_
=	_	_
N	_	_
(	_	_
0	_	_
,	_	_
I	_	_
)	_	_
.	_	_

#210
For	_	_
a	_	_
test	_	_
sketch	_	_
xS	_	_
corresponding	_	_
to	_	_
a	_	_
test	_	_
class	_	_
,	_	_
we	_	_
generate	_	_
ECCV-18	_	_
submission	_	_
ID	_	_
2152	_	_
11	_	_
the	_	_
set	_	_
IxS	_	_
consisting	_	_
of	_	_
N	_	_
(	_	_
a	_	_
hyper-parameter	_	_
)	_	_
such	_	_
samples	_	_
of	_	_
xIgen	_	_
.	_	_

#211
We	_	_
then	_	_
cluster	_	_
these	_	_
generated	_	_
samples	_	_
IxS	_	_
using	_	_
K-Means	_	_
clustering	_	_
and	_	_
obtain	_	_
K	_	_
cluster	_	_
centers	_	_
C1	_	_
,	_	_
C2	_	_
,	_	_
.	_	_

#212
.	_	_

#213
.	_	_

#214
,	_	_
Ck	_	_
for	_	_
each	_	_
test	_	_
sketch	_	_
.	_	_

#215
We	_	_
retrieve	_	_
200	_	_
images	_	_
xIdb	_	_
from	_	_
the	_	_
image	_	_
database	_	_
based	_	_
on	_	_
the	_	_
following	_	_
distance	_	_
metric	_	_
:	_	_
D	_	_
(	_	_
xdbI	_	_
,	_	_
IxS	_	_
)	_	_
=	_	_
minKk=1cosine	_	_
(	_	_
θ	_	_
(	_	_
xdbI	_	_
)	_	_
,	_	_
θ	_	_
(	_	_
Ck	_	_
)	_	_
)	_	_
(	_	_
10	_	_
)	_	_
where	_	_
θ	_	_
is	_	_
the	_	_
VGG-16	_	_
[	_	_
45	_	_
]	_	_
function	_	_
.	_	_

#216
We	_	_
empirically	_	_
observe	_	_
thatK	_	_
=	_	_
5	_	_
gives	_	_
the	_	_
best	_	_
results	_	_
for	_	_
retrieval	_	_
.	_	_

#217
Other	_	_
distance	_	_
metrics	_	_
typically	_	_
used	_	_
in	_	_
clustering	_	_
were	_	_
considered	_	_
but	_	_
this	_	_
gave	_	_
the	_	_
best	_	_
results	_	_
.	_	_

#218
5.4	_	_
Experiments	_	_

#219
We	_	_
conduct	_	_
an	_	_
evaluation	_	_
of	_	_
the	_	_
generative	_	_
models	_	_
on	_	_
the	_	_
proposed	_	_
zero-shot	_	_
setting	_	_
and	_	_
compare	_	_
the	_	_
results	_	_
with	_	_
those	_	_
of	_	_
existing	_	_
methods	_	_
in	_	_
SBIR	_	_
.	_	_

#220
We	_	_
use	_	_
the	_	_
same	_	_
metrics	_	_
i.e	_	_
Precision	_	_
and	_	_
mAP	_	_
,	_	_
for	_	_
evaluation	_	_
.	_	_

#221
We	_	_
use	_	_
the	_	_
VGG-16	_	_
[	_	_
45	_	_
]	_	_
model	_	_
pre-trained	_	_
on	_	_
the	_	_
Imagenet-1K	_	_
dataset	_	_
to	_	_
obtain	_	_
4096	_	_
dimensional	_	_
features	_	_
for	_	_
images	_	_
.	_	_

#222
To	_	_
extract	_	_
the	_	_
sketch	_	_
features	_	_
,	_	_
we	_	_
tune	_	_
the	_	_
network	_	_
for	_	_
sketch	_	_
classification	_	_
task	_	_
using	_	_
only	_	_
the	_	_
training	_	_
sketches	_	_
.	_	_

#223
We	_	_
observed	_	_
that	_	_
this	_	_
training	_	_
gives	_	_
only	_	_
a	_	_
marginal	_	_
improvement	_	_
in	_	_
the	_	_
performance	_	_
and	_	_
is	_	_
hence	_	_
optional	_	_
.	_	_

#224
Baselines	_	_
Along	_	_
with	_	_
the	_	_
state-of-the-art	_	_
models	_	_
for	_	_
the	_	_
SBIR	_	_
task	_	_
,	_	_
we	_	_
consider	_	_
three	_	_
popular	_	_
algorithms	_	_
[	_	_
36	_	_
]	_	_
from	_	_
the	_	_
zero-shot	_	_
image	_	_
classification	_	_
literature	_	_
that	_	_
do	_	_
not	_	_
explicitly	_	_
use	_	_
class	_	_
label	_	_
information	_	_
and	_	_
can	_	_
be	_	_
easily	_	_
adopted	_	_
to	_	_
the	_	_
zero-shot	_	_
SBIR	_	_
task	_	_
.	_	_

#225
Let	_	_
(	_	_
XI	_	_
,	_	_
XS	_	_
)	_	_
∈	_	_
(	_	_
RN×dI	_	_
,	_	_
RN×dS	_	_
)	_	_
represent	_	_
the	_	_
image	_	_
and	_	_
sketch	_	_
feature	_	_
pairs	_	_
from	_	_
the	_	_
training	_	_
data	_	_
respectively	_	_
.	_	_

#226
We	_	_
learn	_	_
a	_	_
mapping	_	_
f	_	_
from	_	_
sketch	_	_
features	_	_
to	_	_
image	_	_
features	_	_
,	_	_
i.e	_	_
f	_	_
:	_	_
RdI	_	_
→	_	_
RdS	_	_
where	_	_
dI	_	_
,	_	_
dS	_	_
are	_	_
the	_	_
dimensions	_	_
of	_	_
the	_	_
image	_	_
and	_	_
sketch	_	_
vectors	_	_
respectively	_	_
.	_	_

#227
We	_	_
describe	_	_
these	_	_
models	_	_
below	_	_
:	_	_
Direct	_	_
Regression	_	_
:	_	_
The	_	_
ZS-SBIR	_	_
task	_	_
is	_	_
formulated	_	_
as	_	_
a	_	_
simple	_	_
regression	_	_
problem	_	_
,	_	_
where	_	_
each	_	_
feature	_	_
of	_	_
the	_	_
image	_	_
feature	_	_
vector	_	_
is	_	_
learnt	_	_
from	_	_
the	_	_
sketch	_	_
features	_	_
.	_	_

#228
This	_	_
is	_	_
similar	_	_
to	_	_
the	_	_
Direct	_	_
Attribute	_	_
prediction	_	_
[	_	_
25	_	_
]	_	_
which	_	_
is	_	_
a	_	_
widely	_	_
used	_	_
baseline	_	_
for	_	_
zero-shot	_	_
image	_	_
classification	_	_
.	_	_

#229
Embarrassingly	_	_
Simple	_	_
Zero-Shot	_	_
Learning	_	_
:	_	_
ESZSL	_	_
was	_	_
introduced	_	_
by	_	_
RomeraParedes	_	_
&	_	_
Torr	_	_
[	_	_
32	_	_
]	_	_
as	_	_
a	_	_
method	_	_
of	_	_
learning	_	_
bilinear	_	_
compatibility	_	_
matrix	_	_
between	_	_
images	_	_
and	_	_
attribute	_	_
vectors	_	_
in	_	_
the	_	_
context	_	_
of	_	_
zero-shot	_	_
classification	_	_
.	_	_

#230
In	_	_
this	_	_
work	_	_
,	_	_
we	_	_
adapt	_	_
the	_	_
model	_	_
to	_	_
the	_	_
ZS-SBIR	_	_
task	_	_
by	_	_
mapping	_	_
the	_	_
sketch	_	_
features	_	_
to	_	_
the	_	_
image	_	_
features	_	_
using	_	_
parallel	_	_
training	_	_
data	_	_
from	_	_
the	_	_
train	_	_
classes	_	_
.	_	_

#231
The	_	_
objective	_	_
is	_	_
to	_	_
estimate	_	_
W	_	_
∈	_	_
RdS×dI	_	_
that	_	_
minimizes	_	_
the	_	_
following	_	_
loss	_	_
:	_	_
||XSW	_	_
−XI	_	_
||2F	_	_
+	_	_
γ	_	_
∣∣∣∣XIW	_	_
T	_	_
∣∣∣∣2	_	_
F	_	_
+	_	_
λ	_	_
||XSW	_	_
||2F	_	_
+	_	_
β	_	_
||W	_	_
||2F	_	_
(	_	_
11	_	_
)	_	_
where	_	_
γ	_	_
,	_	_
λ	_	_
,	_	_
β	_	_
are	_	_
hyper-parameters	_	_
.	_	_

#232
Semantic	_	_
Autoencoder	_	_
:	_	_
The	_	_
Semantic	_	_
Autoencoder	_	_
(	_	_
SAE	_	_
)	_	_
[	_	_
30	_	_
]	_	_
proposes	_	_
an	_	_
autoencoder	_	_
framework	_	_
to	_	_
encourage	_	_
the	_	_
re-constructibility	_	_
of	_	_
the	_	_
sketch	_	_
vector	_	_
from	_	_
the	_	_
generated	_	_
image	_	_
vector	_	_
.	_	_

#233
The	_	_
loss	_	_
term	_	_
is	_	_
given	_	_
by	_	_
:	_	_
||XI	_	_
−XSW	_	_
||2F	_	_
+	_	_
λ	_	_
∣∣∣∣XIW	_	_
T	_	_
−XS	_	_
∣∣∣∣2	_	_
F	_	_
(	_	_
12	_	_
)	_	_

#234
12	_	_
Sasi	_	_
Kiran	_	_
Yelamarthi	_	_
et	_	_
al	_	_

#235
We	_	_
would	_	_
like	_	_
to	_	_
note	_	_
here	_	_
that	_	_
SAE	_	_
,	_	_
though	_	_
simple	_	_
,	_	_
is	_	_
currently	_	_
the	_	_
state-of-the-art	_	_
among	_	_
published	_	_
models	_	_
for	_	_
zero-shot	_	_
image	_	_
classification	_	_
task	_	_
to	_	_
the	_	_
best	_	_
of	_	_
our	_	_
knowledge	_	_
.	_	_

#236
Training	_	_
We	_	_
use	_	_
Adam	_	_
optimizer	_	_
[	_	_
53	_	_
]	_	_
with	_	_
learning	_	_
rate	_	_
α	_	_
=	_	_
2	_	_
×	_	_
10−4	_	_
,	_	_
β1	_	_
=	_	_
0.5	_	_
,	_	_
β2	_	_
=	_	_
0.999	_	_
and	_	_
a	_	_
batch	_	_
size	_	_
of	_	_
64	_	_
and	_	_
128	_	_
for	_	_
training	_	_
the	_	_
CVAE	_	_
and	_	_
CAAE	_	_
respectively	_	_
.	_	_

#237
We	_	_
observe	_	_
that	_	_
the	_	_
validation	_	_
performance	_	_
saturates	_	_
at	_	_
25	_	_
epochs	_	_
for	_	_
the	_	_
CVAE	_	_
model	_	_
and	_	_
at	_	_
6000	_	_
iterations	_	_
for	_	_
the	_	_
CAAE	_	_
model	_	_
.	_	_

#238
While	_	_
training	_	_
CAAE	_	_
,	_	_
we	_	_
train	_	_
the	_	_
discriminator	_	_
for	_	_
32	_	_
iterations	_	_
for	_	_
each	_	_
training	_	_
iteration	_	_
of	_	_
the	_	_
encoder	_	_
and	_	_
decoder	_	_
.	_	_

#239
We	_	_
found	_	_
that	_	_
N	_	_
=	_	_
200	_	_
i.e	_	_
generating	_	_
200	_	_
image	_	_
features	_	_
for	_	_
a	_	_
given	_	_
input	_	_
sketch	_	_
gives	_	_
optimal	_	_
performance	_	_
and	_	_
saturates	_	_
afterwards	_	_
.	_	_

#240
The	_	_
reconstructibility	_	_
parameter	_	_
λ	_	_
is	_	_
set	_	_
via	_	_
cross-validation	_	_
.	_	_

#241
SAE	_	_
has	_	_
a	_	_
single	_	_
hyper-parameter	_	_
and	_	_
is	_	_
solved	_	_
using	_	_
the	_	_
Bartels-Stewart	_	_
algorithm	_	_
[	_	_
54	_	_
]	_	_
.	_	_

#242
ESZSL	_	_
has	_	_
three	_	_
hyper	_	_
parameters	_	_
γ	_	_
,	_	_
λ	_	_
&	_	_
β	_	_
.	_	_

#243
We	_	_
set	_	_
β	_	_
=	_	_
γλ	_	_
following	_	_
the	_	_
authors	_	_
to	_	_
get	_	_
a	_	_
closed	_	_
form	_	_
solution	_	_
.	_	_

#244
We	_	_
tune	_	_
these	_	_
hyper-parameters	_	_
via	_	_
a	_	_
grid	_	_
search	_	_
from	_	_
10−6	_	_
to	_	_
107	_	_
.	_	_

#245
Table	_	_
3	_	_
.	_	_

#246
The	_	_
Precision	_	_
and	_	_
MAP	_	_
evaluated	_	_
on	_	_
the	_	_
retrieved	_	_
200	_	_
images	_	_
in	_	_
ZS-SBIR	_	_
on	_	_
the	_	_
proposed	_	_
split	_	_
Type	_	_
Evaluation	_	_
Methods	_	_
Precision	_	_
@	_	_
200	_	_
mAP	_	_
@	_	_
200	_	_
SBIR	_	_
methods	_	_
Baseline	_	_
0.106	_	_
0.054	_	_
Siamese-1	_	_
0.243	_	_
0.134	_	_
Siamese-2	_	_
0.251	_	_
0.149	_	_
Coarse-grained	_	_
triplet	_	_
0.169	_	_
0.083	_	_
Fine-grained	_	_
triplet	_	_
0.155	_	_
0.081	_	_
DSH	_	_
0.153	_	_
0.059	_	_
ZSL	_	_
methods	_	_
Direct	_	_
Regression	_	_
0.066	_	_
0.022	_	_
ESZSL	_	_
0.187	_	_
0.117	_	_
SAE	_	_
0.238	_	_
0.136	_	_
Ours	_	_
CAAE	_	_
0.260	_	_
0.156	_	_
CVAE	_	_
0.333	_	_
0.225	_	_

#247
6	_	_
Results	_	_

#248
The	_	_
results	_	_
of	_	_
the	_	_
evaluated	_	_
methods	_	_
for	_	_
ZS-SBIR	_	_
are	_	_
summarized	_	_
in	_	_
Table	_	_
3	_	_
.	_	_

#249
As	_	_
observed	_	_
in	_	_
section-4.4	_	_
,	_	_
existing	_	_
SBIR	_	_
models	_	_
perform	_	_
poorly	_	_
in	_	_
the	_	_
ZS-SBIR	_	_
task	_	_
.	_	_

#250
Both	_	_
the	_	_
proposed	_	_
generative	_	_
models	_	_
out-perform	_	_
the	_	_
existing	_	_
models	_	_
indicating	_	_
better	_	_
latent	_	_
alignment	_	_
learning	_	_
in	_	_
the	_	_
generative	_	_
approach	_	_
.	_	_

#251
Qualitative	_	_
Analysis	_	_
:	_	_
We	_	_
show	_	_
some	_	_
of	_	_
the	_	_
retrieved	_	_
images	_	_
for	_	_
sketch	_	_
inputs	_	_
of	_	_
the	_	_
unseen	_	_
classes	_	_
using	_	_
the	_	_
CVAE	_	_
model	_	_
in	_	_
ZS-SBIR	_	_
in	_	_
Figure	_	_
3	_	_
.	_	_

#252
We	_	_
observe	_	_
that	_	_
the	_	_
retrieved	_	_
images	_	_
closely	_	_
match	_	_
the	_	_
outline	_	_
of	_	_
the	_	_
sketch	_	_
.	_	_

#253
We	_	_
also	_	_
observe	_	_
that	_	_
our	_	_
model	_	_
ECCV-18	_	_
submission	_	_
ID	_	_
2152	_	_
13	_	_
Fig.	_	_
3	_	_
.	_	_

#254
Top	_	_
6	_	_
images	_	_
retrieved	_	_
for	_	_
some	_	_
input	_	_
sketches	_	_
using	_	_
CVAE	_	_
in	_	_
the	_	_
proposed	_	_
zero-shot	_	_
setting	_	_
.	_	_

#255
Note	_	_
that	_	_
these	_	_
sketch	_	_
classes	_	_
have	_	_
never	_	_
been	_	_
encountered	_	_
by	_	_
the	_	_
model	_	_
during	_	_
training	_	_
.	_	_

#256
The	_	_
red	_	_
border	_	_
indicates	_	_
that	_	_
the	_	_
retrieved	_	_
image	_	_
does	_	_
not	_	_
belong	_	_
to	_	_
sketch’s	_	_
class	_	_
.	_	_

#257
However	_	_
,	_	_
we	_	_
would	_	_
like	_	_
to	_	_
emphasize	_	_
that	_	_
the	_	_
retrieved	_	_
false	_	_
positives	_	_
do	_	_
match	_	_
the	_	_
outline	_	_
of	_	_
the	_	_
sketch	_	_
makes	_	_
visually	_	_
reasonable	_	_
mistakes	_	_
in	_	_
the	_	_
case	_	_
of	_	_
false	_	_
positives	_	_
wherein	_	_
the	_	_
retrieved	_	_
images	_	_
do	_	_
have	_	_
a	_	_
significant	_	_
similarity	_	_
with	_	_
the	_	_
sketch	_	_
even	_	_
though	_	_
they	_	_
belong	_	_
to	_	_
a	_	_
different	_	_
class	_	_
.	_	_

#258
For	_	_
instance	_	_
,	_	_
in	_	_
the	_	_
last	_	_
example	_	_
the	_	_
false	_	_
positive	_	_
that	_	_
belongs	_	_
to	_	_
the	_	_
class	_	_
rhinoceros	_	_
has	_	_
a	_	_
similar	_	_
outline	_	_
as	_	_
that	_	_
of	_	_
the	_	_
sketch	_	_
.	_	_

#259
These	_	_
may	_	_
be	_	_
considered	_	_
not	_	_
as	_	_
an	_	_
error	_	_
but	_	_
rather	_	_
as	_	_
a	_	_
positive	_	_
retrieval	_	_
,	_	_
but	_	_
can	_	_
only	_	_
be	_	_
evaluated	_	_
qualitatively	_	_
by	_	_
an	_	_
arduous	_	_
manual	_	_
task	_	_
and	_	_
may	_	_
be	_	_
attributed	_	_
to	_	_
data	_	_
bias	_	_
.	_	_

#260
Feature	_	_
visualization	_	_
:	_	_
To	_	_
understand	_	_
the	_	_
kinds	_	_
of	_	_
features	_	_
generated	_	_
by	_	_
the	_	_
model	_	_
,	_	_
we	_	_
visualize	_	_
the	_	_
generated	_	_
image	_	_
features	_	_
of	_	_
the	_	_
test	_	_
sketches	_	_
in	_	_
Figure	_	_
4	_	_
via	_	_
the	_	_
t-sne	_	_
method	_	_
.	_	_

#261
We	_	_
make	_	_
two	_	_
observations	_	_
,	_	_
(	_	_
i	_	_
)	_	_
the	_	_
generated	_	_
features	_	_
are	_	_
largely	_	_
close	_	_
to	_	_
the	_	_
true	_	_
test	_	_
image	_	_
features	_	_
(	_	_
ii	_	_
)	_	_
multiple	_	_
modalities	_	_
of	_	_
the	_	_
distribution	_	_
are	_	_
captured	_	_
by	_	_
our	_	_
model	_	_
.	_	_

#262
Performance	_	_
Comparisons	_	_
:	_	_
Comparison	_	_
among	_	_
the	_	_
current	_	_
state-of-the-art	_	_
models	_	_
in	_	_
the	_	_
zero-shot	_	_
setting	_	_
of	_	_
SBIR	_	_
was	_	_
already	_	_
done	_	_
in	_	_
Section	_	_
4.4	_	_
.	_	_

#263
Direct	_	_
regression	_	_
from	_	_
sketch	_	_
to	_	_
image	_	_
feature	_	_
space	_	_
gives	_	_
a	_	_
precision	_	_
value	_	_
of	_	_
0.066	_	_
.	_	_

#264
This	_	_
serves	_	_
as	_	_
a	_	_
baseline	_	_
to	_	_
evaluate	_	_
other	_	_
explicitly	_	_
imposed	_	_
regularizations	_	_
in	_	_
ESZSL	_	_
and	_	_
SAE	_	_
.	_	_

#265
Our	_	_
first	_	_
observation	_	_
is	_	_
that	_	_
the	_	_
simple	_	_
zero-shot	_	_
learning	_	_
models	_	_
adapted	_	_
to	_	_
the	_	_
ZS-SBIR	_	_
task	_	_
perform	_	_
better	_	_
than	_	_
two	_	_
state-of-the-art	_	_
sketch	_	_
based	_	_
image	_	_
retrieval	_	_
models	_	_
i.e	_	_
Triplet	_	_
network	_	_
and	_	_
DSH	_	_
.	_	_

#266
SAE	_	_
,	_	_
which	_	_
is	_	_
the	_	_
current	_	_
state-of-the-art	_	_

#267
14	_	_
Sasi	_	_
Kiran	_	_
Yelamarthi	_	_
et	_	_
al	_	_

#268
Fig.	_	_
4	_	_
.	_	_

#269
T-SNE	_	_
visualization	_	_
of	_	_
generated	_	_
image	_	_
features	_	_
.	_	_

#270
Test	_	_
data	_	_
features	_	_
are	_	_
presented	_	_
on	_	_
the	_	_
left	_	_
and	_	_
the	_	_
predicted	_	_
image	_	_
features	_	_
are	_	_
on	_	_
the	_	_
right	_	_
.	_	_

#271
Each	_	_
color	_	_
represents	_	_
a	_	_
particular	_	_
class	_	_
for	_	_
zero-shot	_	_
image	_	_
classification	_	_
,	_	_
achieves	_	_
the	_	_
best	_	_
performance	_	_
among	_	_
all	_	_
the	_	_
prior	_	_
methods	_	_
considered	_	_
.	_	_

#272
SAE	_	_
maps	_	_
the	_	_
sketches	_	_
to	_	_
images	_	_
and	_	_
hence	_	_
generates	_	_
a	_	_
single	_	_
image	_	_
for	_	_
a	_	_
given	_	_
sketch	_	_
.	_	_

#273
This	_	_
is	_	_
similar	_	_
to	_	_
our	_	_
proposed	_	_
models	_	_
except	_	_
that	_	_
our	_	_
models	_	_
generate	_	_
a	_	_
number	_	_
of	_	_
samples	_	_
for	_	_
a	_	_
single	_	_
sketch	_	_
by	_	_
filling	_	_
the	_	_
missing	_	_
details	_	_
from	_	_
the	_	_
latent	_	_
distribution	_	_
.	_	_

#274
Furthermore	_	_
our	_	_
model	_	_
is	_	_
non-linear	_	_
whereas	_	_
SAE	_	_
is	_	_
a	_	_
simple	_	_
linear	_	_
projection	_	_
.	_	_

#275
We	_	_
believe	_	_
that	_	_
these	_	_
generalizations	_	_
over	_	_
the	_	_
SAE	_	_
in	_	_
our	_	_
model	_	_
leads	_	_
to	_	_
superior	_	_
performance	_	_
Among	_	_
the	_	_
two	_	_
models	_	_
proposed	_	_
,	_	_
we	_	_
observe	_	_
that	_	_
the	_	_
CVAE	_	_
models	_	_
performs	_	_
significantly	_	_
better	_	_
than	_	_
the	_	_
CAAE	_	_
model	_	_
.	_	_

#276
This	_	_
may	_	_
be	_	_
attributed	_	_
to	_	_
the	_	_
issue	_	_
of	_	_
instability	_	_
while	_	_
training	_	_
adversarial	_	_
models	_	_
.	_	_

#277
We	_	_
observe	_	_
that	_	_
the	_	_
training	_	_
error	_	_
of	_	_
the	_	_
CVAE	_	_
models	_	_
is	_	_
much	_	_
more	_	_
smoother	_	_
compared	_	_
to	_	_
the	_	_
CAAE	_	_
model	_	_
.	_	_

#278
We	_	_
observe	_	_
that	_	_
using	_	_
the	_	_
reconstruction	_	_
loss	_	_
leads	_	_
to	_	_
a	_	_
3	_	_
%	_	_
improvement	_	_
on	_	_
the	_	_
precision	_	_
.	_	_

#279
We	_	_
further	_	_
apply	_	_
these	_	_
proposed	_	_
generative	_	_
models	_	_
to	_	_
the	_	_
zero-shot	_	_
image	_	_
classification	_	_
task	_	_
and	_	_
achieve	_	_
significant	_	_
improvements	_	_
over	_	_
the	_	_
state-of-the-art	_	_
methods	_	_
.	_	_

#280
This	_	_
work	_	_
has	_	_
been	_	_
submitted	_	_
to	_	_
a	_	_
parallel	_	_
conference	_	_
and	_	_
has	_	_
been	_	_
included	_	_
in	_	_
the	_	_
Supplementary	_	_
Material	_	_
[	_	_
28	_	_
]	_	_
.	_	_

#281
7	_	_
Conclusion	_	_

#282
We	_	_
identified	_	_
major	_	_
drawbacks	_	_
in	_	_
current	_	_
evaluation	_	_
schemes	_	_
in	_	_
sketch-based	_	_
image	_	_
retrieval	_	_
(	_	_
SBIR	_	_
)	_	_
task	_	_
.	_	_

#283
While	_	_
coarse-grained	_	_
evaluation	_	_
suffers	_	_
from	_	_
class-specific	_	_
learning	_	_
,	_	_
fine-grained	_	_
evaluation	_	_
requires	_	_
arduous	_	_
manual	_	_
labor	_	_
while	_	_
also	_	_
suffering	_	_
from	_	_
human	_	_
biases	_	_
.	_	_

#284
To	_	_
this	_	_
end	_	_
,	_	_
we	_	_
pose	_	_
the	_	_
problem	_	_
of	_	_
sketch-based	_	_
retrieval	_	_
in	_	_
a	_	_
zero-shot	_	_
framework	_	_
(	_	_
ZS-SBIR	_	_
)	_	_
.	_	_

#285
By	_	_
making	_	_
a	_	_
careful	_	_
split	_	_
in	_	_
the	_	_
”Sketchy”	_	_
dataset	_	_
,	_	_
we	_	_
provide	_	_
a	_	_
benchmark	_	_
for	_	_
this	_	_
task	_	_
.	_	_

#286
We	_	_
then	_	_
evaluate	_	_
current	_	_
state-of-the-art	_	_
SBIR	_	_
models	_	_
in	_	_
this	_	_
framework	_	_
and	_	_
show	_	_
that	_	_
the	_	_
performance	_	_
of	_	_
these	_	_
models	_	_
drop	_	_
significantly	_	_
,	_	_
thus	_	_
exposing	_	_
the	_	_
class-specific	_	_
learning	_	_
which	_	_
is	_	_
inherent	_	_
to	_	_
these	_	_
discriminative	_	_
models	_	_
.	_	_

#287
We	_	_
also	_	_
extend	_	_
the	_	_
existing	_	_
zero-shot	_	_
image	_	_
classification	_	_
methods	_	_
to	_	_
this	_	_
ZS-SBIR	_	_
task	_	_
.	_	_

#288
We	_	_
then	_	_
pose	_	_
the	_	_
SBIR	_	_
problem	_	_
as	_	_
a	_	_
generative	_	_
task	_	_
and	_	_
propose	_	_
two	_	_
conditional	_	_
generative	_	_
models	_	_
which	_	_
achieve	_	_
significant	_	_
improvement	_	_
over	_	_
the	_	_
existing	_	_
methods	_	_
.	_	_

#289
ECCV-18	_	_
submission	_	_
ID	_	_
2152	_	_
15	_	_