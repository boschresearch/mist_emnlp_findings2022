#0
Deep	_	_
Multiple	_	_
Instance	_	_
Learning	_	_
for	_	_
Zero-shot	_	_
Image	_	_
Tagging	_	_
Shafin	_	_
Rahman†	_	_
?	_	_

#1
and	_	_
Salman	_	_
Khan	_	_
?	_	_
†	_	_
†Australian	_	_
National	_	_
University	_	_
?	_	_
DATA61	_	_
,	_	_
CSIRO	_	_
Abstract	_	_
.	_	_

#2
In-line	_	_
with	_	_
the	_	_
success	_	_
of	_	_
deep	_	_
learning	_	_
on	_	_
traditional	_	_
recognition	_	_
problem	_	_
,	_	_
several	_	_
end-to-end	_	_
deep	_	_
models	_	_
for	_	_
zero-shot	_	_
recognition	_	_
have	_	_
been	_	_
proposed	_	_
in	_	_
the	_	_
literature	_	_
.	_	_

#3
These	_	_
models	_	_
are	_	_
successful	_	_
to	_	_
predict	_	_
a	_	_
single	_	_
unseen	_	_
label	_	_
given	_	_
an	_	_
input	_	_
image	_	_
,	_	_
but	_	_
does	_	_
not	_	_
scale	_	_
to	_	_
cases	_	_
where	_	_
multiple	_	_
unseen	_	_
objects	_	_
are	_	_
present	_	_
.	_	_

#4
In	_	_
this	_	_
paper	_	_
,	_	_
we	_	_
model	_	_
this	_	_
problem	_	_
within	_	_
the	_	_
framework	_	_
of	_	_
Multiple	_	_
Instance	_	_
Learning	_	_
(	_	_
MIL	_	_
)	_	_
.	_	_

#5
To	_	_
the	_	_
best	_	_
of	_	_
our	_	_
knowledge	_	_
,	_	_
we	_	_
propose	_	_
the	_	_
first	_	_
end-to-end	_	_
trainable	_	_
deep	_	_
MIL	_	_
framework	_	_
for	_	_
the	_	_
multi-label	_	_
zero-shot	_	_
tagging	_	_
problem	_	_
.	_	_

#6
Due	_	_
to	_	_
its	_	_
novel	_	_
design	_	_
,	_	_
the	_	_
proposed	_	_
framework	_	_
has	_	_
several	_	_
interesting	_	_
features	_	_
:	_	_
(	_	_
1	_	_
)	_	_
Unlike	_	_
previous	_	_
deep	_	_
MIL	_	_
models	_	_
,	_	_
it	_	_
does	_	_
not	_	_
use	_	_
any	_	_
off-line	_	_
procedure	_	_
(	_	_
e.g.	_	_
,	_	_
Selective	_	_
Search	_	_
or	_	_
EdgeBoxes	_	_
)	_	_
for	_	_
bag	_	_
generation	_	_
.	_	_

#7
(	_	_
2	_	_
)	_	_
During	_	_
test	_	_
time	_	_
,	_	_
it	_	_
can	_	_
process	_	_
any	_	_
number	_	_
of	_	_
unseen	_	_
labels	_	_
given	_	_
their	_	_
semantic	_	_
embedding	_	_
vectors	_	_
.	_	_

#8
(	_	_
3	_	_
)	_	_
Using	_	_
only	_	_
seen	_	_
labels	_	_
per	_	_
image	_	_
as	_	_
weak	_	_
annotation	_	_
,	_	_
it	_	_
can	_	_
produce	_	_
a	_	_
bounding	_	_
box	_	_
for	_	_
each	_	_
predicted	_	_
labels	_	_
.	_	_

#9
We	_	_
experiment	_	_
with	_	_
the	_	_
NUS-WIDE	_	_
dataset	_	_
and	_	_
achieve	_	_
superior	_	_
performance	_	_
across	_	_
conventional	_	_
,	_	_
zero-shot	_	_
and	_	_
generalized	_	_
zero-shot	_	_
tagging	_	_
tasks	_	_
.	_	_

#10
Keywords	_	_
:	_	_
Zero-shot	_	_
tagging	_	_
,	_	_
Object	_	_
detection	_	_
,	_	_
Multiple	_	_
instance	_	_
learning	_	_
,	_	_
Deep	_	_
learning	_	_

#11
1	_	_
Introduction	_	_

#12
In	_	_
recent	_	_
years	_	_
,	_	_
numerous	_	_
single	_	_
label	_	_
zero-shot	_	_
classification	_	_
methods	_	_
have	_	_
been	_	_
proposed	_	_
aiming	_	_
to	_	_
recognize	_	_
novel	_	_
concepts	_	_
with	_	_
no	_	_
training	_	_
examples	_	_
[	_	_
1,2,3,4,5,6,7	_	_
]	_	_
.	_	_

#13
However	_	_
in	_	_
real	_	_
life	_	_
settings	_	_
,	_	_
images	_	_
often	_	_
come	_	_
with	_	_
multiple	_	_
objects	_	_
or	_	_
concepts	_	_
that	_	_
may	_	_
or	_	_
may	_	_
not	_	_
be	_	_
observed	_	_
during	_	_
training	_	_
.	_	_

#14
For	_	_
example	_	_
,	_	_
enormous	_	_
growth	_	_
in	_	_
on-line	_	_
photo	_	_
collections	_	_
require	_	_
automatic	_	_
image	_	_
tagging	_	_
algorithms	_	_
that	_	_
can	_	_
provide	_	_
both	_	_
seen	_	_
and	_	_
unseen	_	_
labels	_	_
to	_	_
the	_	_
images	_	_
.	_	_

#15
Despite	_	_
the	_	_
importance	_	_
and	_	_
practical	_	_
nature	_	_
of	_	_
this	_	_
problem	_	_
,	_	_
there	_	_
are	_	_
very	_	_
few	_	_
existing	_	_
methods	_	_
with	_	_
the	_	_
capability	_	_
to	_	_
address	_	_
the	_	_
zero-shot	_	_
image	_	_
tagging	_	_
task	_	_
[	_	_
8,9,10,11	_	_
]	_	_
.	_	_

#16
Notably	_	_
,	_	_
any	_	_
object	_	_
or	_	_
concept	_	_
can	_	_
either	_	_
be	_	_
present	_	_
at	_	_
the	_	_
localized	_	_
region	_	_
or	_	_
be	_	_
inferred	_	_
from	_	_
the	_	_
holistic	_	_
scene	_	_
information	_	_
.	_	_

#17
Moreover	_	_
,	_	_
part	_	_
of	_	_
the	_	_
object	_	_
or	_	_
concept	_	_
can	_	_
be	_	_
partially	_	_
occluded	_	_
by	_	_
other	_	_
objects	_	_
.	_	_

#18
Therefore	_	_
,	_	_
assigning	_	_
the	_	_
multiple	_	_
tags	_	_
to	_	_
an	_	_
image	_	_
requires	_	_
searching	_	_
for	_	_
both	_	_
local	_	_
and	_	_
global	_	_
details	_	_
present	_	_
at	_	_
different	_	_
scales	_	_
,	_	_
orientations	_	_
,	_	_
poses	_	_
and	_	_
illumination	_	_
conditions	_	_
.	_	_

#19
ar	_	_
X	_	_
iv	_	_
:1	_	_
3	_	_
.	_	_

#20
1v	_	_
1	_	_
[	_	_
cs	_	_
.C	_	_
V	_	_
]	_	_
1	_	_
6	_	_
M	_	_
ar	_	_
2	_	_

#21
2	_	_
Shafin	_	_
Rahman	_	_
and	_	_
Salman	_	_
Khan	_	_

#22
It	_	_
is	_	_
considered	_	_
as	_	_
a	_	_
challenging	_	_
task	_	_
even	_	_
for	_	_
the	_	_
traditional	_	_
case	_	_
let	_	_
alone	_	_
the	_	_
zero-shot	_	_
version	_	_
of	_	_
the	_	_
problem	_	_
.	_	_

#23
The	_	_
existing	_	_
attempts	_	_
on	_	_
zero-shot	_	_
image	_	_
tagging	_	_
(	_	_
e.g.	_	_
,	_	_
[	_	_
8,9,10,11	_	_
]	_	_
)	_	_
mostly	_	_
used	_	_
deep	_	_
CNN	_	_
features	_	_
of	_	_
the	_	_
whole	_	_
images	_	_
.	_	_

#24
But	_	_
,	_	_
as	_	_
objects	_	_
or	_	_
concepts	_	_
are	_	_
more	_	_
likely	_	_
to	_	_
be	_	_
present	_	_
at	_	_
the	_	_
localized	_	_
regions	_	_
,	_	_
the	_	_
extracted	_	_
features	_	_
from	_	_
the	_	_
whole	_	_
image	_	_
can	_	_
not	_	_
represent	_	_
all	_	_
possible	_	_
labels	_	_
.	_	_

#25
In	_	_
this	_	_
paper	_	_
,	_	_
we	_	_
propose	_	_
a	_	_
deep	_	_
Multiple	_	_
Instance	_	_
Learning	_	_
(	_	_
MIL	_	_
)	_	_
framework	_	_
that	_	_
operates	_	_
on	_	_
a	_	_
bag	_	_
of	_	_
instances	_	_
generated	_	_
from	_	_
each	_	_
image	_	_
.	_	_

#26
MIL	_	_
assumes	_	_
that	_	_
each	_	_
bag	_	_
contains	_	_
at	_	_
least	_	_
one	_	_
instance	_	_
of	_	_
the	_	_
true	_	_
labels	_	_
defined	_	_
by	_	_
the	_	_
ground-truth	_	_
.	_	_

#27
A	_	_
distinguishing	_	_
feature	_	_
of	_	_
our	_	_
approach	_	_
is	_	_
that	_	_
the	_	_
bag	_	_
of	_	_
instances	_	_
not	_	_
only	_	_
encodes	_	_
the	_	_
global	_	_
information	_	_
about	_	_
a	_	_
scene	_	_
,	_	_
but	_	_
also	_	_
have	_	_
a	_	_
rich	_	_
representation	_	_
for	_	_
localized	_	_
object-level	_	_
features	_	_
.	_	_

#28
This	_	_
is	_	_
different	_	_
from	_	_
the	_	_
existing	_	_
literature	_	_
in	_	_
image	_	_
tagging	_	_
,	_	_
where	_	_
MIL	_	_
based	_	_
strategies	_	_
do	_	_
not	_	_
consider	_	_
local	_	_
image	_	_
details	_	_
.	_	_

#29
For	_	_
example	_	_
,	_	_
[	_	_
12	_	_
]	_	_
used	_	_
image-level	_	_
features	_	_
at	_	_
different	_	_
scale	_	_
of	_	_
the	_	_
network	_	_
whereas	_	_
[	_	_
13	_	_
]	_	_
used	_	_
whole	_	_
image	_	_
features	_	_
from	_	_
different	_	_
video	_	_
frames	_	_
as	_	_
the	_	_
bag	_	_
of	_	_
instance	_	_
.	_	_

#30
These	_	_
techniques	_	_
therefore	_	_
work	_	_
only	_	_
for	_	_
the	_	_
most	_	_
prominent	_	_
objects	_	_
but	_	_
often	_	_
fail	_	_
for	_	_
non-salient	_	_
concepts	_	_
due	_	_
to	_	_
the	_	_
lack	_	_
of	_	_
localized	_	_
information	_	_
.	_	_

#31
In	_	_
addition	_	_
to	_	_
the	_	_
use	_	_
of	_	_
localized	_	_
features	_	_
,	_	_
we	_	_
integrate	_	_
the	_	_
instance	_	_
localization	_	_
within	_	_
a	_	_
unified	_	_
system	_	_
that	_	_
can	_	_
be	_	_
trained	_	_
jointly	_	_
in	_	_
an	_	_
end-to-end	_	_
manner	_	_
.	_	_

#32
We	_	_
note	_	_
that	_	_
the	_	_
previous	_	_
approaches	_	_
[	_	_
14,15,16,17	_	_
]	_	_
applied	_	_
off-line	_	_
procedures	_	_
like	_	_
Selective	_	_
Search	_	_
[	_	_
18	_	_
]	_	_
/EdgeBoxes	_	_
[	_	_
19	_	_
]	_	_
/BING	_	_
[	_	_
20	_	_
]	_	_
for	_	_
object	_	_
proposal	_	_
or	_	_
patch	_	_
generation	_	_
which	_	_
served	_	_
as	_	_
a	_	_
bag-of-instance	_	_
.	_	_

#33
Patches	_	_
obtained	_	_
from	_	_
any	_	_
external	_	_
procedure	_	_
were	_	_
used	_	_
in	_	_
three	_	_
ways	_	_
:	_	_
(	_	_
1	_	_
)	_	_
to	_	_
extract	_	_
features	_	_
for	_	_
each	_	_
patch	_	_
from	_	_
a	_	_
pre-trained	_	_
deep	_	_
network	_	_
to	_	_
create	_	_
bag-of-instance	_	_
[	_	_
14,21	_	_
]	_	_
,	_	_
(	_	_
2	_	_
)	_	_
to	_	_
use	_	_
a	_	_
set	_	_
of	_	_
patches	_	_
as	_	_
a	_	_
bag	_	_
and	_	_
feed	_	_
the	_	_
bag	_	_
as	_	_
an	_	_
input	_	_
to	_	_
a	_	_
deep	_	_
network	_	_
to	_	_
perform	_	_
MIL	_	_
such	_	_
that	_	_
the	_	_
image	_	_
features	_	_
can	_	_
be	_	_
fine-tined	_	_
[	_	_
15,16	_	_
]	_	_
,	_	_
(	_	_
3	_	_
)	_	_
to	_	_
feed	_	_
an	_	_
input	_	_
image	_	_
with	_	_
all	_	_
patch	_	_
locations	_	_
and	_	_
later	_	_
perform	_	_
a	_	_
ROIPooling	_	_
to	_	_
generate	_	_
bag	_	_
of	_	_
features	_	_
[	_	_
17,22	_	_
]	_	_
.	_	_

#34
One	_	_
common	_	_
issue	_	_
with	_	_
these	_	_
approaches	_	_
is	_	_
that	_	_
none	_	_
of	_	_
the	_	_
methods	_	_
are	_	_
end-to-end	_	_
trainable	_	_
because	_	_
of	_	_
the	_	_
dependency	_	_
on	_	_
the	_	_
external	_	_
non-differentiable	_	_
procedure	_	_
in	_	_
either	_	_
feature	_	_
extraction	_	_
or	_	_
bag	_	_
of	_	_
instance	_	_
generation	_	_
.	_	_

#35
Furthermore	_	_
,	_	_
the	_	_
above	_	_
methods	_	_
do	_	_
not	_	_
address	_	_
zero-shot	_	_
tagging	_	_
problem	_	_
and	_	_
can	_	_
not	_	_
relate	_	_
the	_	_
visual	_	_
and	_	_
semantic	_	_
concepts	_	_
.	_	_

#36
A	_	_
recent	_	_
work	_	_
from	_	_
Ren	_	_
et	_	_
al.	_	_
[	_	_
23	_	_
]	_	_
proposed	_	_
a	_	_
solution	_	_
for	_	_
zero-shot	_	_
tagging	_	_
in-line	_	_
with	_	_
the	_	_
third	_	_
approach	_	_
above	_	_
,	_	_
that	_	_
can	_	_
not	_	_
dynamically	_	_
adapt	_	_
the	_	_
patch	_	_
locations	_	_
.	_	_

#37
Finally	_	_
,	_	_
our	_	_
proposed	_	_
network	_	_
maps	_	_
local	_	_
and	_	_
global	_	_
information	_	_
inside	_	_
the	_	_
bag	_	_
to	_	_
a	_	_
semantic	_	_
embedding	_	_
space	_	_
so	_	_
that	_	_
the	_	_
correspondences	_	_
with	_	_
both	_	_
seen	_	_
and	_	_
unseen	_	_
classes	_	_
can	_	_
be	_	_
found	_	_
.	_	_

#38
With	_	_
respect	_	_
to	_	_
zero-shot	_	_
tagging	_	_
,	_	_
[	_	_
10,23	_	_
]	_	_
are	_	_
closest	_	_
to	_	_
our	_	_
work	_	_
as	_	_
they	_	_
handle	_	_
a	_	_
visual-semantic	_	_
mapping	_	_
to	_	_
bridge	_	_
seen	_	_
and	_	_
unseen	_	_
classes	_	_
.	_	_

#39
However	_	_
,	_	_
[	_	_
10	_	_
]	_	_
uses	_	_
off	_	_
the	_	_
shelf	_	_
features	_	_
and	_	_
does	_	_
not	_	_
consider	_	_
local	_	_
details	_	_
.	_	_

#40
To	_	_
extract	_	_
local	_	_
image	_	_
information	_	_
,	_	_
our	_	_
approach	_	_
finds	_	_
localized	_	_
patches	_	_
similar	_	_
to	_	_
[	_	_
23	_	_
]	_	_
.	_	_

#41
However	_	_
,	_	_
instead	_	_
of	_	_
using	_	_
an	_	_
external	_	_
off-line	_	_
procedure	_	_
as	_	_
in	_	_
[	_	_
23	_	_
]	_	_
for	_	_
bag	_	_
generation	_	_
,	_	_
our	_	_
network	_	_
produces	_	_
the	_	_
bag	_	_
by	_	_
itself	_	_
.	_	_

#42
Moreover	_	_
,	_	_
it	_	_
can	_	_
simultaneously	_	_
fine-tune	_	_
the	_	_
feature	_	_
extraction	_	_
and	_	_
bag	_	_
generation	_	_
process	_	_
instead	_	_
of	_	_
just	_	_
using	_	_
pre-trained	_	_
patch	_	_
features	_	_
.	_	_

#43
In	_	_
Figure	_	_
1	_	_
,	_	_
we	_	_
illustrate	_	_
a	_	_
block	_	_
diagram	_	_
of	_	_
different	_	_
kinds	_	_
of	_	_
image	_	_
tagging	_	_
frameworks	_	_
.	_	_

#44
Our	_	_
framework	_	_
Deep	_	_
Multiple	_	_
Instance	_	_
Learning	_	_
for	_	_
ZST	_	_
3	_	_
Fig.	_	_
1	_	_
.	_	_

#45
Overview	_	_
of	_	_
different	_	_
multi-label	_	_
image	_	_
annotation	_	_
architecture	_	_
.	_	_

#46
(	_	_
a	_	_
)	_	_
[	_	_
10,14,21	_	_
]	_	_
extract	_	_
deep	_	_
features	_	_
separately	_	_
,	_	_
then	_	_
feed	_	_
those	_	_
features	_	_
to	_	_
a	_	_
neural	_	_
network	_	_
for	_	_
classification	_	_
(	_	_
b	_	_
)	_	_
[	_	_
15,16	_	_
]	_	_
use	_	_
external	_	_
procedure	_	_
to	_	_
extract	_	_
image	_	_
patches	_	_
for	_	_
bag	_	_
generation	_	_
then	_	_
feed	_	_
those	_	_
patches	_	_
to	_	_
a	_	_
deep	_	_
model	_	_
to	_	_
get	_	_
final	_	_
bag	_	_
score	_	_
for	_	_
seen	_	_
classes	_	_
(	_	_
c	_	_
)	_	_
[	_	_
17,23,22	_	_
]	_	_
process	_	_
the	_	_
whole	_	_
image	_	_
as	_	_
well	_	_
as	_	_
some	_	_
patches	_	_
obtained	_	_
using	_	_
external	_	_
process	_	_
together	_	_
where	_	_
all	_	_
patches	_	_
from	_	_
one	_	_
image	_	_
share	_	_
the	_	_
same	_	_
CNN	_	_
layers	_	_
to	_	_
get	_	_
bag	_	_
score	_	_
for	_	_
seen	_	_
classes	_	_
(	_	_
d	_	_
)	_	_
Our	_	_
proposed	_	_
MIL	_	_
model	_	_
simply	_	_
takes	_	_
an	_	_
image	_	_
as	_	_
an	_	_
input	_	_
and	_	_
produces	_	_
bag	_	_
score	_	_
for	_	_
both	_	_
seen	_	_
and	_	_
unseen	_	_
classes	_	_
.	_	_

#47
encompasses	_	_
all	_	_
different	_	_
modules	_	_
of	_	_
MIL	_	_
into	_	_
only	_	_
a	_	_
single	_	_
integrated	_	_
network	_	_
,	_	_
which	_	_
results	_	_
in	_	_
state-of-the-art	_	_
performances	_	_
for	_	_
conventional	_	_
and	_	_
zero-shot	_	_
image	_	_
tagging	_	_
.	_	_

#48
The	_	_
key	_	_
contributions	_	_
of	_	_
our	_	_
paper	_	_
are	_	_
:	_	_
–	_	_
We	_	_
propose	_	_
the	_	_
first	_	_
truly	_	_
end-to-end	_	_
deep	_	_
MIL	_	_
framework	_	_
for	_	_
multi-label	_	_
image	_	_
tagging	_	_
that	_	_
can	_	_
work	_	_
in	_	_
both	_	_
conventional	_	_
and	_	_
zero-shot	_	_
settings	_	_
.	_	_

#49
–	_	_
The	_	_
proposed	_	_
method	_	_
does	_	_
not	_	_
require	_	_
any	_	_
off-line	_	_
procedure	_	_
to	_	_
generate	_	_
bag	_	_
of	_	_
instances	_	_
for	_	_
MIL	_	_
,	_	_
rather	_	_
incorporates	_	_
this	_	_
step	_	_
in	_	_
a	_	_
joint	_	_
framework	_	_
.	_	_

#50
–	_	_
The	_	_
proposed	_	_
method	_	_
is	_	_
extendable	_	_
to	_	_
any	_	_
number	_	_
of	_	_
novel	_	_
tags	_	_
from	_	_
an	_	_
open	_	_
vocabulary	_	_
as	_	_
it	_	_
does	_	_
not	_	_
use	_	_
any	_	_
prior	_	_
information	_	_
about	_	_
the	_	_
unseen	_	_
concept	_	_
.	_	_

#51
–	_	_
The	_	_
proposed	_	_
method	_	_
can	_	_
annotate	_	_
a	_	_
bounding	_	_
box	_	_
for	_	_
both	_	_
seen	_	_
and	_	_
unseen	_	_
tags	_	_
without	_	_
even	_	_
using	_	_
any	_	_
ground-truth	_	_
bounding	_	_
box	_	_
during	_	_
training	_	_
.	_	_

#52
2	_	_
Related	_	_
Work	_	_

#53
Zero-shot	_	_
learning	_	_
:	_	_
In	_	_
recent	_	_
years	_	_
,	_	_
we	_	_
have	_	_
seen	_	_
some	_	_
exciting	_	_
papers	_	_
on	_	_
Zero	_	_
Shot	_	_
Learning	_	_
(	_	_
ZSL	_	_
)	_	_
.	_	_

#54
The	_	_
overall	_	_
goal	_	_
of	_	_
those	_	_
efforts	_	_
is	_	_
basically	_	_
to	_	_
classify	_	_
an	_	_

#55
4	_	_
Shafin	_	_
Rahman	_	_
and	_	_
Salman	_	_
Khan	_	_

#56
image	_	_
to	_	_
an	_	_
unseen	_	_
class	_	_
for	_	_
which	_	_
no	_	_
training	_	_
is	_	_
performed	_	_
.	_	_

#57
Investigations	_	_
are	_	_
focused	_	_
on	_	_
domain	_	_
adaptation	_	_
[	_	_
4	_	_
]	_	_
,	_	_
class	_	_
attribute	_	_
association	_	_
[	_	_
24	_	_
]	_	_
,	_	_
unsupervised	_	_
semantics	_	_
[	_	_
4	_	_
]	_	_
,	_	_
hubness	_	_
effect	_	_
[	_	_
3	_	_
]	_	_
and	_	_
generalized	_	_
setting	_	_
[	_	_
1	_	_
]	_	_
of	_	_
inductive	_	_
[	_	_
2	_	_
]	_	_
or	_	_
transductive	_	_
ZSL	_	_
learning	_	_
[	_	_
5	_	_
]	_	_
.	_	_

#58
The	_	_
major	_	_
shortcoming	_	_
of	_	_
these	_	_
approaches	_	_
is	_	_
their	_	_
inability	_	_
to	_	_
assign	_	_
multiple	_	_
labels	_	_
to	_	_
an	_	_
image	_	_
,	_	_
which	_	_
is	_	_
a	_	_
major	_	_
limitation	_	_
in	_	_
real-world	_	_
settings	_	_
.	_	_

#59
In	_	_
line	_	_
with	_	_
the	_	_
general	_	_
consideration	_	_
of	_	_
only	_	_
a	_	_
singe	_	_
label	_	_
per	_	_
image	_	_
,	_	_
traditional	_	_
ZSL	_	_
methods	_	_
use	_	_
recognition	_	_
datasets	_	_
which	_	_
mostly	_	_
contain	_	_
only	_	_
one	_	_
prominent	_	_
concept	_	_
per	_	_
image	_	_
.	_	_

#60
Here	_	_
,	_	_
we	_	_
present	_	_
an	_	_
end-to-end	_	_
deep	_	_
zero	_	_
shot	_	_
tagging	_	_
method	_	_
that	_	_
can	_	_
assign	_	_
multiple	_	_
tags	_	_
per	_	_
image	_	_
.	_	_

#61
End-to-end	_	_
object	_	_
detection	_	_
:	_	_
Image	_	_
tags	_	_
can	_	_
corresponds	_	_
to	_	_
either	_	_
whole	_	_
image	_	_
or	_	_
any	_	_
specific	_	_
location	_	_
inside	_	_
it	_	_
.	_	_

#62
To	_	_
model	_	_
the	_	_
relations	_	_
between	_	_
tag	_	_
and	_	_
its	_	_
corresponding	_	_
locations	_	_
we	_	_
intend	_	_
to	_	_
localize	_	_
objects	_	_
in	_	_
a	_	_
scene	_	_
.	_	_

#63
To	_	_
do	_	_
so	_	_
,	_	_
we	_	_
are	_	_
interested	_	_
in	_	_
end-to-end	_	_
object	_	_
detection	_	_
framework	_	_
.	_	_

#64
Popular	_	_
examples	_	_
of	_	_
such	_	_
frameworks	_	_
are	_	_
Faster	_	_
R-CNN	_	_
[	_	_
25	_	_
]	_	_
,	_	_
R-FCN	_	_
[	_	_
26	_	_
]	_	_
,	_	_
SSD	_	_
[	_	_
27	_	_
]	_	_
and	_	_
YOLO	_	_
[	_	_
28	_	_
]	_	_
.	_	_

#65
The	_	_
main	_	_
distinction	_	_
among	_	_
these	_	_
models	_	_
is	_	_
the	_	_
object	_	_
localization	_	_
process	_	_
.	_	_

#66
R-CNN	_	_
[	_	_
25	_	_
]	_	_
and	_	_
R-FCN	_	_
[	_	_
26	_	_
]	_	_
used	_	_
a	_	_
Region	_	_
Proposal	_	_
Network	_	_
(	_	_
RPN	_	_
)	_	_
to	_	_
generate	_	_
object	_	_
proposals	_	_
whereas	_	_
SSD	_	_
[	_	_
27	_	_
]	_	_
and	_	_
YOLO	_	_
[	_	_
28	_	_
]	_	_
propose	_	_
bounding	_	_
box	_	_
and	_	_
classify	_	_
it	_	_
in	_	_
a	_	_
single	_	_
step	_	_
.	_	_

#67
The	_	_
later	_	_
group	_	_
of	_	_
models	_	_
usually	_	_
runs	_	_
faster	_	_
but	_	_
relatively	_	_
less	_	_
accurate	_	_
than	_	_
the	_	_
first	_	_
group	_	_
.	_	_

#68
Due	_	_
to	_	_
the	_	_
focus	_	_
on	_	_
highly	_	_
accurate	_	_
object	_	_
detection	_	_
,	_	_
we	_	_
built	_	_
on	_	_
Faster	_	_
R-CNN	_	_
[	_	_
25	_	_
]	_	_
as	_	_
the	_	_
backbone	_	_
architecture	_	_
in	_	_
the	_	_
current	_	_
work	_	_
.	_	_

#69
Image	_	_
tagging	_	_
with	_	_
deep	_	_
MIL	_	_
:	_	_
Existing	_	_
image	_	_
tagging	_	_
approaches	_	_
based	_	_
on	_	_
MIL	_	_
mostly	_	_
use	_	_
hand	_	_
crafted	_	_
or	_	_
deep	_	_
CNN	_	_
features	_	_
[	_	_
21,14	_	_
]	_	_
.	_	_

#70
End-to-end	_	_
learnable	_	_
architectures	_	_
for	_	_
image	_	_
tagging	_	_
are	_	_
relatively	_	_
less	_	_
explored	_	_
in	_	_
the	_	_
literature	_	_
.	_	_

#71
Based	_	_
on	_	_
bag-of-instance	_	_
generation	_	_
,	_	_
these	_	_
architectures	_	_
are	_	_
of	_	_
two	_	_
kinds	_	_
.	_	_

#72
The	_	_
first	_	_
kind	_	_
generates	_	_
bags	_	_
using	_	_
an	_	_
offline	_	_
procedure	_	_
,	_	_
external	_	_
to	_	_
the	_	_
deep	_	_
architecture	_	_
.	_	_

#73
For	_	_
example	_	_
,	_	_
[	_	_
15,16	_	_
]	_	_
generate	_	_
object	_	_
proposal/patches	_	_
using	_	_
Selective	_	_
Search	_	_
[	_	_
18	_	_
]	_	_
/EdgeBoxes	_	_
[	_	_
19	_	_
]	_	_
/BING	_	_
[	_	_
20	_	_
]	_	_
and	_	_
feed	_	_
those	_	_
into	_	_
the	_	_
network	_	_
separately	_	_
.	_	_

#74
In	_	_
contrast	_	_
,	_	_
[	_	_
22,17	_	_
]	_	_
process	_	_
all	_	_
proposals	_	_
together	_	_
where	_	_
every	_	_
proposal	_	_
shares	_	_
same	_	_
CNN	_	_
layers	_	_
to	_	_
allow	_	_
object	_	_
classification	_	_
and	_	_
discovery	_	_
at	_	_
the	_	_
same	_	_
time	_	_
.	_	_

#75
The	_	_
second	_	_
kind	_	_
does	_	_
not	_	_
depend	_	_
on	_	_
an	_	_
external	_	_
instance	_	_
generator	_	_
,	_	_
rather	_	_
produces	_	_
the	_	_
bag	_	_
using	_	_
the	_	_
network	_	_
itself	_	_
based	_	_
on	_	_
activations	_	_
of	_	_
different	_	_
layers	_	_
[	_	_
12	_	_
]	_	_
or	_	_
from	_	_
different	_	_
frames	_	_
in	_	_
case	_	_
of	_	_
videos	_	_
[	_	_
13	_	_
]	_	_
.	_	_

#76
These	_	_
approaches	_	_
do	_	_
not	_	_
have	_	_
the	_	_
advantage	_	_
to	_	_
consider	_	_
localized	_	_
image	_	_
feature	_	_
.	_	_

#77
In	_	_
our	_	_
work	_	_
,	_	_
we	_	_
propose	_	_
a	_	_
model	_	_
that	_	_
combines	_	_
both	_	_
kind	_	_
of	_	_
approaches	_	_
to	_	_
leverage	_	_
their	_	_
individual	_	_
strengths	_	_
.	_	_

#78
Our	_	_
proposed	_	_
model	_	_
can	_	_
generate	_	_
the	_	_
bag	_	_
of	_	_
instancepatches/proposals	_	_
by	_	_
itself	_	_
without	_	_
the	_	_
need	_	_
of	_	_
external	_	_
bag	_	_
generator	_	_
and	_	_
can	_	_
process	_	_
all	_	_
the	_	_
patches	_	_
together	_	_
.	_	_

#79
Zero-shot	_	_
image	_	_
tagging	_	_
:	_	_
Instead	_	_
of	_	_
assigning	_	_
one	_	_
unseen	_	_
label	_	_
to	_	_
an	_	_
image	_	_
during	_	_
recognition	_	_
task	_	_
,	_	_
zero-shot	_	_
tagging	_	_
allows	_	_
to	_	_
tag	_	_
multiple	_	_
unseen	_	_
tags	_	_
to	_	_
an	_	_
image	_	_
and/or	_	_
ranking	_	_
the	_	_
array	_	_
of	_	_
unseen	_	_
tags	_	_
.	_	_

#80
Although	_	_
interesting	_	_
,	_	_
this	_	_
Deep	_	_
Multiple	_	_
Instance	_	_
Learning	_	_
for	_	_
ZST	_	_
5	_	_
problem	_	_
is	_	_
not	_	_
well-addressed	_	_
in	_	_
the	_	_
zero-shot	_	_
learning	_	_
literature	_	_
.	_	_

#81
An	_	_
early	_	_
attempt	_	_
of	_	_
such	_	_
kind	_	_
extended	_	_
a	_	_
work	_	_
for	_	_
zero-shot	_	_
recognition	_	_
[	_	_
29	_	_
]	_	_
to	_	_
perform	_	_
zero-shot	_	_
tagging	_	_
by	_	_
proposing	_	_
a	_	_
hierarchical	_	_
semantic	_	_
embedding	_	_
to	_	_
make	_	_
the	_	_
label	_	_
embedding	_	_
more	_	_
reliable	_	_
[	_	_
11	_	_
]	_	_
.	_	_

#82
[	_	_
9	_	_
]	_	_
proposed	_	_
a	_	_
transductive	_	_
multi-label	_	_
version	_	_
of	_	_
the	_	_
problem	_	_
where	_	_
a	_	_
predefined	_	_
and	_	_
relatively	_	_
small	_	_
set	_	_
of	_	_
unseen	_	_
tags	_	_
were	_	_
considered	_	_
.	_	_

#83
In	_	_
a	_	_
recent	_	_
work	_	_
,	_	_
[	_	_
10	_	_
]	_	_
proposed	_	_
a	_	_
fast	_	_
zero-shot	_	_
tagging	_	_
approach	_	_
that	_	_
can	_	_
be	_	_
trained	_	_
using	_	_
only	_	_
seen	_	_
tags	_	_
and	_	_
tested	_	_
using	_	_
both	_	_
seen	_	_
and	_	_
unseen	_	_
tags	_	_
for	_	_
test	_	_
images	_	_
.	_	_

#84
[	_	_
23	_	_
]	_	_
proposed	_	_
a	_	_
multi-instance	_	_
visual-semantic	_	_
embedding	_	_
approach	_	_
that	_	_
can	_	_
extract	_	_
localized	_	_
image	_	_
features	_	_
.	_	_

#85
The	_	_
main	_	_
drawback	_	_
of	_	_
these	_	_
early	_	_
efforts	_	_
is	_	_
the	_	_
dependence	_	_
on	_	_
pre-trained	_	_
CNN	_	_
features	_	_
(	_	_
in	_	_
[	_	_
9,10,11	_	_
]	_	_
)	_	_
or	_	_
fast-RCNN	_	_
[	_	_
22	_	_
]	_	_
features	_	_
(	_	_
in	_	_
[	_	_
23	_	_
]	_	_
)	_	_
and	_	_
therefore	_	_
not	_	_
end-to-end	_	_
trainable	_	_
.	_	_

#86
In	_	_
this	_	_
work	_	_
,	_	_
we	_	_
propose	_	_
a	_	_
fully	_	_
end-to-end	_	_
solution	_	_
for	_	_
both	_	_
conventional	_	_
and	_	_
zero-shot	_	_
tagging	_	_
.	_	_

#87
3	_	_
Our	_	_
Method	_	_

#88
3.1	_	_
Problem	_	_
Formulation	_	_

#89
Suppose	_	_
,	_	_
we	_	_
have	_	_
a	_	_
set	_	_
of	_	_
‘seen’	_	_
tags	_	_
denoted	_	_
by	_	_
S	_	_
=	_	_
{	_	_
1	_	_
,	_	_
.	_	_

#90
.	_	_

#91
.	_	_

#92
,	_	_
S	_	_
}	_	_
and	_	_
another	_	_
set	_	_
of	_	_
‘unseen’	_	_
tags	_	_
U	_	_
=	_	_
{	_	_
S	_	_
+	_	_
1	_	_
,	_	_
.	_	_

#93
.	_	_

#94
.	_	_

#95
,	_	_
S	_	_
+	_	_
U	_	_
}	_	_
,	_	_
such	_	_
that	_	_
S	_	_
∩	_	_
U	_	_
=	_	_
φ	_	_
where	_	_
,	_	_
S	_	_
and	_	_
U	_	_
represents	_	_
the	_	_
total	_	_
number	_	_
of	_	_
seen	_	_
and	_	_
unseen	_	_
tags	_	_
respectively	_	_
.	_	_

#96
We	_	_
also	_	_
denote	_	_
C	_	_
=	_	_
S	_	_
∪U	_	_
,	_	_
such	_	_
that	_	_
C	_	_
=	_	_
S+U	_	_
is	_	_
the	_	_
cardinality	_	_
of	_	_
the	_	_
tag-label	_	_
space	_	_
.	_	_

#97
For	_	_
each	_	_
of	_	_
the	_	_
tag	_	_
c	_	_
∈	_	_
C	_	_
,	_	_
we	_	_
can	_	_
obtain	_	_
a	_	_
‘d’	_	_
dimensional	_	_
word	_	_
vector	_	_
vc	_	_
(	_	_
word2vec	_	_
or	_	_
GloVe	_	_
)	_	_
as	_	_
semantic	_	_
embedding	_	_
.	_	_

#98
The	_	_
training	_	_
examples	_	_
can	_	_
be	_	_
defined	_	_
as	_	_
a	_	_
set	_	_
of	_	_
tuples	_	_
,	_	_
{	_	_
(	_	_
Xs	_	_
,	_	_
ys	_	_
)	_	_
:	_	_
s	_	_
∈	_	_
[	_	_
1	_	_
,	_	_
M	_	_
]	_	_
}	_	_
,	_	_
where	_	_
Xs	_	_
is	_	_
the	_	_
sth	_	_
input	_	_
image	_	_
and	_	_
ys	_	_
⊂	_	_
S	_	_
is	_	_
the	_	_
set	_	_
of	_	_
relevant	_	_
seen	_	_
tags	_	_
.	_	_

#99
We	_	_
represent	_	_
uth	_	_
testing	_	_
image	_	_
as	_	_
Xu	_	_
which	_	_
correspondences	_	_
to	_	_
a	_	_
set	_	_
of	_	_
relevant	_	_
seen	_	_
and/or	_	_
unseen	_	_
tag	_	_
yu	_	_
⊂	_	_
C.	_	_
Note	_	_
that	_	_
,	_	_
Xu	_	_
,	_	_
yu	_	_
,	_	_
U	_	_
and	_	_
its	_	_
corresponding	_	_
word	_	_
vectors	_	_
are	_	_
not	_	_
observed	_	_
during	_	_
training	_	_
.	_	_

#100
Now	_	_
,	_	_
we	_	_
define	_	_
the	_	_
following	_	_
problems	_	_
:	_	_
•	_	_
Conventional	_	_
tagging	_	_
:	_	_
Given	_	_
Xu	_	_
as	_	_
input	_	_
,	_	_
assign	_	_
relevant	_	_
seen	_	_
tags	_	_
y	_	_
=	_	_
{	_	_
yu	_	_
∩	_	_
S	_	_
}	_	_
.	_	_

#101
•	_	_
Zero-shot	_	_
tagging	_	_
(	_	_
ZST	_	_
)	_	_
:	_	_
Given	_	_
Xu	_	_
as	_	_
input	_	_
,	_	_
assign	_	_
relevant	_	_
unseen	_	_
tags	_	_
y	_	_
=	_	_
{	_	_
yu	_	_
∩	_	_
U	_	_
}	_	_
.	_	_

#102
•	_	_
Generalized	_	_
zero-shot	_	_
tagging	_	_
(	_	_
GZST	_	_
)	_	_
:	_	_
Given	_	_
Xu	_	_
as	_	_
input	_	_
,	_	_
assign	_	_
relevant	_	_
tags	_	_
from	_	_
both	_	_
seen	_	_
and	_	_
unseen	_	_
yu	_	_
⊂	_	_
C.	_	_
MIL	_	_
formulation	_	_
:	_	_
We	_	_
formulate	_	_
the	_	_
above	_	_
mentioned	_	_
problems	_	_
in	_	_
Multiple	_	_
Instance	_	_
Learning	_	_
(	_	_
MIL	_	_
)	_	_
framework	_	_
.	_	_

#103
Let	_	_
us	_	_
represent	_	_
the	_	_
sth	_	_
training	_	_
image	_	_
with	_	_
a	_	_
bag	_	_
of	_	_
n	_	_
+	_	_
1	_	_
instances	_	_
Xs	_	_
=	_	_
{	_	_
xs0	_	_
.	_	_

#104
.	_	_

#105
.xsn	_	_
}	_	_
,	_	_
where	_	_
ith	_	_
instance	_	_
xsi	_	_
represents	_	_
either	_	_
an	_	_
image	_	_
patch	_	_
(	_	_
for	_	_
i	_	_
>	_	_
0	_	_
)	_	_
or	_	_
the	_	_
complete	_	_
image	_	_
itself	_	_
(	_	_
for	_	_
i	_	_
=	_	_
0	_	_
)	_	_
.	_	_

#106
As	_	_
ys	_	_
represents	_	_
relevant	_	_
seen	_	_
tags	_	_
of	_	_
Xs	_	_
,	_	_
according	_	_
to	_	_
MIL	_	_
assumption	_	_
,	_	_
the	_	_
bag	_	_
has	_	_
at	_	_
least	_	_
one	_	_
instance	_	_
for	_	_
each	_	_
tag	_	_
in	_	_
the	_	_
set	_	_
ys	_	_
and	_	_
no	_	_
instance	_	_
for	_	_
S	_	_
\ys	_	_
tags	_	_
.	_	_

#107
Thus	_	_
,	_	_
instances	_	_
in	_	_
Xs	_	_
can	_	_
work	_	_
as	_	_
a	_	_
positive	_	_
example	_	_
for	_	_
y	_	_
∈	_	_
ys	_	_
and	_	_
negative	_	_
example	_	_
for	_	_
y′	_	_
∈	_	_
{	_	_
S	_	_
\	_	_
ys	_	_
}	_	_
.	_	_

#108
This	_	_
formulation	_	_
does	_	_
not	_	_
use	_	_
instance	_	_
level	_	_
tag	_	_
annotation	_	_
which	_	_
makes	_	_
it	_	_
a	_	_
weakly	_	_
supervised	_	_
problem	_	_
.	_	_

#109
Our	_	_
aim	_	_
is	_	_
to	_	_
design	_	_
and	_	_
learn	_	_
an	_	_
end-to-end	_	_
deep	_	_
learning	_	_
model	_	_
that	_	_
can	_	_
itself	_	_
generate	_	_
the	_	_
appropriate	_	_
bag	_	_
of	_	_
instances	_	_
and	_	_
simultaneously	_	_
assign	_	_
relevant	_	_
tags	_	_
to	_	_
the	_	_
bag	_	_
.	_	_

#110
6	_	_
Shafin	_	_
Rahman	_	_
and	_	_
Salman	_	_
Khan	_	_

#111
Fig.	_	_
2	_	_
.	_	_

#112
Proposed	_	_
network	_	_
architecture	_	_
for	_	_
MIL	_	_
based	_	_
zero-shot	_	_
image	_	_
tagging	_	_
.	_	_

#113
3.2	_	_
Network	_	_
Architecture	_	_

#114
The	_	_
proposed	_	_
network	_	_
architecture	_	_
is	_	_
illustrated	_	_
in	_	_
Fig.	_	_
2	_	_
.	_	_

#115
It	_	_
is	_	_
composed	_	_
of	_	_
two	_	_
parts	_	_
:	_	_
bag	_	_
generation	_	_
(	_	_
left	_	_
)	_	_
and	_	_
multiple	_	_
instance	_	_
learning	_	_
(	_	_
MIL	_	_
)	_	_
network	_	_
(	_	_
right	_	_
)	_	_
.	_	_

#116
The	_	_
bag	_	_
generation	_	_
network	_	_
generates	_	_
the	_	_
bag	_	_
of	_	_
instances	_	_
as	_	_
well	_	_
as	_	_
their	_	_
visual	_	_
features	_	_
,	_	_
and	_	_
the	_	_
MIL	_	_
network	_	_
processes	_	_
the	_	_
resulting	_	_
bag	_	_
of	_	_
instance	_	_
features	_	_
to	_	_
find	_	_
the	_	_
final	_	_
multi-label	_	_
prediction	_	_
which	_	_
is	_	_
calculated	_	_
by	_	_
a	_	_
global	_	_
pooling	_	_
of	_	_
the	_	_
prediction	_	_
scores	_	_
of	_	_
individual	_	_
instances	_	_
.	_	_

#117
In	_	_
this	_	_
manner	_	_
,	_	_
bag	_	_
generation	_	_
and	_	_
zero-shot	_	_
prediction	_	_
steps	_	_
are	_	_
combined	_	_
in	_	_
a	_	_
unified	_	_
framework	_	_
that	_	_
effectively	_	_
transfers	_	_
learning	_	_
from	_	_
seen	_	_
to	_	_
unseen	_	_
tags	_	_
.	_	_

#118
Bag	_	_
generation	_	_
:	_	_
In	_	_
our	_	_
proposed	_	_
method	_	_
,	_	_
the	_	_
bag	_	_
contains	_	_
image	_	_
patches	_	_
which	_	_
are	_	_
assumed	_	_
to	_	_
cover	_	_
all	_	_
objects	_	_
and	_	_
concepts	_	_
presented	_	_
inside	_	_
the	_	_
image	_	_
.	_	_

#119
Many	_	_
closely	_	_
related	_	_
traditional	_	_
methods	_	_
[	_	_
15,16,17,23	_	_
]	_	_
apply	_	_
some	_	_
external	_	_
procedure	_	_
like	_	_
Selective	_	_
Search	_	_
[	_	_
18	_	_
]	_	_
,	_	_
EdgeBoxes	_	_
[	_	_
19	_	_
]	_	_
,	_	_
BING	_	_
[	_	_
20	_	_
]	_	_
etc	_	_
.	_	_

#120
for	_	_
this	_	_
purpose	_	_
.	_	_

#121
Such	_	_
a	_	_
strategy	_	_
creates	_	_
three	_	_
problems	_	_
:	_	_
(	_	_
1	_	_
)	_	_
the	_	_
off-line	_	_
external	_	_
process	_	_
does	_	_
not	_	_
allow	_	_
an	_	_
end-to-end	_	_
learnable	_	_
framework	_	_
,	_	_
(	_	_
2	_	_
)	_	_
patch	_	_
generation	_	_
process	_	_
is	_	_
prone	_	_
to	_	_
more	_	_
frequent	_	_
errors	_	_
because	_	_
it	_	_
can	_	_
not	_	_
get	_	_
fine-tuned	_	_
on	_	_
the	_	_
target	_	_
dataset	_	_
,	_	_
and	_	_
(	_	_
3	_	_
)	_	_
the	_	_
MIL	_	_
framework	_	_
need	_	_
to	_	_
process	_	_
patches	_	_
rather	_	_
than	_	_
the	_	_
image	_	_
itself	_	_
.	_	_

#122
In	_	_
this	_	_
paper	_	_
,	_	_
we	_	_
propose	_	_
to	_	_
solve	_	_
these	_	_
problems	_	_
by	_	_
generating	_	_
useful	_	_
bag	_	_
of	_	_
patches	_	_
by	_	_
the	_	_
network	_	_
itself	_	_
.	_	_

#123
The	_	_
recent	_	_
achievements	_	_
of	_	_
object	_	_
detection	_	_
framework	_	_
,	_	_
such	_	_
as	_	_
the	_	_
Faster-RCNN	_	_
[	_	_
25	_	_
]	_	_
,	_	_
allows	_	_
us	_	_
to	_	_
generate	_	_
object	_	_
proposals	_	_
and	_	_
later	_	_
perform	_	_
detection	_	_
within	_	_
a	_	_
single	_	_
network	_	_
.	_	_

#124
We	_	_
adopt	_	_
this	_	_
strategy	_	_
to	_	_
generate	_	_
bag	_	_
of	_	_
image	_	_
patches	_	_
for	_	_
MIL	_	_
.	_	_

#125
Remarkably	_	_
,	_	_
the	_	_
original	_	_
Faster-RCNN	_	_
model	_	_
is	_	_
designed	_	_
for	_	_
supervised	_	_
learning	_	_
,	_	_
while	_	_
our	_	_
MIL	_	_
framework	_	_
extends	_	_
it	_	_
to	_	_
weakly	_	_
supervised	_	_
setting	_	_
.	_	_

#126
A	_	_
Faster-RCNN	_	_
model	_	_
[	_	_
25	_	_
]	_	_
with	_	_
Region	_	_
Proposal	_	_
Network	_	_
(	_	_
RPN	_	_
)	_	_
is	_	_
learned	_	_
using	_	_
the	_	_
ILSVRC-2017	_	_
detection	_	_
dataset	_	_
.	_	_

#127
This	_	_
architecture	_	_
uses	_	_
a	_	_
base	_	_
network	_	_
ResNet-50	_	_
[	_	_
30	_	_
]	_	_
which	_	_
is	_	_
shared	_	_
between	_	_
RPN	_	_
and	_	_
classification/localization	_	_
network	_	_
.	_	_

#128
As	_	_
practiced	_	_
,	_	_
the	_	_
base	_	_
network	_	_
is	_	_
initialized	_	_
with	_	_
the	_	_
pre-trained	_	_
weights	_	_
.	_	_

#129
Deep	_	_
Multiple	_	_
Instance	_	_
Learning	_	_
for	_	_
ZST	_	_
7	_	_
Though	_	_
not	_	_
investigated	_	_
in	_	_
this	_	_
paper	_	_
,	_	_
other	_	_
popular	_	_
CNN	_	_
models	_	_
e.g.	_	_
,	_	_
VGG	_	_
[	_	_
31	_	_
]	_	_
and	_	_
GoogLeNet	_	_
[	_	_
32	_	_
]	_	_
can	_	_
also	_	_
be	_	_
used	_	_
as	_	_
the	_	_
shared	_	_
base	_	_
network	_	_
.	_	_

#130
Now	_	_
,	_	_
given	_	_
a	_	_
training	_	_
image	_	_
Xs	_	_
,	_	_
the	_	_
RPN	_	_
can	_	_
produce	_	_
a	_	_
fixed	_	_
number	_	_
(	_	_
n	_	_
)	_	_
of	_	_
region	_	_
of	_	_
interest	_	_
(	_	_
ROI	_	_
)	_	_
proposals	_	_
{	_	_
xs1	_	_
.	_	_

#131
.	_	_

#132
.xsn	_	_
}	_	_
with	_	_
a	_	_
high	_	_
recall	_	_
rate	_	_
.	_	_

#133
For	_	_
image	_	_
tagging	_	_
,	_	_
all	_	_
tags	_	_
may	_	_
not	_	_
represent	_	_
an	_	_
object	_	_
.	_	_

#134
Rather	_	_
,	_	_
tags	_	_
can	_	_
be	_	_
concepts	_	_
that	_	_
describe	_	_
the	_	_
whole	_	_
image	_	_
e.g.	_	_
,	_	_
nature	_	_
and	_	_
landscape	_	_
.	_	_

#135
To	_	_
address	_	_
this	_	_
issue	_	_
,	_	_
we	_	_
add	_	_
a	_	_
global	_	_
image	_	_
ROI	_	_
(	_	_
denoted	_	_
by	_	_
xs0	_	_
)	_	_
comprising	_	_
of	_	_
complete	_	_
image	_	_
to	_	_
the	_	_
ROI	_	_
proposal	_	_
set	_	_
generated	_	_
by	_	_
the	_	_
RPN	_	_
.	_	_

#136
Afterwards	_	_
,	_	_
ROIs	_	_
are	_	_
fed	_	_
to	_	_
ROI-Pooling	_	_
and	_	_
subsequent	_	_
densely	_	_
connected	_	_
layers	_	_
to	_	_
calculate	_	_
a	_	_
D-dimensional	_	_
feature	_	_
Fs	_	_
=	_	_
[	_	_
fs0	_	_
.	_	_

#137
.	_	_

#138
.	_	_

#139
fsn	_	_
]	_	_
∈	_	_
RD×	_	_
(	_	_
n+1	_	_
)	_	_
for	_	_
each	_	_
ROI	_	_
where	_	_
fs0	_	_
is	_	_
the	_	_
feature	_	_
representation	_	_
of	_	_
the	_	_
whole	_	_
image	_	_
.	_	_

#140
This	_	_
bag	_	_
is	_	_
forwarded	_	_
to	_	_
MIL	_	_
network	_	_
for	_	_
prediction	_	_
.	_	_

#141
Training	_	_
:	_	_
We	_	_
first	_	_
initialize	_	_
a	_	_
Faster-RCNN	_	_
model	_	_
with	_	_
the	_	_
pre-trained	_	_
weights	_	_
for	_	_
ILSVRC-2017	_	_
object	_	_
detection	_	_
dataset	_	_
.	_	_

#142
After	_	_
that	_	_
,	_	_
the	_	_
last	_	_
two	_	_
layers	_	_
(	_	_
i.e.	_	_
the	_	_
classification	_	_
and	_	_
localization	_	_
head	_	_
)	_	_
are	_	_
popped	_	_
out	_	_
to	_	_
produce	_	_
bag	_	_
generation	_	_
network	_	_
.	_	_

#143
Our	_	_
network	_	_
design	_	_
then	_	_
comprises	_	_
of	_	_
three	_	_
fully	_	_
connected	_	_
(	_	_
FC	_	_
)	_	_
layers	_	_
and	_	_
a	_	_
global	_	_
pooling	_	_
layer	_	_
(	_	_
either	_	_
max	_	_
or	_	_
mean	_	_
pooling	_	_
)	_	_
with	_	_
the	_	_
resulting	_	_
network	_	_
to	_	_
predict	_	_
scores	_	_
for	_	_
S	_	_
number	_	_
of	_	_
seen	_	_
tags	_	_
.	_	_

#144
The	_	_
network	_	_
is	_	_
then	_	_
fine-tuned	_	_
on	_	_
target	_	_
tagging	_	_
dataset	_	_
i.e.	_	_
NUS-WIDE	_	_
[	_	_
33	_	_
]	_	_
.	_	_

#145
Note	_	_
that	_	_
,	_	_
at	_	_
this	_	_
stage	_	_
,	_	_
the	_	_
resulting	_	_
network	_	_
can	_	_
not	_	_
train	_	_
the	_	_
RPN	_	_
further	_	_
because	_	_
no	_	_
localization	_	_
branch	_	_
is	_	_
left	_	_
in	_	_
the	_	_
network	_	_
.	_	_

#146
However	_	_
,	_	_
the	_	_
shared	_	_
base	_	_
network	_	_
(	_	_
ResNet-50	_	_
)	_	_
gets	_	_
fine-tuned	_	_
for	_	_
better	_	_
proposal	_	_
generation	_	_
.	_	_

#147
Similarly	_	_
,	_	_
the	_	_
weights	_	_
connecting	_	_
the	_	_
newly	_	_
added	_	_
layers	_	_
remains	_	_
trainable	_	_
along	_	_
with	_	_
the	_	_
other	_	_
parts	_	_
of	_	_
the	_	_
network	_	_
.	_	_

#148
The	_	_
only	_	_
exception	_	_
is	_	_
the	_	_
last	_	_
FC	_	_
layer	_	_
,	_	_
where	_	_
we	_	_
use	_	_
a	_	_
fixed	_	_
semantic	_	_
embedding	_	_
W	_	_
=	_	_
[	_	_
v1	_	_
.	_	_

#149
.	_	_

#150
.vS	_	_
]	_	_
∈	_	_
Rd×S	_	_
containing	_	_
word	_	_
vector	_	_
of	_	_
seen	_	_
tags	_	_
as	_	_
non-trainable	_	_
weights	_	_
for	_	_
that	_	_
layer	_	_
.	_	_

#151
Notably	_	_
,	_	_
a	_	_
non-linear	_	_
activation	_	_
ReLU	_	_
is	_	_
applied	_	_
between	_	_
the	_	_
first	_	_
two	_	_
FC	_	_
layer	_	_
but	_	_
not	_	_
considered	_	_
between	_	_
second	_	_
and	_	_
third	_	_
layers	_	_
.	_	_

#152
The	_	_
role	_	_
of	_	_
the	_	_
first	_	_
two	_	_
layers	_	_
is	_	_
to	_	_
process	_	_
bag	_	_
of	_	_
features	_	_
by	_	_
calculating	_	_
F	_	_
′s	_	_
=	_	_
[	_	_
f	_	_
′s0	_	_
.	_	_

#153
.	_	_

#154
.	_	_

#155
f	_	_
′	_	_
sn	_	_
]	_	_
∈	_	_
Rd×	_	_
(	_	_
n+1	_	_
)	_	_
for	_	_
the	_	_
projection	_	_
onto	_	_
the	_	_
fixed	_	_
embedding	_	_
.	_	_

#156
The	_	_
third	_	_
FC	_	_
layer	_	_
projects	_	_
F	_	_
′s	_	_
in	_	_
the	_	_
semantic	_	_
tag	_	_
space	_	_
and	_	_
produce	_	_
scores	_	_
for	_	_
individual	_	_
instances	_	_
.	_	_

#157
Given	_	_
,	_	_
a	_	_
bag	_	_
of	_	_
instance	_	_
feature	_	_
F	_	_
′s	_	_
,	_	_
we	_	_
compute	_	_
the	_	_
prediction	_	_
scores	_	_
of	_	_
individual	_	_
instances	_	_
,	_	_
Ps	_	_
=	_	_
[	_	_
ps0	_	_
.	_	_

#158
.	_	_

#159
.psn	_	_
]	_	_
∈	_	_
RS×	_	_
(	_	_
n+1	_	_
)	_	_
as	_	_
follows	_	_
:	_	_
Ps	_	_
=	_	_
WTF	_	_
′	_	_
.	_	_

#160
(	_	_
1	_	_
)	_	_
Often	_	_
bag	_	_
generation	_	_
network	_	_
produces	_	_
noisy	_	_
ROIs	_	_
which	_	_
usually	_	_
results	_	_
in	_	_
unreliable	_	_
scores	_	_
in	_	_
Ps	_	_
.	_	_

#161
To	_	_
suppress	_	_
this	_	_
noise	_	_
,	_	_
we	_	_
add	_	_
the	_	_
global	_	_
pooling	_	_
(	_	_
max	_	_
or	_	_
mean	_	_
)	_	_
layer	_	_
which	_	_
performs	_	_
the	_	_
following	_	_
operation	_	_
to	_	_
calculate	_	_
final	_	_
multi-label	_	_
prediction	_	_
score	_	_
for	_	_
a	_	_
bag	_	_
:	_	_
os	_	_
=	_	_
max	_	_
(	_	_
ps0	_	_
,	_	_
ps1	_	_
,	_	_
.	_	_

#162
.	_	_

#163
.	_	_

#164
,	_	_
psn	_	_
)	_	_
or	_	_
os	_	_
=	_	_
n+	_	_
1	_	_
n∑	_	_
j=0	_	_
psj	_	_
.	_	_

#165
(	_	_
2	_	_
)	_	_
Loss	_	_
formulation	_	_
:	_	_
Suppose	_	_
,	_	_
for	_	_
sth	_	_
training	_	_
image	_	_
,	_	_
os	_	_
=	_	_
[	_	_
o1	_	_
.	_	_

#166
.	_	_

#167
.	_	_

#168
oS	_	_
]	_	_
contains	_	_
final	_	_
multi-label	_	_
prediction	_	_
of	_	_
a	_	_
bag	_	_
for	_	_
seen	_	_
classes	_	_
.	_	_

#169
This	_	_
bag	_	_
is	_	_
a	_	_
positive	_	_
exam8	_	_
Shafin	_	_
Rahman	_	_
and	_	_
Salman	_	_
Khan	_	_
ple	_	_
for	_	_
each	_	_
tag	_	_
y	_	_
∈	_	_
ys	_	_
and	_	_
negative	_	_
examples	_	_
for	_	_
each	_	_
tag	_	_
y′	_	_
∈	_	_
{	_	_
S	_	_
\	_	_
ys	_	_
}	_	_
.	_	_

#170
Thus	_	_
,	_	_
for	_	_
each	_	_
pair	_	_
of	_	_
y	_	_
and	_	_
y′	_	_
,	_	_
the	_	_
difference	_	_
oy′	_	_
−	_	_
oy	_	_
represents	_	_
the	_	_
disparity	_	_
between	_	_
predictions	_	_
for	_	_
positive	_	_
and	_	_
negative	_	_
tags	_	_
.	_	_

#171
Our	_	_
goal	_	_
is	_	_
to	_	_
minimize	_	_
these	_	_
differences	_	_
in	_	_
each	_	_
iteration	_	_
.	_	_

#172
We	_	_
formalize	_	_
the	_	_
loss	_	_
of	_	_
a	_	_
bag	_	_
considering	_	_
it	_	_
to	_	_
contain	_	_
both	_	_
positive	_	_
and	_	_
negative	_	_
examples	_	_
for	_	_
different	_	_
tags	_	_
:	_	_
Ltag	_	_
(	_	_
os	_	_
,	_	_
ys	_	_
)	_	_
=	_	_
|ys||S	_	_
\	_	_
ys|	_	_
∑	_	_
y′∈	_	_
{	_	_
S\ys	_	_
}	_	_
∑	_	_
y∈ys	_	_
log	_	_
(	_	_
1	_	_
+	_	_
exp	_	_
(	_	_
oy′	_	_
−	_	_
oy	_	_
)	_	_
)	_	_
.	_	_

#173
We	_	_
minimize	_	_
the	_	_
overall	_	_
loss	_	_
on	_	_
all	_	_
training	_	_
images	_	_
as	_	_
follows	_	_
:	_	_
L	_	_
=	_	_
arg	_	_
min	_	_
Θ	_	_
M	_	_
M∑	_	_
s=1	_	_
(	_	_
Ltag	_	_
(	_	_
os	_	_
,	_	_
ys	_	_
)	_	_
)	_	_
.	_	_

#174
Here	_	_
,	_	_
Θ	_	_
denote	_	_
the	_	_
parameter	_	_
set	_	_
of	_	_
the	_	_
proposed	_	_
network	_	_
and	_	_
M	_	_
is	_	_
the	_	_
total	_	_
number	_	_
of	_	_
training	_	_
images	_	_
.	_	_

#175
Prediction	_	_
:	_	_
During	_	_
testing	_	_
,	_	_
we	_	_
modify	_	_
the	_	_
fixed	_	_
embedding	_	_
W	_	_
with	_	_
both	_	_
seen	_	_
and	_	_
unseen	_	_
word	_	_
vectors	_	_
instead	_	_
of	_	_
only	_	_
seen	_	_
word	_	_
vectors	_	_
.	_	_

#176
Suppose	_	_
,	_	_
after	_	_
modification	_	_
W	_	_
becomes	_	_
W′	_	_
=	_	_
[	_	_
v1	_	_
.	_	_

#177
.	_	_

#178
.vS	_	_
,	_	_
vS+1	_	_
.	_	_

#179
.	_	_

#180
.vS+U	_	_
]	_	_
∈	_	_
Rd×C	_	_
.	_	_

#181
With	_	_
the	_	_
use	_	_
of	_	_
W′	_	_
in	_	_
Eq.	_	_
1	_	_
,	_	_
we	_	_
get	_	_
prediction	_	_
score	_	_
of	_	_
both	_	_
seen	_	_
and	_	_
unseen	_	_
tags	_	_
for	_	_
each	_	_
individual	_	_
instance	_	_
in	_	_
the	_	_
bag	_	_
.	_	_

#182
Then	_	_
,	_	_
after	_	_
the	_	_
global	_	_
pooling	_	_
(	_	_
mean	_	_
or	_	_
max	_	_
)	_	_
,	_	_
we	_	_
get	_	_
the	_	_
final	_	_
prediction	_	_
score	_	_
for	_	_
each	_	_
seen	_	_
and	_	_
unseen	_	_
tags	_	_
.	_	_

#183
Finally	_	_
,	_	_
based	_	_
on	_	_
the	_	_
tagging	_	_
task	_	_
(	_	_
conventional/zero-shot/generalized	_	_
zero-shot	_	_
)	_	_
,	_	_
we	_	_
assign	_	_
top	_	_
K	_	_
target	_	_
tags	_	_
(	_	_
from	_	_
the	_	_
set	_	_
S	_	_
,	_	_
U	_	_
or	_	_
C	_	_
)	_	_
with	_	_
higher	_	_
scores	_	_
.	_	_

#184
4	_	_
Experiment	_	_

#185
4.1	_	_
Setup	_	_

#186
Dataset	_	_
:	_	_
We	_	_
perform	_	_
our	_	_
experiments	_	_
using	_	_
a	_	_
real-world	_	_
web	_	_
image	_	_
dataset	_	_
namely	_	_
NUS-WIDE	_	_
[	_	_
33	_	_
]	_	_
.	_	_

#187
It	_	_
contains	_	_
269,648	_	_
images	_	_
with	_	_
three	_	_
sets	_	_
of	_	_
per	_	_
image	_	_
tags	_	_
from	_	_
Flickr	_	_
.	_	_

#188
The	_	_
first	_	_
,	_	_
second	_	_
and	_	_
third	_	_
set	_	_
contain	_	_
81	_	_
,	_	_
1000	_	_
and	_	_
5018	_	_
tags	_	_
respectively	_	_
.	_	_

#189
The	_	_
tags	_	_
inside	_	_
the	_	_
first	_	_
set	_	_
are	_	_
carefully	_	_
chosen	_	_
,	_	_
therefore	_	_
less	_	_
noisy	_	_
whereas	_	_
third	_	_
set	_	_
has	_	_
the	_	_
highest	_	_
noise	_	_
in	_	_
annotations	_	_
.	_	_

#190
Following	_	_
the	_	_
previous	_	_
work	_	_
[	_	_
10	_	_
]	_	_
,	_	_
we	_	_
use	_	_
81	_	_
first	_	_
set	_	_
tags	_	_
as	_	_
unseen	_	_
in	_	_
this	_	_
paper	_	_
.	_	_

#191
We	_	_
notice	_	_
that	_	_
the	_	_
tag	_	_
‘interesting’	_	_
comes	_	_
twice	_	_
within	_	_
the	_	_
second	_	_
set	_	_
.	_	_

#192
After	_	_
removing	_	_
this	_	_
inconsistency	_	_
and	_	_
selecting	_	_
81	_	_
unseen	_	_
tags	_	_
from	_	_
the	_	_
second	_	_
set	_	_
results	_	_
in	_	_
924	_	_
tags	_	_
which	_	_
we	_	_
use	_	_
as	_	_
seen	_	_
for	_	_
our	_	_
experiment	_	_
.	_	_

#193
The	_	_
dataset	_	_
provides	_	_
the	_	_
split	_	_
of	_	_
161,789	_	_
training	_	_
and	_	_
107,859	_	_
testing	_	_
images	_	_
.	_	_

#194
We	_	_
use	_	_
this	_	_
recommended	_	_
setting	_	_
ignoring	_	_
the	_	_
nontagged	_	_
images	_	_
.	_	_

#195
Visual	_	_
and	_	_
semantic	_	_
embedding	_	_
:	_	_
Unlike	_	_
previous	_	_
attempts	_	_
in	_	_
zero-shot	_	_
tagging	_	_
[	_	_
11,10	_	_
]	_	_
,	_	_
our	_	_
model	_	_
works	_	_
in	_	_
an	_	_
end-to-end	_	_
manner	_	_
using	_	_
ResNet-50	_	_
[	_	_
30	_	_
]	_	_
as	_	_
a	_	_
base	_	_
network	_	_
.	_	_

#196
It	_	_
means	_	_
the	_	_
visual	_	_
feature	_	_
are	_	_
originating	_	_
from	_	_
ResNet-50	_	_
,	_	_
Deep	_	_
Multiple	_	_
Instance	_	_
Learning	_	_
for	_	_
ZST	_	_
9	_	_
but	_	_
they	_	_
are	_	_
updated	_	_
during	_	_
iterations	_	_
.	_	_

#197
As	_	_
the	_	_
semantic	_	_
embedding	_	_
,	_	_
we	_	_
use	_	_
`2	_	_
normalized	_	_
300	_	_
dimensional	_	_
GloVe	_	_
vectors	_	_
[	_	_
34	_	_
]	_	_
.	_	_

#198
We	_	_
are	_	_
unable	_	_
to	_	_
use	_	_
word2vec	_	_
vectors	_	_
[	_	_
35	_	_
]	_	_
because	_	_
the	_	_
pre-trained	_	_
word-vector	_	_
model	_	_
can	_	_
not	_	_
provide	_	_
vectors	_	_
for	_	_
all	_	_
of	_	_
1005	_	_
(	_	_
924	_	_
seen	_	_
+	_	_
81	_	_
unseen	_	_
)	_	_
tags	_	_
.	_	_

#199
Evaluation	_	_
metric	_	_
:	_	_
Following	_	_
the	_	_
work	_	_
[	_	_
10	_	_
]	_	_
,	_	_
we	_	_
calculate	_	_
precision	_	_
(	_	_
P	_	_
)	_	_
,	_	_
recall	_	_
(	_	_
R	_	_
)	_	_
and	_	_
F-1	_	_
score	_	_
(	_	_
F1	_	_
)	_	_
of	_	_
the	_	_
top	_	_
K	_	_
predicted	_	_
tags	_	_
(	_	_
K	_	_
=	_	_
3	_	_
and	_	_
5	_	_
is	_	_
used	_	_
)	_	_
and	_	_
Mean	_	_
image	_	_
Average	_	_
Precision	_	_
(	_	_
MiAP	_	_
)	_	_
as	_	_
evaluation	_	_
metric	_	_
.	_	_

#200
We	_	_
use	_	_
the	_	_
following	_	_
equation	_	_
to	_	_
calculate	_	_
MiAP	_	_
of	_	_
an	_	_
input	_	_
image	_	_
I	_	_
:	_	_
MiAP	_	_
(	_	_
I	_	_
)	_	_
=	_	_
|G|	_	_
|G|∑	_	_
j=1	_	_
rj	_	_
j	_	_
δ	_	_
(	_	_
I	_	_
,	_	_
tj	_	_
)	_	_
,	_	_
where	_	_
,	_	_
|G|	_	_
=	_	_
total	_	_
number	_	_
of	_	_
ground	_	_
truth	_	_
tags	_	_
,	_	_
rj	_	_
=	_	_
number	_	_
of	_	_
relevant	_	_
tags	_	_
of	_	_
jth	_	_
rank	_	_
and	_	_
δ	_	_
(	_	_
I	_	_
,	_	_
tj	_	_
)	_	_
=	_	_
1	_	_
if	_	_
jth	_	_
tag	_	_
tj	_	_
is	_	_
associated	_	_
with	_	_
the	_	_
input	_	_
image	_	_
I	_	_
,	_	_
otherwise	_	_
δ	_	_
(	_	_
I	_	_
,	_	_
tj	_	_
)	_	_
=	_	_
0	_	_
.	_	_

#201
Implementation	_	_
details	_	_
:	_	_
We	_	_
used	_	_
the	_	_
following	_	_
settings	_	_
during	_	_
Faster-RCNN	_	_
training	_	_
,	_	_
following	_	_
the	_	_
proposed	_	_
settings	_	_
of	_	_
[	_	_
25	_	_
]	_	_
:	_	_
rescaling	_	_
shorter	_	_
size	_	_
of	_	_
image	_	_
as	_	_
600	_	_
pixels	_	_
,	_	_
RPN	_	_
stride	_	_
=	_	_
16	_	_
,	_	_
three	_	_
anchor	_	_
box	_	_
scale	_	_
128	_	_
,	_	_
256	_	_
and	_	_
512	_	_
pixels	_	_
,	_	_
three	_	_
aspect	_	_
ratios	_	_
1:1	_	_
,	_	_
1:2	_	_
and	_	_
2:1	_	_
,	_	_
non-maximum	_	_
suppression	_	_
(	_	_
NMS	_	_
)	_	_
with	_	_
IoU	_	_
threshold	_	_
=	_	_
0.7	_	_
with	_	_
maximum	_	_
proposal	_	_
=	_	_
300	_	_
for	_	_
faster-RCNN	_	_
.	_	_

#202
During	_	_
training	_	_
our	_	_
MIL	_	_
framework	_	_
,	_	_
we	_	_
generated	_	_
one	_	_
bag	_	_
of	_	_
instances	_	_
at	_	_
each	_	_
iteration	_	_
from	_	_
an	_	_
image	_	_
to	_	_
feed	_	_
our	_	_
network	_	_
.	_	_

#203
We	_	_
chose	_	_
a	_	_
fixed	_	_
n	_	_
number	_	_
of	_	_
RoIs	_	_
proposed	_	_
by	_	_
RPN	_	_
which	_	_
archives	_	_
best	_	_
objectness	_	_
score	_	_
.	_	_

#204
We	_	_
carried	_	_
out	_	_
774k	_	_
training	_	_
iterations	_	_
using	_	_
Adam	_	_
optimizer	_	_
with	_	_
a	_	_
learning	_	_
rate	_	_
of	_	_
10−5	_	_
,	_	_
β1	_	_
=	_	_
0.9	_	_
and	_	_
β2	_	_
=	_	_
0.999	_	_
.	_	_

#205
We	_	_
implemented	_	_
our	_	_
model	_	_
in	_	_
Keras	_	_
library	_	_
.	_	_

#206
4.2	_	_
Tagging	_	_
Performance	_	_

#207
In	_	_
this	_	_
subsection	_	_
,	_	_
we	_	_
evaluate	_	_
the	_	_
performance	_	_
of	_	_
our	_	_
framework	_	_
on	_	_
three	_	_
variants	_	_
of	_	_
tagging	_	_
as	_	_
introduced	_	_
in	_	_
Sec	_	_
.	_	_

#208
3.1	_	_
,	_	_
namely	_	_
conventional	_	_
,	_	_
zero-shot	_	_
and	_	_
generalized	_	_
zero-shot	_	_
tagging	_	_
.	_	_

#209
Compared	_	_
methods	_	_
:	_	_
To	_	_
compare	_	_
our	_	_
results	_	_
,	_	_
we	_	_
have	_	_
reimplemented	_	_
two	_	_
similar	_	_
published	_	_
methods	_	_
(	_	_
ConSE	_	_
[	_	_
29	_	_
]	_	_
and	_	_
Fast0Tag	_	_
[	_	_
10	_	_
]	_	_
)	_	_
and	_	_
one	_	_
simple	_	_
baseline	_	_
based	_	_
on	_	_
ResNet-50	_	_
.	_	_

#210
We	_	_
choose	_	_
these	_	_
methods	_	_
for	_	_
comparison	_	_
because	_	_
of	_	_
their	_	_
suitability	_	_
to	_	_
perform	_	_
zero-shot	_	_
tasks	_	_
.	_	_

#211
ConSE	_	_
[	_	_
29	_	_
]	_	_
was	_	_
originally	_	_
introduced	_	_
for	_	_
zero-shot	_	_
learning	_	_
.	_	_

#212
This	_	_
approach	_	_
first	_	_
learns	_	_
a	_	_
classifier	_	_
for	_	_
seen	_	_
tags	_	_
and	_	_
generates	_	_
a	_	_
semantic	_	_
embedding	_	_
for	_	_
unseen	_	_
input	_	_
by	_	_
linearly	_	_
combining	_	_
word	_	_
vectors	_	_
of	_	_
seen	_	_
classes	_	_
using	_	_
seen	_	_
prediction	_	_
scores	_	_
.	_	_

#213
In	_	_
this	_	_
way	_	_
,	_	_
it	_	_
can	_	_
rank	_	_
unseen	_	_
tags	_	_
based	_	_
on	_	_
the	_	_
distance	_	_
of	_	_
generated	_	_
semantic	_	_
embedding	_	_
and	_	_
the	_	_
embedding	_	_
of	_	_
unseen	_	_
tags	_	_
.	_	_

#214
10	_	_
Shafin	_	_
Rahman	_	_
and	_	_
Salman	_	_
Khan	_	_

#215
Method	_	_
MiAP	_	_
K	_	_
=	_	_
3	_	_
K	_	_
=	_	_
5	_	_
P	_	_
R	_	_
F1	_	_
P	_	_
R	_	_
F1	_	_
Fast0Tag	_	_
[	_	_
10	_	_
]	_	_
35.73	_	_
20.24	_	_
34.48	_	_
25.51	_	_
16.16	_	_
45.87	_	_
23.90	_	_
Baseline	_	_
40.45	_	_
22.95	_	_
39.09	_	_
28.92	_	_
17.99	_	_
51.09	_	_
26.61	_	_
Ours	_	_
(	_	_
Bag	_	_
:	_	_
32	_	_
)	_	_
53.97	_	_
30.17	_	_
51.41	_	_
38.03	_	_
22.66	_	_
64.35	_	_
33.52	_	_
Ours	_	_
(	_	_
Bag	_	_
:	_	_
64	_	_
)	_	_
53.94	_	_
30.23	_	_
51.61	_	_
38.18	_	_
22.73	_	_
64.54	_	_
33.62	_	_
Table	_	_
1	_	_
.	_	_

#216
Results	_	_
for	_	_
conventional	_	_
tagging	_	_
.	_	_

#217
K	_	_
denotes	_	_
the	_	_
number	_	_
of	_	_
assigned	_	_
tags	_	_
.	_	_

#218
Method	_	_
Zero-shot	_	_
tagging	_	_
Generalized	_	_
zero-shot	_	_
tagging	_	_
MiAP	_	_
K=3	_	_
K=5	_	_
MiAP	_	_
K=3	_	_
K=5	_	_
P	_	_
R	_	_
F1	_	_
P	_	_
R	_	_
F1	_	_
P	_	_
R	_	_
F1	_	_
P	_	_
R	_	_
F1	_	_
ConSE	_	_
[	_	_
29	_	_
]	_	_
18.91	_	_
8.39	_	_
14.30	_	_
10.58	_	_
7.16	_	_
20.33	_	_
10.59	_	_
7.27	_	_
2.11	_	_
3.59	_	_
2.65	_	_
8.82	_	_
5.69	_	_
6.92	_	_
Fast0Tag	_	_
[	_	_
10	_	_
]	_	_
24.73	_	_
13.21	_	_
22.51	_	_
16.65	_	_
11.00	_	_
31.23	_	_
16.27	_	_
10.36	_	_
5.21	_	_
8.88	_	_
6.57	_	_
12.41	_	_
8.00	_	_
9.73	_	_
Baseline	_	_
29.75	_	_
16.64	_	_
28.34	_	_
20.97	_	_
13.49	_	_
38.32	_	_
19.96	_	_
12.07	_	_
5.99	_	_
10.20	_	_
7.54	_	_
14.28	_	_
9.21	_	_
11.20	_	_
Ours	_	_
(	_	_
Bag	_	_
:	_	_
32	_	_
)	_	_
37.50	_	_
21.16	_	_
36.06	_	_
26.67	_	_
16.62	_	_
47.20	_	_
24.59	_	_
20.55	_	_
27.66	_	_
10.70	_	_
15.43	_	_
23.67	_	_
15.27	_	_
18.56	_	_
Ours	_	_
(	_	_
Bag	_	_
:	_	_
64	_	_
)	_	_
39.01	_	_
22.05	_	_
37.56	_	_
27.79	_	_
17.26	_	_
49.01	_	_
25.53	_	_
20.32	_	_
27.09	_	_
10.48	_	_
15.12	_	_
23.27	_	_
15.01	_	_
18.25	_	_
Table	_	_
2	_	_
.	_	_

#219
Results	_	_
for	_	_
zero-shot	_	_
and	_	_
generalize	_	_
zero-shot	_	_
tagging	_	_
tasks	_	_
.	_	_

#220
Fast0Tag	_	_
[	_	_
10	_	_
]	_	_
is	_	_
the	_	_
main	_	_
competitor	_	_
of	_	_
our	_	_
work	_	_
.	_	_

#221
This	_	_
is	_	_
a	_	_
deep	_	_
feature	_	_
based	_	_
approach	_	_
,	_	_
where	_	_
features	_	_
are	_	_
calculated	_	_
from	_	_
a	_	_
pre-trained	_	_
VGG-19	_	_
[	_	_
31	_	_
]	_	_
.	_	_

#222
Afterwards	_	_
,	_	_
a	_	_
neural	_	_
network	_	_
is	_	_
trained	_	_
on	_	_
these	_	_
features	_	_
to	_	_
classify	_	_
seen	_	_
and	_	_
unseen	_	_
input	_	_
.	_	_

#223
This	_	_
approach	_	_
outperforms	_	_
many	_	_
established	_	_
methods	_	_
like	_	_
WRAP	_	_
[	_	_
36	_	_
]	_	_
,	_	_
WSABIE	_	_
[	_	_
37	_	_
]	_	_
,	_	_
TagProp	_	_
[	_	_
38	_	_
]	_	_
,	_	_
FastTag	_	_
[	_	_
39	_	_
]	_	_
on	_	_
conventional	_	_
tagging	_	_
task	_	_
.	_	_

#224
Therefore	_	_
,	_	_
in	_	_
this	_	_
paper	_	_
,	_	_
we	_	_
do	_	_
not	_	_
consider	_	_
those	_	_
low-performing	_	_
methods	_	_
for	_	_
comparison	_	_
.	_	_

#225
The	_	_
performance	_	_
reported	_	_
in	_	_
this	_	_
paper	_	_
using	_	_
Fast0Tag	_	_
method	_	_
is	_	_
relatively	_	_
different	_	_
from	_	_
the	_	_
published	_	_
results	_	_
because	_	_
of	_	_
few	_	_
reasons	_	_
:	_	_
(	_	_
1	_	_
)	_	_
We	_	_
use	_	_
the	_	_
recent	_	_
ResNet-50	_	_
whereas	_	_
[	_	_
10	_	_
]	_	_
reported	_	_
results	_	_
on	_	_
VGG-19	_	_
,	_	_
(	_	_
2	_	_
)	_	_
Although	_	_
[	_	_
10	_	_
]	_	_
experimented	_	_
on	_	_
NUS-WIDE	_	_
,	_	_
they	_	_
only	_	_
used	_	_
a	_	_
subset	_	_
223,821	_	_
images	_	_
in	_	_
total	_	_
,	_	_
(	_	_
3	_	_
)	_	_
The	_	_
implementation	_	_
for	_	_
[	_	_
10	_	_
]	_	_
did	_	_
not	_	_
consider	_	_
the	_	_
repetition	_	_
of	_	_
the	_	_
seen	_	_
tag	_	_
‘interesting’	_	_
.	_	_

#226
The	_	_
baseline	_	_
method	_	_
is	_	_
a	_	_
special	_	_
case	_	_
of	_	_
our	_	_
proposed	_	_
method	_	_
which	_	_
uses	_	_
the	_	_
whole	_	_
image	_	_
as	_	_
a	_	_
single	_	_
instance	_	_
inside	_	_
the	_	_
bag	_	_
.	_	_

#227
It	_	_
breaks	_	_
the	_	_
multiple	_	_
instance	_	_
learning	_	_
consideration	_	_
but	_	_
does	_	_
not	_	_
affect	_	_
the	_	_
end-to-end	_	_
nature	_	_
of	_	_
the	_	_
solution	_	_
.	_	_

#228
Results	_	_
:	_	_
As	_	_
mentioned	_	_
earlier	_	_
,	_	_
we	_	_
perform	_	_
our	_	_
training	_	_
with	_	_
924	_	_
seen	_	_
tags	_	_
and	_	_
testing	_	_
with	_	_
81	_	_
unseen	_	_
tags	_	_
for	_	_
zero-shot	_	_
settings	_	_
.	_	_

#229
However	_	_
,	_	_
in	_	_
conventional	_	_
tagging	_	_
case	_	_
,	_	_
all	_	_
tags	_	_
are	_	_
considered	_	_
as	_	_
seen	_	_
.	_	_

#230
Therefore	_	_
,	_	_
we	_	_
use	_	_
the	_	_
81	_	_
tag	_	_
set	_	_
in	_	_
both	_	_
training	_	_
and	_	_
testing	_	_
.	_	_

#231
Note	_	_
that	_	_
,	_	_
in	_	_
all	_	_
of	_	_
our	_	_
experiments	_	_
the	_	_
same	_	_
test	_	_
images	_	_
are	_	_
used	_	_
.	_	_

#232
Thus	_	_
,	_	_
the	_	_
basic	_	_
difference	_	_
between	_	_
conventional	_	_
vs.	_	_
zero-shot	_	_
tagging	_	_
is	_	_
whether	_	_
those	_	_
81	_	_
tags	_	_
were	_	_
used	_	_
during	_	_
training	_	_
or	_	_
not	_	_
.	_	_

#233
For	_	_
generalized	_	_
zero-shot	_	_
tagging	_	_
case	_	_
same	_	_
testing	_	_
image	_	_
set	_	_
is	_	_
used	_	_
,	_	_
but	_	_
instead	_	_
of	_	_
predicting	_	_
tags	_	_
from	_	_
81	_	_
tag	_	_
set	_	_
,	_	_
our	_	_
method	_	_
predicts	_	_
tags	_	_
from	_	_
seen	_	_
924	_	_
+	_	_
unseen	_	_
81	_	_
=	_	_
1005	_	_
tag	_	_
set	_	_
.	_	_

#234
The	_	_
performances	_	_
of	_	_
ours	_	_
and	_	_
compared	_	_
methods	_	_
on	_	_
the	_	_
tagging	_	_
tasks	_	_
are	_	_
reported	_	_
in	_	_
Table	_	_
1	_	_
and	_	_
2	_	_
for	_	_
the	_	_
case	_	_
of	_	_
NUS-WIDE	_	_
dataset	_	_
.	_	_

#235
Our	_	_
method	_	_
outperforms	_	_
all	_	_
competitor	_	_
methods	_	_
by	_	_
a	_	_
significant	_	_
margin	_	_
.	_	_

#236
Notably	_	_
,	_	_
the	_	_
folDeep	_	_
Multiple	_	_
Instance	_	_
Learning	_	_
for	_	_
ZST	_	_
11	_	_
lowing	_	_
observations	_	_
can	_	_
be	_	_
developed	_	_
from	_	_
the	_	_
results	_	_
:	_	_
(	_	_
1	_	_
)	_	_
The	_	_
performance	_	_
of	_	_
conventional	_	_
tagging	_	_
is	_	_
much	_	_
better	_	_
than	_	_
zero-shot	_	_
cases	_	_
because	_	_
unseen	_	_
tags	_	_
and	_	_
associated	_	_
images	_	_
are	_	_
not	_	_
present	_	_
during	_	_
training	_	_
for	_	_
zero-shot	_	_
tasks	_	_
.	_	_

#237
One	_	_
can	_	_
consider	_	_
that	_	_
the	_	_
performance	_	_
of	_	_
conventional	_	_
case	_	_
is	_	_
an	_	_
upper-bound	_	_
for	_	_
zero-shot	_	_
tagging	_	_
case	_	_
.	_	_

#238
(	_	_
2	_	_
)	_	_
Similar	_	_
to	_	_
previous	_	_
work	_	_
[	_	_
1	_	_
]	_	_
,	_	_
the	_	_
performance	_	_
for	_	_
the	_	_
generalized	_	_
zero-shot	_	_
tagging	_	_
task	_	_
is	_	_
even	_	_
poorer	_	_
than	_	_
the	_	_
zero-shot	_	_
tagging	_	_
task	_	_
.	_	_

#239
This	_	_
can	_	_
be	_	_
explained	_	_
by	_	_
the	_	_
fact	_	_
that	_	_
the	_	_
network	_	_
gets	_	_
biased	_	_
towards	_	_
the	_	_
seen	_	_
tags	_	_
and	_	_
scores	_	_
low	_	_
on	_	_
unseen	_	_
categories	_	_
.	_	_

#240
This	_	_
subsequently	_	_
leads	_	_
to	_	_
a	_	_
decrease	_	_
in	_	_
performance	_	_
.	_	_

#241
(	_	_
3	_	_
)	_	_
Similar	_	_
to	_	_
the	_	_
observation	_	_
from	_	_
[	_	_
10	_	_
]	_	_
,	_	_
Fast0Tag	_	_
beats	_	_
ConSE	_	_
[	_	_
29	_	_
]	_	_
in	_	_
zero-shot	_	_
cases	_	_
.	_	_

#242
The	_	_
main	_	_
reason	_	_
is	_	_
that	_	_
the	_	_
ConSE	_	_
[	_	_
29	_	_
]	_	_
does	_	_
not	_	_
use	_	_
semantic	_	_
word	_	_
vectors	_	_
during	_	_
its	_	_
training	_	_
which	_	_
is	_	_
crucial	_	_
to	_	_
find	_	_
a	_	_
bridge	_	_
between	_	_
seen	_	_
and	_	_
unseen	_	_
tags	_	_
.	_	_

#243
No	_	_
results	_	_
are	_	_
reported	_	_
with	_	_
ConSE	_	_
for	_	_
the	_	_
conventional	_	_
tagging	_	_
case	_	_
because	_	_
it	_	_
is	_	_
only	_	_
designed	_	_
for	_	_
zero-shot	_	_
scenarios	_	_
.	_	_

#244
(	_	_
4	_	_
)	_	_
The	_	_
baseline	_	_
beats	_	_
other	_	_
two	_	_
compared	_	_
methods	_	_
across	_	_
all	_	_
tasks	_	_
because	_	_
of	_	_
the	_	_
end-to-end	_	_
training	_	_
considering	_	_
word	_	_
vectors	_	_
in	_	_
the	_	_
learning	_	_
phase	_	_
.	_	_

#245
This	_	_
approach	_	_
is	_	_
benefited	_	_
by	_	_
the	_	_
appropriate	_	_
adaptation	_	_
of	_	_
feature	_	_
representations	_	_
for	_	_
the	_	_
tagging	_	_
task	_	_
.	_	_

#246
(	_	_
5	_	_
)	_	_
Our	_	_
approach	_	_
outperforms	_	_
all	_	_
other	_	_
competitors	_	_
because	_	_
it	_	_
utilizes	_	_
localized	_	_
image	_	_
features	_	_
based	_	_
on	_	_
MIL	_	_
,	_	_
perform	_	_
end-to-end	_	_
training	_	_
and	_	_
integrate	_	_
semantic	_	_
vectors	_	_
of	_	_
seen	_	_
tags	_	_
within	_	_
the	_	_
network	_	_
.	_	_

#247
We	_	_
also	_	_
illustrate	_	_
some	_	_
qualitative	_	_
comparisons	_	_
in	_	_
Fig.	_	_
3	_	_
.	_	_

#248
Ablation	_	_
study	_	_
:	_	_
The	_	_
proposed	_	_
framework	_	_
can	_	_
work	_	_
for	_	_
different	_	_
number	_	_
of	_	_
instances	_	_
in	_	_
the	_	_
bag	_	_
.	_	_

#249
Moreover	_	_
,	_	_
the	_	_
global	_	_
pooling	_	_
before	_	_
the	_	_
last	_	_
layer	_	_
can	_	_
be	_	_
based	_	_
on	_	_
either	_	_
mean	_	_
or	_	_
max	_	_
pooling	_	_
.	_	_

#250
In	_	_
Table	_	_
3	_	_
,	_	_
we	_	_
perform	_	_
an	_	_
ablation	_	_
study	_	_
for	_	_
zero-shot	_	_
tagging	_	_
based	_	_
on	_	_
different	_	_
combinations	_	_
of	_	_
network	_	_
settings	_	_
.	_	_

#251
We	_	_
observe	_	_
that	_	_
with	_	_
only	_	_
a	_	_
few	_	_
number	_	_
of	_	_
instances	_	_
(	_	_
e.g.	_	_
,	_	_
4	_	_
)	_	_
in	_	_
the	_	_
bag	_	_
,	_	_
our	_	_
method	_	_
can	_	_
beat	_	_
state-of-the-art	_	_
approaches	_	_
[	_	_
10,29	_	_
]	_	_
.	_	_

#252
The	_	_
required	_	_
bag	_	_
size	_	_
is	_	_
actually	_	_
depended	_	_
on	_	_
the	_	_
dataset	_	_
and	_	_
pooling	_	_
type	_	_
.	_	_

#253
We	_	_
notice	_	_
that	_	_
a	_	_
large	_	_
bagsize	_	_
improves	_	_
tagging	_	_
performance	_	_
for	_	_
mean	_	_
pooling	_	_
and	_	_
vise	_	_
versa	_	_
for	_	_
max	_	_
pooling	_	_
case	_	_
.	_	_

#254
This	_	_
variation	_	_
is	_	_
related	_	_
to	_	_
the	_	_
noise	_	_
inside	_	_
the	_	_
tag	_	_
annotation	_	_
of	_	_
the	_	_
ground	_	_
truth	_	_
.	_	_

#255
Many	_	_
previous	_	_
deep	_	_
MIL	_	_
networks	_	_
[	_	_
16,17	_	_
]	_	_
recommended	_	_
max-pooling	_	_
for	_	_
MIL	_	_
where	_	_
they	_	_
experimented	_	_
on	_	_
object	_	_
detection	_	_
dataset	_	_
containing	_	_
the	_	_
ground-truth	_	_
annotation	_	_
without	_	_
any	_	_
label	_	_
noise	_	_
.	_	_

#256
In	_	_
contrast	_	_
,	_	_
other	_	_
than	_	_
the	_	_
81-tag	_	_
set	_	_
,	_	_
NUS-WIDE	_	_
contains	_	_
significant	_	_
noise	_	_
in	_	_
the	_	_
tag	_	_
annotations	_	_
.	_	_

#257
Therefore	_	_
,	_	_
mean-pooling	_	_
with	_	_
large	_	_
bag	_	_
size	_	_
achieves	_	_
a	_	_
balance	_	_
in	_	_
the	_	_
noisy	_	_
tags	_	_
,	_	_
outperforming	_	_
max-pooling	_	_
in	_	_
general	_	_
for	_	_
NUS-WIDE	_	_
.	_	_

#258
Notably	_	_
,	_	_
the	_	_
bag	_	_
size	_	_
of	_	_
our	_	_
framework	_	_
is	_	_
far	_	_
less	_	_
compared	_	_
to	_	_
other	_	_
MIL	_	_
approaches	_	_
[	_	_
16,17	_	_
]	_	_
.	_	_

#259
Being	_	_
dependent	_	_
on	_	_
external	_	_
bag	_	_
generator	_	_
[	_	_
18,19,20	_	_
]	_	_
previous	_	_
methods	_	_
lose	_	_
control	_	_
inside	_	_
the	_	_
generation	_	_
process	_	_
.	_	_

#260
Thus	_	_
,	_	_
a	_	_
large	_	_
bag	_	_
size	_	_
helps	_	_
them	_	_
to	_	_
get	_	_
enough	_	_
proposals	_	_
to	_	_
choose	_	_
the	_	_
best	_	_
score	_	_
in	_	_
last	_	_
max-pooling	_	_
layer	_	_
.	_	_

#261
Conversely	_	_
,	_	_
our	_	_
method	_	_
controls	_	_
the	_	_
bag	_	_
generation	_	_
network	_	_
by	_	_
fine-tuning	_	_
shared	_	_
ResNet-50	_	_
layers	_	_
which	_	_
eventually	_	_
can	_	_
relax	_	_
the	_	_
requirement	_	_
of	_	_
large	_	_
bag	_	_
sizes	_	_
.	_	_

#262
Tagging	_	_
in	_	_
the	_	_
wild	_	_
:	_	_
Since	_	_
our	_	_
method	_	_
does	_	_
not	_	_
use	_	_
any	_	_
information	_	_
about	_	_
unseen	_	_
tags	_	_
in	_	_
zero-shot	_	_
settings	_	_
,	_	_
it	_	_
can	_	_
process	_	_
an	_	_
infinite	_	_
number	_	_
of	_	_
unseen	_	_
tags	_	_

#263
12	_	_
Shafin	_	_
Rahman	_	_
and	_	_
Salman	_	_
Khan	_	_

#264
Bag	_	_
size	_	_
(	_	_
n	_	_
+	_	_
1	_	_
)	_	_
Mean	_	_
Pooling	_	_
Max	_	_
Pooling	_	_
MiAP	_	_
K=3	_	_
K=5	_	_
MiAP	_	_
K=3	_	_
K=5	_	_
P	_	_
R	_	_
F1	_	_
P	_	_
R	_	_
F1	_	_
P	_	_
R	_	_
F1	_	_
P	_	_
R	_	_
F1	_	_
4	_	_
32.85	_	_
18.28	_	_
31.15	_	_
23.04	_	_
14.79	_	_
42.00	_	_
21.88	_	_
35.75	_	_
20.20	_	_
34.42	_	_
25.46	_	_
16.13	_	_
45.79	_	_
23.85	_	_
8	_	_
36.33	_	_
20.68	_	_
35.23	_	_
26.06	_	_
16.38	_	_
46.51	_	_
24.23	_	_
34.89	_	_
19.61	_	_
33.42	_	_
24.72	_	_
15.67	_	_
44.49	_	_
23.18	_	_
16	_	_
37.20	_	_
21.08	_	_
35.92	_	_
26.57	_	_
16.58	_	_
47.08	_	_
24.53	_	_
32.03	_	_
18.01	_	_
30.68	_	_
22.69	_	_
14.85	_	_
42.17	_	_
21.97	_	_
32	_	_
37.50	_	_
21.16	_	_
36.06	_	_
26.67	_	_
16.62	_	_
47.20	_	_
24.59	_	_
29.29	_	_
16.57	_	_
28.23	_	_
20.88	_	_
14.00	_	_
39.75	_	_
20.70	_	_
64	_	_
39.01	_	_
22.05	_	_
37.56	_	_
27.79	_	_
17.26	_	_
49.01	_	_
25.53	_	_
32.05	_	_
17.68	_	_
30.13	_	_
22.29	_	_
14.38	_	_
40.82	_	_
21.27	_	_
Table	_	_
3	_	_
.	_	_

#265
Ablation	_	_
study	_	_
:	_	_
Impact	_	_
of	_	_
pooling	_	_
type	_	_
and	_	_
bag	_	_
size	_	_
on	_	_
zero-shot	_	_
tagging	_	_
Method	_	_
MiAP	_	_
K=3	_	_
K=5	_	_
P	_	_
R	_	_
F1	_	_
P	_	_
R	_	_
F1	_	_
ConSE	_	_
[	_	_
29	_	_
]	_	_
0.36	_	_
0.08	_	_
0.06	_	_
0.07	_	_
0.10	_	_
0.13	_	_
0.11	_	_
Fast0Tag	_	_
[	_	_
10	_	_
]	_	_
3.26	_	_
3.15	_	_
2.40	_	_
2.72	_	_
2.51	_	_
3.18	_	_
2.81	_	_
Baseline	_	_
3.61	_	_
3.51	_	_
2.67	_	_
3.04	_	_
2.83	_	_
3.59	_	_
3.16	_	_
Ours	_	_
(	_	_
Bag	_	_
:	_	_
32	_	_
)	_	_
5.85	_	_
5.42	_	_
4.12	_	_
4.68	_	_
4.42	_	_
5.60	_	_
4.94	_	_
Ours	_	_
(	_	_
Bag	_	_
:	_	_
64	_	_
)	_	_
5.52	_	_
5.01	_	_
3.81	_	_
4.33	_	_
4.10	_	_
5.20	_	_
4.59	_	_
Table	_	_
4	_	_
.	_	_

#266
Results	_	_
for	_	_
zero-shot	_	_
tagging	_	_
task	_	_
with	_	_
4,084	_	_
unseen	_	_
tags	_	_
.	_	_

#267
from	_	_
an	_	_
open	_	_
vocabulary	_	_
.	_	_

#268
We	_	_
test	_	_
such	_	_
setting	_	_
using	_	_
5018	_	_
tag	_	_
set	_	_
of	_	_
NUS-WIDE	_	_
.	_	_

#269
We	_	_
remove	_	_
924	_	_
seen	_	_
tags	_	_
and	_	_
ten	_	_
other	_	_
tags	_	_
(	_	_
handsewn	_	_
,	_	_
interestingness	_	_
,	_	_
manganite	_	_
,	_	_
marruecos	_	_
,	_	_
mixs	_	_
,	_	_
monochromia	_	_
,	_	_
shopwindow	_	_
,	_	_
skys	_	_
,	_	_
topv	_	_
and	_	_
uncropped	_	_
for	_	_
which	_	_
no	_	_
GloVe	_	_
vectors	_	_
were	_	_
found	_	_
)	_	_
to	_	_
produce	_	_
a	_	_
large	_	_
set	_	_
of	_	_
4084	_	_
unseen	_	_
tags	_	_
.	_	_

#270
After	_	_
training	_	_
with	_	_
924	_	_
seen	_	_
tags	_	_
,	_	_
the	_	_
performance	_	_
of	_	_
zero-shot	_	_
tagging	_	_
with	_	_
this	_	_
set	_	_
is	_	_
shown	_	_
in	_	_
Table	_	_
4	_	_
.	_	_

#271
Because	_	_
of	_	_
extreme	_	_
noise	_	_
in	_	_
the	_	_
annotations	_	_
,	_	_
the	_	_
results	_	_
are	_	_
very	_	_
poor	_	_
in	_	_
general	_	_
,	_	_
but	_	_
our	_	_
method	_	_
still	_	_
outperforms	_	_
other	_	_
competitors	_	_
[	_	_
10,29	_	_
]	_	_
.	_	_

#272
4.3	_	_
Zero	_	_
Shot	_	_
Recognition	_	_
(	_	_
ZSR	_	_
)	_	_

#273
Our	_	_
proposed	_	_
framework	_	_
is	_	_
designed	_	_
to	_	_
handle	_	_
zero-shot	_	_
multi-label	_	_
problem	_	_
.	_	_

#274
Therefore	_	_
,	_	_
it	_	_
can	_	_
also	_	_
be	_	_
used	_	_
for	_	_
single	_	_
label	_	_
ZSR	_	_
problem	_	_
.	_	_

#275
To	_	_
evaluate	_	_
the	_	_
performance	_	_
of	_	_
ZSR	_	_
,	_	_
we	_	_
experiment	_	_
with	_	_
the	_	_
Caltech-UCSD	_	_
Birds-200-2011	_	_
(	_	_
CUB	_	_
)	_	_
dataset	_	_
[	_	_
40	_	_
]	_	_
.	_	_

#276
Although	_	_
the	_	_
size	_	_
of	_	_
this	_	_
dataset	_	_
is	_	_
relatively	_	_
small	_	_
containing	_	_
11,788	_	_
images	_	_
belonging	_	_
to	_	_
200	_	_
classes	_	_
,	_	_
it	_	_
is	_	_
popular	_	_
for	_	_
fine-grain	_	_
recognition	_	_
tasks	_	_
.	_	_

#277
In	_	_
ZSR	_	_
literature	_	_
[	_	_
1,41	_	_
]	_	_
,	_	_
the	_	_
standard	_	_
train/test	_	_
split	_	_
allows	_	_
fixed	_	_
150	_	_
seen	_	_
and	_	_
50	_	_
unseen	_	_
classes	_	_
for	_	_
experiments	_	_
.	_	_

#278
We	_	_
follow	_	_
this	_	_
traditional	_	_
setting	_	_
without	_	_
using	_	_
bounding	_	_
boxes	_	_
annotation	_	_
,	_	_
per	_	_
image	_	_
part	_	_
annotation	_	_
(	_	_
like	_	_
[	_	_
7	_	_
]	_	_
)	_	_
and	_	_
descriptions	_	_
(	_	_
like	_	_
[	_	_
3	_	_
]	_	_
)	_	_
.	_	_

#279
To	_	_
be	_	_
consistent	_	_
with	_	_
the	_	_
rest	_	_
of	_	_
the	_	_
paper	_	_
,	_	_
we	_	_
consider	_	_
400-d	_	_
unsupervised	_	_
GloVe	_	_
(	_	_
glo	_	_
)	_	_
and	_	_
word2vec	_	_
(	_	_
w2v	_	_
)	_	_
vectors	_	_
used	_	_
in	_	_
[	_	_
41	_	_
]	_	_
.	_	_

#280
For	_	_
a	_	_
given	_	_
test	_	_
image	_	_
,	_	_
our	_	_
network	_	_
predicts	_	_
unseen	_	_
class	_	_
scores	_	_
and	_	_
an	_	_
image	_	_
is	_	_
classified	_	_
to	_	_
the	_	_
unseen	_	_
class	_	_
which	_	_
gets	_	_
the	_	_
maximum	_	_
score	_	_
.	_	_

#281
As	_	_
per	_	_
standard	_	_
practice	_	_
,	_	_
we	_	_
report	_	_
the	_	_
mean	_	_
per	_	_
class	_	_
Top1	_	_
accuracy	_	_
of	_	_
unseen	_	_
classes	_	_
in	_	_
Table	_	_
5	_	_
.	_	_

#282
Our	_	_
method	_	_
achieves	_	_
superior	_	_
results	_	_
in	_	_
comparison	_	_
to	_	_
state-of-the-art	_	_
methods	_	_
using	_	_
the	_	_
same	_	_
settings	_	_
.	_	_

#283
Note	_	_
that	_	_
,	_	_
all	_	_
other	_	_
methods	_	_
are	_	_
deep	_	_
feature	_	_
(	_	_
VGG/GoogLeNet	_	_
)	_	_
Deep	_	_
Multiple	_	_
Instance	_	_
Learning	_	_
for	_	_
ZST	_	_
13	_	_
Top1	_	_
Accuracy	_	_
Network	_	_
w2v	_	_
glo	_	_
Akata’16	_	_
[	_	_
7	_	_
]	_	_
V	_	_
33.90	_	_
DMaPI’17	_	_
[	_	_
5	_	_
]	_	_
G+V	_	_
26.38	_	_
30.34	_	_
SCoRe’17	_	_
[	_	_
6	_	_
]	_	_
G	_	_
31.51	_	_
Akata’15	_	_
[	_	_
42	_	_
]	_	_
G	_	_
28.40	_	_
24.20	_	_
LATEM’16	_	_
[	_	_
41	_	_
]	_	_
G	_	_
31.80	_	_
32.50	_	_
DMaP-I’17	_	_
[	_	_
5	_	_
]	_	_
G	_	_
26.28	_	_
23.69	_	_
Ours	_	_
(	_	_
Bag	_	_
size	_	_
:	_	_
32	_	_
)	_	_
R	_	_
31.77	_	_
29.56	_	_
Ours	_	_
(	_	_
Bag	_	_
size	_	_
:	_	_
64	_	_
)	_	_
R	_	_
36.55	_	_
33.00	_	_
Table	_	_
5	_	_
.	_	_

#284
Zero	_	_
shot	_	_
recognition	_	_
on	_	_
CUB	_	_
using	_	_
mean	_	_
pooling	_	_
based	_	_
MIL	_	_
.	_	_

#285
For	_	_
fairness	_	_
,	_	_
we	_	_
only	_	_
compared	_	_
our	_	_
results	_	_
with	_	_
the	_	_
inductive	_	_
setting	_	_
of	_	_
other	_	_
methods	_	_
without	_	_
per	_	_
image	_	_
part	_	_
annotation	_	_
and	_	_
description	_	_
.	_	_

#286
We	_	_
refer	_	_
investigated	_	_
network	_	_
structures	_	_
as	_	_
V=VGG	_	_
,	_	_
R=ResNet	_	_
,	_	_
G=GoogLeNet	_	_
.	_	_

#287
Fig.	_	_
3	_	_
.	_	_

#288
Example	_	_
of	_	_
top	_	_
5	_	_
predicted	_	_
tags	_	_
across	_	_
different	_	_
tasks	_	_
by	_	_
our	_	_
method	_	_
(	_	_
left/blue	_	_
)	_	_
and	_	_
fast0tag	_	_
[	_	_
10	_	_
]	_	_
(	_	_
right/black	_	_
)	_	_
.	_	_

#289
Bold	_	_
text	_	_
represents	_	_
the	_	_
correct	_	_
tags	_	_
according	_	_
to	_	_
ground-truth	_	_
.	_	_

#290
First	_	_
two	_	_
rows	_	_
of	_	_
images	_	_
illustrate	_	_
successful	_	_
examples	_	_
of	_	_
our	_	_
method	_	_
and	_	_
third	_	_
row	_	_
is	_	_
for	_	_
negative	_	_
cases	_	_
.	_	_

#291
based	_	_
approaches	_	_
that	_	_
do	_	_
not	_	_
train	_	_
a	_	_
joint	_	_
framework	_	_
in	_	_
an	_	_
end-to-end	_	_
manner	_	_
.	_	_

#292
In	_	_
contrast	_	_
,	_	_
our	_	_
method	_	_
is	_	_
end-to-end	_	_
learnable	_	_
based	_	_
on	_	_
ResNet-50	_	_
and	_	_
additionally	_	_
generates	_	_
bounding	_	_
boxes	_	_
without	_	_
using	_	_
any	_	_
box	_	_
annotations	_	_
.	_	_

#293
4.4	_	_
Discussion	_	_

#294
How	_	_
does	_	_
MIL	_	_
help	_	_
in	_	_
the	_	_
multi-label	_	_
zero-shot	_	_
annotation	_	_
?	_	_

#295
We	_	_
explain	_	_
this	_	_
aspect	_	_
using	_	_
the	_	_
illustration	_	_
in	_	_
Figure	_	_
3	_	_
.	_	_

#296
One	_	_
can	_	_
observe	_	_
that	_	_
several	_	_
tags	_	_
pertain	_	_
to	_	_
localized	_	_
information	_	_
in	_	_
a	_	_
scene	_	_
that	_	_
is	_	_
represented	_	_
by	_	_
only	_	_
a	_	_
small	_	_
subset	_	_
of	_	_
the	_	_
whole	_	_
image	_	_
,	_	_
e.g.	_	_
,	_	_
fish	_	_
,	_	_
coral	_	_
,	_	_
bike	_	_
and	_	_
bird	_	_
.	_	_

#297
This	_	_
demonstrates	_	_
that	_	_
a	_	_
multi-label	_	_
tagging	_	_
method	_	_
should	deontic	_
consider	_	_
localized	_	_
regions	_	_
in	_	_
conjunction	_	_
with	_	_
the	_	_
whole	_	_
image	_	_
.	_	_

#298
Our	_	_
proposed	_	_
method	_	_
incorporates	_	_
such	_	_
consideration	_	_
using	_	_
MIL	_	_
.	_	_

#299
Therefore	_	_
,	_	_
it	_	_
can	_	_
annotate	_	_
those	_	_
localized	_	_
tags	_	_
where	_	_
previous	_	_
method	_	_
,	_	_
fast0tag	_	_
,	_	_
[	_	_
10	_	_
]	_	_
usually	_	_
fails	_	_
(	_	_
see	_	_
rows	_	_
1-2	_	_
in	_	_
Fig.	_	_
3	_	_
)	_	_
.	_	_

#300
However	_	_
,	_	_
tags	_	_
like	_	_
beach	_	_
,	_	_
sunset	_	_
,	_	_
landscape	_	_
in	_	_
the	_	_
third	_	_
row	_	_
of	_	_
the	_	_
figure	_	_
are	_	_
related	_	_
to	_	_
the	_	_
global	_	_
information	_	_
in	_	_
an	_	_
image	_	_
which	_	_
does	_	_
not	_	_
depend	_	_
on	_	_
the	_	_
localized	_	_
features	_	_
.	_	_

#301
Therefore	_	_
,	_	_
in	_	_
this	_	_
respect	_	_
,	_	_
our	_	_
method	_	_
sometimes	_	_
fail	_	_
in	_	_
compared	_	_
to	_	_
fast0tag	_	_
[	_	_
10	_	_
]	_	_
(	_	_
see	_	_
row	_	_
3	_	_
in	_	_
Fig.	_	_
3	_	_
)	_	_
.	_	_

#302
However	_	_
,	_	_
as	_	_
illustrated	_	_
in	_	_
Fig.	_	_
3	_	_
(	_	_
the	_	_
non-bold	_	_
tags	_	_
in	_	_

#303
14	_	_
Shafin	_	_
Rahman	_	_
and	_	_
Salman	_	_
Khan	_	_

#304
Fig.	_	_
4	_	_
.	_	_

#305
Tag	_	_
discovery	_	_
.	_	_

#306
Bounding	_	_
boxes	_	_
are	_	_
shown	_	_
for	_	_
Top	_	_
2	_	_
tags	_	_
.	_	_

#307
blue	_	_
and	_	_
black	_	_
colors	_	_
)	_	_
,	_	_
the	_	_
predicted	_	_
tags	_	_
of	_	_
our	_	_
method	_	_
in	_	_
those	_	_
failure	_	_
cases	_	_
are	_	_
still	_	_
meaningful	_	_
and	_	_
relevant	_	_
compared	_	_
to	_	_
the	_	_
failure	_	_
cases	_	_
of	_	_
fast0tag	_	_
[	_	_
10	_	_
]	_	_
.	_	_

#308
Image	_	_
location	_	_
and	_	_
tag	_	_
correspondence	_	_
:	_	_
As	_	_
a	_	_
byproduct	_	_
,	_	_
our	_	_
approach	_	_
can	_	_
generate	_	_
a	_	_
bounding	_	_
box	_	_
for	_	_
each	_	_
assigned	_	_
tag	_	_
.	_	_

#309
In	_	_
Fig.	_	_
4	_	_
,	_	_
we	_	_
illustrate	_	_
some	_	_
boxes	_	_
(	_	_
for	_	_
top	_	_
2	_	_
tags	_	_
)	_	_
to	_	_
indicate	_	_
the	_	_
correspondence	_	_
between	_	_
image	_	_
locations	_	_
and	_	_
associated	_	_
tags	_	_
.	_	_

#310
Note	_	_
that	_	_
,	_	_
our	_	_
method	_	_
often	_	_
selects	_	_
the	_	_
whole	_	_
image	_	_
as	_	_
one	_	_
bounding	_	_
box	_	_
because	_	_
we	_	_
consider	_	_
whole	_	_
image	_	_
as	_	_
an	_	_
instance	_	_
inside	_	_
the	_	_
bag	_	_
.	_	_

#311
This	_	_
consideration	_	_
is	_	_
particularly	_	_
helpful	_	_
for	_	_
NUS-WIDE	_	_
dataset	_	_
because	_	_
it	_	_
contains	_	_
many	_	_
tags	_	_
which	_	_
are	_	_
not	_	_
only	_	_
related	_	_
to	_	_
objects	_	_
but	_	_
are	_	_
relevant	_	_
to	_	_
the	_	_
overall	_	_
scene	_	_
such	_	_
as	_	_
natural	_	_
concept	_	_
(	_	_
sky	_	_
,	_	_
water	_	_
,	_	_
sunset	_	_
)	_	_
,	_	_
aesthetic	_	_
style	_	_
(	_	_
reflection	_	_
,	_	_
tattoo	_	_
)	_	_
or	_	_
action	_	_
(	_	_
protest	_	_
,	_	_
earthquake	_	_
,	_	_
sports	_	_
)	_	_
.	_	_

#312
Any	_	_
quantitative	_	_
analysis	_	_
for	_	_
this	_	_
weakly	_	_
supervised	_	_
box	_	_
detection	_	_
task	_	_
was	_	_
not	_	_
possible	_	_
because	_	_
the	_	_
NUS-WIDE	_	_
dataset	_	_
does	_	_
not	_	_
provide	_	_
any	_	_
localization	_	_
ground-truth	_	_
for	_	_
tags	_	_
in	_	_
an	_	_
image	_	_
.	_	_

#313
5	_	_
Conclusion	_	_

#314
While	_	_
traditional	_	_
zero-shot	_	_
learning	_	_
methods	_	_
only	_	_
handle	_	_
single	_	_
unseen	_	_
label	_	_
per	_	_
image	_	_
,	_	_
this	_	_
paper	_	_
attempts	_	_
to	_	_
assign	_	_
multiple	_	_
unseen	_	_
tags	_	_
.	_	_

#315
For	_	_
the	_	_
first	_	_
time	_	_
,	_	_
we	_	_
propose	_	_
an	_	_
end-to-end	_	_
,	_	_
deep	_	_
MIL	_	_
framework	_	_
to	_	_
tackle	_	_
multi-label	_	_
zero-shot	_	_
tagging	_	_
.	_	_

#316
Unlike	_	_
previous	_	_
models	_	_
for	_	_
traditional	_	_
image	_	_
tagging	_	_
,	_	_
our	_	_
MIL	_	_
framework	_	_
does	_	_
not	_	_
depend	_	_
on	_	_
off-line	_	_
bag	_	_
generator	_	_
.	_	_

#317
Building	_	_
on	_	_
recent	_	_
advancements	_	_
in	_	_
object	_	_
detection	_	_
,	_	_
our	_	_
model	_	_
automatically	_	_
generates	_	_
the	_	_
bag	_	_
of	_	_
instances	_	_
in	_	_
an	_	_
efficient	_	_
manner	_	_
and	_	_
can	_	_
assign	_	_
both	_	_
seen	_	_
and	_	_
unseen	_	_
labels	_	_
to	_	_
input	_	_
images	_	_
.	_	_

#318
Moreover	_	_
,	_	_
any	_	_
number	_	_
of	_	_
unseen	_	_
tags	_	_
from	_	_
an	_	_
open	_	_
vocabulary	_	_
could	feasibility	_
be	_	_
employed	_	_
in	_	_
the	_	_
model	_	_
during	_	_
test	_	_
time	_	_
.	_	_

#319
In	_	_
addition	_	_
,	_	_
our	_	_
method	_	_
can	_	_
be	_	_
viewed	_	_
as	_	_
a	_	_
weakly	_	_
supervised	_	_
learning	_	_
approach	_	_
because	_	_
of	_	_
its	_	_
ability	_	_
to	_	_
find	_	_
a	_	_
bounding	_	_
box	_	_
for	_	_
each	_	_
tag	_	_
without	_	_
requiring	_	_
any	_	_
box	_	_
annotation	_	_
during	_	_
training	_	_
.	_	_

#320
We	_	_
validate	_	_
our	_	_
framework	_	_
by	_	_
achieving	_	_
state-of-the-art	_	_
performance	_	_
on	_	_
a	_	_
large-scale	_	_
tagging	_	_
dataset	_	_
outperforming	_	_
established	_	_
methods	_	_
in	_	_
the	_	_
literature	_	_
.	_	_

#321
In	_	_
future	_	_
,	_	_
we	_	_
will	_	_
explore	_	_
the	_	_
semantic	_	_
relationship	_	_
of	_	_
word	_	_
vectors	_	_
to	_	_
incorporate	_	_
dependency	_	_
among	_	_
tags	_	_
.	_	_

#322
Deep	_	_
Multiple	_	_
Instance	_	_
Learning	_	_
for	_	_
ZST	_	_
15	_	_