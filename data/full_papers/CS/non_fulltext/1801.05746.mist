#0
TernausNet	_	_
:	_	_
U-Net	_	_
with	_	_
VGG11	_	_
Encoder	_	_
Pre-Trained	_	_
on	_	_
ImageNet	_	_
for	_	_
Image	_	_
Segmentation	_	_
Vladimir	_	_
Iglovikov	_	_
Lyft	_	_
Inc.	_	_
San	_	_
Francisco	_	_
,	_	_
CA	_	_
94107	_	_
,	_	_
USA	_	_
Email	_	_
:	_	_
iglovikov	_	_
@	_	_
gmail.com	_	_
Alexey	_	_
Shvets	_	_
Massachusetts	_	_
Institute	_	_
of	_	_
Technology	_	_
Cambridge	_	_
,	_	_
MA	_	_
02142	_	_
,	_	_
USA	_	_
Email	_	_
:	_	_
shvets	_	_
@	_	_
mit.edu	_	_
Abstract—Pixel-wise	_	_
image	_	_
segmentation	_	_
is	_	_
demanding	_	_
task	_	_
in	_	_
computer	_	_
vision	_	_
.	_	_

#1
Classical	_	_
U-Net	_	_
architectures	_	_
composed	_	_
of	_	_
encoders	_	_
and	_	_
decoders	_	_
are	_	_
very	_	_
popular	_	_
for	_	_
segmentation	_	_
of	_	_
medical	_	_
images	_	_
,	_	_
satellite	_	_
images	_	_
etc	_	_
.	_	_

#2
Typically	_	_
,	_	_
neural	_	_
network	_	_
initialized	_	_
with	_	_
weights	_	_
from	_	_
a	_	_
network	_	_
pre-trained	_	_
on	_	_
a	_	_
large	_	_
data	_	_
set	_	_
like	_	_
ImageNet	_	_
shows	_	_
better	_	_
performance	_	_
than	_	_
those	_	_
trained	_	_
from	_	_
scratch	_	_
on	_	_
a	_	_
small	_	_
dataset	_	_
.	_	_

#3
In	_	_
some	_	_
practical	_	_
applications	_	_
,	_	_
particularly	_	_
in	_	_
medicine	_	_
and	_	_
traffic	_	_
safety	_	_
,	_	_
the	_	_
accuracy	_	_
of	_	_
the	_	_
models	_	_
is	_	_
of	_	_
utmost	_	_
importance	_	_
.	_	_

#4
In	_	_
this	_	_
paper	_	_
,	_	_
we	_	_
demonstrate	_	_
how	_	_
the	_	_
U-Net	_	_
type	_	_
architecture	_	_
can	_	_
be	_	_
improved	_	_
by	_	_
the	_	_
use	_	_
of	_	_
the	_	_
pre-trained	_	_
encoder	_	_
.	_	_

#5
Our	_	_
code	_	_
and	_	_
corresponding	_	_
pre-trained	_	_
weights	_	_
are	_	_
publicly	_	_
available	_	_
at	_	_
https	_	_
:	_	_
//github.com/ternaus/TernausNet	_	_
.	_	_

#6
We	_	_
compare	_	_
three	_	_
weight	_	_
initialization	_	_
schemes	_	_
:	_	_
LeCun	_	_
uniform	_	_
,	_	_
the	_	_
encoder	_	_
with	_	_
weights	_	_
from	_	_
VGG11	_	_
and	_	_
full	_	_
network	_	_
trained	_	_
on	_	_
the	_	_
Carvana	_	_
dataset	_	_
.	_	_

#7
This	_	_
network	_	_
architecture	_	_
was	_	_
a	_	_
part	_	_
of	_	_
the	_	_
winning	_	_
solution	_	_
(	_	_
1st	_	_
out	_	_
of	_	_
735	_	_
)	_	_
in	_	_
the	_	_
Kaggle	_	_
:	_	_
Carvana	_	_
Image	_	_
Masking	_	_
Challenge	_	_
.	_	_

#8
Keywords—Computer	_	_
Vision	_	_
,	_	_
Image	_	_
Segmentation	_	_
,	_	_
Image	_	_
Recognition	_	_
,	_	_
Deep	_	_
learning	_	_
,	_	_
Medical	_	_
Image	_	_
Processing	_	_
,	_	_
Satellite	_	_
Imagery	_	_
.	_	_

#9
I	_	_
.	_	_

#10
INTRODUCTION	_	_
Recent	_	_
progress	_	_
in	_	_
computer	_	_
hardware	_	_
with	_	_
the	_	_
democratization	_	_
to	_	_
perform	_	_
intensive	_	_
calculations	_	_
has	_	_
enabled	_	_
researchers	_	_
to	_	_
work	_	_
with	_	_
models	_	_
,	_	_
that	_	_
have	_	_
millions	_	_
of	_	_
free	_	_
parameters	_	_
.	_	_

#11
Convolutional	_	_
neural	_	_
networks	_	_
(	_	_
CNN	_	_
)	_	_
have	_	_
already	_	_
demonstrated	_	_
their	_	_
success	_	_
in	_	_
image	_	_
classification	_	_
,	_	_
object	_	_
detection	_	_
,	_	_
scene	_	_
understanding	_	_
etc	_	_
.	_	_

#12
For	_	_
almost	_	_
any	_	_
computer	_	_
vision	_	_
problems	_	_
,	_	_
CNN-based	_	_
approaches	_	_
outperform	_	_
other	_	_
techniques	_	_
and	_	_
in	_	_
many	_	_
cases	_	_
even	_	_
human	_	_
experts	_	_
in	_	_
the	_	_
corresponding	_	_
field	_	_
.	_	_

#13
Now	_	_
almost	_	_
all	_	_
computer	_	_
vision	_	_
application	_	_
try	_	_
to	_	_
involve	_	_
deep	_	_
learning	_	_
techniques	_	_
to	_	_
improve	_	_
traditional	_	_
approaches	_	_
.	_	_

#14
They	_	_
influence	_	_
our	_	_
everyday	_	_
lives	_	_
and	_	_
the	_	_
potential	_	_
uses	_	_
of	_	_
these	_	_
technologies	_	_
look	_	_
truly	_	_
impressive	_	_
.	_	_

#15
Reliable	_	_
image	_	_
segmentation	_	_
is	_	_
one	_	_
of	_	_
the	_	_
important	_	_
tasks	_	_
in	_	_
computer	_	_
vision	_	_
.	_	_

#16
This	_	_
problem	_	_
is	_	_
especially	_	_
important	_	_
for	_	_
medical	_	_
imaging	_	_
that	_	_
can	_	_
potentially	_	_
improve	_	_
our	_	_
diagnostic	_	_
abilities	_	_
and	_	_
in	_	_
scene	_	_
understanding	_	_
to	_	_
make	_	_
safe	_	_
self-driving	_	_
vehicles	_	_
.	_	_

#17
Dense	_	_
image	_	_
segmentation	_	_
essentially	_	_
involves	_	_
dividing	_	_
images	_	_
into	_	_
meaningful	_	_
regions	_	_
,	_	_
which	_	_
can	_	_
be	_	_
viewed	_	_
as	_	_
a	_	_
pixel	_	_
level	_	_
classification	_	_
task	_	_
.	_	_

#18
The	_	_
most	_	_
straightforward	_	_
(	_	_
and	_	_
slow	_	_
)	_	_
approach	_	_
to	_	_
such	_	_
problem	_	_
is	_	_
manual	_	_
segmentation	_	_
of	_	_
the	_	_
images	_	_
.	_	_

#19
However	_	_
,	_	_
this	_	_
is	_	_
a	_	_
time-consuming	_	_
process	_	_
that	_	_
is	_	_
prone	_	_
to	_	_
mistakes	_	_
and	_	_
inconsistencies	_	_
that	_	_
are	_	_
unavoidable	_	_
when	_	_
human	_	_
data	_	_
curators	_	_
are	_	_
involved	_	_
.	_	_

#20
Automating	_	_
the	_	_
treatment	_	_
provides	_	_
a	_	_
systematic	_	_
way	_	_
of	_	_
segmenting	_	_
an	_	_
image	_	_
on	_	_
the	_	_
fly	_	_
as	_	_
soon	_	_
as	_	_
the	_	_
image	_	_
is	_	_
acquired	_	_
.	_	_

#21
This	_	_
process	_	_
requires	_	_
providing	_	_
necessary	_	_
accuracy	_	_
to	_	_
be	_	_
useful	_	_
in	_	_
the	_	_
production	_	_
environment	_	_
.	_	_

#22
In	_	_
the	_	_
last	_	_
years	_	_
,	_	_
different	_	_
methods	_	_
have	_	_
been	_	_
proposed	_	_
to	_	_
tackle	_	_
the	_	_
problem	_	_
of	_	_
creating	_	_
CNN’s	_	_
that	_	_
can	_	_
produce	_	_
a	_	_
segmentation	_	_
map	_	_
for	_	_
an	_	_
entire	_	_
input	_	_
image	_	_
in	_	_
a	_	_
single	_	_
forward	_	_
pass	_	_
.	_	_

#23
One	_	_
of	_	_
the	_	_
most	_	_
successful	_	_
state-of-the-art	_	_
deep	_	_
learning	_	_
method	_	_
is	_	_
based	_	_
on	_	_
the	_	_
Fully	_	_
Convolutional	_	_
Networks	_	_
(	_	_
FCN	_	_
)	_	_
[	_	_
2	_	_
]	_	_
.	_	_

#24
The	_	_
main	_	_
idea	_	_
of	_	_
this	_	_
approach	_	_
is	_	_
to	_	_
use	_	_
CNN	_	_
as	_	_
a	_	_
powerful	_	_
feature	_	_
extractor	_	_
by	_	_
replacing	_	_
the	_	_
fully	_	_
connected	_	_
layers	_	_
by	_	_
convolution	_	_
one	_	_
to	_	_
output	_	_
spatial	_	_
feature	_	_
maps	_	_
instead	_	_
of	_	_
classification	_	_
scores	_	_
.	_	_

#25
Those	_	_
maps	_	_
are	_	_
further	_	_
upsampled	_	_
to	_	_
produce	_	_
dense	_	_
pixel-wise	_	_
output	_	_
.	_	_

#26
This	_	_
method	_	_
allows	_	_
training	_	_
CNN	_	_
in	_	_
the	_	_
end	_	_
to	_	_
end	_	_
manner	_	_
for	_	_
segmentation	_	_
with	_	_
input	_	_
images	_	_
of	_	_
arbitrary	_	_
sizes	_	_
.	_	_

#27
Moreover	_	_
,	_	_
this	_	_
approach	_	_
achieved	_	_
an	_	_
improvement	_	_
in	_	_
segmentation	_	_
accuracy	_	_
over	_	_
common	_	_
methods	_	_
on	_	_
standard	_	_
datasets	_	_
like	_	_
PASCAL	_	_
VOC	_	_
[	_	_
3	_	_
]	_	_
.	_	_

#28
This	_	_
method	_	_
has	_	_
been	_	_
further	_	_
improved	_	_
and	_	_
now	_	_
known	_	_
as	_	_
U-Net	_	_
neural	_	_
network	_	_
[	_	_
4	_	_
]	_	_
.	_	_

#29
The	_	_
U-Net	_	_
architecture	_	_
uses	_	_
skip	_	_
connections	_	_
to	_	_
combine	_	_
low-level	_	_
feature	_	_
maps	_	_
with	_	_
higher-level	_	_
ones	_	_
,	_	_
which	_	_
enables	_	_
precise	_	_
pixel-level	_	_
localization	_	_
.	_	_

#30
A	_	_
large	_	_
number	_	_
of	_	_
feature	_	_
channels	_	_
in	_	_
upsampling	_	_
part	_	_
allows	_	_
propagating	_	_
context	_	_
information	_	_
to	_	_
higher	_	_
resolution	_	_
layers	_	_
.	_	_

#31
This	_	_
type	_	_
of	_	_
network	_	_
architecture	_	_
proven	_	_
themselves	_	_
in	_	_
binary	_	_
image	_	_
segmentation	_	_
competitions	_	_
such	_	_
as	_	_
satellite	_	_
image	_	_
analysis	_	_
[	_	_
5	_	_
]	_	_
and	_	_
medical	_	_
image	_	_
analysis	_	_
[	_	_
6	_	_
]	_	_
,	_	_
[	_	_
7	_	_
]	_	_
and	_	_
other	_	_
[	_	_
9	_	_
]	_	_
.	_	_

#32
In	_	_
this	_	_
paper	_	_
,	_	_
we	_	_
show	_	_
how	_	_
the	_	_
performance	_	_
of	_	_
U-Net	_	_
can	_	_
be	_	_
easily	_	_
improved	_	_
by	_	_
using	_	_
pre-trained	_	_
weights	_	_
.	_	_

#33
As	_	_
an	_	_
example	_	_
,	_	_
we	_	_
show	_	_
the	_	_
application	_	_
of	_	_
such	_	_
approach	_	_
to	_	_
Aerial	_	_
Image	_	_
Labeling	_	_
Dataset	_	_
[	_	_
8	_	_
]	_	_
,	_	_
that	_	_
contains	_	_
aerospace	_	_
images	_	_
of	_	_
several	_	_
cities	_	_
with	_	_
high	_	_
resolution	_	_
.	_	_

#34
Each	_	_
pixel	_	_
of	_	_
the	_	_
images	_	_
is	_	_
labeled	_	_
as	_	_
belonging	_	_
to	_	_
either	_	_
”building”	_	_
or	_	_
”not-building”	_	_
classes	_	_
.	_	_

#35
Another	_	_
example	_	_
of	_	_
the	_	_
successful	_	_
application	_	_
of	_	_
such	_	_
an	_	_
architecture	_	_
and	_	_
initialization	_	_
scheme	_	_
is	_	_
Kaggle	_	_
Carvana	_	_
image	_	_
segmentation	_	_
competition	_	_
[	_	_
9	_	_
]	_	_
,	_	_
where	_	_
one	_	_
of	_	_
the	_	_
authors	_	_
used	_	_
it	_	_
as	_	_
a	_	_
part	_	_
of	_	_
the	_	_
winning	_	_
(	_	_
1st	_	_
out	_	_
735	_	_
teams	_	_
)	_	_
solution	_	_
.	_	_

#36
II	_	_
.	_	_

#37
NETWORK	_	_
ARCHITECTURE	_	_
In	_	_
general	_	_
,	_	_
a	_	_
U-Net	_	_
architecture	_	_
consists	_	_
of	_	_
a	_	_
contracting	_	_
path	_	_
to	_	_
capture	_	_
context	_	_
and	_	_
of	_	_
a	_	_
symmetrically	_	_
expanding	_	_
path	_	_
that	_	_
enables	_	_
precise	_	_
localization	_	_
(	_	_
see	_	_
for	_	_
example	_	_
Fig.	_	_
1	_	_
)	_	_
.	_	_

#38
The	_	_
contracting	_	_
path	_	_
follows	_	_
the	_	_
typical	_	_
architecture	_	_
of	_	_
a	_	_
convolutional	_	_
network	_	_
with	_	_
alternating	_	_
convolution	_	_
and	_	_
pooling	_	_
operations	_	_
and	_	_
progressively	_	_
downsamples	_	_
feature	_	_
maps	_	_
,	_	_
increasing	_	_
the	_	_
number	_	_
of	_	_
feature	_	_
maps	_	_
per	_	_
layer	_	_
at	_	_
the	_	_
same	_	_
time	_	_
.	_	_

#39
Every	_	_
step	_	_
in	_	_
the	_	_
expansive	_	_
path	_	_
consists	_	_
of	_	_
an	_	_
upsampling	_	_
of	_	_
the	_	_
feature	_	_
map	_	_
followed	_	_
by	_	_
a	_	_
convolution	_	_
.	_	_

#40
ar	_	_
X	_	_
iv	_	_
:1	_	_
1	_	_
.	_	_

#41
6v	_	_
1	_	_
[	_	_
cs	_	_
.C	_	_
V	_	_
]	_	_
1	_	_
7	_	_
Ja	_	_
n	_	_
3	_	_
6	_	_
2	_	_
5	_	_
2	_	_
5	_	_
copy	_	_
and	_	_
concatanate	_	_
copy	_	_
and	_	_
concatanate	_	_
copy	_	_
and	_	_
concatanate	_	_
in	_	_
p	_	_
ut	_	_
im	_	_
ag	_	_
e	_	_
2	_	_
6	_	_
4	_	_
1	_	_
si	_	_
gm	_	_
oi	_	_
d	_	_
o	_	_
u	_	_
tp	_	_
ut	_	_
copy	_	_
and	_	_
concatanate	_	_
copy	_	_
and	_	_
concatanate	_	_
3x3	_	_
Conv2d+ReLU	_	_
2x2	_	_
MaxPool	_	_
3x3	_	_
ConvTranspose2d	_	_
(	_	_
stride=2	_	_
)	_	_
+ReLU	_	_
3x3	_	_
Conv2d+ReLU	_	_
(	_	_
pre-trained	_	_
)	_	_
Fig.	_	_
1	_	_
.	_	_

#42
Encoder-decoder	_	_
neural	_	_
network	_	_
architecture	_	_
also	_	_
known	_	_
as	_	_
U-Net	_	_
where	_	_
VGG11	_	_
neural	_	_
network	_	_
without	_	_
fully	_	_
connected	_	_
layers	_	_
as	_	_
its	_	_
encoder	_	_
.	_	_

#43
Each	_	_
blue	_	_
rectangular	_	_
block	_	_
represents	_	_
a	_	_
multi-channel	_	_
features	_	_
map	_	_
passing	_	_
through	_	_
a	_	_
series	_	_
of	_	_
transformations	_	_
.	_	_

#44
The	_	_
height	_	_
of	_	_
the	_	_
rod	_	_
shows	_	_
a	_	_
relative	_	_
map	_	_
size	_	_
(	_	_
in	_	_
pixels	_	_
)	_	_
,	_	_
while	_	_
their	_	_
widths	_	_
are	_	_
proportional	_	_
to	_	_
the	_	_
number	_	_
of	_	_
channels	_	_
(	_	_
the	_	_
number	_	_
is	_	_
explicitly	_	_
subscribed	_	_
to	_	_
the	_	_
corresponding	_	_
rod	_	_
)	_	_
.	_	_

#45
The	_	_
number	_	_
of	_	_
channels	_	_
increases	_	_
stage	_	_
by	_	_
stage	_	_
on	_	_
the	_	_
left	_	_
part	_	_
while	_	_
decrease	_	_
stage	_	_
by	_	_
stage	_	_
on	_	_
the	_	_
right	_	_
decoding	_	_
part	_	_
.	_	_

#46
The	_	_
arrows	_	_
on	_	_
top	_	_
show	_	_
transfer	_	_
of	_	_
information	_	_
from	_	_
each	_	_
encoding	_	_
layer	_	_
and	_	_
concatenating	_	_
it	_	_
to	_	_
a	_	_
corresponding	_	_
decoding	_	_
layer	_	_
.	_	_

#47
Hence	_	_
,	_	_
the	_	_
expansive	_	_
branch	_	_
increases	_	_
the	_	_
resolution	_	_
of	_	_
the	_	_
output	_	_
.	_	_

#48
In	_	_
order	_	_
to	_	_
localize	_	_
,	_	_
upsampled	_	_
features	_	_
,	_	_
the	_	_
expansive	_	_
path	_	_
combines	_	_
them	_	_
with	_	_
high-resolution	_	_
features	_	_
from	_	_
the	_	_
contracting	_	_
path	_	_
via	_	_
skip-connections	_	_
[	_	_
4	_	_
]	_	_
.	_	_

#49
The	_	_
output	_	_
of	_	_
the	_	_
model	_	_
is	_	_
a	_	_
pixel-by-pixel	_	_
mask	_	_
that	_	_
shows	_	_
the	_	_
class	_	_
of	_	_
each	_	_
pixel	_	_
.	_	_

#50
This	_	_
architecture	_	_
proved	_	_
itself	_	_
very	_	_
useful	_	_
for	_	_
segmentation	_	_
problems	_	_
with	_	_
limited	_	_
amounts	_	_
of	_	_
data	_	_
,	_	_
e.g.	_	_
see	_	_
[	_	_
5	_	_
]	_	_
.	_	_

#51
U-Net	_	_
is	_	_
capable	_	_
of	_	_
learning	_	_
from	_	_
a	_	_
relatively	_	_
small	_	_
training	_	_
set	_	_
.	_	_

#52
In	_	_
most	_	_
cases	_	_
,	_	_
data	_	_
sets	_	_
for	_	_
image	_	_
segmentation	_	_
consist	_	_
of	_	_
at	_	_
most	_	_
thousands	_	_
of	_	_
images	_	_
,	_	_
since	_	_
manual	_	_
preparation	_	_
of	_	_
the	_	_
masks	_	_
is	_	_
a	_	_
very	_	_
costly	_	_
procedure	_	_
.	_	_

#53
Typically	_	_
U-Net	_	_
is	_	_
trained	_	_
from	_	_
scratch	_	_
starting	_	_
with	_	_
randomly	_	_
initialized	_	_
weights	_	_
.	_	_

#54
It	_	_
is	_	_
well	_	_
known	_	_
that	_	_
training	_	_
network	_	_
without	_	_
over-fitting	_	_
the	_	_
data	_	_
set	_	_
should	deontic	_
be	_	_
relatively	_	_
large	_	_
,	_	_
millions	_	_
of	_	_
images	_	_
.	_	_

#55
Networks	_	_
that	_	_
are	_	_
trained	_	_
on	_	_
the	_	_
Imagenet	_	_
[	_	_
10	_	_
]	_	_
data	_	_
set	_	_
are	_	_
widely	_	_
used	_	_
as	_	_
a	_	_
source	_	_
of	_	_
the	_	_
initialization	_	_
for	_	_
network	_	_
weights	_	_
in	_	_
other	_	_
tasks	_	_
.	_	_

#56
In	_	_
this	_	_
way	_	_
,	_	_
the	_	_
learning	_	_
procedure	_	_
can	_	_
be	_	_
done	_	_
for	_	_
non-pre-trained	_	_
several	_	_
layers	_	_
of	_	_
the	_	_
network	_	_
(	_	_
sometimes	_	_
only	_	_
for	_	_
the	_	_
last	_	_
layer	_	_
)	_	_
to	_	_
take	_	_
into	_	_
account	_	_
features	_	_
of	_	_
the	_	_
date	_	_
set	_	_
.	_	_

#57
As	_	_
an	_	_
encoder	_	_
in	_	_
our	_	_
U-Net	_	_
network	_	_
,	_	_
we	_	_
used	_	_
relatively	_	_
simple	_	_
CNN	_	_
of	_	_
the	_	_
VGG	_	_
family	_	_
[	_	_
11	_	_
]	_	_
that	_	_
consists	_	_
of	_	_
11	_	_
sequential	_	_
layers	_	_
and	_	_
known	_	_
as	_	_
VGG11	_	_
see	_	_
Fig.	_	_
2	_	_
.	_	_

#58
VGG11	_	_
contains	_	_
seven	_	_
convolutional	_	_
layers	_	_
,	_	_
each	_	_
followed	_	_
by	_	_
a	_	_
ReLU	_	_
activation	_	_
function	_	_
,	_	_
and	_	_
five	_	_
max	_	_
polling	_	_
operations	_	_
,	_	_
each	_	_
reducing	_	_
feature	_	_
map	_	_
by	_	_
2	_	_
.	_	_

#59
All	_	_
convolutional	_	_
layers	_	_
have	_	_
3×3	_	_
kernels	_	_
and	_	_
the	_	_
number	_	_
of	_	_
channels	_	_
is	_	_
given	_	_
in	_	_
Fig.	_	_
2	_	_
.	_	_

#60
The	_	_
first	_	_
convolutional	_	_
layer	_	_
produces	_	_
64	_	_
channels	_	_
and	_	_
then	_	_
,	_	_
as	_	_
the	_	_
network	_	_
deepens	_	_
,	_	_
the	_	_
number	_	_
of	_	_
channels	_	_
doubles	_	_
after	_	_
each	_	_
max	_	_
pooling	_	_
operation	_	_
until	_	_
it	_	_
reaches	_	_
512	_	_
.	_	_

#61
On	_	_
the	_	_
following	_	_
layers	_	_
,	_	_
the	_	_
number	_	_
of	_	_
channels	_	_
does	_	_
not	_	_
change	_	_
.	_	_

#62
To	_	_
construct	_	_
an	_	_
encoder	_	_
,	_	_
we	_	_
remove	_	_
the	_	_
fully	_	_
connected	_	_
layers	_	_
and	_	_
replace	_	_
them	_	_
with	_	_
a	_	_
single	_	_
convolutional	_	_
layer	_	_
of	_	_
512	_	_
channels	_	_
that	_	_
serves	_	_
as	_	_
a	_	_
bottleneck	_	_
central	_	_
part	_	_
of	_	_
the	_	_
network	_	_
,	_	_
separating	_	_
encoder	_	_
from	_	_
the	_	_
decoder	_	_
.	_	_

#63
To	_	_
construct	_	_
the	_	_
decoder	_	_
we	_	_
use	_	_
transposed	_	_
convolutions	_	_
layers	_	_
that	_	_
doubles	_	_
the	_	_
size	_	_
of	_	_
a	_	_
feature	_	_
map	_	_
while	_	_
reducing	_	_
the	_	_
number	_	_
of	_	_
channels	_	_
by	_	_
half	_	_
.	_	_

#64
And	_	_
the	_	_
output	_	_
of	_	_
a	_	_
transposed	_	_
convolution	_	_
is	_	_
then	_	_
concatenated	_	_
with	_	_
an	_	_
output	_	_
of	_	_
the	_	_
corresponding	_	_
part	_	_
of	_	_
the	_	_
decoder	_	_
.	_	_

#65
The	_	_
resultant	_	_
feature	_	_
map	_	_
is	_	_
treated	_	_
by	_	_
convolution	_	_
operation	_	_
to	_	_
keep	_	_
the	_	_
number	_	_
of	_	_
channels	_	_
the	_	_
same	_	_
as	_	_
in	_	_
a	_	_
symmetric	_	_
encoder	_	_
term	_	_
.	_	_

#66
This	_	_
upsampling	_	_
procedure	_	_
is	_	_
repeated	_	_
5	_	_
times	_	_
to	_	_
pair	_	_
up	_	_
with	_	_
5	_	_
max	_	_
poolings	_	_
,	_	_
as	_	_
shown	_	_
in	_	_
Fig.	_	_
1	_	_
.	_	_

#67
Technically	_	_
fully	_	_
connected	_	_
layers	_	_
can	_	_
take	_	_
an	_	_
input	_	_
of	_	_
any	_	_
size	_	_
,	_	_
but	_	_
because	_	_
we	_	_
have	_	_
5	_	_
max-pooling	_	_
layers	_	_
,	_	_
each	_	_
downsampling	_	_
an	_	_
image	_	_
two	_	_
times	_	_
,	_	_
only	_	_
images	_	_
with	_	_
a	_	_
side	_	_
divisible	_	_
by	_	_
32	_	_
(	_	_
25	_	_
)	_	_
can	_	_
be	_	_
used	_	_
as	_	_
an	_	_
input	_	_
to	_	_
the	_	_
current	_	_
3x3	_	_
conv	_	_
,	_	_
64	_	_
3x3	_	_
conv	_	_
,	_	_
128	_	_
3x3	_	_
conv	_	_
,	_	_
256	_	_
3x3	_	_
conv	_	_
,	_	_
256	_	_
3x3	_	_
conv	_	_
,	_	_
512	_	_
3x3	_	_
conv	_	_
,	_	_
512	_	_
3x3	_	_
conv	_	_
,	_	_
512	_	_
3x3	_	_
conv	_	_
,	_	_
512	_	_
fcc	_	_
,	_	_
4096	_	_
fcc	_	_
,	_	_
4096	_	_
fcc	_	_
,	_	_
num	_	_
.	_	_

#68
classes	_	_
2x2	_	_
MaxPool	_	_
2x2	_	_
MaxPool	_	_
2x2	_	_
MaxPool	_	_
2x2	_	_
MaxPool	_	_
2x2	_	_
MaxPool	_	_
Fig.	_	_
2	_	_
.	_	_

#69
VGG11	_	_
network	_	_
architecture	_	_
.	_	_

#70
In	_	_
this	_	_
picture	_	_
each	_	_
convolutional	_	_
layer	_	_
is	_	_
followed	_	_
by	_	_
ReLU	_	_
activation	_	_
function	_	_
.	_	_

#71
The	_	_
number	_	_
in	_	_
each	_	_
box	_	_
represents	_	_
the	_	_
number	_	_
of	_	_
channels	_	_
in	_	_
the	_	_
corresponding	_	_
feature	_	_
map	_	_
.	_	_

#72
network	_	_
implementation	_	_
.	_	_

#73
III	_	_
.	_	_

#74
RESULTS	_	_
We	_	_
applied	_	_
our	_	_
model	_	_
to	_	_
Inria	_	_
Aerial	_	_
Image	_	_
Labeling	_	_
Dataset	_	_
[	_	_
8	_	_
]	_	_
.	_	_

#75
This	_	_
dataset	_	_
consists	_	_
of	_	_
180	_	_
aerial	_	_
images	_	_
of	_	_
urban	_	_
settlements	_	_
in	_	_
Europe	_	_
and	_	_
United	_	_
States	_	_
,	_	_
and	_	_
is	_	_
labeled	_	_
as	_	_
a	_	_
building	_	_
and	_	_
not	_	_
building	_	_
classes	_	_
.	_	_

#76
Every	_	_
image	_	_
in	_	_
the	_	_
data	_	_
set	_	_
is	_	_
RGB	_	_
and	_	_
has	_	_
5000×5000	_	_
pixels	_	_
resolution	_	_
where	_	_
each	_	_
pixel	_	_
corresponds	_	_
to	_	_
a	_	_
30	_	_
×	_	_
30	_	_
cm2	_	_
of	_	_
Earth	_	_
surface	_	_
.	_	_

#77
We	_	_
used	_	_
30	_	_
images	_	_
(	_	_
5	_	_
from	_	_
every	_	_
6	_	_
cities	_	_
in	_	_
the	_	_
train	_	_
set	_	_
)	_	_
for	_	_
validation	_	_
,	_	_
as	_	_
suggested	_	_
in	_	_
[	_	_
12	_	_
]	_	_
(	_	_
valid	_	_
.	_	_

#78
IoU	_	_
'	_	_
0.647	_	_
)	_	_
and	_	_
[	_	_
13	_	_
]	_	_
(	_	_
best	_	_
valid	_	_
.	_	_

#79
IoU	_	_
'	_	_
0.73	_	_
)	_	_
and	_	_
trained	_	_
the	_	_
network	_	_
on	_	_
the	_	_
remaining	_	_
150	_	_
images	_	_
for	_	_
100	_	_
epochs	_	_
.	_	_

#80
Random	_	_
crops	_	_
of	_	_
768×768	_	_
were	_	_
used	_	_
for	_	_
training	_	_
and	_	_
central	_	_
crops	_	_
1440×1440	_	_
for	_	_
validation	_	_
.	_	_

#81
Adam	_	_
with	_	_
learning	_	_
rate	_	_
0.001	_	_
as	_	_
an	_	_
optimization	_	_
algorithm	_	_
[	_	_
14	_	_
]	_	_
.	_	_

#82
We	_	_
choose	_	_
Jaccard	_	_
index	_	_
(	_	_
Intersection	_	_
Over	_	_
Union	_	_
)	_	_
as	_	_
evaluation	_	_
metric	_	_
.	_	_

#83
It	_	_
can	_	_
be	_	_
interpreted	_	_
as	_	_
similarity	_	_
measure	_	_
between	_	_
a	_	_
finite	_	_
number	_	_
of	_	_
sets	_	_
.	_	_

#84
Intersection	_	_
over	_	_
union	_	_
for	_	_
similarity	_	_
measure	_	_
between	_	_
two	_	_
sets	_	_
A	_	_
and	_	_
B	_	_
,	_	_
can	_	_
be	_	_
defined	_	_
as	_	_
following	_	_
:	_	_
J	_	_
(	_	_
A	_	_
,	_	_
B	_	_
)	_	_
=	_	_
|A	_	_
∩B|	_	_
|A	_	_
∪B|	_	_
=	_	_
|A	_	_
∩B|	_	_
|A|+	_	_
|B|	_	_
−	_	_
|A	_	_
∩B|	_	_
(	_	_
1	_	_
)	_	_
where	_	_
normalization	_	_
condition	_	_
takes	_	_
place	_	_
:	_	_
0	_	_
≤	_	_
J	_	_
(	_	_
A	_	_
,	_	_
B	_	_
)	_	_
≤	_	_
1	_	_
Fig.	_	_
3	_	_
.	_	_

#85
Jaccard	_	_
index	_	_
as	_	_
a	_	_
function	_	_
of	_	_
a	_	_
training	_	_
epoch	_	_
for	_	_
three	_	_
U-Net	_	_
models	_	_
with	_	_
different	_	_
weight	_	_
initialization	_	_
.	_	_

#86
The	_	_
blue	_	_
line	_	_
shows	_	_
a	_	_
model	_	_
with	_	_
randomly	_	_
initialized	_	_
weights	_	_
,	_	_
orange	_	_
line	_	_
shows	_	_
a	_	_
model	_	_
,	_	_
where	_	_
the	_	_
encoder	_	_
was	_	_
initialized	_	_
with	_	_
VGG11	_	_
network	_	_
pre-trained	_	_
on	_	_
ImageNet	_	_
.	_	_

#87
Green	_	_
line	_	_
shows	_	_
a	_	_
model	_	_
,	_	_
where	_	_
the	_	_
entire	_	_
network	_	_
was	_	_
pre-trained	_	_
on	_	_
Carvana	_	_
data	_	_
set	_	_
.	_	_

#88
Every	_	_
image	_	_
is	_	_
consists	_	_
of	_	_
pixels	_	_
.	_	_

#89
To	_	_
adapt	_	_
the	_	_
last	_	_
expression	_	_
for	_	_
discrete	_	_
objects	_	_
,	_	_
we	_	_
can	_	_
write	_	_
it	_	_
in	_	_
the	_	_
following	_	_
way	_	_
J	_	_
=	_	_
n	_	_
n∑	_	_
i=1	_	_
(	_	_
yiŷi	_	_
yi	_	_
+	_	_
ŷi	_	_
−	_	_
yiŷi	_	_
)	_	_
(	_	_
2	_	_
)	_	_
where	_	_
yi	_	_
is	_	_
a	_	_
binary	_	_
value	_	_
(	_	_
label	_	_
)	_	_
of	_	_
the	_	_
corresponding	_	_
pixel	_	_
i	_	_
and	_	_
ŷi	_	_
is	_	_
predicted	_	_
probability	_	_
for	_	_
the	_	_
pixel	_	_
.	_	_

#90
Since	_	_
,	_	_
we	_	_
can	_	_
consider	_	_
image	_	_
segmentation	_	_
task	_	_
as	_	_
a	_	_
pixel	_	_
classification	_	_
problem	_	_
,	_	_
we	_	_
also	_	_
use	_	_
the	_	_
common	_	_
loss	_	_
function	_	_
for	_	_
binary	_	_
classification	_	_
tasks	_	_
-	_	_
binary	_	_
cross	_	_
entropy	_	_
that	_	_
is	_	_
defined	_	_
as	_	_
:	_	_
H	_	_
=	_	_
−	_	_
1	_	_
n	_	_
n∑	_	_
i=1	_	_
(	_	_
yi	_	_
log	_	_
ŷi	_	_
+	_	_
(	_	_
1−	_	_
yi	_	_
)	_	_
log	_	_
(	_	_
1−	_	_
ŷi	_	_
)	_	_
)	_	_
(	_	_
3	_	_
)	_	_
Join	_	_
these	_	_
expressions	_	_
,	_	_
we	_	_
can	_	_
generalized	_	_
the	_	_
loss	_	_
function	_	_
,	_	_
namely	_	_
,	_	_
L	_	_
=	_	_
H	_	_
−	_	_
log	_	_
J	_	_
(	_	_
4	_	_
)	_	_
Therefore	_	_
,	_	_
minimizing	_	_
this	_	_
loss	_	_
function	_	_
,	_	_
we	_	_
simultaneously	_	_
maximize	_	_
probabilities	_	_
for	_	_
right	_	_
pixels	_	_
to	_	_
be	_	_
predicted	_	_
and	_	_
maximize	_	_
the	_	_
intersection	_	_
,	_	_
J	_	_
between	_	_
masks	_	_
and	_	_
corresponding	_	_
predictions	_	_
.	_	_

#91
For	_	_
more	_	_
details	_	_
,	_	_
see	_	_
[	_	_
5	_	_
]	_	_
.	_	_

#92
At	_	_
the	_	_
output	_	_
of	_	_
a	_	_
given	_	_
neural	_	_
network	_	_
,	_	_
we	_	_
obtain	_	_
an	_	_
image	_	_
where	_	_
each	_	_
pixel	_	_
corresponds	_	_
to	_	_
a	_	_
probability	_	_
to	_	_
detect	_	_
interested	_	_
area	_	_
.	_	_

#93
The	_	_
size	_	_
of	_	_
the	_	_
output	_	_
image	_	_
is	_	_
coincides	_	_
with	_	_
the	_	_
input	_	_
image	_	_
.	_	_

#94
In	_	_
order	_	_
to	_	_
have	_	_
only	_	_
binary	_	_
pixel	_	_
values	_	_
,	_	_
we	_	_
choose	_	_
a	_	_
threshold	_	_
0.3	_	_
.	_	_

#95
This	_	_
number	_	_
can	_	_
be	_	_
found	_	_
using	_	_
validation	_	_
data	_	_
set	_	_
and	_	_
it	_	_
is	_	_
pretty	_	_
universal	_	_
for	_	_
our	_	_
generalized	_	_
loss	_	_
function	_	_
and	_	_
many	_	_
different	_	_
image	_	_
data	_	_
sets	_	_
.	_	_

#96
For	_	_
different	_	_
loss	_	_
function	_	_
this	_	_
number	_	_
is	_	_
different	_	_
and	_	_
should	deontic	_
be	_	_
found	_	_
independently	_	_
.	_	_

#97
All	_	_
pixel	_	_
values	_	_
below	_	_
the	_	_
specified	_	_
threshold	_	_
,	_	_
we	_	_
set	_	_
to	_	_
be	_	_
zero	_	_
while	_	_
all	_	_
values	_	_
above	_	_
the	_	_
threshold	_	_
,	_	_
we	_	_
set	_	_
to	_	_
be	_	_
1	_	_
.	_	_

#98
Then	_	_
,	_	_
multiplying	_	_
by	_	_
255	_	_
every	_	_
pixel	_	_
in	_	_
an	_	_
output	_	_
image	_	_
,	_	_
we	_	_
can	_	_
get	_	_
a	_	_
black	_	_
and	_	_
white	_	_
predicted	_	_
mask	_	_

#99
In	_	_
our	_	_
experiment	_	_
,	_	_
we	_	_
test	_	_
3	_	_
U-Nets	_	_
with	_	_
the	_	_
same	_	_
architecture	_	_
as	_	_
shown	_	_
in	_	_
Fig.	_	_
1	_	_
differing	_	_
only	_	_
in	_	_
the	_	_
way	_	_
of	_	_
weights	_	_
initialization	_	_
.	_	_

#100
For	_	_
the	_	_
basic	_	_
model	_	_
we	_	_
use	_	_
network	_	_
with	_	_
weights	_	_
initialized	_	_
by	_	_
LeCun	_	_
uniform	_	_
initializer	_	_
.	_	_

#101
In	_	_
this	_	_
initializer	_	_
samples	_	_
draw	_	_
from	_	_
a	_	_
uniform	_	_
distribution	_	_
within	_	_
[	_	_
−L	_	_
,	_	_
L	_	_
]	_	_
,	_	_
where	_	_
L	_	_
=	_	_
√	_	_
1/fin	_	_
and	_	_
fin	_	_
is	_	_
the	_	_
number	_	_
of	_	_
input	_	_
units	_	_
in	_	_
the	_	_
weight	_	_
tensor	_	_
.	_	_

#102
This	_	_
method	_	_
is	_	_
implement	_	_
in	_	_
pytorch	_	_
[	_	_
15	_	_
]	_	_
as	_	_
a	_	_
default	_	_
method	_	_
of	_	_
weight	_	_
initialization	_	_
in	_	_
convolutional	_	_
layers	_	_
.	_	_

#103
Next	_	_
,	_	_
we	_	_
utilize	_	_
the	_	_
same	_	_
architecture	_	_
with	_	_
VGG11	_	_
encoder	_	_
pre-trained	_	_
on	_	_
ImageNet	_	_
while	_	_
all	_	_
layers	_	_
in	_	_
decoder	_	_
are	_	_
initialized	_	_
by	_	_
the	_	_
LeCun	_	_
uniform	_	_
initializer	_	_
.	_	_

#104
Then	_	_
,	_	_
as	_	_
a	_	_
final	_	_
example	_	_
,	_	_
we	_	_
use	_	_
network	_	_
with	_	_
weights	_	_
pre-trained	_	_
on	_	_
Carvana	_	_
dataset	_	_
[	_	_
9	_	_
]	_	_
(	_	_
both	_	_
encoder	_	_
and	_	_
decoder	_	_
)	_	_
.	_	_

#105
Therefore	_	_
,	_	_
after	_	_
100	_	_
epochs	_	_
,	_	_
we	_	_
obtain	_	_
the	_	_
following	_	_
results	_	_
for	_	_
validation	_	_
subset	_	_
:	_	_
1	_	_
)	_	_
LeCun	_	_
uniform	_	_
initializer	_	_
:	_	_
IoU	_	_
=	_	_
0.593	_	_
2	_	_
)	_	_
The	_	_
Encoder	_	_
is	_	_
pre-trained	_	_
on	_	_
ImageNet	_	_
:	_	_
IoU	_	_
=	_	_
0.686	_	_
3	_	_
)	_	_
Fully	_	_
pre-trained	_	_
U-Net	_	_
on	_	_
Carvana	_	_
:	_	_
IoU	_	_
=	_	_
0.687	_	_
Validation	_	_
learning	_	_
curves	_	_
in	_	_
Fig.	_	_
3	_	_
show	_	_
benefits	_	_
of	_	_
our	_	_
approach	_	_
.	_	_

#106
First	_	_
of	_	_
all	_	_
,	_	_
pre-trained	_	_
models	_	_
converge	_	_
much	_	_
faster	_	_
to	_	_
its	_	_
steady	_	_
value	_	_
in	_	_
comparison	_	_
to	_	_
the	_	_
non-pre-trained	_	_
network	_	_
.	_	_

#107
Moreover	_	_
,	_	_
the	_	_
steady-state	_	_
value	_	_
seems	_	_
higher	_	_
for	_	_
the	_	_
pre-trained	_	_
models	_	_
.	_	_

#108
Ground	_	_
truth	_	_
,	_	_
as	_	_
well	_	_
as	_	_
three	_	_
masks	_	_
,	_	_
predicted	_	_
by	_	_
these	_	_
three	_	_
models	_	_
,	_	_
are	_	_
superimposed	_	_
on	_	_
an	_	_
original	_	_
image	_	_
in	_	_
Fig.	_	_
4	_	_
.	_	_

#109
One	_	_
can	_	_
easily	_	_
notice	_	_
the	_	_
difference	_	_
in	_	_
the	_	_
prediction	_	_
quality	_	_
after	_	_
100	_	_
epochs	_	_
.	_	_

#110
Moreover	_	_
,	_	_
validation	_	_
learning	_	_
curves	_	_
in	_	_
Our	_	_
results	_	_
for	_	_
the	_	_
Inria	_	_
Aerial	_	_
Image	_	_
Labeling	_	_
Dataset	_	_
can	_	_
be	_	_
easily	_	_
further	_	_
improved	_	_
using	_	_
different	_	_
hyper-parameters	_	_
optimization	_	_
techniques	_	_
or	_	_
standard	_	_
computer	_	_
vision	_	_
methods	_	_
applying	_	_
them	_	_
during	_	_
pre-	_	_
and	_	_
post-processing	_	_
.	_	_

#111
IV	_	_
.	_	_

#112
CONCLUSION	_	_
In	_	_
this	_	_
paper	_	_
,	_	_
we	_	_
show	_	_
how	_	_
the	_	_
performance	_	_
of	_	_
U-Net	_	_
can	_	_
be	_	_
improved	_	_
using	_	_
technique	_	_
knows	_	_
as	_	_
fine-tuning	_	_
to	_	_
initialize	_	_
weights	_	_
for	_	_
an	_	_
encoder	_	_
of	_	_
the	_	_
network	_	_
.	_	_

#113
This	_	_
kind	_	_
of	_	_
neural	_	_
network	_	_
is	_	_
widely	_	_
used	_	_
for	_	_
image	_	_
segmentation	_	_
tasks	_	_
and	_	_
shows	_	_
state	_	_
of	_	_
the	_	_
art	_	_
results	_	_
in	_	_
many	_	_
binary	_	_
image	_	_
segmentation	_	_
,	_	_
competitions	_	_
.	_	_

#114
Fine-tuning	_	_
is	_	_
already	_	_
widely	_	_
used	_	_
for	_	_
image	_	_
classification	_	_
tasks	_	_
,	_	_
but	_	_
to	_	_
our	_	_
knowledge	_	_
is	_	_
not	_	_
with	_	_
U-Net	_	_
type	_	_
family	_	_
architectures	_	_
.	_	_

#115
For	_	_
the	_	_
problems	_	_
of	_	_
image	_	_
segmentation	_	_
,	_	_
the	_	_
fine-tuning	_	_
should	deontic	_
be	_	_
considered	_	_
even	_	_
more	_	_
natural	_	_
because	_	_
it	_	_
is	_	_
problematic	_	_
to	_	_
collect	_	_
a	_	_
large	_	_
volume	_	_
of	_	_
training	_	_
dataset	_	_
(	_	_
in	_	_
particular	_	_
for	_	_
medical	_	_
images	_	_
)	_	_
and	_	_
qualitatively	_	_
label	_	_
it	_	_
.	_	_

#116
Furthermore	_	_
,	_	_
pre-trained	_	_
networks	_	_
substantially	_	_
reduce	_	_
training	_	_
time	_	_
that	_	_
also	_	_
helps	_	_
to	_	_
prevent	_	_
over-fitting	_	_
.	_	_

#117
Our	_	_
approach	_	_
can	_	_
be	_	_
further	_	_
improved	_	_
considering	_	_
more	_	_
advanced	_	_
pre-trained	_	_
encoders	_	_
such	_	_
as	_	_
VGG16	_	_
[	_	_
11	_	_
]	_	_
or	_	_
any	_	_
pre-trained	_	_
network	_	_
from	_	_
ResNet	_	_
family	_	_
[	_	_
16	_	_
]	_	_
.	_	_

#118
With	_	_
this	_	_
improved	_	_
encoders	_	_
the	_	_
decoders	_	_
can	_	_
be	_	_
kept	_	_
as	_	_
simple	_	_
as	_	_
we	_	_
use	_	_
.	_	_

#119
Our	_	_
code	_	_
is	_	_
available	_	_
as	_	_
an	_	_
open	_	_
source	_	_
project	_	_
under	_	_
MIT	_	_
license	_	_
and	_	_
can	_	_
be	_	_
found	_	_
at	_	_
https	_	_
:	_	_
//github.com/ternaus/TernausNet	_	_
.	_	_

#120
ACKNOWLEDGMENT	_	_
The	_	_
authors	_	_
would	_	_
like	_	_
to	_	_
thank	_	_
Open	_	_
Data	_	_
Science	_	_
community	_	_
[	_	_
17	_	_
]	_	_
for	_	_
many	_	_
valuable	_	_
discussions	_	_
and	_	_
educational	_	_
help	_	_
in	_	_
the	_	_
growing	_	_
field	_	_
of	_	_
machine/deep	_	_
learning	_	_
.	_	_

#121
The	_	_
authors	_	_
also	_	_
express	_	_
their	_	_
sincere	_	_
gratitude	_	_
to	_	_
Alexander	_	_
Buslaev	_	_
who	_	_
originally	_	_
suggested	_	_
to	_	_
use	_	_
a	_	_
pre-trained	_	_
VGG	_	_
network	_	_
as	_	_
an	_	_
encoder	_	_
in	_	_
a	_	_
U-Net	_	_
network	_	_
.	_	_