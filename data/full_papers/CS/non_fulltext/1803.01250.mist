#0
A	_	_
Benchmark	_	_
for	_	_
Iris	_	_
Location	_	_
and	_	_
a	_	_
Deep	_	_
Learning	_	_
Detector	_	_
Evaluation	_	_
Evair	_	_
Severo∗	_	_
,	_	_
Rayson	_	_
Laroca∗	_	_
,	_	_
Cides	_	_
S.	_	_
Bezerra∗	_	_
,	_	_
Luiz	_	_
A.	_	_
Zanlorensi∗	_	_
,	_	_
Daniel	_	_
Weingaertner∗	_	_
,	_	_
Gladston	_	_
Moreira†	_	_
and	_	_
David	_	_
Menotti∗	_	_
∗Postgraduate	_	_
Program	_	_
in	_	_
Informatics	_	_
,	_	_
Federal	_	_
University	_	_
of	_	_
Paraná	_	_
(	_	_
UFPR	_	_
)	_	_
,	_	_
Curitiba	_	_
,	_	_
Paraná	_	_
,	_	_
Brazil	_	_
†Computing	_	_
Department	_	_
,	_	_
Federal	_	_
University	_	_
of	_	_
Ouro	_	_
Preto	_	_
(	_	_
UFOP	_	_
)	_	_
,	_	_
Ouro	_	_
Preto	_	_
,	_	_
Minas	_	_
Gerais	_	_
,	_	_
Brazil	_	_
Email	_	_
:	_	_
{	_	_
ebsevero	_	_
,	_	_
rblsantos	_	_
,	_	_
csbezerra	_	_
,	_	_
lazjunior	_	_
,	_	_
daniel	_	_
,	_	_
menotti	_	_
}	_	_
@	_	_
inf.ufpr.br	_	_
gladston	_	_
@	_	_
iceb.ufop.br	_	_
Abstract—The	_	_
iris	_	_
is	_	_
considered	_	_
as	_	_
the	_	_
biometric	_	_
trait	_	_
with	_	_
the	_	_
highest	_	_
unique	_	_
probability	_	_
.	_	_

#1
The	_	_
iris	_	_
location	_	_
is	_	_
an	_	_
important	_	_
task	_	_
for	_	_
biometrics	_	_
systems	_	_
,	_	_
affecting	_	_
directly	_	_
the	_	_
results	_	_
obtained	_	_
in	_	_
specific	_	_
applications	_	_
such	_	_
as	_	_
iris	_	_
recognition	_	_
,	_	_
spoofing	_	_
and	_	_
contact	_	_
lenses	_	_
detection	_	_
,	_	_
among	_	_
others	_	_
.	_	_

#2
This	_	_
work	_	_
defines	_	_
the	_	_
iris	_	_
location	_	_
problem	_	_
as	_	_
the	_	_
delimitation	_	_
of	_	_
the	_	_
smallest	_	_
squared	_	_
window	_	_
that	_	_
encompasses	_	_
the	_	_
iris	_	_
region	_	_
.	_	_

#3
In	_	_
order	_	_
to	_	_
build	_	_
a	_	_
benchmark	_	_
for	_	_
iris	_	_
location	_	_
we	_	_
annotate	_	_
(	_	_
iris	_	_
squared	_	_
bounding	_	_
boxes	_	_
)	_	_
four	_	_
databases	_	_
from	_	_
different	_	_
biometric	_	_
applications	_	_
and	_	_
make	_	_
them	_	_
publicly	_	_
available	_	_
to	_	_
the	_	_
community	_	_
.	_	_

#4
Besides	_	_
these	_	_
4	_	_
annotated	_	_
databases	_	_
,	_	_
we	_	_
include	_	_
2	_	_
others	_	_
from	_	_
the	_	_
literature	_	_
.	_	_

#5
We	_	_
perform	_	_
experiments	_	_
on	_	_
these	_	_
six	_	_
databases	_	_
,	_	_
five	_	_
obtained	_	_
with	_	_
near	_	_
infra-red	_	_
sensors	_	_
and	_	_
one	_	_
with	_	_
visible	_	_
light	_	_
sensor	_	_
.	_	_

#6
We	_	_
compare	_	_
the	_	_
classical	_	_
and	_	_
outstanding	_	_
Daugman	_	_
iris	_	_
location	_	_
approach	_	_
with	_	_
two	_	_
window	_	_
based	_	_
detectors	_	_
:	_	_
1	_	_
)	_	_
a	_	_
sliding	_	_
window	_	_
detector	_	_
based	_	_
on	_	_
features	_	_
from	_	_
Histogram	_	_
of	_	_
Oriented	_	_
Gradients	_	_
(	_	_
HOG	_	_
)	_	_
and	_	_
a	_	_
linear	_	_
Support	_	_
Vector	_	_
Machines	_	_
(	_	_
SVM	_	_
)	_	_
classifier	_	_
;	_	_
2	_	_
)	_	_
a	_	_
deep	_	_
learning	_	_
based	_	_
detector	_	_
fine-tuned	_	_
from	_	_
YOLO	_	_
object	_	_
detector	_	_
.	_	_

#7
Experimental	_	_
results	_	_
showed	_	_
that	_	_
the	_	_
deep	_	_
learning	_	_
based	_	_
detector	_	_
outperforms	_	_
the	_	_
other	_	_
ones	_	_
in	_	_
terms	_	_
of	_	_
accuracy	_	_
and	_	_
runtime	_	_
(	_	_
GPUs	_	_
version	_	_
)	_	_
and	_	_
should	deontic	_
be	_	_
chosen	_	_
whenever	_	_
possible	_	_
.	_	_

#8
Index	_	_
Terms—Iris	_	_
location	_	_
;	_	_
Daugman	_	_
detector	_	_
;	_	_
HOG	_	_
&	_	_
linear	_	_
SVM	_	_
;	_	_
YOLO	_	_
;	_	_
Deep	_	_
Learning	_	_
.	_	_

#9
I.	_	_
INTRODUCTION	_	_

#10
Biometrics	_	_
systems	_	_
have	_	_
significantly	_	_
improved	_	_
person	_	_
identification	_	_
and	_	_
authentication	_	_
,	_	_
performing	_	_
an	_	_
important	_	_
role	_	_
in	_	_
personal	_	_
,	_	_
national	_	_
and	_	_
global	_	_
security	_	_
[	_	_
1	_	_
]	_	_
.	_	_

#11
In	_	_
biometry	_	_
,	_	_
the	_	_
iris	_	_
appears	_	_
as	_	_
one	_	_
of	_	_
the	_	_
main	_	_
biological	_	_
characteristics	_	_
,	_	_
since	_	_
it	_	_
remains	_	_
unchanged	_	_
over	_	_
time	_	_
and	_	_
is	_	_
unique	_	_
for	_	_
each	_	_
person	_	_
[	_	_
2	_	_
]	_	_
.	_	_

#12
Furthermore	_	_
,	_	_
the	_	_
identification	_	_
process	_	_
is	_	_
noninvasive	_	_
,	_	_
in	_	_
other	_	_
words	_	_
,	_	_
there	_	_
is	_	_
no	_	_
need	_	_
of	_	_
physical	_	_
contact	_	_
to	_	_
obtain	_	_
an	_	_
iris	_	_
image	_	_
and	_	_
analyze	_	_
it	_	_
[	_	_
3	_	_
]	_	_
.	_	_

#13
Figure	_	_
1a	_	_
illustrates	_	_
the	_	_
iris	_	_
and	_	_
other	_	_
structures	_	_
of	_	_
a	_	_
human	_	_
eye	_	_
.	_	_

#14
Iris	_	_
location	_	_
is	_	_
usually	_	_
the	_	_
initial	_	_
step	_	_
in	_	_
recognition	_	_
,	_	_
authentication	_	_
and	_	_
identification	_	_
systems	_	_
[	_	_
4	_	_
]	_	_
and	_	_
thus	_	_
can	_	_
directly	_	_
affect	_	_
their	_	_
performance	_	_
[	_	_
5	_	_
]	_	_
,	_	_
[	_	_
6	_	_
]	_	_
.	_	_

#15
In	_	_
this	_	_
sense	_	_
,	_	_
how	_	_
the	_	_
iris	_	_
location	_	_
step	_	_
influences	_	_
those	_	_
systems	_	_
is	_	_
an	_	_
interesting	_	_
question	_	_
to	_	_
be	_	_
studied	_	_
.	_	_

#16
For	_	_
achieving	_	_
such	_	_
aim	_	_
,	_	_
here	_	_
,	_	_
we	_	_
propose	_	_
to	_	_
benchmark/evaluate	_	_
baseline	_	_
methods	_	_
that	_	_
can	_	_
be	_	_
applied	_	_
to	_	_
iris	_	_
location	_	_
.	_	_

#17
Initially	_	_
,	_	_
we	_	_
survey	_	_
some	_	_
methods	_	_
in	_	_
the	_	_
literature	_	_
.	_	_

#18
The	_	_
pioneer	_	_
and	_	_
maybe	_	_
the	_	_
most	_	_
well	_	_
known	_	_
methods	_	_
for	_	_
iris	_	_
location	_	_
is	_	_
the	_	_
one	_	_
proposed	_	_
by	_	_
Daugman	_	_
[	_	_
6	_	_
]	_	_
,	_	_
which	_	_
defines	_	_
an	_	_
integro-differential	_	_
operator	_	_
to	_	_
identify	_	_
the	_	_
circular	_	_
(	_	_
a	_	_
)	_	_
(	_	_
b	_	_
)	_	_
Figure	_	_
1	_	_
.	_	_

#19
(	_	_
a	_	_
)	_	_
Periocular	_	_
region	_	_
and	_	_
its	_	_
main	_	_
structures	_	_
.	_	_

#20
(	_	_
b	_	_
)	_	_
Manual	_	_
iris	_	_
location	_	_
through	_	_
a	_	_
bounding	_	_
box	_	_
and	_	_
a	_	_
circle	_	_
.	_	_

#21
borders	_	_
present	_	_
in	_	_
the	_	_
images	_	_
.	_	_

#22
This	_	_
operator	_	_
takes	_	_
into	_	_
account	_	_
the	_	_
circular	_	_
shape	_	_
of	_	_
the	_	_
iris	_	_
in	_	_
order	_	_
to	_	_
find	_	_
the	_	_
correct	_	_
position	_	_
,	_	_
by	_	_
maximizing	_	_
the	_	_
partial	_	_
derivative	_	_
with	_	_
respect	_	_
to	_	_
the	_	_
radius	_	_
.	_	_

#23
Wildes	_	_
[	_	_
5	_	_
]	_	_
proposed	_	_
another	_	_
relevant	_	_
method	_	_
for	_	_
iris	_	_
location	_	_
by	_	_
using	_	_
border	_	_
detection	_	_
and	_	_
the	_	_
Hough	_	_
transform	_	_
.	_	_

#24
First	_	_
,	_	_
the	_	_
iris	_	_
is	_	_
isolated	_	_
by	_	_
using	_	_
Gaussian	_	_
filters	_	_
of	_	_
low	_	_
pass	_	_
followed	_	_
by	_	_
a	_	_
spatial	_	_
sub-sampling	_	_
.	_	_

#25
Subsequently	_	_
,	_	_
the	_	_
Hough	_	_
transform	_	_
is	_	_
applied	_	_
and	_	_
those	_	_
elements	_	_
that	_	_
better	_	_
fit	_	_
a	_	_
circle	_	_
according	_	_
to	_	_
a	_	_
defined	_	_
condition	_	_
are	_	_
selected	_	_
.	_	_

#26
Tisse	_	_
et	_	_
al.	_	_
[	_	_
7	_	_
]	_	_
,	_	_
present	_	_
a	_	_
modification	_	_
of	_	_
Daugman’s	_	_
algorithm	_	_
.	_	_

#27
This	_	_
approach	_	_
applies	_	_
a	_	_
Hough	_	_
transform	_	_
on	_	_
a	_	_
gradient	_	_
decomposition	_	_
to	_	_
find	_	_
an	_	_
approximation	_	_
of	_	_
the	_	_
pupil	_	_
center	_	_
.	_	_

#28
Then	_	_
,	_	_
the	_	_
integro-differential	_	_
operator	_	_
is	_	_
applied	_	_
to	_	_
locate	_	_
the	_	_
iris	_	_
boundaries	_	_
.	_	_

#29
It	_	_
has	_	_
the	_	_
advantage	_	_
of	_	_
eliminating	_	_
the	_	_
errors	_	_
caused	_	_
by	_	_
specular	_	_
reflections	_	_
.	_	_

#30
Rodrı́guez	_	_
&	_	_
Rubio	_	_
[	_	_
8	_	_
]	_	_
used	_	_
two	_	_
strategies	_	_
to	_	_
locate	_	_
inner	_	_
and	_	_
outer	_	_
iris	_	_
contours	_	_
.	_	_

#31
For	_	_
locating	_	_
the	_	_
inner	_	_
contour	_	_
of	_	_
the	_	_
iris	_	_
,	_	_
the	_	_
operator	_	_
proposed	_	_
by	_	_
Daugman	_	_
is	_	_
used	_	_
.	_	_

#32
Then	_	_
,	_	_
for	_	_
determining	_	_
the	_	_
outer	_	_
boundary	_	_
of	_	_
the	_	_
iris	_	_
,	_	_
three	_	_
points	_	_
are	_	_
detected	_	_
,	_	_
which	_	_
represent	_	_
the	_	_
vertexes	_	_
of	_	_
a	_	_
triangle	_	_
inscribed	_	_
in	_	_
a	_	_
circumference	_	_
that	_	_
models	_	_
the	_	_
iris	_	_
boundary	_	_
.	_	_

#33
This	_	_
approach	_	_
presented	_	_
no	_	_
better	_	_
accuracy	_	_
than	_	_
the	_	_
Daugman	_	_
method	_	_
,	_	_
but	_	_
makes	_	_
full	_	_
use	_	_
of	_	_
the	_	_
local	_	_
texture	_	_
variation	_	_
and	_	_
does	_	_
not	_	_
use	_	_
any	_	_
optimization	_	_
procedure	_	_
.	_	_

#34
For	_	_
this	_	_
reason	_	_
,	_	_
it	_	_
can	_	_
reduce	_	_
the	_	_
computational	_	_
cost	_	_
[	_	_
8	_	_
]	_	_
.	_	_

#35
Alvarez-Betancourt	_	_
&	_	_
Garcia-Silvente	_	_
[	_	_
9	_	_
]	_	_
presented	_	_
an	_	_
iris	_	_
location	_	_
method	_	_
based	_	_
on	_	_
the	_	_
detection	_	_
of	_	_
circular	_	_
boundaries	_	_
under	_	_
an	_	_
approach	_	_
of	_	_
gradient	_	_
analysis	_	_
in	_	_
points	_	_
of	_	_
interest	_	_
ar	_	_
X	_	_
iv	_	_
:1	_	_
3	_	_
.	_	_

#36
0v	_	_
5	_	_
[	_	_
cs	_	_
.C	_	_
V	_	_
]	_	_
3	_	_
0	_	_
A	_	_
pr	_	_
2	_	_
of	_	_
successive	_	_
arcs	_	_
.	_	_

#37
The	_	_
quantified	_	_
majority	_	_
operator	_	_
QMAOWA	_	_
[	_	_
10	_	_
]	_	_
was	_	_
used	_	_
in	_	_
order	_	_
to	_	_
obtain	_	_
a	_	_
representative	_	_
value	_	_
for	_	_
each	_	_
successive	_	_
arc	_	_
.	_	_

#38
The	_	_
identification	_	_
of	_	_
the	_	_
iris	_	_
boundary	_	_
is	_	_
given	_	_
by	_	_
obtaining	_	_
the	_	_
arc	_	_
with	_	_
the	_	_
greatest	_	_
representative	_	_
value	_	_
.	_	_

#39
The	_	_
authors	_	_
reported	_	_
similar	_	_
results	_	_
to	_	_
those	_	_
achieved	_	_
by	_	_
the	_	_
Daugman	_	_
method	_	_
,	_	_
with	_	_
improvements	_	_
in	_	_
processing	_	_
time	_	_
.	_	_

#40
In	_	_
the	_	_
method	_	_
proposed	_	_
by	_	_
ZhuYu	_	_
&	_	_
Cui	_	_
[	_	_
11	_	_
]	_	_
,	_	_
the	_	_
first	_	_
step	_	_
is	_	_
to	_	_
remove	_	_
the	_	_
eyelashes	_	_
by	_	_
dual-threshold	_	_
method	_	_
,	_	_
which	_	_
can	_	_
be	_	_
an	_	_
advantage	_	_
over	_	_
other	_	_
iris	_	_
location	_	_
approaches	_	_
.	_	_

#41
Next	_	_
,	_	_
the	_	_
facula	_	_
is	_	_
removed	_	_
through	_	_
erosion	_	_
method	_	_
.	_	_

#42
Finally	_	_
,	_	_
the	_	_
accurate	_	_
location	_	_
is	_	_
obtained	_	_
through	_	_
Hough	_	_
Transform	_	_
and	_	_
least-squares	_	_
method	_	_
.	_	_

#43
Zhou	_	_
et	_	_
al.	_	_
[	_	_
12	_	_
]	_	_
presented	_	_
a	_	_
method	_	_
for	_	_
iris	_	_
location	_	_
based	_	_
on	_	_
Vector	_	_
Field	_	_
Convolution	_	_
(	_	_
VFC	_	_
)	_	_
,	_	_
which	_	_
is	_	_
used	_	_
to	_	_
estimate	_	_
the	_	_
initial	_	_
location	_	_
of	_	_
the	_	_
iris	_	_
.	_	_

#44
This	_	_
initial	_	_
estimate	_	_
makes	_	_
pupil	_	_
location	_	_
much	_	_
closer	_	_
to	_	_
the	_	_
real	_	_
boundary	_	_
instead	_	_
of	_	_
circle	_	_
fitting	_	_
,	_	_
improving	_	_
location	_	_
accuracy	_	_
and	_	_
reducing	_	_
computational	_	_
cost	_	_
.	_	_

#45
The	_	_
final	_	_
result	_	_
is	_	_
obtained	_	_
using	_	_
the	_	_
algorithm	_	_
proposed	_	_
by	_	_
Daugman	_	_
[	_	_
6	_	_
]	_	_
.	_	_

#46
Zhang	_	_
et	_	_
al.	_	_
[	_	_
13	_	_
]	_	_
used	_	_
an	_	_
algorithm	_	_
which	_	_
adopts	_	_
a	_	_
momentum	_	_
based	_	_
level	_	_
set	_	_
method	_	_
[	_	_
14	_	_
]	_	_
,	_	_
[	_	_
15	_	_
]	_	_
to	_	_
locate	_	_
the	_	_
pupil	_	_
boundary	_	_
.	_	_

#47
Finally	_	_
,	_	_
the	_	_
Daugman’s	_	_
method	_	_
was	_	_
used	_	_
in	_	_
order	_	_
to	_	_
locate	_	_
the	_	_
iris	_	_
.	_	_

#48
Determine	_	_
the	_	_
initial	_	_
contour	_	_
for	_	_
momentum	_	_
based	_	_
level	_	_
set	_	_
by	_	_
minimum	_	_
average	_	_
gray	_	_
level	_	_
method	_	_
decreases	_	_
the	_	_
time	_	_
consumption	_	_
and	_	_
improves	_	_
the	_	_
results	_	_
obtained	_	_
by	_	_
the	_	_
Daugman’s	_	_
method	_	_
.	_	_

#49
This	_	_
improvement	_	_
happens	_	_
because	_	_
this	_	_
initial	_	_
contour	_	_
,	_	_
as	_	_
well	_	_
as	_	_
the	_	_
Zhou	_	_
et	_	_
al.	_	_
[	_	_
12	_	_
]	_	_
approach	_	_
,	_	_
is	_	_
generally	_	_
close	_	_
to	_	_
the	_	_
real	_	_
iris	_	_
inner	_	_
boundary	_	_
[	_	_
13	_	_
]	_	_
.	_	_

#50
Su	_	_
et	_	_
al.	_	_
[	_	_
16	_	_
]	_	_
proposed	_	_
an	_	_
iris	_	_
location	_	_
algorithm	_	_
based	_	_
on	_	_
regional	_	_
property	_	_
and	_	_
iterative	_	_
searching	_	_
.	_	_

#51
The	_	_
pupil	_	_
area	_	_
is	_	_
extracted	_	_
using	_	_
the	_	_
regional	_	_
attribute	_	_
of	_	_
the	_	_
iris	_	_
image	_	_
,	_	_
and	_	_
the	_	_
iris	_	_
inner	_	_
edge	_	_
is	_	_
fitted	_	_
by	_	_
iterating	_	_
,	_	_
comparing	_	_
and	_	_
sorting	_	_
the	_	_
pupil	_	_
edge	_	_
points	_	_
.	_	_

#52
The	_	_
outer	_	_
edge	_	_
location	_	_
is	_	_
completed	_	_
in	_	_
an	_	_
iterative	_	_
searching	_	_
method	_	_
on	_	_
the	_	_
basis	_	_
of	_	_
the	_	_
extracted	_	_
pupil	_	_
centre	_	_
and	_	_
radius	_	_
.	_	_

#53
As	_	_
can	_	_
be	_	_
seen	_	_
,	_	_
several	_	_
works	_	_
in	_	_
the	_	_
literature	_	_
have	_	_
proposed	_	_
methods	_	_
to	_	_
perform	_	_
iris	_	_
location	_	_
by	_	_
determining	_	_
a	_	_
circle	_	_
that	_	_
delimits	_	_
it	_	_
(	_	_
as	_	_
shown	_	_
in	_	_
red	_	_
in	_	_
Figure	_	_
1b	_	_
)	_	_
,	_	_
since	_	_
in	_	_
many	_	_
applications	_	_
it	_	_
is	_	_
necessary	_	_
to	_	_
perform	_	_
the	_	_
iris	_	_
normalization	_	_
.	_	_

#54
Normalization	_	_
consists	_	_
in	_	_
transforming	_	_
the	_	_
circular	_	_
region	_	_
of	_	_
the	_	_
iris	_	_
from	_	_
the	_	_
Cartesian	_	_
space	_	_
into	_	_
a	_	_
polar	_	_
coordinate	_	_
system	_	_
,	_	_
so	_	_
that	_	_
the	_	_
iris	_	_
is	_	_
represented	_	_
by	_	_
a	_	_
rectangle	_	_
.	_	_

#55
Usually	_	_
,	_	_
representations	_	_
and	_	_
characteristics	_	_
used	_	_
on	_	_
further	_	_
processes	_	_
are	_	_
extracted	_	_
from	_	_
the	_	_
transformed	_	_
image	_	_
.	_	_

#56
In	_	_
contrast	_	_
,	_	_
with	_	_
the	_	_
increasing	_	_
success	_	_
of	_	_
deep	_	_
learning	_	_
techniques	_	_
and	_	_
Convolutional	_	_
Neural	_	_
Networks	_	_
(	_	_
CNNs	_	_
)	_	_
in	_	_
computer	_	_
vision	_	_
problems	_	_
[	_	_
1	_	_
]	_	_
,	_	_
[	_	_
17	_	_
]	_	_
–	_	_
[	_	_
21	_	_
]	_	_
,	_	_
it	_	_
has	_	_
become	_	_
interesting	_	_
also	_	_
in	_	_
iris-related	_	_
biometrics	_	_
problems	_	_
(	_	_
besides	_	_
faces	_	_
)	_	_
the	_	_
use	_	_
of	_	_
the	_	_
entire	_	_
iris	_	_
region	_	_
,	_	_
including	_	_
the	_	_
pupil	_	_
and	_	_
some	_	_
sclera	_	_
region	_	_
,	_	_
without	_	_
the	_	_
need	_	_
for	_	_
normalization	_	_
.	_	_

#57
In	_	_
this	_	_
sense	_	_
,	_	_
this	_	_
work	_	_
defines	_	_
the	_	_
iris	_	_
location	_	_
task	_	_
as	_	_
the	_	_
determination	_	_
of	_	_
the	_	_
smallest	_	_
squared	_	_
bounding	_	_
box	_	_
that	_	_
encompasses	_	_
the	_	_
entire	_	_
region	_	_
of	_	_
the	_	_
iris	_	_
as	_	_
show	_	_
in	_	_
yellow	_	_
in	_	_
Figure	_	_
1b	_	_
.	_	_

#58
Thus	_	_
we	_	_
propose	_	_
to	_	_
evaluate	_	_
,	_	_
as	_	_
baselines	_	_
,	_	_
the	_	_
following	_	_
window-based	_	_
detectors	_	_
:	_	_
1	_	_
)	_	_
a	_	_
sliding	_	_
window	_	_
detector	_	_
based	_	_
on	_	_
features	_	_
from	_	_
Histogram	_	_
of	_	_
Oriented	_	_
Gradients	_	_
(	_	_
HOG	_	_
)	_	_
and	_	_
a	_	_
linear	_	_
Support	_	_
Vector	_	_
Machines	_	_
(	_	_
SVM	_	_
)	_	_
classifier	_	_
,	_	_
i.e.	_	_
,	_	_
an	_	_
adaptation	_	_
from	_	_
the	_	_
human	_	_
detection	_	_
method	_	_
proposed	_	_
by	_	_
Dalal	_	_
&	_	_
Triggs	_	_
[	_	_
22	_	_
]	_	_
;	_	_
2	_	_
)	_	_
a	_	_
deep	_	_
learning	_	_
based	_	_
detector	_	_
fine-tuned	_	_
from	_	_
YOLO	_	_
object	_	_
detector	_	_
[	_	_
23	_	_
]	_	_
,	_	_
[	_	_
24	_	_
]	_	_
.	_	_

#59
We	_	_
compare	_	_
our	_	_
results	_	_
with	_	_
the	_	_
well-known	_	_
method	_	_
of	_	_
Daugman	_	_
[	_	_
4	_	_
]	_	_
,	_	_
since	_	_
its	_	_
notoriety	_	_
and	_	_
one	_	_
fair	_	_
implementation	_	_
can	_	_
be	_	_
publicly	_	_
found1	_	_
.	_	_

#60
The	_	_
experiments	_	_
were	_	_
performed	_	_
in	_	_
six	_	_
databases	_	_
and	_	_
the	_	_
reported	_	_
results	_	_
show	_	_
that	_	_
the	_	_
use	_	_
of	_	_
deep	_	_
learning	_	_
to	_	_
iris	_	_
location	_	_
is	_	_
promising	_	_
.	_	_

#61
The	_	_
fine-tuned	_	_
model	_	_
from	_	_
YOLO	_	_
object	_	_
detector	_	_
yielded	_	_
real-time	_	_
location	_	_
with	_	_
high	_	_
accuracy	_	_
,	_	_
overcoming	_	_
problems	_	_
such	_	_
as	_	_
noise	_	_
,	_	_
eyelids	_	_
,	_	_
eyelashes	_	_
and	_	_
reflections	_	_
.	_	_

#62
This	_	_
paper	_	_
is	_	_
structured	_	_
as	_	_
follows	_	_
:	_	_
Section	_	_
II	_	_
presents	_	_
the	_	_
databases	_	_
used	_	_
in	_	_
the	_	_
experiments	_	_
;	_	_
Section	_	_
III	_	_
describes	_	_
the	_	_
baseline	_	_
methods	_	_
used	_	_
in	_	_
this	_	_
work	_	_
;	_	_
Section	_	_
IV	_	_
reports	_	_
our	_	_
experiments	_	_
and	_	_
discusses	_	_
our	_	_
results	_	_
;	_	_
Finally	_	_
,	_	_
Section	_	_
V	_	_
concludes	_	_
the	_	_
work	_	_
.	_	_

#63
II	_	_
.	_	_

#64
DATABASES	_	_
Six	_	_
databases	_	_
were	_	_
used	_	_
for	_	_
the	_	_
experiments	_	_
performed	_	_
in	_	_
this	_	_
work	_	_
:	_	_
IIIT-Delhi	_	_
Contact	_	_
Lens	_	_
Iris	_	_
(	_	_
IIIT-D	_	_
CLI	_	_
)	_	_
[	_	_
25	_	_
]	_	_
,	_	_
Notre	_	_
Dame	_	_
Contact	_	_
Lens	_	_
Detection	_	_
2015	_	_
(	_	_
NDCLD15	_	_
)	_	_
[	_	_
26	_	_
]	_	_
,	_	_
MobBIOfake	_	_
[	_	_
27	_	_
]	_	_
,	_	_
Notre	_	_
Dame	_	_
Cosmetic	_	_
Contact	_	_
Lenses	_	_
(	_	_
NDCCL	_	_
)	_	_
[	_	_
28	_	_
]	_	_
,	_	_
CASIA-IrisV3	_	_
Interval	_	_
[	_	_
29	_	_
]	_	_
and	_	_
BERC	_	_
mobile-iris	_	_
database	_	_
[	_	_
30	_	_
]	_	_
.	_	_

#65
Except	_	_
the	_	_
NDCLD15	_	_
,	_	_
all	_	_
other	_	_
databases	_	_
were	_	_
manually	_	_
annotated	_	_
from	_	_
a	_	_
single	_	_
annotator2	_	_
.	_	_

#66
The	_	_
NDCLD15	_	_
annotations	_	_
were	_	_
provided	_	_
by	_	_
the	_	_
database	_	_
authors	_	_
[	_	_
26	_	_
]	_	_
.	_	_

#67
Bellow	_	_
we	_	_
present	_	_
a	_	_
brief	_	_
description	_	_
of	_	_
these	_	_
databases	_	_
and	_	_
how	_	_
they	_	_
were	_	_
used	_	_
in	_	_
the	_	_
experiments	_	_
.	_	_

#68
IIIT-Delhi	_	_
Contact	_	_
Lens	_	_
Iris	_	_
:	_	_
The	_	_
IIIT-D	_	_
CLI	_	_
database	_	_
consists	_	_
of	_	_
6570	_	_
iris	_	_
images	_	_
of	_	_
101	_	_
individuals	_	_
.	_	_

#69
Three	_	_
classes	_	_
of	_	_
images	_	_
were	_	_
used	_	_
for	_	_
the	_	_
composition	_	_
of	_	_
the	_	_
database	_	_
:	_	_
individuals	_	_
who	_	_
are	_	_
not	_	_
using	_	_
contact	_	_
lenses	_	_
,	_	_
individuals	_	_
using	_	_
transparent	_	_
lenses	_	_
and	_	_
individuals	_	_
using	_	_
color	_	_
cosmetic	_	_
lenses	_	_
.	_	_

#70
In	_	_
order	_	_
to	_	_
study	_	_
the	_	_
effect	_	_
of	_	_
the	_	_
acquisition	_	_
device	_	_
,	_	_
iris	_	_
images	_	_
were	_	_
captured	_	_
using	_	_
two	_	_
sensors	_	_
:	_	_
Cogent	_	_
iris	_	_
sensor	_	_
and	_	_
VistaFA2E	_	_
single	_	_
iris	_	_
sensor	_	_
[	_	_
25	_	_
]	_	_
.	_	_

#71
For	_	_
the	_	_
training	_	_
set	_	_
,	_	_
1500	_	_
images	_	_
of	_	_
each	_	_
sensor	_	_
were	_	_
randomly	_	_
selected	_	_
.	_	_

#72
The	_	_
remaining	_	_
images	_	_
(	_	_
3570	_	_
)	_	_
were	_	_
used	_	_
to	_	_
compose	_	_
the	_	_
test	_	_
set	_	_
.	_	_

#73
All	_	_
images	_	_
have	_	_
resolution	_	_
of	_	_
640×480	_	_
pixels	_	_
and	_	_
were	_	_
manually	_	_
annotated	_	_
.	_	_

#74
Figure	_	_
2a	_	_
and	_	_
Figure	_	_
2b	_	_
show	_	_
,	_	_
respectively	_	_
,	_	_
examples	_	_
of	_	_
images	_	_
obtained	_	_
by	_	_
VistaFA2E	_	_
and	_	_
Cogent	_	_
sensors	_	_
.	_	_

#75
CASIA-IrisV3	_	_
Interval	_	_
-	_	_
This	_	_
database	_	_
consists	_	_
of	_	_
2639	_	_
iris	_	_
images	_	_
with	_	_
resolution	_	_
of	_	_
320	_	_
×	_	_
280	_	_
pixels	_	_
,	_	_
obtained	_	_
in	_	_
two	_	_
sections	_	_
.	_	_

#76
The	_	_
images	_	_
were	_	_
captured	_	_
with	_	_
their	_	_
own	_	_
developed	_	_
camera	_	_
and	_	_
an	_	_
example	_	_
can	_	_
be	_	_
seen	_	_
in	_	_
Figure	_	_
2f	_	_
.	_	_

#77
The	_	_
main	_	_
characteristic	_	_
of	_	_
this	_	_
database	_	_
is	_	_
that	_	_
a	_	_
circular	_	_
near-infrared	_	_
led	_	_
illumination	_	_
was	_	_
used	_	_
when	_	_
the	_	_
images	_	_
were	_	_
captured	_	_
,	_	_
thus	_	_
this	_	_
database	_	_
can	_	_
be	_	_
used	_	_
for	_	_
studies	_	_
on	_	_
the	_	_
detailing	_	_
of	_	_
1https	_	_
:	_	_
//github.com/Qingbao/iris	_	_
2The	_	_
iris	_	_
location	_	_
annotations	_	_
are	_	_
publicly	_	_
available	_	_
to	_	_
the	_	_
research	_	_
community	_	_
at	_	_
https	_	_
:	_	_
//web.inf.ufpr.br/vri/databases/iris-location-annotations/	_	_
(	_	_
a	_	_
)	_	_
IIIT-D	_	_
CLI	_	_
(	_	_
VistaFA2E	_	_
sensor	_	_
)	_	_
(	_	_
b	_	_
)	_	_
IIIT-D	_	_
CLI	_	_
(	_	_
Cogent	_	_
sensor	_	_
)	_	_
(	_	_
c	_	_
)	_	_
BERC	_	_
(	_	_
d	_	_
)	_	_
MobBIO	_	_
(	_	_
Fake	_	_
)	_	_
(	_	_
e	_	_
)	_	_
MobBIO	_	_
(	_	_
Real	_	_
)	_	_
(	_	_
f	_	_
)	_	_
CASIA-IrisV3	_	_
Interval	_	_
(	_	_
g	_	_
)	_	_
NDCCL	_	_
(	_	_
AD100	_	_
sensor	_	_
)	_	_
(	_	_
h	_	_
)	_	_
NDCCL	_	_
(	_	_
LG4000	_	_
sensor	_	_
)	_	_
(	_	_
i	_	_
)	_	_
NDCLD15	_	_
Figure	_	_
2	_	_
.	_	_

#78
Examples	_	_
of	_	_
images	_	_
from	_	_
the	_	_
databases	_	_
used	_	_
.	_	_

#79
texture	_	_
features	_	_
in	_	_
iris	_	_
images	_	_
[	_	_
29	_	_
]	_	_
.	_	_

#80
For	_	_
training	_	_
,	_	_
1500	_	_
images	_	_
were	_	_
randomly	_	_
selected	_	_
.	_	_

#81
The	_	_
remaining	_	_
images	_	_
were	_	_
used	_	_
for	_	_
testing	_	_
.	_	_

#82
Notre	_	_
Dame	_	_
Cosmetic	_	_
Contact	_	_
Lenses	_	_
-	_	_
The	_	_
images	_	_
from	_	_
the	_	_
NDCCL	_	_
database	_	_
have	_	_
resolution	_	_
of	_	_
640	_	_
×	_	_
480	_	_
pixels	_	_
and	_	_
were	_	_
captured	_	_
under	_	_
near-infrared	_	_
illumination	_	_
.	_	_

#83
Two	_	_
iris	_	_
cameras	_	_
were	_	_
used	_	_
:	_	_
IrisGuard	_	_
AD100	_	_
(	_	_
Figure	_	_
2g	_	_
and	_	_
IrisAccess	_	_
LG4000	_	_
sensor	_	_
(	_	_
Figure	_	_
2h	_	_
)	_	_
,	_	_
composing	_	_
two	_	_
subsets	_	_
.	_	_

#84
The	_	_
IrisAccess	_	_
LG4000	_	_
subset	_	_
has	_	_
a	_	_
training	_	_
set	_	_
with	_	_
3000	_	_
images	_	_
and	_	_
a	_	_
test	_	_
set	_	_
of	_	_
1200	_	_
images	_	_
.	_	_

#85
IrisGuard	_	_
AD100	_	_
subset	_	_
has	_	_
600	_	_
images	_	_
for	_	_
training	_	_
and	_	_
300	_	_
for	_	_
testing	_	_
[	_	_
31	_	_
]	_	_
,	_	_
[	_	_
32	_	_
]	_	_
.	_	_

#86
The	_	_
database	_	_
contains	_	_
images	_	_
of	_	_
individuals	_	_
divided	_	_
into	_	_
three	_	_
classes	_	_
:	_	_
no	_	_
contact	_	_
lenses	_	_
,	_	_
non-textured	_	_
contact	_	_
lenses	_	_
and	_	_
textured	_	_
contact	_	_
lenses	_	_
.	_	_

#87
MobBIOfake	_	_
-	_	_
The	_	_
MobBIOfake	_	_
database	_	_
was	_	_
created	_	_
with	_	_
the	_	_
purpose	_	_
of	_	_
studying	_	_
the	_	_
liveliness	_	_
detection	_	_
in	_	_
iris	_	_
images	_	_
obtained	_	_
from	_	_
mobile	_	_
devices	_	_
in	_	_
uncontrolled	_	_
environments	_	_
[	_	_
27	_	_
]	_	_
.	_	_

#88
This	_	_
database	_	_
is	_	_
composed	_	_
of	_	_
1600	_	_
fake	_	_
iris	_	_
images	_	_
of	_	_
250	_	_
×	_	_
200	_	_
pixels	_	_
,	_	_
obtained	_	_
from	_	_
a	_	_
subset	_	_
of	_	_
800	_	_
images	_	_
belonging	_	_
to	_	_
the	_	_
MobBIO	_	_
database	_	_
[	_	_
33	_	_
]	_	_
.	_	_

#89
For	_	_
the	_	_
creation	_	_
of	_	_
the	_	_
fake	_	_
images	_	_
,	_	_
the	_	_
original	_	_
images	_	_
were	_	_
grouped	_	_
by	_	_
each	_	_
subject	_	_
and	_	_
a	_	_
pre-processing	_	_
was	_	_
performed	_	_
in	_	_
order	_	_
to	_	_
improve	_	_
the	_	_
contrast	_	_
.	_	_

#90
The	_	_
images	_	_
were	_	_
then	_	_
printed	_	_
using	_	_
a	_	_
professional	_	_
printer	_	_
in	_	_
a	_	_
high	_	_
quality	_	_
photo	_	_
paper	_	_
and	_	_
recaptured	_	_
using	_	_
the	_	_
same	_	_
device	_	_
.	_	_

#91
Finally	_	_
,	_	_
the	_	_
images	_	_
were	_	_
cropped	_	_
and	_	_
resized	_	_
to	_	_
unify	_	_
the	_	_
dimensions	_	_
.	_	_

#92
The	_	_
database	_	_
is	_	_
equally	_	_
divided	_	_
into	_	_
training	_	_
and	_	_
test	_	_
sets	_	_
,	_	_
in	_	_
other	_	_
words	_	_
,	_	_
400	_	_
real	_	_
images	_	_
and	_	_
400	_	_
fake	_	_
images	_	_
were	_	_
destined	_	_
for	_	_
the	_	_
training	_	_
sets	_	_
.	_	_

#93
Figure	_	_
2d	_	_
and	_	_
Figure	_	_
2e	_	_
are	_	_
examples	_	_
of	_	_
fake	_	_
and	_	_
real	_	_
images	_	_
,	_	_
respectively	_	_
.	_	_

#94
Notre	_	_
Dame	_	_
Contact	_	_
Lens	_	_
Detection	_	_
2015	_	_
-	_	_
The	_	_
NDCLD15	_	_
database	_	_
is	_	_
composed	_	_
of	_	_
7300	_	_
iris	_	_
images	_	_
with	_	_
resolution	_	_
of	_	_
640×	_	_
480	_	_
pixels	_	_
.	_	_

#95
This	_	_
database	_	_
is	_	_
composed	_	_
of	_	_
6000	_	_
images	_	_
for	_	_
training	_	_
and	_	_
1300	_	_
images	_	_
for	_	_
evaluation	_	_
.	_	_

#96
Images	_	_
were	_	_
acquired	_	_
using	_	_
either	_	_
IrisAccess	_	_
LG4000	_	_
sensor	_	_
or	_	_
Iris-Guard	_	_
AD100	_	_
sensor	_	_
.	_	_

#97
All	_	_
iris	_	_
images	_	_
were	_	_
captured	_	_
in	_	_
a	_	_
windowless	_	_
indoor	_	_
lab	_	_
under	_	_
consistent	_	_
lighting	_	_
conditions	_	_
.	_	_

#98
This	_	_
database	_	_
was	_	_
created	_	_
with	_	_
the	_	_
purpose	_	_
of	_	_
studying	_	_
the	_	_
classification	_	_
of	_	_
iris	_	_
images	_	_
between	_	_
types	_	_
of	_	_
contact	_	_
lenses	_	_
[	_	_
26	_	_
]	_	_
.	_	_

#99
Therefore	_	_
,	_	_
the	_	_
database	_	_
contains	_	_
images	_	_
of	_	_
individuals	_	_
divided	_	_
into	_	_
three	_	_
classes	_	_
:	_	_
no	_	_
contact	_	_
lenses	_	_
,	_	_
non-textured	_	_
contact	_	_
lenses	_	_
and	_	_
textured	_	_
contact	_	_
lenses	_	_
.	_	_

#100
An	_	_
example	_	_
image	_	_
of	_	_
this	_	_
database	_	_
can	_	_
be	_	_
seen	_	_
in	_	_
Figure	_	_
2i	_	_
.	_	_

#101
BERC	_	_
Mobile-iris	_	_
Database	_	_
-	_	_
The	_	_
BERC	_	_
database	_	_
is	_	_
composed	_	_
of	_	_
images	_	_
obtained	_	_
in	_	_
near-infrared	_	_
wavelength	_	_
with	_	_
a	_	_
resolution	_	_
of	_	_
1280×960	_	_
pixels	_	_
.	_	_

#102
The	_	_
images	_	_
were	_	_
captured	_	_
by	_	_
a	_	_
mobile	_	_
device	_	_
under	_	_
vertical	_	_
position	_	_
,	_	_
in	_	_
sequences	_	_
composed	_	_
of	_	_
90	_	_
images	_	_
[	_	_
30	_	_
]	_	_
.	_	_

#103
In	_	_
order	_	_
to	_	_
simulate	_	_
the	_	_
situation	_	_
where	_	_
the	_	_
user	_	_
moves	_	_
the	_	_
mobile	_	_
phone	_	_
back	_	_
and	_	_
forth	_	_
to	_	_
adjust	_	_
the	_	_
focus	_	_
,	_	_
the	_	_
sequences	_	_
of	_	_
images	_	_
were	_	_
obtained	_	_
by	_	_
moving	_	_
the	_	_
mobile	_	_
phone	_	_
to	_	_
the	_	_
iris	_	_
at	_	_
3	_	_
distances	_	_
:	_	_
40	_	_
to	_	_
15	_	_
cm	_	_
,	_	_
15	_	_
to	_	_
25	_	_
cm	_	_
and	_	_
25	_	_
to	_	_
15	_	_
cm	_	_
.	_	_

#104
The	_	_
best	_	_
images	_	_
of	_	_
each	_	_
sequence	_	_
were	_	_
selected	_	_
,	_	_
totaling	_	_
500	_	_
iris	_	_
images	_	_
of	_	_
100	_	_
subjects	_	_
.	_	_

#105
An	_	_
example	_	_
image	_	_
of	_	_
this	_	_
database	_	_
can	_	_
be	_	_
seen	_	_
in	_	_
Figure	_	_
2c	_	_
.	_	_

#106
In	_	_
this	_	_
database	_	_
,	_	_
400	_	_
images	_	_
were	_	_
randomly	_	_
selected	_	_
for	_	_
training	_	_
and	_	_
100	_	_
for	_	_
testing	_	_
.	_	_

#107
III	_	_
.	_	_

#108
BASELINES	_	_
In	_	_
this	_	_
work	_	_
,	_	_
we	_	_
use	_	_
two	_	_
approaches	_	_
to	_	_
perform	_	_
iris	_	_
location	_	_
.	_	_

#109
One	_	_
of	_	_
them	_	_
is	_	_
based	_	_
on	_	_
HOG	_	_
and	_	_
SVM	_	_
,	_	_
which	_	_
is	_	_
an	_	_
adaptation	_	_
of	_	_
the	_	_
human	_	_
detection	_	_
method	_	_
proposed	_	_
by	_	_
Dalal	_	_
&	_	_
Triggs	_	_
[	_	_
22	_	_
]	_	_
.	_	_

#110
We	_	_
use	_	_
this	_	_
approach	_	_
together	_	_
with	_	_
the	_	_
sliding	_	_
window	_	_
technique	_	_
presented	_	_
on	_	_
the	_	_
face	_	_
detection	_	_
method	_	_
,	_	_
proposed	_	_
by	_	_
Viola	_	_
&	_	_
Jones	_	_
[	_	_
34	_	_
]	_	_
,	_	_
[	_	_
35	_	_
]	_	_
.	_	_

#111
The	_	_
other	_	_
approach	_	_
is	_	_
based	_	_
on	_	_
deep	_	_
learning	_	_
,	_	_
using	_	_
YOLO	_	_
CNNs	_	_
[	_	_
23	_	_
]	_	_
.	_	_

#112
A.	_	_
Histogram	_	_
of	_	_
Oriented	_	_
Gradients	_	_
and	_	_
Support	_	_
Vector	_	_
Machines	_	_
Despite	_	_
image	_	_
acquisition	_	_
with	_	_
different	_	_
devices	_	_
,	_	_
lighting	_	_
conditions	_	_
,	_	_
variations	_	_
of	_	_
translation	_	_
,	_	_
rotation	_	_
and	_	_
scale	_	_
[	_	_
2	_	_
]	_	_
,	_	_
the	_	_
iris	_	_
presents	_	_
a	_	_
common	_	_
structure	_	_
,	_	_
following	_	_
patterns	_	_
of	_	_
texture	_	_
,	_	_
shape	_	_
and	_	_
edge	_	_
orientations	_	_
,	_	_
which	_	_
can	_	_
be	_	_
described	_	_
by	_	_
a	_	_
feature	_	_
descriptor	_	_
and	_	_
interpreted	_	_
by	_	_
a	_	_
classifier	_	_
.	_	_

#113
HOG	_	_
is	_	_
a	_	_
feature	_	_
descriptor	_	_
used	_	_
in	_	_
computer	_	_
vision	_	_
for	_	_
object	_	_
detection	_	_
.	_	_

#114
This	_	_
method	_	_
quantizes	_	_
the	_	_
gradient	_	_
orientation	_	_
occurrences	_	_
in	_	_
regions	_	_
of	_	_
an	_	_
image	_	_
,	_	_
extracting	_	_
shape	_	_
information	_	_
from	_	_
objects	_	_
[	_	_
22	_	_
]	_	_
.	_	_

#115
Figure	_	_
3	_	_
illustrates	_	_
an	_	_
image	_	_
described	_	_
by	_	_
HOG	_	_
.	_	_

#116
In	_	_
this	_	_
work	_	_
,	_	_
each	_	_
window	_	_
was	_	_
divided	_	_
into	_	_
cells	_	_
of	_	_
8×	_	_
8	_	_
pixels	_	_
.	_	_

#117
For	_	_
each	_	_
cell	_	_
,	_	_
the	_	_
horizontal	_	_
and	_	_
vertical	_	_
gradients	_	_
in	_	_
all	_	_
pixels	_	_
are	_	_
calculated	_	_
.	_	_

#118
Thus	_	_
,	_	_
the	_	_
orientations	_	_
and	_	_
magnitudes	_	_
of	_	_
the	_	_
gradient	_	_
are	_	_
obtained	_	_
.	_	_

#119
The	_	_
gradient	_	_
orientations	_	_
are	_	_
then	_	_
quantified	_	_
in	_	_
nine	_	_
directions	_	_
.	_	_

#120
In	_	_
order	_	_
to	_	_
avoid	_	_
effects	_	_
of	_	_
light	_	_
and	_	_
contrast	_	_
variation	_	_
,	_	_
the	_	_
histograms	_	_
of	_	_
all	_	_
cells	_	_
on	_	_
blocks	_	_
(	_	_
2×	_	_
2	_	_
cells	_	_
)	_	_
are	_	_
normalized	_	_
.	_	_

#121
The	_	_
HOG	_	_
feature	_	_
vector	_	_
that	_	_
describes	_	_
each	_	_
iris	_	_
window	_	_
is	_	_
then	_	_
Figure	_	_
3	_	_
.	_	_

#122
Exemple	_	_
of	_	_
image	_	_
described	_	_
by	_	_
HOG	_	_
.	_	_

#123
constructed	_	_
by	_	_
concatenating	_	_
the	_	_
normalized	_	_
cell	_	_
histograms	_	_
for	_	_
all	_	_
blocks	_	_
.	_	_

#124
Finally	_	_
,	_	_
a	_	_
feature	_	_
vector	_	_
(	_	_
2×2	_	_
blocks	_	_
×	_	_
8	_	_
cells	_	_
×	_	_
9	_	_
orientations	_	_
)	_	_
is	_	_
obtained	_	_
to	_	_
describe	_	_
each	_	_
iris	_	_
candidate	_	_
window	_	_
.	_	_

#125
The	_	_
window	_	_
containing	_	_
the	_	_
iris	_	_
region	_	_
(	_	_
ground	_	_
truth	_	_
)	_	_
from	_	_
each	_	_
training	_	_
image	_	_
is	_	_
extracted	_	_
and	_	_
used	_	_
to	_	_
compose	_	_
the	_	_
examples	_	_
of	_	_
positive	_	_
windows	_	_
.	_	_

#126
Furthermore	_	_
,	_	_
windows	_	_
that	_	_
are	_	_
completely	_	_
outside	_	_
or	_	_
have	_	_
only	_	_
a	_	_
small	_	_
intersection	_	_
with	_	_
the	_	_
iris	_	_
region	_	_
are	_	_
extracted	_	_
and	_	_
considered	_	_
negative	_	_
windows	_	_
.	_	_

#127
We	_	_
created	_	_
10	_	_
negative	_	_
windows	_	_
for	_	_
each	_	_
positive	_	_
window	_	_
.	_	_

#128
Figures	_	_
4a	_	_
and	_	_
4b	_	_
illustrate	_	_
,	_	_
respectively	_	_
,	_	_
positive	_	_
and	_	_
negative	_	_
samples	_	_
used	_	_
for	_	_
the	_	_
training	_	_
of	_	_
the	_	_
proposed	_	_
approach	_	_
.	_	_

#129
(	_	_
a	_	_
)	_	_
Positive	_	_
samples	_	_
(	_	_
b	_	_
)	_	_
Negative	_	_
samples	_	_
Figure	_	_
4	_	_
.	_	_

#130
Training	_	_
samples	_	_
used	_	_
by	_	_
SVM	_	_
.	_	_

#131
From	_	_
these	_	_
positive	_	_
and	_	_
negative	_	_
samples	_	_
,	_	_
the	_	_
SVM	_	_
classifier	_	_
is	_	_
trained	_	_
using	_	_
a	_	_
linear	_	_
kernel	_	_
and	_	_
the	_	_
constant	_	_
is	_	_
determined	_	_
by	_	_
grid-search	_	_
in	_	_
the	_	_
training	_	_
set	_	_
.	_	_

#132
The	_	_
SVM	_	_
was	_	_
first	_	_
presented	_	_
by	_	_
Vladimir	_	_
Vapknik	_	_
[	_	_
36	_	_
]	_	_
,	_	_
and	_	_
is	_	_
one	_	_
of	_	_
the	_	_
most	_	_
used	_	_
classification	_	_
methods	_	_
in	_	_
recent	_	_
years	_	_
[	_	_
37	_	_
]	_	_
,	_	_
[	_	_
38	_	_
]	_	_
.	_	_

#133
To	_	_
find	_	_
the	_	_
decision	_	_
boundary	_	_
,	_	_
the	_	_
SVM	_	_
minimizes	_	_
the	_	_
upper	_	_
limit	_	_
of	_	_
the	_	_
generalization	_	_
error	_	_
,	_	_
which	_	_
is	_	_
obtained	_	_
by	_	_
maximizing	_	_
the	_	_
margin	_	_
distance	_	_
from	_	_
the	_	_
training	_	_
data	_	_
.	_	_

#134
In	_	_
order	_	_
to	_	_
perform	_	_
the	_	_
iris	_	_
location	_	_
,	_	_
a	_	_
sliding	_	_
window	_	_
approach	_	_
with	_	_
different	_	_
scales	_	_
is	_	_
applied	_	_
in	_	_
each	_	_
test	_	_
image	_	_
.	_	_

#135
We	_	_
adopted	_	_
windows	_	_
with	_	_
size	_	_
50	_	_
×	_	_
50	_	_
pixels	_	_
as	_	_
canonical	_	_
scale	_	_
.	_	_

#136
From	_	_
this	_	_
scale	_	_
,	_	_
we	_	_
used	_	_
6	_	_
lower	_	_
scales	_	_
and	_	_
8	_	_
higher	_	_
scales	_	_
by	_	_
a	_	_
factor	_	_
of	_	_
5	_	_
%	_	_
.	_	_

#137
The	_	_
image	_	_
region	_	_
that	_	_
presents	_	_
the	_	_
greatest	_	_
similarity	_	_
with	_	_
the	_	_
iris	_	_
can	_	_
be	_	_
found	_	_
through	_	_
the	_	_
decision	_	_
border	_	_
generated	_	_
by	_	_
the	_	_
SVM	_	_
,	_	_
which	_	_
will	_	_
return	_	_
the	_	_
highest	_	_
positive	_	_
response	_	_
for	_	_
the	_	_
best	_	_
estimated	_	_
iris	_	_
location	_	_
.	_	_

#138
B.	_	_
YOLO	_	_
Object	_	_
Detector	_	_
Currently	_	_
,	_	_
deep	_	_
CNNs	_	_
are	_	_
one	_	_
of	_	_
the	_	_
most	_	_
efficient	_	_
ways	_	_
to	_	_
perform	_	_
image	_	_
classification	_	_
,	_	_
segmentation	_	_
and	_	_
object	_	_
detection	_	_
.	_	_

#139
In	_	_
this	_	_
work	_	_
,	_	_
we	_	_
use	_	_
the	_	_
Darknet	_	_
[	_	_
39	_	_
]	_	_
,	_	_
which	_	_
is	_	_
an	_	_
open	_	_
source	_	_
neural	_	_
network	_	_
framework	_	_
used	_	_
to	_	_
implement	_	_
YOLO	_	_
,	_	_
a	_	_
state-of-the-art	_	_
real-time	_	_
object	_	_
detection	_	_
system	_	_
[	_	_
23	_	_
]	_	_
.	_	_

#140
The	_	_
YOLO	_	_
network	_	_
,	_	_
as	_	_
most	_	_
CNNs	_	_
,	_	_
is	_	_
composed	_	_
of	_	_
three	_	_
main	_	_
operation	_	_
layers	_	_
to	_	_
object	_	_
detection	_	_
,	_	_
which	_	_
are	_	_
:	_	_
convolution	_	_
,	_	_
max	_	_
pooling	_	_
and	_	_
classification	_	_
,	_	_
the	_	_
latter	_	_
occurs	_	_
through	_	_
fully	_	_
connected	_	_
layers	_	_
.	_	_

#141
On	_	_
Darknet	_	_
,	_	_
convolutional	_	_
layers	_	_
work	_	_
as	_	_
feature	_	_
extraction	_	_
,	_	_
in	_	_
other	_	_
words	_	_
,	_	_
a	_	_
convolutional	_	_
kernel	_	_
is	_	_
sliding	_	_
in	_	_
the	_	_
input	_	_
image	_	_
.	_	_

#142
The	_	_
network	_	_
architecture	_	_
is	_	_
inspired	_	_
by	_	_
the	_	_
GoogLeNet	_	_
model	_	_
for	_	_
image	_	_
classification	_	_
[	_	_
40	_	_
]	_	_
.	_	_

#143
The	_	_
original	_	_
YOLO	_	_
has	_	_
24	_	_
convolutional	_	_
layers	_	_
that	_	_
produce	_	_
different	_	_
feature	_	_
maps	_	_
from	_	_
the	_	_
input	_	_
.	_	_

#144
The	_	_
feature	_	_
maps	_	_
are	_	_
then	_	_
processed	_	_
by	_	_
max	_	_
pooling	_	_
layers	_	_
,	_	_
which	_	_
dimensionally	_	_
reduces	_	_
the	_	_
previously	_	_
obtained	_	_
feature	_	_
map	_	_
.	_	_

#145
max	_	_
pooling	_	_
divides	_	_
the	_	_
feature	_	_
map	_	_
into	_	_
blocks	_	_
and	_	_
reduces	_	_
each	_	_
block	_	_
into	_	_
one	_	_
value	_	_
.	_	_

#146
Instead	_	_
of	_	_
the	_	_
inception	_	_
modules	_	_
used	_	_
by	_	_
GoogLeNet	_	_
,	_	_
YOLO	_	_
uses	_	_
1	_	_
×	_	_
1	_	_
reduction	_	_
layers	_	_
followed	_	_
by	_	_
3	_	_
×	_	_
3	_	_
convolutional	_	_
layers	_	_
,	_	_
similar	_	_
to	_	_
Lin	_	_
et	_	_
al.	_	_
[	_	_
41	_	_
]	_	_
.	_	_

#147
However	_	_
,	_	_
in	_	_
this	_	_
work	_	_
we	_	_
use	_	_
an	_	_
fast	_	_
version	_	_
of	_	_
YOLO	_	_
,	_	_
based	_	_
on	_	_
a	_	_
neural	_	_
network	_	_
with	_	_
fewer	_	_
convolutional	_	_
layers	_	_
(	_	_
9	_	_
instead	_	_
of	_	_
24	_	_
)	_	_
and	_	_
fewer	_	_
filters	_	_
in	_	_
those	_	_
layers	_	_
.	_	_

#148
Other	_	_
than	_	_
the	_	_
size	_	_
of	_	_
the	_	_
network	_	_
,	_	_
all	_	_
training	_	_
and	_	_
testing	_	_
parameters	_	_
are	_	_
the	_	_
same	_	_
for	_	_
both	_	_
YOLO	_	_
and	_	_
Fast-YOLO	_	_
.	_	_

#149
IV	_	_
.	_	_

#150
RESULTS	_	_
AND	_	_
DISCUSSION	_	_
In	_	_
this	_	_
work	_	_
,	_	_
we	_	_
evaluate	_	_
both	_	_
HOG-SVM	_	_
and	_	_
YOLO	_	_
approaches	_	_
,	_	_
applied	_	_
to	_	_
iris	_	_
location	_	_
and	_	_
compare	_	_
them	_	_
to	_	_
the	_	_
well-known	_	_
Daugman	_	_
method	_	_
.	_	_

#151
The	_	_
experiments	_	_
were	_	_
performed	_	_
in	_	_
the	_	_
six	_	_
databases	_	_
described	_	_
in	_	_
Section	_	_
II	_	_
.	_	_

#152
All	_	_
experiments	_	_
were	_	_
performed	_	_
on	_	_
a	_	_
NVIDIA	_	_
Titan	_	_
XP	_	_
GPU	_	_
(	_	_
3840	_	_
CUDA	_	_
cores	_	_
and	_	_
12	_	_
GB	_	_
of	_	_
RAM	_	_
)	_	_
and	_	_
also	_	_
using	_	_
an	_	_
Intel	_	_
(	_	_
R	_	_
)	_	_
Core	_	_
i7-5820K	_	_
CPU	_	_
@	_	_
3.30GHz	_	_
12	_	_
core	_	_
,	_	_
64GB	_	_
of	_	_
DDR4	_	_
RAM	_	_
.	_	_

#153
In	_	_
order	_	_
to	_	_
analyze	_	_
the	_	_
experiments	_	_
,	_	_
we	_	_
employ	_	_
the	_	_
following	_	_
metrics	_	_
:	_	_
Recall	_	_
,	_	_
Precision	_	_
,	_	_
Accuracy	_	_
and	_	_
Intersection	_	_
over	_	_
Union	_	_
(	_	_
IoU	_	_
)	_	_
.	_	_

#154
These	_	_
metrics	_	_
are	_	_
defined	_	_
between	_	_
the	_	_
area	_	_
of	_	_
the	_	_
ground	_	_
truth	_	_
and	_	_
predicted	_	_
bounding	_	_
boxes	_	_
in	_	_
terms	_	_
of	_	_
False	_	_
Positives	_	_
(	_	_
FP	_	_
)	_	_
,	_	_
False	_	_
Negatives	_	_
(	_	_
FN	_	_
)	_	_
,	_	_
True	_	_
Positives	_	_
(	_	_
TP	_	_
)	_	_
,	_	_
and	_	_
True	_	_
Negatives	_	_
(	_	_
TN	_	_
)	_	_
pixels	_	_
,	_	_
and	_	_
can	_	_
formally	_	_
be	_	_
expressed	_	_
as	_	_
:	_	_
Recall	_	_
=	_	_
TP	_	_
TP	_	_
+	_	_
FN	_	_
,	_	_
Precision	_	_
=	_	_
TP	_	_
TP	_	_
+	_	_
FP	_	_
,	_	_
Accuracy	_	_
=	_	_
TP	_	_
+	_	_
TN	_	_
TP	_	_
+	_	_
TN	_	_
+	_	_
FP	_	_
+	_	_
FN	_	_
,	_	_
IoU	_	_
=	_	_
TP	_	_
FP	_	_
+	_	_
TP	_	_
+	_	_
FN	_	_
In	_	_
the	_	_
following	_	_
,	_	_
we	_	_
describe	_	_
experiments	_	_
in	_	_
three	_	_
different	_	_
scenarios	_	_
:	_	_
intra-sensor	_	_
,	_	_
inter-sensor	_	_
,	_	_
multiple-sensors	_	_
and	_	_
mixing	_	_
of	_	_
databases	_	_
.	_	_

#155
Intra-sensor	_	_
:	_	_
Table	_	_
I	_	_
shows	_	_
the	_	_
results	_	_
obtained	_	_
by	_	_
intra-sensor	_	_
experiments	_	_
,	_	_
in	_	_
other	_	_
words	_	_
,	_	_
experiments	_	_
in	_	_
which	_	_
the	_	_
models	_	_
were	_	_
trained	_	_
and	_	_
tested	_	_
with	_	_
images	_	_
from	_	_
the	_	_
same	_	_
sensor	_	_
.	_	_

#156
The	_	_
YOLO	_	_
CNN	_	_
achieved	_	_
the	_	_
best	_	_
averages	_	_
in	_	_
almost	_	_
all	_	_
analyzed	_	_
metrics	_	_
and	_	_
required	_	_
less	_	_
processing	_	_
time	_	_
for	_	_
iris	_	_
location	_	_
per	_	_
image	_	_
.	_	_

#157
The	_	_
exception	_	_
is	_	_
for	_	_
CASIA	_	_
IrisV3	_	_
Interval	_	_
database	_	_
where	_	_
Daugman	_	_
method	_	_
presented	_	_
slightly	_	_
better	_	_
Precision	_	_
(	_	_
96.23	_	_
%	_	_
against	_	_
96.02	_	_
%	_	_
)	_	_
and	_	_
Accuracy	_	_
(	_	_
97.38	_	_
%	_	_
against	_	_
97.10	_	_
%	_	_
)	_	_
.	_	_

#158
This	_	_
surprising	_	_
result	_	_
can	_	_
be	_	_
explained	_	_
by	_	_
the	_	_
high	_	_
level	_	_
of	_	_
cooperation	_	_
and	_	_
control	_	_
in	_	_
the	_	_
image	_	_
acquisition	_	_
of	_	_
such	_	_
database	_	_
.	_	_

#159
That	_	_
is	_	_
,	_	_
the	_	_
Daugman	_	_
method	_	_
take	_	_
somehow	_	_
advantage	_	_
of	_	_
the	_	_
scenario	_	_
.	_	_

#160
Anyway	_	_
,	_	_
the	_	_
YOLO	_	_
CNN	_	_
locates	_	_
the	_	_
iris	_	_
in	_	_
real-time	_	_
(	_	_
0.02	_	_
seconds	_	_
per	_	_
image	_	_
,	_	_
on	_	_
average	_	_
)	_	_
using	_	_
our	_	_
fast	_	_
Titan	_	_
XP	_	_
GPU	_	_
,	_	_
whilst	_	_
the	_	_
Daugman	_	_
method	_	_
and	_	_
the	_	_
HOG-SVM	_	_
approach	_	_
demand	_	_
,	_	_
on	_	_
average	_	_
,	_	_
3.5	_	_
and	_	_
5.2	_	_
seconds	_	_
,	_	_
respectively	_	_
,	_	_
to	_	_
locate	_	_
the	_	_
iris	_	_
in	_	_
each	_	_
image	_	_
using	_	_
a	_	_
single	_	_
CPU	_	_
core	_	_
.	_	_

#161
Inter-sensor	_	_
:	_	_
In	_	_
addition	_	_
,	_	_
for	_	_
databases	_	_
containing	_	_
images	_	_
acquired	_	_
with	_	_
more	_	_
than	_	_
one	_	_
sensor	_	_
,	_	_
inter-sensor	_	_
experiments	_	_
were	_	_
performed	_	_
and	_	_
are	_	_
presented	_	_
in	_	_
Table	_	_
II	_	_
.	_	_

#162
That	_	_
is	_	_
,	_	_
we	_	_
train	_	_
the	_	_
detectors	_	_
with	_	_
images	_	_
of	_	_
one	_	_
sensor	_	_
and	_	_
test/evaluate	_	_
then	_	_
on	_	_
the	_	_
images	_	_
from	_	_
other	_	_
sensor	_	_
.	_	_

#163
These	_	_
experiments	_	_
show	_	_
that	_	_
in	_	_
some	_	_
cases	_	_
YOLO	_	_
CNN	_	_
did	_	_
not	_	_
achieve	_	_
promising	_	_
results	_	_
as	_	_
previously	_	_
shown	_	_
.	_	_

#164
For	_	_
example	_	_
,	_	_
in	_	_
the	_	_
database	_	_
NDCCL	_	_
,	_	_
when	_	_
fine	_	_
tunning/training	_	_
the	_	_
detector	_	_
with	_	_
images	_	_
from	_	_
the	_	_
AD100	_	_
sensor	_	_
and	_	_
testing	_	_
with	_	_
the	_	_
ones	_	_
from	_	_
LG4000	_	_
sensor	_	_
.	_	_

#165
The	_	_
reason	_	_
for	_	_
the	_	_
poor	_	_
result	_	_
might	speculation	_
lie	_	_
in	_	_
the	_	_
fact	_	_
that	_	_
the	_	_
database	_	_
for	_	_
that	_	_
specific	_	_
sensor	_	_
(	_	_
AD100	_	_
)	_	_
has	_	_
only	_	_
600	_	_
images	_	_
,	_	_
thus	_	_
not	_	_
allowing	_	_
a	_	_
good	_	_
generalization	_	_
of	_	_
the	_	_
trained	_	_
CNN	_	_
.	_	_

#166
In	_	_
Figure	_	_
5a	_	_
,	_	_
we	_	_
can	_	_
observe	_	_
some	_	_
examples	_	_
where	_	_
the	_	_
iris	_	_
location	_	_
obtained	_	_
by	_	_
the	_	_
YOLO	_	_
method	_	_
did	_	_
not	_	_
achieved	_	_
good	_	_
results	_	_
.	_	_

#167
Multiple-sensors	_	_
:	_	_
In	_	_
order	_	_
to	_	_
better	_	_
analyze	_	_
and	_	_
understand	_	_
the	_	_
results	_	_
of	_	_
the	_	_
inter-sensor	_	_
experiments	_	_
and	_	_
to	_	_
confirm	_	_
our	_	_
hypothesis	_	_
that	_	_
the	_	_
YOLO’s	_	_
poor	_	_
performance	_	_
is	_	_
due	_	_
to	_	_
few/homogeneous	_	_
training	_	_
samples	_	_
,	_	_
experiments	_	_
were	_	_
performed	_	_
combining	_	_
images	_	_
from	_	_
multiple	_	_
sensors	_	_
of	_	_
the	_	_
same	_	_
databases	_	_
.	_	_

#168
The	_	_
figures	_	_
obtained	_	_
in	_	_
this	_	_
new	_	_
experiment	_	_
can	_	_
be	_	_
seen	_	_
in	_	_
Table	_	_
III	_	_
.	_	_

#169
It	_	_
highlights	_	_
the	_	_
importance	_	_
of	_	_
a	_	_
diverse	_	_
collection	_	_
of	_	_
images	_	_
for	_	_
the	_	_
training	_	_
set	_	_
in	_	_
CNNs	_	_
.	_	_

#170
With	_	_
a	_	_
larger	_	_
number	_	_
of	_	_
images	_	_
acquired	_	_
from	_	_
different	_	_
sensors	_	_
in	_	_
the	_	_
training	_	_
set	_	_
,	_	_
the	_	_
CNN	_	_
was	_	_
able	_	_
to	_	_
better	_	_
generalize	_	_
,	_	_
increasing	_	_
the	_	_
correct	_	_
iris	_	_
location	_	_
in	_	_
most	_	_
cases	_	_
.	_	_

#171
Some	_	_
examples	_	_
of	_	_
good	_	_
iris	_	_
location	_	_
can	_	_
be	_	_
seen	_	_
in	_	_
Figure	_	_
5b	_	_
.	_	_

#172
0	_	_
10	_	_
20	_	_
30	_	_
40	_	_
50	_	_
60	_	_
70	_	_
80	_	_
90	_	_
100	_	_
Recall	_	_
(	_	_
%	_	_
)	_	_
Im	_	_
a	_	_
g	_	_
e	_	_
s	_	_
(	_	_
%	_	_
)	_	_
Daugman	_	_
Method	_	_
Darknet	_	_
YOLO	_	_
Figure	_	_
6	_	_
.	_	_

#173
Recall	_	_
curve	_	_
of	_	_
both	_	_
Daugman	_	_
and	_	_
YOLO	_	_
methods	_	_
applied	_	_
to	_	_
all	_	_
test	_	_
sets	_	_
.	_	_

#174
Mixing	_	_
databases	_	_
:	_	_
Table	_	_
IV	_	_
contains	_	_
the	_	_
results	_	_
obtained	_	_
by	_	_
experiments	_	_
where	_	_
YOLO	_	_
was	_	_
trained	_	_
with	_	_
the	_	_
training	_	_
sets	_	_
of	_	_
all	_	_
the	_	_
databases	_	_
and	_	_
tested	_	_
in	_	_
the	_	_
test	_	_
images	_	_
of	_	_
all	_	_
the	_	_
databases	_	_
.	_	_

#175
The	_	_
results	_	_
achieved	_	_
by	_	_
the	_	_
Daugman	_	_
method	_	_
applied	_	_
to	_	_
all	_	_
the	_	_
test	_	_
images	_	_
are	_	_
also	_	_
presented	_	_
,	_	_
and	_	_
we	_	_
used	_	_
specific	_	_
parameters	_	_
for	_	_
each	_	_
database	_	_
.	_	_

#176
By	_	_
analyzing	_	_
these	_	_
figures	_	_
,	_	_
we	_	_
observe	_	_
that	_	_
YOLO	_	_
strikingly	_	_
outperforms	_	_
the	_	_
Daugman	_	_
method	_	_
in	_	_
all	_	_
analyzed	_	_
metrics	_	_
.	_	_

#177
Figure	_	_
6	_	_
shows	_	_
the	_	_
behavior	_	_
of	_	_
the	_	_
recall	_	_
curve	_	_
for	_	_
the	_	_
experiment	_	_
reported	_	_
in	_	_
Table	_	_
IV	_	_
.	_	_

#178
It	_	_
depicts	_	_
how	_	_
the	_	_
percentage	_	_
of	_	_
images	_	_
varies	_	_
when	_	_
we	_	_
required	_	_
a	_	_
minimum	_	_
Recall	_	_
rate	_	_
.	_	_

#179
These	_	_
curve	_	_
highlights	_	_
how	_	_
YOLO	_	_
is	_	_
a	_	_
promising	_	_
alternative	_	_
to	_	_
iris	_	_
location	_	_
,	_	_
since	_	_
all	_	_
tested	_	_
images	_	_
achieved	_	_
Recall	_	_
values	_	_
above	_	_
80	_	_
%	_	_
.	_	_

#180
That	_	_
is	_	_
,	_	_
at	_	_
least	_	_
80	_	_
%	_	_
of	_	_
the	_	_
required	_	_
region	_	_
of	_	_
a	_	_
iris	_	_
is	_	_
certainly	_	_
located	_	_
by	_	_
the	_	_
YOLO	_	_
detector	_	_
.	_	_

#181
V.	_	_
CONCLUSION	_	_
The	_	_
iris	_	_
location	_	_
is	_	_
a	_	_
preliminary	_	_
but	_	_
extremely	_	_
important	_	_
task	_	_
in	_	_
specific	_	_
applications	_	_
such	_	_
as	_	_
iris	_	_
recognition	_	_
,	_	_
spoofing	_	_
and	_	_
liveness	_	_
detection	_	_
,	_	_
as	_	_
well	_	_
as	_	_
contact	_	_
lens	_	_
detection	_	_
,	_	_
among	_	_
others	_	_
.	_	_

#182
In	_	_
this	_	_
work	_	_
,	_	_
two	_	_
object	_	_
detection	_	_
approaches	_	_
were	_	_
evaluated	_	_
for	_	_
the	_	_
iris	_	_
location	_	_
.	_	_

#183
The	_	_
experiments	_	_
were	_	_
performed	_	_
in	_	_
six	_	_
databases	_	_
.	_	_

#184
We	_	_
manually	_	_
annotated	_	_
four	_	_
of	_	_
the	_	_
six	_	_
databases	_	_
used	_	_
in	_	_
this	_	_
work	_	_
,	_	_
and	_	_
those	_	_
annotations	_	_
are	_	_
publicly	_	_
available	_	_
to	_	_
the	_	_
research	_	_
community	_	_
.	_	_

#185
The	_	_
experiments	_	_
showed	_	_
that	_	_
the	_	_
use	_	_
of	_	_
the	_	_
YOLO	_	_
object	_	_
detector	_	_
,	_	_
based	_	_
on	_	_
deep	_	_
learning	_	_
,	_	_
applied	_	_
to	_	_
the	_	_
iris	_	_
location	_	_
TABLE	_	_
I	_	_
INTRA-SENSOR	_	_
RESULTS	_	_
(	_	_
%	_	_
)	_	_
Database	_	_
Recall	_	_
Precision	_	_
Accuracy	_	_
IoU	_	_
Daugman	_	_
HOG	_	_
YOLO	_	_
Daugman	_	_
HOG	_	_
YOLO	_	_
Daugman	_	_
HOG	_	_
YOLO	_	_
Daugman	_	_
HOG	_	_
YOLO	_	_
[	_	_
6	_	_
]	_	_
SVM	_	_
[	_	_
6	_	_
]	_	_
SVM	_	_
[	_	_
6	_	_
]	_	_
SVM	_	_
[	_	_
6	_	_
]	_	_
SVM	_	_
NDCCL	_	_
AD100	_	_
84.60	_	_
92.39	_	_
98.78	_	_
82.49	_	_
94.78	_	_
95.03	_	_
94.28	_	_
96.98	_	_
98.49	_	_
80.41	_	_
87.52	_	_
93.84	_	_
LG4000	_	_
93.41	_	_
96.72	_	_
97.81	_	_
92.15	_	_
90.80	_	_
97.73	_	_
97.53	_	_
97.24	_	_
99.05	_	_
89.67	_	_
87.76	_	_
95.06	_	_
IIIT-D	_	_
CLI	_	_
Vista	_	_
85.49	_	_
94.51	_	_
97.85	_	_
89.34	_	_
92.24	_	_
93.71	_	_
95.38	_	_
98.10	_	_
98.28	_	_
80.82	_	_
87.23	_	_
91.76	_	_
Cogent	_	_
86.24	_	_
96.44	_	_
96.02	_	_
92.82	_	_
87.99	_	_
95.58	_	_
96.34	_	_
96.67	_	_
98.33	_	_
82.61	_	_
84.76	_	_
91.84	_	_
MobBIO	_	_
Real	_	_
76.32	_	_
95.77	_	_
96.81	_	_
74.71	_	_
72.26	_	_
94.02	_	_
85.26	_	_
95.33	_	_
98.97	_	_
70.79	_	_
68.76	_	_
91.02	_	_
Fake	_	_
75.81	_	_
93.28	_	_
96.06	_	_
73.45	_	_
74.33	_	_
95.05	_	_
84.81	_	_
95.26	_	_
98.90	_	_
70.12	_	_
68.99	_	_
91.27	_	_
BERC	_	_
88.19	_	_
92.83	_	_
98.10	_	_
85.64	_	_
87.95	_	_
93.56	_	_
98.72	_	_
98.49	_	_
99.71	_	_
79.10	_	_
85.10	_	_
91.15	_	_
CASIA	_	_
IrisV3	_	_
Interval	_	_
96.38	_	_
96.97	_	_
97.79	_	_
96.23	_	_
88.48	_	_
96.02	_	_
97.38	_	_
92.21	_	_
97.10	_	_
90.95	_	_
86.17	_	_
91.24	_	_
NDCLD15	_	_
91.63	_	_
96.04	_	_
97.28	_	_
89.76	_	_
90.29	_	_
95.71	_	_
96.67	_	_
97.14	_	_
98.54	_	_
85.34	_	_
86.85	_	_
93.25	_	_
TABLE	_	_
II	_	_
INTER-SENSOR	_	_
RESULTS	_	_
(	_	_
%	_	_
)	_	_
Database	_	_
Set	_	_
Recall	_	_
Precision	_	_
Accuracy	_	_
IoU	_	_
Train	_	_
Test	_	_
HOG-SVM	_	_
YOLO	_	_
HOG-SVM	_	_
YOLO	_	_
HOG-SVM	_	_
YOLO	_	_
HOG-SVM	_	_
YOLO	_	_
NDCCL	_	_
AD100	_	_
LG4000	_	_
92.95	_	_
79.25	_	_
91.13	_	_
89.18	_	_
96.84	_	_
92.67	_	_
85.78	_	_
68.71	_	_
LG4000	_	_
AD100	_	_
93.22	_	_
97.99	_	_
93.15	_	_
93.59	_	_
96.78	_	_
97.94	_	_
86.76	_	_
91.63	_	_
IIIT-D	_	_
CLI	_	_
Vista	_	_
Cogent	_	_
96.89	_	_
96.13	_	_
89.89	_	_
94.21	_	_
96.43	_	_
97.98	_	_
83.94	_	_
90.57	_	_
Cogent	_	_
Vista	_	_
93.44	_	_
98.26	_	_
93.61	_	_
87.97	_	_
97.08	_	_
96.65	_	_
87.55	_	_
80.92	_	_
TABLE	_	_
III	_	_
COMBINED	_	_
SENSOR	_	_
RESULTS	_	_
(	_	_
%	_	_
)	_	_
,	_	_
SAME	_	_
DATABASES	_	_
Database	_	_
Set	_	_
Recall	_	_
Precision	_	_
Accuracy	_	_
IoU	_	_
Train	_	_
Test	_	_
HOG-SVM	_	_
YOLO	_	_
HOG-SVM	_	_
YOLO	_	_
HOG-SVM	_	_
YOLO	_	_
HOG-SVM	_	_
YOLO	_	_
NDCCL	_	_
AD100	_	_
&	_	_
LG4000	_	_
LG4000	_	_
95.37	_	_
99.29	_	_
92.93	_	_
99.68	_	_
97.48	_	_
99.77	_	_
88.63	_	_
98.91	_	_
AD100	_	_
&	_	_
LG4000	_	_
AD100	_	_
91.77	_	_
99.37	_	_
94.77	_	_
97.42	_	_
96.85	_	_
99.36	_	_
86.91	_	_
96.85	_	_
IIIT-D	_	_
CLI	_	_
Vista	_	_
&	_	_
Cogent	_	_
Cogent	_	_
96.73	_	_
97.26	_	_
87.15	_	_
96.48	_	_
96.50	_	_
98.49	_	_
84.17	_	_
92.50	_	_
Vista	_	_
&	_	_
Cogent	_	_
Vista	_	_
94.20	_	_
98.34	_	_
92.74	_	_
93.79	_	_
97.01	_	_
98.55	_	_
87.41	_	_
91.78	_	_
TABLE	_	_
IV	_	_
COMBINED	_	_
SENSOR	_	_
RESULTS	_	_
(	_	_
%	_	_
)	_	_
,	_	_
MIXED	_	_
DATABASES	_	_
Method	_	_
Set	_	_
Recall	_	_
Precision	_	_
Accuracy	_	_
IoU	_	_
Time	_	_
Train	_	_
Test	_	_
YOLO	_	_
All	_	_
training	_	_
sets	_	_
All	_	_
test	_	_
sets	_	_
97.13	_	_
95.20	_	_
98.32	_	_
92.54	_	_
0.02	_	_
s	_	_
Daugman	_	_
[	_	_
6	_	_
]	_	_
-	_	_
All	_	_
test	_	_
sets	_	_
86.45	_	_
86.28	_	_
94.04	_	_
81.09	_	_
3.50	_	_
s	_	_
presents	_	_
promising	_	_
results	_	_
for	_	_
all	_	_
studied	_	_
databases	_	_
.	_	_

#186
Moreover	_	_
,	_	_
the	_	_
iris	_	_
location	_	_
using	_	_
this	_	_
approach	_	_
runs	_	_
in	_	_
real-time	_	_
(	_	_
0.02	_	_
seconds	_	_
per	_	_
image	_	_
,	_	_
on	_	_
average	_	_
)	_	_
using	_	_
a	_	_
current	_	_
and	_	_
powerful	_	_
GPU	_	_
(	_	_
NVIDIA	_	_
GeForce	_	_
Titan	_	_
XP	_	_
Pascal	_	_
)	_	_
.	_	_

#187
Another	_	_
relevant	_	_
conclusion	_	_
to	_	_
be	_	_
mentioned	_	_
is	_	_
that	_	_
,	_	_
similar	_	_
to	_	_
other	_	_
deep	_	_
learning	_	_
approaches	_	_
,	_	_
it	_	_
is	_	_
important	_	_
to	_	_
have	_	_
a	_	_
sufficiently	_	_
large	_	_
number	_	_
of	_	_
images	_	_
for	_	_
training	_	_
.	_	_

#188
The	_	_
number	_	_
and	_	_
variety	_	_
of	_	_
images	_	_
in	_	_
the	_	_
training	_	_
set	_	_
directly	_	_
affects	_	_
the	_	_
generalization	_	_
capability	_	_
of	_	_
the	_	_
learned	_	_
model	_	_
.	_	_

#189
As	_	_
future	_	_
work	_	_
,	_	_
we	_	_
intend	_	_
to	_	_
perform	_	_
experiments	_	_
with	_	_
more	_	_
visible	_	_
and	_	_
cross-spectral	_	_
iris	_	_
databases	_	_
.	_	_

#190
In	_	_
addition	_	_
,	_	_
we	_	_
intend	_	_
to	_	_
analyze	_	_
the	_	_
impact	_	_
that	_	_
iris	_	_
location	_	_
exerts	_	_
on	_	_
iris	_	_
recognition	_	_
,	_	_
spoofing	_	_
,	_	_
liveness	_	_
,	_	_
and	_	_
contact	_	_
lens	_	_
detection	_	_
systems	_	_
.	_	_

#191
Also	_	_
,	_	_
we	_	_
plan	_	_
to	_	_
study	_	_
how	_	_
a	_	_
short	_	_
and	_	_
shallow	_	_
network	_	_
than	_	_
YOLO	_	_
one	_	_
can	_	_
be	_	_
designed	_	_
for	_	_
our	_	_
single	_	_
object	_	_
detection	_	_
problem	_	_
,	_	_
the	_	_
iris	_	_
location	_	_
.	_	_

#192
ACKNOWLEDGMENTS	_	_
This	_	_
research	_	_
has	_	_
been	_	_
supported	_	_
by	_	_
Coordination	_	_
for	_	_
the	_	_
Improvement	_	_
of	_	_
Higher	_	_
Education	_	_
Personnel	_	_
(	_	_
CAPES	_	_
)	_	_
,	_	_
the	_	_
Foundation	_	_
for	_	_
Research	_	_
Support	_	_
of	_	_
the	_	_
State	_	_
of	_	_
Minas	_	_
Gerais	_	_
(	_	_
Fapemig	_	_
)	_	_
and	_	_
the	_	_
National	_	_
Council	_	_
for	_	_
Scientific	_	_
and	_	_
Technological	_	_
Development	_	_
(	_	_
CNPq	_	_
)	_	_
grants	_	_
471050/2013-0	_	_
,	_	_
#	_	_
428333/2016-8	_	_
,	_	_
and	_	_
#	_	_
313423/2017-2	_	_
)	_	_
We	_	_
thank	_	_
the	_	_
NVIDIA	_	_
Corporation	_	_
for	_	_
the	_	_
donation	_	_
of	_	_
the	_	_
GeForce	_	_
GTX	_	_
Titan	_	_
XP	_	_
Pascal	_	_
GPU	_	_
used	_	_
for	_	_
this	_	_
research	_	_
.	_	_

#193
The	_	_
annotations	_	_
made	_	_
in	_	_
the	_	_
IIIT-D	_	_
CLI	_	_
database	_	_
are	_	_
thanks	_	_
to	_	_
Pedro	_	_
Silva	_	_
(	_	_
UFOP	_	_
)	_	_
.	_	_