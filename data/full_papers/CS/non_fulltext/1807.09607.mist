#0
Multi-Resolution	_	_
Networks	_	_
for	_	_
Semantic	_	_
Segmentation	_	_
in	_	_
Whole	_	_
Slide	_	_
Images	_	_
Feng	_	_
Gu	_	_
,	_	_
Nikolay	_	_
Burlutskiy	_	_
,	_	_
Mats	_	_
Andersson	_	_
,	_	_
and	_	_
Lena	_	_
Kajland	_	_
Wilén	_	_
ContextVision	_	_
AB	_	_
,	_	_
Linköping	_	_
,	_	_
Sweden	_	_
feng.gu	_	_
@	_	_
contextvision.se	_	_
Abstract	_	_
.	_	_

#1
Digital	_	_
pathology	_	_
provides	_	_
an	_	_
excellent	_	_
opportunity	_	_
for	_	_
applying	_	_
fully	_	_
convolutional	_	_
networks	_	_
(	_	_
FCNs	_	_
)	_	_
to	_	_
tasks	_	_
,	_	_
such	_	_
as	_	_
semantic	_	_
segmentation	_	_
of	_	_
whole	_	_
slide	_	_
images	_	_
(	_	_
WSIs	_	_
)	_	_
.	_	_

#2
However	_	_
,	_	_
standard	_	_
FCNs	_	_
face	_	_
challenges	_	_
with	_	_
respect	_	_
to	_	_
multi-resolution	_	_
,	_	_
inherited	_	_
from	_	_
the	_	_
pyramid	_	_
arrangement	_	_
of	_	_
WSIs	_	_
.	_	_

#3
As	_	_
a	_	_
result	_	_
,	_	_
networks	_	_
specifically	_	_
designed	_	_
to	_	_
learn	_	_
and	_	_
aggregate	_	_
information	_	_
at	_	_
different	_	_
levels	_	_
are	_	_
desired	_	_
.	_	_

#4
In	_	_
this	_	_
paper	_	_
,	_	_
we	_	_
propose	_	_
two	_	_
novel	_	_
multi-resolution	_	_
networks	_	_
based	_	_
on	_	_
the	_	_
popular	_	_
‘U-Net’	_	_
architecture	_	_
,	_	_
which	_	_
are	_	_
evaluated	_	_
on	_	_
a	_	_
benchmark	_	_
dataset	_	_
for	_	_
binary	_	_
semantic	_	_
segmentation	_	_
in	_	_
WSIs	_	_
.	_	_

#5
The	_	_
proposed	_	_
methods	_	_
outperform	_	_
the	_	_
U-Net	_	_
,	_	_
demonstrating	_	_
superior	_	_
learning	_	_
and	_	_
generalization	_	_
capabilities	_	_
.	_	_

#6
Keywords	_	_
:	_	_
Deep	_	_
Learning	_	_
,	_	_
Digital	_	_
Pathology	_	_
,	_	_
Whole	_	_
Slide	_	_
Images	_	_

#7
1	_	_
Introduction	_	_

#8
The	_	_
working	_	_
pattern	_	_
of	_	_
an	_	_
experienced	_	_
pathologist	_	_
is	_	_
frequently	_	_
characterized	_	_
by	_	_
a	_	_
repeated	_	_
zooming	_	_
in	_	_
and	_	_
zooming	_	_
out	_	_
motion	_	_
while	_	_
moving	_	_
over	_	_
the	_	_
tissue	_	_
to	_	_
be	_	_
graded	_	_
.	_	_

#9
This	_	_
behavior	_	_
is	_	_
similar	_	_
if	_	_
a	_	_
microscope	_	_
is	_	_
used	_	_
or	_	_
if	_	_
a	_	_
whole	_	_
slide	_	_
image	_	_
(	_	_
WSI	_	_
)	_	_
is	_	_
observed	_	_
on	_	_
a	_	_
screen	_	_
.	_	_

#10
The	_	_
human	_	_
visual	_	_
system	_	_
needs	_	_
these	_	_
multiple	_	_
perspectives	_	_
to	_	_
be	_	_
able	_	_
to	_	_
grade	_	_
the	_	_
slide	_	_
.	_	_

#11
Only	_	_
in	_	_
rare	_	_
cases	_	_
can	_	_
a	_	_
local	_	_
neighborhood	_	_
of	_	_
a	_	_
slide	_	_
be	_	_
safely	_	_
graded	_	_
,	_	_
independent	_	_
from	_	_
the	_	_
surroundings	_	_
.	_	_

#12
The	_	_
heart	_	_
of	_	_
the	_	_
matter	_	_
is	_	_
that	_	_
the	_	_
slide	_	_
only	_	_
represents	_	_
a	_	_
2D	_	_
cut	_	_
out	_	_
of	_	_
a	_	_
complex	_	_
3D	_	_
structure	_	_
.	_	_

#13
A	_	_
glandular	_	_
tissue	_	_
in	_	_
3D	_	_
resembles	_	_
the	_	_
structure	_	_
of	_	_
a	_	_
cauliflower	_	_
.	_	_

#14
Depending	_	_
on	_	_
the	_	_
position	_	_
of	_	_
the	_	_
2D	_	_
cut	_	_
,	_	_
the	_	_
size	_	_
and	_	_
shape	_	_
of	_	_
the	_	_
glands	_	_
on	_	_
the	_	_
slide	_	_
may	_	_
vary	_	_
significantly	_	_
.	_	_

#15
To	_	_
assess	_	_
if	_	_
a	_	_
deviation	_	_
in	_	_
size	_	_
or	_	_
shape	_	_
is	_	_
due	_	_
to	_	_
the	_	_
position	_	_
of	_	_
the	_	_
cut	_	_
or	_	_
to	_	_
a	_	_
lesion	_	_
,	_	_
a	_	_
multi-resolution	_	_
view	_	_
is	_	_
crucial	_	_
.	_	_

#16
The	_	_
structure	_	_
of	_	_
the	_	_
surrounding	_	_
glands	_	_
must	deontic	_
be	_	_
accounted	_	_
for	_	_
when	_	_
the	_	_
current	_	_
gland	_	_
is	_	_
being	_	_
investigated	_	_
at	_	_
a	_	_
higher	_	_
resolution	_	_
.	_	_

#17
Digital	_	_
pathology	_	_
opens	_	_
the	_	_
possibility	_	_
to	_	_
support	_	_
pathologists	_	_
by	_	_
using	_	_
fully	_	_
convolutional	_	_
networks	_	_
(	_	_
FCNs	_	_
)	_	_
[	_	_
11	_	_
]	_	_
for	_	_
semantic	_	_
segmentation	_	_
of	_	_
WSIs	_	_
.	_	_

#18
Standard	_	_
FCNs	_	_
do	_	_
however	_	_
face	_	_
the	_	_
same	_	_
challenge	_	_
with	_	_
respect	_	_
to	_	_
multi-resolution	_	_
.	_	_

#19
It	_	_
can	_	_
be	_	_
argued	_	_
that	_	_
a	_	_
network	_	_
like	_	_
U-Net	_	_
[	_	_
13	_	_
]	_	_
can	_	_
to	_	_
some	_	_
extent	_	_
handle	_	_
multiresolution	_	_
,	_	_
since	_	_
such	_	_
a	_	_
structure	_	_
is	_	_
inherent	_	_
in	_	_
the	_	_
network	_	_
.	_	_

#20
However	_	_
,	_	_
patches	_	_
(	_	_
image	_	_
regions	_	_
of	_	_
a	_	_
WSI	_	_
at	_	_
a	_	_
given	_	_
resolution	_	_
)	_	_
with	_	_
the	_	_
finest	_	_
details	_	_
should	_	_
probably	_	_
be	_	_
extracted	_	_
at	_	_
the	_	_
highest	_	_
resolution	_	_
,	_	_
to	_	_
utilize	_	_
such	_	_
a	_	_
capability	_	_
.	_	_

#21
It	_	_
ar	_	_
X	_	_
iv	_	_
:1	_	_
7	_	_
.	_	_

#22
7v	_	_
1	_	_
[	_	_
cs	_	_
.C	_	_
V	_	_
]	_	_
2	_	_
5	_	_
Ju	_	_
l	_	_
2	_	_
2	_	_
Feng	_	_
Gu	_	_
et	_	_
al.	_	_
may	_	_
also	_	_
require	_	_
the	_	_
patch	_	_
size	_	_
to	_	_
be	_	_
considerably	_	_
larger	_	_
,	_	_
making	_	_
it	_	_
infeasible	_	_
for	_	_
the	_	_
VRAM	_	_
of	_	_
a	_	_
modern	_	_
GPU	_	_
to	_	_
fully	_	_
explore	_	_
the	_	_
multi-resolution	_	_
.	_	_

#23
As	_	_
a	_	_
result	_	_
,	_	_
approaches	_	_
capable	_	_
of	_	_
learning	_	_
from	_	_
data	_	_
and	_	_
aggregating	_	_
information	_	_
efficiently	_	_
and	_	_
effectively	_	_
at	_	_
multiple	_	_
resolutions	_	_
are	_	_
desired	_	_
.	_	_

#24
In	_	_
this	_	_
paper	_	_
,	_	_
two	_	_
novel	_	_
multi-resolution	_	_
networks	_	_
are	_	_
proposed	_	_
to	_	_
learn	_	_
from	_	_
input	_	_
patches	_	_
extracted	_	_
at	_	_
multiple	_	_
levels	_	_
.	_	_

#25
These	_	_
patches	_	_
share	_	_
the	_	_
same	_	_
centroid	_	_
and	_	_
shape	_	_
(	_	_
size	_	_
in	_	_
pixels	_	_
)	_	_
,	_	_
but	_	_
with	_	_
an	_	_
octave	_	_
based	_	_
increase	_	_
of	_	_
the	_	_
pixel	_	_
size	_	_
,	_	_
micrometers	_	_
per	_	_
pixel	_	_
(	_	_
mpp	_	_
)	_	_
.	_	_

#26
Only	_	_
the	_	_
central	_	_
high	_	_
resolution	_	_
patch	_	_
is	_	_
segmented	_	_
at	_	_
the	_	_
output	_	_
.	_	_

#27
The	_	_
proposed	_	_
methods	_	_
are	_	_
evaluated	_	_
and	_	_
compared	_	_
with	_	_
the	_	_
standard	_	_
U-Net	_	_
on	_	_
a	_	_
benchmark	_	_
dataset	_	_
of	_	_
WSIs	_	_
.	_	_

#28
2	_	_
Related	_	_
Work	_	_

#29
Semantic	_	_
segmentation	_	_
problems	_	_
were	_	_
initially	_	_
solved	_	_
by	_	_
traditional	_	_
machine	_	_
learning	_	_
approaches	_	_
,	_	_
where	_	_
hand	_	_
crafted	_	_
features	_	_
were	_	_
engineered	_	_
[	_	_
15	_	_
]	_	_
.	_	_

#30
Researchers	_	_
applied	_	_
methods	_	_
,	_	_
such	_	_
as	_	_
predictive	_	_
sparse	_	_
decomposition	_	_
and	_	_
spatial	_	_
pyramid	_	_
matching	_	_
,	_	_
to	_	_
extract	_	_
features	_	_
of	_	_
histopathological	_	_
tissues	_	_
[	_	_
4	_	_
]	_	_
.	_	_

#31
However	_	_
,	_	_
deep	_	_
learning	_	_
approaches	_	_
based	_	_
on	_	_
FCNs	_	_
[	_	_
11	_	_
]	_	_
showed	_	_
significantly	_	_
higher	_	_
performance	_	_
and	_	_
eventually	_	_
have	_	_
substituted	_	_
them	_	_
[	_	_
7	_	_
]	_	_
.	_	_

#32
To	_	_
overcome	_	_
the	_	_
so	_	_
called	_	_
‘checkerboard	_	_
artifacts’	_	_
of	_	_
transposed	_	_
convolutions	_	_
,	_	_
several	_	_
approaches	_	_
have	_	_
been	_	_
proposed	_	_
,	_	_
e.g.	_	_
SegNet	_	_
[	_	_
1	_	_
]	_	_
,	_	_
DeepLab-CRF	_	_
[	_	_
5	_	_
]	_	_
,	_	_
and	_	_
upscaling	_	_
using	_	_
dilated	_	_
convolutions	_	_
[	_	_
18	_	_
]	_	_
.	_	_

#33
To	_	_
increase	_	_
localization	_	_
of	_	_
learned	_	_
features	_	_
,	_	_
high	_	_
resolution	_	_
features	_	_
from	_	_
the	_	_
downsampling	_	_
path	_	_
can	_	_
be	_	_
aggregated	_	_
with	_	_
the	_	_
upsampled	_	_
output	_	_
.	_	_

#34
Such	_	_
an	_	_
operation	_	_
is	_	_
known	_	_
as	_	_
‘skip	_	_
connections’	_	_
,	_	_
which	_	_
enables	_	_
a	_	_
successive	_	_
convolution	_	_
layer	_	_
to	_	_
learn	_	_
and	_	_
assemble	_	_
a	_	_
more	_	_
precise	_	_
output	_	_
based	_	_
on	_	_
the	_	_
aggregated	_	_
information	_	_
.	_	_

#35
Several	_	_
researchers	_	_
successfully	_	_
demonstrated	_	_
that	_	_
architectures	_	_
with	_	_
skip	_	_
connections	_	_
can	_	_
result	_	_
in	_	_
better	_	_
performance	_	_
.	_	_

#36
Such	_	_
networks	_	_
include	_	_
U-Net	_	_
,	_	_
densely	_	_
connected	_	_
convolutional	_	_
networks	_	_
[	_	_
9	_	_
]	_	_
,	_	_
and	_	_
highway	_	_
networks	_	_
with	_	_
skip	_	_
connections	_	_
[	_	_
16	_	_
]	_	_
.	_	_

#37
On	_	_
overall	_	_
,	_	_
U-Net	_	_
has	_	_
proved	_	_
to	_	_
be	_	_
one	_	_
of	_	_
the	_	_
most	_	_
popular	_	_
networks	_	_
for	_	_
biomedical	_	_
segmentation	_	_
tasks	_	_
[	_	_
3	_	_
]	_	_
.	_	_

#38
One	_	_
limitation	_	_
of	_	_
standard	_	_
FCNs	_	_
is	_	_
the	_	_
fact	_	_
that	_	_
the	_	_
networks	_	_
are	_	_
composed	_	_
of	_	_
convolution	_	_
layers	_	_
with	_	_
a	_	_
set	_	_
of	_	_
filters	_	_
that	_	_
have	_	_
the	_	_
same	_	_
receptive	_	_
field	_	_
size	_	_
.	_	_

#39
The	_	_
receptive	_	_
field	_	_
size	_	_
corresponds	_	_
to	_	_
the	_	_
context	_	_
that	_	_
a	_	_
network	_	_
can	_	_
learn	_	_
from	_	_
,	_	_
and	_	_
eventually	_	_
influences	_	_
the	_	_
network	_	_
performance	_	_
.	_	_

#40
Grais	_	_
et	_	_
al.	_	_
[	_	_
8	_	_
]	_	_
proposed	_	_
a	_	_
multi-resolution	_	_
FCN	_	_
with	_	_
different	_	_
receptive	_	_
field	_	_
sizes	_	_
for	_	_
each	_	_
layer	_	_
,	_	_
for	_	_
the	_	_
audio	_	_
source	_	_
separation	_	_
problem	_	_
.	_	_

#41
Such	_	_
a	_	_
design	_	_
allowed	_	_
to	_	_
extract	_	_
features	_	_
of	_	_
the	_	_
same	_	_
input	_	_
at	_	_
multiple	_	_
perspectives	_	_
(	_	_
determined	_	_
by	_	_
the	_	_
receptive	_	_
field	_	_
sizes	_	_
)	_	_
,	_	_
and	_	_
thus	_	_
to	_	_
capture	_	_
global	_	_
and	_	_
local	_	_
details	_	_
from	_	_
the	_	_
input	_	_
.	_	_

#42
Fu	_	_
et	_	_
al.	_	_
introduced	_	_
a	_	_
multi-scale	_	_
M-Net	_	_
[	_	_
6	_	_
]	_	_
to	_	_
tackle	_	_
the	_	_
problem	_	_
of	_	_
joint	_	_
optic	_	_
disc	_	_
and	_	_
cup	_	_
segmentation	_	_
,	_	_
where	_	_
the	_	_
same	_	_
image	_	_
contents	_	_
of	_	_
different	_	_
input	_	_
shapes	_	_
or	_	_
scales	_	_
are	_	_
passed	_	_
through	_	_
the	_	_
network	_	_
.	_	_

#43
However	_	_
,	_	_
both	_	_
methods	_	_
were	_	_
designed	_	_
to	_	_
handle	_	_
the	_	_
same	_	_
input	_	_
audio	_	_
or	_	_
image	_	_
content	_	_
,	_	_
while	_	_
learning	_	_
features	_	_
from	_	_
multiple	_	_
perspectives	_	_
by	_	_
either	_	_
employing	_	_
encoders	_	_
with	_	_
varied	_	_
respective	_	_
fields	_	_
or	_	_
taking	_	_
inputs	_	_
with	_	_
multiple	_	_
scales	_	_
.	_	_

#44
Roullier	_	_
et	_	_
al.	_	_
[	_	_
14	_	_
]	_	_
proposed	_	_
multi-resolution	_	_
graph-based	_	_
analysis	_	_
of	_	_
whole	_	_
slide	_	_
images	_	_
for	_	_
mitotic	_	_
cell	_	_
segmentation	_	_
.	_	_

#45
The	_	_
approach	_	_
is	_	_
based	_	_
on	_	_
MRN	_	_
for	_	_
Semantic	_	_
Segmentation	_	_
in	_	_
WSIs	_	_
3	_	_
domain	_	_
specific	_	_
knowledge	_	_
,	_	_
which	_	_
can	_	_
not	_	_
be	_	_
easily	_	_
transferred	_	_
to	_	_
another	_	_
problem	_	_
domain	_	_
.	_	_

#46
Recently	_	_
,	_	_
an	_	_
approach	_	_
of	_	_
using	_	_
multi-resolution	_	_
information	_	_
in	_	_
FCN	_	_
was	_	_
described	_	_
in	_	_
[	_	_
12	_	_
]	_	_
.	_	_

#47
However	_	_
,	_	_
the	_	_
fusion	_	_
of	_	_
multi-resolution	_	_
inputs	_	_
was	_	_
performed	_	_
before	_	_
encoders	_	_
,	_	_
instead	_	_
of	_	_
within	_	_
the	_	_
network	_	_
.	_	_

#48
In	_	_
addition	_	_
,	_	_
the	_	_
approach	_	_
could	_	_
only	_	_
be	_	_
applied	_	_
to	_	_
a	_	_
subset	_	_
of	_	_
small	_	_
regions	_	_
of	_	_
interests	_	_
,	_	_
rather	_	_
than	_	_
WSIs	_	_
.	_	_

#49
Networks	_	_
that	_	_
incorporate	_	_
inputs	_	_
extracted	_	_
from	_	_
different	_	_
resolutions	_	_
with	_	_
respect	_	_
to	_	_
the	_	_
same	_	_
corresponding	_	_
tissue	_	_
area	_	_
in	_	_
WSIs	_	_
are	_	_
desired	_	_
,	_	_
to	_	_
tackle	_	_
the	_	_
challenge	_	_
of	_	_
multi-resolution	_	_
effectively	_	_
.	_	_

#50
In	_	_
addition	_	_
,	_	_
the	_	_
networks	_	_
should	_	_
be	_	_
scalable	_	_
in	_	_
terms	_	_
of	_	_
resolutions	_	_
and	_	_
VRAM	_	_
efficient	_	_
for	_	_
training	_	_
and	_	_
prediction	_	_
.	_	_

#51
These	_	_
motivated	_	_
us	_	_
to	_	_
develop	_	_
the	_	_
multi-resolution	_	_
networks	_	_
in	_	_
this	_	_
work	_	_
.	_	_

#52
3	_	_
Algorithmic	_	_
Formulation	_	_

#53
A	_	_
common	_	_
practice	_	_
of	_	_
handling	_	_
a	_	_
WSI	_	_
with	_	_
deep	_	_
learning	_	_
is	_	_
to	_	_
divide	_	_
it	_	_
into	_	_
multiple	_	_
equally	_	_
sized	_	_
patches	_	_
[	_	_
17	_	_
]	_	_
.	_	_

#54
Here	_	_
the	_	_
deep	_	_
learning	_	_
task	_	_
is	_	_
formulated	_	_
as	_	_
a	_	_
binary	_	_
semantic	_	_
segmentation	_	_
problem	_	_
of	_	_
patches	_	_
,	_	_
where	_	_
each	_	_
patch	_	_
is	_	_
considered	_	_
an	_	_
image	_	_
example	_	_
.	_	_

#55
At	_	_
prediction	_	_
,	_	_
a	_	_
trained	_	_
model	_	_
first	_	_
predicts	_	_
each	_	_
patch	_	_
individually	_	_
,	_	_
and	_	_
then	_	_
stitches	_	_
predictions	_	_
of	_	_
all	_	_
the	_	_
patches	_	_
,	_	_
to	_	_
form	_	_
the	_	_
prediction	_	_
of	_	_
the	_	_
entire	_	_
slide	_	_
(	_	_
a	_	_
probabilistic	_	_
map	_	_
indicating	_	_
the	_	_
probability	_	_
of	_	_
each	_	_
pixel	_	_
belonging	_	_
to	_	_
the	_	_
class	_	_
of	_	_
interest	_	_
)	_	_
.	_	_

#56
3.1	_	_
Learning	_	_
and	_	_
Inference	_	_

#57
Let	_	_
(	_	_
x	_	_
,	_	_
𝑦	_	_
)	_	_
∈	_	_
X	_	_
×	_	_
Y	_	_
be	_	_
a	_	_
patch	_	_
or	_	_
an	_	_
example	_	_
of	_	_
a	_	_
given	_	_
dataset	_	_
,	_	_
where	_	_
X	_	_
⊆	_	_
R𝑁×𝐷×3	_	_
and	_	_
Y	_	_
⊆	_	_
N𝑁×𝐷	_	_
.	_	_

#58
The	_	_
value	_	_
of	_	_
𝑁	_	_
is	_	_
equal	_	_
to	_	_
the	_	_
number	_	_
of	_	_
examples	_	_
(	_	_
or	_	_
patches	_	_
)	_	_
,	_	_
and	_	_
𝐷	_	_
is	_	_
the	_	_
dimensionality	_	_
of	_	_
the	_	_
feature	_	_
vector	_	_
(	_	_
i.e.	_	_
the	_	_
product	_	_
of	_	_
height	_	_
and	_	_
width	_	_
of	_	_
the	_	_
patch	_	_
ℎ	_	_
×	_	_
𝑤	_	_
)	_	_
.	_	_

#59
So	_	_
x	_	_
can	_	_
be	_	_
a	_	_
RGB	_	_
image	_	_
extracted	_	_
from	_	_
a	_	_
slide	_	_
,	_	_
and	_	_
𝑦	_	_
can	_	_
be	_	_
a	_	_
binary	_	_
ground	_	_
truth	_	_
mask	_	_
associated	_	_
with	_	_
the	_	_
RGB	_	_
image	_	_
.	_	_

#60
We	_	_
can	_	_
formulate	_	_
a	_	_
deep	_	_
network	_	_
as	_	_
a	_	_
function	_	_
𝑓	_	_
(	_	_
x	_	_
;	_	_
W	_	_
)	_	_
,	_	_
where	_	_
W	_	_
is	_	_
a	_	_
collection	_	_
of	_	_
weights	_	_
of	_	_
all	_	_
the	_	_
parametrized	_	_
layers	_	_
.	_	_

#61
The	_	_
learning	_	_
task	_	_
is	_	_
a	_	_
process	_	_
of	_	_
searching	_	_
for	_	_
the	_	_
optimal	_	_
set	_	_
of	_	_
parameters	_	_
Ŵ	_	_
that	_	_
minimizes	_	_
a	_	_
loss	_	_
function	_	_
ℒ	_	_
(	_	_
𝑦	_	_
,	_	_
𝑓	_	_
(	_	_
x	_	_
;	_	_
W	_	_
)	_	_
)	_	_
.	_	_

#62
The	_	_
output	_	_
of	_	_
the	_	_
function	_	_
𝑓	_	_
can	_	_
be	_	_
transformed	_	_
to	_	_
a	_	_
probabilistic	_	_
value	_	_
in	_	_
the	_	_
range	_	_
of	_	_
[	_	_
0	_	_
,	_	_
1	_	_
]	_	_
via	_	_
a	_	_
sigmoid	_	_
function	_	_
.	_	_

#63
A	_	_
commonly	_	_
used	_	_
loss	_	_
function	_	_
for	_	_
binary	_	_
semantic	_	_
segmentation	_	_
is	_	_
the	_	_
binary	_	_
cross	_	_
entropy	_	_
loss	_	_
.	_	_

#64
To	_	_
counter	_	_
over-fitting	_	_
and	_	_
improve	_	_
the	_	_
generalization	_	_
capability	_	_
of	_	_
a	_	_
trained	_	_
model	_	_
,	_	_
a	_	_
regularization	_	_
term	_	_
ℛ	_	_
(	_	_
·	_	_
)	_	_
is	_	_
often	_	_
added	_	_
to	_	_
the	_	_
objective	_	_
function	_	_
as	_	_
ℰW	_	_
=	_	_
𝑁∑︁	_	_
𝑖=1	_	_
ℒ	_	_
(	_	_
𝑦	_	_
,	_	_
𝑓	_	_
(	_	_
x𝑖	_	_
;	_	_
W	_	_
)	_	_
)	_	_
+	_	_
𝜆ℛ	_	_
(	_	_
W	_	_
)	_	_
(	_	_
1	_	_
)	_	_
where	_	_
the	_	_
scalar	_	_
𝜆	_	_
determines	_	_
the	_	_
weighting	_	_
between	_	_
two	_	_
terms	_	_
.	_	_

#65
One	_	_
popular	_	_
regularization	_	_
function	_	_
is	_	_
ℓ2-regularization	_	_
,	_	_
such	_	_
that	_	_
ℛ	_	_
(	_	_
W	_	_
)	_	_
=	_	_
‖W‖2	_	_
2	_	_
.	_	_

#66
Search	_	_
of	_	_
the	_	_
optimal	_	_
set	_	_
of	_	_
parameters	_	_
Ŵ	_	_
=	_	_
arg	_	_
minW	_	_
ℰW	_	_
for	_	_
the	_	_
objective	_	_
function	_	_
is	_	_
known	_	_
as	_	_
optimization	_	_
in	_	_
machine	_	_
learning	_	_
.	_	_

#67
Popular	_	_
optimizers	_	_
include	_	_
stochastic	_	_
gradient	_	_
descent	_	_
(	_	_
SGD	_	_
)	_	_
,	_	_
adaptive	_	_
gradient	_	_
(	_	_
AdaGrad	_	_
)	_	_
,	_	_
and	_	_
root	_	_
mean	_	_
square	_	_
propagation	_	_
(	_	_
RMSProp	_	_
)	_	_
.	_	_

#68
Recently	_	_
,	_	_
adaptive	_	_
moment	_	_
estimation	_	_
(	_	_
Adam	_	_
)	_	_
[	_	_
10	_	_
]	_	_
has	_	_
become	_	_
a	_	_
particularly	_	_
popular	_	_
method	_	_
for	_	_
optimizing	_	_
deep	_	_
networks	_	_
.	_	_

#69
4	_	_
Feng	_	_
Gu	_	_
et	_	_
al.	_	_
Fig.	_	_
1	_	_
:	_	_
From	_	_
left	_	_
to	_	_
right	_	_
are	_	_
the	_	_
patches	_	_
with	_	_
the	_	_
same	_	_
central	_	_
coordinates	_	_
,	_	_
where	_	_
mpp=0.5	_	_
is	_	_
equivalent	_	_
to	_	_
20x	_	_
and	_	_
so	_	_
forth	_	_
.	_	_

#70
The	_	_
increase	_	_
of	_	_
mpp	_	_
values	_	_
corresponds	_	_
to	_	_
the	_	_
zooming	_	_
out	_	_
action	_	_
to	_	_
enlarge	_	_
the	_	_
field	_	_
of	_	_
view	_	_
,	_	_
and	_	_
the	_	_
yellow	_	_
squares	_	_
represent	_	_
the	_	_
effective	_	_
tissue	_	_
ares	_	_
at	_	_
different	_	_
magnifications	_	_
.	_	_

#71
C	_	_
o	_	_
n	_	_
v	_	_
3	_	_
x	_	_
M	_	_
a	_	_
x	_	_
P	_	_
o	_	_
o	_	_
l	_	_
Tr	_	_
a	_	_
n	_	_
s	_	_
C	_	_
o	_	_
n	_	_
v	_	_
C	_	_
o	_	_
n	_	_
v	_	_
1	_	_
x	_	_
C	_	_
o	_	_
n	_	_
v	_	_
3	_	_
x	_	_
M	_	_
a	_	_
x	_	_
P	_	_
o	_	_
o	_	_
l	_	_
C	_	_
o	_	_
n	_	_
v	_	_
3	_	_
x	_	_
M	_	_
a	_	_
x	_	_
P	_	_
o	_	_
o	_	_
l	_	_
C	_	_
o	_	_
n	_	_
v	_	_
3	_	_
x	_	_
M	_	_
a	_	_
x	_	_
P	_	_
o	_	_
o	_	_
l	_	_
C	_	_
o	_	_
n	_	_
v	_	_
3	_	_
x	_	_
C	_	_
o	_	_
n	_	_
v	_	_
1	_	_
x	_	_
C	_	_
o	_	_
n	_	_
v	_	_
3	_	_
x	_	_
Tr	_	_
a	_	_
n	_	_
s	_	_
C	_	_
o	_	_
n	_	_
v	_	_
C	_	_
o	_	_
n	_	_
v	_	_
1	_	_
x	_	_
C	_	_
o	_	_
n	_	_
v	_	_
3	_	_
x	_	_
Tr	_	_
a	_	_
n	_	_
s	_	_
C	_	_
o	_	_
n	_	_
v	_	_
C	_	_
o	_	_
n	_	_
v	_	_
1	_	_
x	_	_
C	_	_
o	_	_
n	_	_
v	_	_
3	_	_
x	_	_
Tr	_	_
a	_	_
n	_	_
s	_	_
C	_	_
o	_	_
n	_	_
v	_	_
C	_	_
o	_	_
n	_	_
v	_	_
1	_	_
x	_	_
C	_	_
o	_	_
n	_	_
v	_	_
3	_	_
x	_	_
C	_	_
o	_	_
n	_	_
v	_	_
3	_	_
x	_	_
M	_	_
a	_	_
x	_	_
P	_	_
o	_	_
o	_	_
l	_	_
C	_	_
o	_	_
n	_	_
v	_	_
3	_	_
x	_	_
M	_	_
a	_	_
x	_	_
P	_	_
o	_	_
o	_	_
l	_	_
C	_	_
o	_	_
n	_	_
v	_	_
3	_	_
x	_	_
M	_	_
a	_	_
x	_	_
P	_	_
o	_	_
o	_	_
l	_	_
C	_	_
o	_	_
n	_	_
v	_	_
3	_	_
x	_	_
M	_	_
a	_	_
x	_	_
P	_	_
o	_	_
o	_	_
l	_	_
C	_	_
o	_	_
n	_	_
v	_	_
3	_	_
x	_	_
C	_	_
o	_	_
n	_	_
v	_	_
1	_	_
x	_	_
C	_	_
ro	_	_
p	_	_
R	_	_
e	_	_
si	_	_
ze	_	_
C	_	_
ro	_	_
p	_	_
R	_	_
e	_	_
si	_	_
ze	_	_
C	_	_
ro	_	_
p	_	_
R	_	_
e	_	_
si	_	_
ze	_	_
C	_	_
ro	_	_
p	_	_
R	_	_
e	_	_
si	_	_
ze	_	_
C	_	_
ro	_	_
p	_	_
R	_	_
e	_	_
si	_	_
ze	_	_
m	_	_
p	_	_
p	_	_
=	_	_
.5	_	_
m	_	_
p	_	_
p	_	_
=	_	_
Fig.	_	_
2	_	_
:	_	_
An	_	_
illustration	_	_
of	_	_
the	_	_
proposed	_	_
MRN	_	_
methods	_	_
when	_	_
two	_	_
resolutions	_	_
are	_	_
involved	_	_
.	_	_

#72
The	_	_
dark	_	_
blue	_	_
boxes	_	_
represent	_	_
stacks	_	_
of	_	_
two	_	_
3	_	_
×	_	_
3	_	_
convolution	_	_
layers	_	_
with	_	_
ReLU	_	_
activations	_	_
;	_	_
the	_	_
red	_	_
boxes	_	_
are	_	_
2	_	_
×	_	_
2	_	_
max	_	_
pooling	_	_
layers	_	_
;	_	_
the	_	_
light	_	_
blue	_	_
boxes	_	_
are	_	_
1	_	_
×	_	_
1	_	_
convolution	_	_
layers	_	_
with	_	_
identity	_	_
activations	_	_
;	_	_
the	_	_
green	_	_
boxes	_	_
are	_	_
2	_	_
×	_	_
2	_	_
transposed	_	_
convolution	_	_
layers	_	_
with	_	_
stride=2	_	_
and	_	_
ReLU	_	_
activations	_	_
.	_	_

#73
3.2	_	_
Multi-Resolution	_	_
Networks	_	_

#74
Here	_	_
we	_	_
propose	_	_
two	_	_
multi-resolution	_	_
networks	_	_
(	_	_
MRN	_	_
)	_	_
that	_	_
are	_	_
based	_	_
on	_	_
the	_	_
architecture	_	_
of	_	_
U-Net	_	_
[	_	_
13	_	_
]	_	_
.	_	_

#75
A	_	_
standard	_	_
U-Net	_	_
can	_	_
be	_	_
seen	_	_
as	_	_
two	_	_
parts	_	_
,	_	_
an	_	_
‘encoder’	_	_
for	_	_
downsampling	_	_
and	_	_
a	_	_
‘decoder’	_	_
for	_	_
upsampling	_	_
.	_	_

#76
The	_	_
downsampled	_	_
feature	_	_
maps	_	_
are	_	_
concatenated	_	_
with	_	_
the	_	_
corresponding	_	_
layers	_	_
of	_	_
the	_	_
decoder	_	_
in	_	_
the	_	_
upsampling	_	_
pathway	_	_
.	_	_

#77
The	_	_
proposed	_	_
MRN	_	_
employ	_	_
multiple	_	_
encoders	_	_
corresponding	_	_
to	_	_
different	_	_
resolutions	_	_
that	_	_
are	_	_
structurally	_	_
identical	_	_
for	_	_
downsampling	_	_
,	_	_
and	_	_
one	_	_
single	_	_
decoder	_	_
for	_	_
upsampling	_	_
.	_	_

#78
The	_	_
input	_	_
shapes	_	_
of	_	_
all	_	_
resolutions	_	_
are	_	_
identical	_	_
,	_	_
and	_	_
the	_	_
examples	_	_
share	_	_
the	_	_
common	_	_
central	_	_
coordinates	_	_
and	_	_
effectively	_	_
cover	_	_
tissue	_	_
areas	_	_
in	_	_
a	_	_
pyramid	_	_
manner	_	_
,	_	_
as	_	_
in	_	_
Fig.	_	_
1	_	_
.	_	_

#79
Let	_	_
(	_	_
x	_	_
,	_	_
𝑦	_	_
)	_	_
be	_	_
an	_	_
example	_	_
,	_	_
where	_	_
x𝑗	_	_
=	_	_
[	_	_
x1	_	_
,	_	_
x2	_	_
,	_	_
.	_	_

#80
.	_	_

#81
.	_	_

#82
,	_	_
x𝐽	_	_
]	_	_
and	_	_
𝑦	_	_
=	_	_
𝑦1	_	_
,	_	_
where	_	_
the	_	_
resolutions	_	_
are	_	_
in	_	_
a	_	_
descending	_	_
order	_	_
.	_	_

#83
The	_	_
shapes	_	_
of	_	_
x	_	_
and	_	_
𝑦	_	_
are	_	_
there	_	_
ℎ	_	_
×	_	_
𝑤	_	_
×	_	_
3	_	_
×	_	_
𝐽	_	_
and	_	_
ℎ	_	_
×	_	_
𝑤	_	_
×	_	_
1	_	_
respectively	_	_
.	_	_

#84
The	_	_
rationale	_	_
behind	_	_
such	_	_
an	_	_
arrangement	_	_
is	_	_
that	_	_
the	_	_
pixel	_	_
correspondence	_	_
is	_	_
more	_	_
cumbersome	_	_
compared	_	_
MRN	_	_
for	_	_
Semantic	_	_
Segmentation	_	_
in	_	_
WSIs	_	_
5	_	_
to	_	_
a	_	_
standard	_	_
U-Net	_	_
.	_	_

#85
A	_	_
key	_	_
issue	_	_
is	_	_
to	_	_
enable	_	_
a	_	_
sufficient	_	_
receptive	_	_
field	_	_
for	_	_
the	_	_
low	_	_
resolution	_	_
branches	_	_
of	_	_
the	_	_
network	_	_
to	_	_
successfully	_	_
convey	_	_
the	_	_
information	_	_
from	_	_
the	_	_
peripheral	_	_
regions	_	_
into	_	_
the	_	_
central	_	_
parts	_	_
.	_	_

#86
To	_	_
preserve	_	_
the	_	_
information	_	_
relevant	_	_
to	_	_
the	_	_
area	_	_
of	_	_
interest	_	_
(	_	_
i.e.	_	_
the	_	_
central	_	_
part	_	_
)	_	_
at	_	_
a	_	_
lower	_	_
resolution	_	_
,	_	_
we	_	_
center	_	_
crop	_	_
the	_	_
output	_	_
feature	_	_
maps	_	_
of	_	_
each	_	_
encoder	_	_
unit	_	_
and	_	_
then	_	_
resize	_	_
them	_	_
back	_	_
to	_	_
the	_	_
original	_	_
resolutions	_	_
via	_	_
upscaling	_	_
.	_	_

#87
We	_	_
can	_	_
defined	_	_
a	_	_
nested	_	_
function	_	_
𝑢	_	_
∘	_	_
𝑣	_	_
such	_	_
that	_	_
𝑢	_	_
:	_	_
R𝑤×ℎ×𝑐	_	_
→	_	_
R⌊	_	_
𝑤	_	_
𝛾	_	_
⌋×⌊	_	_
ℎ	_	_
𝛾	_	_
⌋×𝑐	_	_
and	_	_
𝑣	_	_
:	_	_
R⌊	_	_
𝑤	_	_
𝛾	_	_
⌋×⌊	_	_
ℎ	_	_
𝛾	_	_
⌋×𝑐	_	_
→	_	_
R𝑤×ℎ×𝑐	_	_
(	_	_
2	_	_
)	_	_
where	_	_
the	_	_
cropping	_	_
factor	_	_
is	_	_
𝛾	_	_
=	_	_
2N	_	_
,	_	_
since	_	_
resolutions	_	_
at	_	_
different	_	_
levels	_	_
of	_	_
a	_	_
WSI	_	_
are	_	_
usually	_	_
downsampled	_	_
by	_	_
a	_	_
factor	_	_
2	_	_
in	_	_
both	_	_
height	_	_
and	_	_
width	_	_
.	_	_

#88
On	_	_
one	_	_
hand	_	_
,	_	_
the	_	_
function	_	_
𝑢	_	_
center	_	_
crops	_	_
a	_	_
real-valued	_	_
tensor	_	_
of	_	_
shape	_	_
ℎ	_	_
×	_	_
𝑤	_	_
×	_	_
𝑐	_	_
(	_	_
height	_	_
,	_	_
width	_	_
,	_	_
and	_	_
channels	_	_
)	_	_
to	_	_
the	_	_
shape	_	_
of	_	_
⌊	_	_
𝑤	_	_
𝛾	_	_
⌋	_	_
×	_	_
⌊	_	_
ℎ	_	_
𝛾	_	_
⌋	_	_
×	_	_
𝑐	_	_
.	_	_

#89
On	_	_
the	_	_
other	_	_
hand	_	_
,	_	_
the	_	_
function	_	_
𝑣	_	_
upscales	_	_
the	_	_
output	_	_
of	_	_
𝑢	_	_
to	_	_
the	_	_
original	_	_
shape	_	_
.	_	_

#90
For	_	_
upscaling	_	_
,	_	_
we	_	_
present	_	_
two	_	_
options	_	_
,	_	_
namely	_	_
‘MRN-bilinear’	_	_
via	_	_
bilinear	_	_
interpolation	_	_
and	_	_
‘MRN-transposed’	_	_
through	_	_
transposed	_	_
convolution	_	_
.	_	_

#91
The	_	_
outputs	_	_
of	_	_
𝑢∘𝑣	_	_
are	_	_
concatenated	_	_
with	_	_
the	_	_
convoluted	_	_
feature	_	_
maps	_	_
of	_	_
the	_	_
corresponding	_	_
layers	_	_
in	_	_
the	_	_
encoder	_	_
of	_	_
the	_	_
highest	_	_
resolution	_	_
.	_	_

#92
The	_	_
concatenated	_	_
feature	_	_
maps	_	_
are	_	_
then	_	_
passed	_	_
though	_	_
a	_	_
1	_	_
×	_	_
1	_	_
convolution	_	_
layer	_	_
with	_	_
an	_	_
identity	_	_
activation	_	_
,	_	_
before	_	_
being	_	_
combined	_	_
with	_	_
layers	_	_
in	_	_
the	_	_
decoder	_	_
.	_	_

#93
The	_	_
1×1	_	_
convolution	_	_
acts	_	_
as	_	_
a	_	_
weighted	_	_
sum	_	_
to	_	_
aggregate	_	_
feature	_	_
maps	_	_
from	_	_
all	_	_
the	_	_
resolutions	_	_
,	_	_
while	_	_
keeping	_	_
the	_	_
number	_	_
feature	_	_
maps	_	_
in	_	_
the	_	_
decoder	_	_
constant	_	_
despite	_	_
the	_	_
number	_	_
of	_	_
resolutions	_	_
involved	_	_
.	_	_

#94
Fig.	_	_
2	_	_
illustrates	_	_
an	_	_
example	_	_
of	_	_
such	_	_
networks	_	_
when	_	_
two	_	_
resolutions	_	_
are	_	_
involved	_	_
,	_	_
and	_	_
this	_	_
is	_	_
easily	_	_
expandable	_	_
with	_	_
more	_	_
resolutions	_	_
.	_	_

#95
4	_	_
Experimental	_	_
Conditions	_	_

#96
4.1	_	_
Implementation	_	_
Details	_	_

#97
We	_	_
implemented	_	_
all	_	_
the	_	_
networks	_	_
in	_	_
TensorFlow	_	_
,	_	_
with	_	_
‘SAME’	_	_
padding	_	_
.	_	_

#98
Batch	_	_
normalization	_	_
and	_	_
ℓ2-regularization	_	_
with	_	_
𝜆	_	_
=	_	_
0.005	_	_
were	_	_
applied	_	_
to	_	_
all	_	_
the	_	_
convolution	_	_
and	_	_
transposed	_	_
convolution	_	_
layers	_	_
,	_	_
to	_	_
improve	_	_
convergence	_	_
rates	_	_
and	_	_
counter	_	_
over-fitting	_	_
.	_	_

#99
We	_	_
employ	_	_
the	_	_
Adam	_	_
optimizer	_	_
with	_	_
default	_	_
parameters	_	_
(	_	_
𝜂=0.001	_	_
,	_	_
𝛽1=0.9	_	_
,	_	_
𝛽2=0.999	_	_
,	_	_
and	_	_
𝜖	_	_
=	_	_
10−8	_	_
)	_	_
.	_	_

#100
The	_	_
input	_	_
shape	_	_
is	_	_
512	_	_
in	_	_
height	_	_
and	_	_
width	_	_
,	_	_
and	_	_
the	_	_
collection	_	_
of	_	_
resolutions	_	_
are	_	_
mpp	_	_
∈	_	_
{	_	_
0.5	_	_
,	_	_
1	_	_
,	_	_
2	_	_
,	_	_
4	_	_
}	_	_
,	_	_
where	_	_
the	_	_
U-Net	_	_
deals	_	_
with	_	_
one	_	_
of	_	_
the	_	_
resolutions	_	_
at	_	_
each	_	_
time	_	_
and	_	_
the	_	_
MRN	_	_
methods	_	_
handles	_	_
all	_	_
the	_	_
resolutions	_	_
simultaneously	_	_
.	_	_

#101
The	_	_
batch	_	_
size	_	_
is	_	_
equal	_	_
to	_	_
16	_	_
,	_	_
which	_	_
is	_	_
limited	_	_
by	_	_
the	_	_
VRAM	_	_
of	_	_
an	_	_
NVIDIA	_	_
Titan	_	_
XP	_	_
.	_	_

#102
The	_	_
number	_	_
maximum	_	_
epochs	_	_
is	_	_
set	_	_
to	_	_
500	_	_
for	_	_
the	_	_
training	_	_
to	_	_
be	_	_
terminated	_	_
.	_	_

#103
4.2	_	_
Segmentation	_	_
Experiments	_	_

#104
CAMELYON	_	_
datasets	_	_
[	_	_
2	_	_
]	_	_
are	_	_
the	_	_
only	_	_
few	_	_
publicly	_	_
available	_	_
WSI	_	_
datasets	_	_
with	_	_
pixel-level	_	_
annotations	_	_
.	_	_

#105
In	_	_
particular	_	_
,	_	_
the	_	_
CAMELYON16	_	_
dataset	_	_
has	_	_
both	_	_
the	_	_
training	_	_
and	_	_
testing	_	_
sets	_	_
available	_	_
,	_	_
and	_	_
is	_	_
one	_	_
of	_	_
the	_	_
most	_	_
popular	_	_
benchmark	_	_
6	_	_
Feng	_	_
Gu	_	_
et	_	_
al.	_	_
0.0	_	_
0.2	_	_
0.4	_	_
0.6	_	_
0.8	_	_
1.0	_	_
0	_	_
.	_	_

#106
0	_	_
.	_	_

#107
0	_	_
.	_	_

#108
0	_	_
.	_	_

#109
0	_	_
.	_	_

#110
1	_	_
.	_	_

#111
False	_	_
Positive	_	_
Rate	_	_
Tr	_	_
ue	_	_
P	_	_
os	_	_
iti	_	_
ve	_	_
R	_	_
at	_	_
e	_	_
U−Net_0.5um	_	_
(	_	_
AUC=0.991	_	_
)	_	_
U−Net_1um	_	_
(	_	_
AUC=0.990	_	_
)	_	_
U−Net_2um	_	_
(	_	_
AUC=0.990	_	_
)	_	_
U−Net_4um	_	_
(	_	_
AUC=0.989	_	_
)	_	_
MRN_bilinear	_	_
(	_	_
AUC=0.991	_	_
)	_	_
MRN_transposed	_	_
(	_	_
AUC=0.990	_	_
)	_	_
(	_	_
a	_	_
)	_	_
Validation	_	_
Set	_	_
0.0	_	_
0.2	_	_
0.4	_	_
0.6	_	_
0.8	_	_
1.0	_	_
0	_	_
.	_	_

#112
0	_	_
.	_	_

#113
0	_	_
.	_	_

#114
0	_	_
.	_	_

#115
0	_	_
.	_	_

#116
1	_	_
.	_	_

#117
False	_	_
Positive	_	_
Rate	_	_
Tr	_	_
ue	_	_
P	_	_
os	_	_
iti	_	_
ve	_	_
R	_	_
at	_	_
e	_	_
U−Net_0.5um	_	_
(	_	_
AUC=0.950	_	_
)	_	_
U−Net_1um	_	_
(	_	_
AUC=0.946	_	_
)	_	_
U−Net_2um	_	_
(	_	_
AUC=0.926	_	_
)	_	_
U−Net_4um	_	_
(	_	_
AUC=0.905	_	_
)	_	_
MRN_bilinear	_	_
(	_	_
AUC=0.952	_	_
)	_	_
MRN_transposed	_	_
(	_	_
AUC=0.955	_	_
)	_	_
(	_	_
b	_	_
)	_	_
Testing	_	_
Set	_	_
Fig.	_	_
3	_	_
:	_	_
Comparisons	_	_
of	_	_
the	_	_
standard	_	_
U-Net	_	_
and	_	_
MRNs	_	_
on	_	_
CAMELYON16	_	_
,	_	_
when	_	_
different	_	_
thresholds	_	_
are	_	_
applied	_	_
to	_	_
the	_	_
predictions	_	_
.	_	_

#118
H	_	_
&	_	_
E	_	_
GT	_	_
mask	_	_
U-Net_0.5um	_	_
MRN_transposedU-Net_1um	_	_
U-Net_2um	_	_
U-Net_4um	_	_
MRN_bilinear	_	_
Fig.	_	_
4	_	_
:	_	_
A	_	_
qualitative	_	_
comparison	_	_
of	_	_
all	_	_
methods	_	_
on	_	_
‘test_090’	_	_
slide	_	_
.	_	_

#119
datasets	_	_
in	_	_
the	_	_
field	_	_
of	_	_
digital	_	_
pathology	_	_
.	_	_

#120
As	_	_
a	_	_
result	_	_
,	_	_
it	_	_
was	_	_
chosen	_	_
for	_	_
evaluating	_	_
the	_	_
proposed	_	_
methods	_	_
against	_	_
the	_	_
standard	_	_
U-Net	_	_
,	_	_
for	_	_
binary	_	_
semantic	_	_
segmentation	_	_
of	_	_
‘normal’	_	_
and	_	_
‘tumor’	_	_
classes	_	_
in	_	_
WSIs	_	_
1	_	_
.	_	_

#121
There	_	_
are	_	_
269	_	_
slides	_	_
in	_	_
the	_	_
training	_	_
set	_	_
,	_	_
159	_	_
of	_	_
which	_	_
are	_	_
normal	_	_
and	_	_
the	_	_
remaining	_	_
110	_	_
are	_	_
tumor	_	_
.	_	_

#122
As	_	_
pointed	_	_
out	_	_
in	_	_
[	_	_
17	_	_
]	_	_
,	_	_
18	_	_
tumor	_	_
slides	_	_
have	_	_
non-exhaustive	_	_
annotations	_	_
and	_	_
thus	_	_
are	_	_
excluded	_	_
from	_	_
the	_	_
experiments	_	_
.	_	_

#123
The	_	_
training	_	_
set	_	_
is	_	_
then	_	_
randomly	_	_
divided	_	_
into	_	_
‘training’	_	_
(	_	_
80	_	_
%	_	_
)	_	_
and	_	_
‘validation’	_	_
(	_	_
20	_	_
%	_	_
)	_	_
,	_	_
where	_	_
the	_	_
validation	_	_
set	_	_
is	_	_
used	_	_
to	_	_
select	_	_
the	_	_
best	_	_
model	_	_
with	_	_
respect	_	_
to	_	_
lowest	_	_
validation	_	_
losses	_	_
.	_	_

#124
The	_	_
testing	_	_
set	_	_
has	_	_
130	_	_
slides	_	_
,	_	_
80	_	_
of	_	_
which	_	_
are	_	_
normal	_	_
and	_	_
the	_	_
rest	_	_
are	_	_
tumor	_	_
.	_	_

#125
We	_	_
excluded	_	_
2	_	_
tumor	_	_
slides	_	_
,	_	_
due	_	_
to	_	_
non-exhaustive	_	_
annotations	_	_
.	_	_

#126
1	_	_
Note	_	_
we	_	_
have	_	_
no	_	_
intention	_	_
to	_	_
tackle	_	_
the	_	_
CAMELYON16	_	_
tasks	_	_
of	_	_
slide-based	_	_
or	_	_

#127
lesion-based	_	_
classifications	_	_
,	_	_
or	_	_
the	_	_
CAMELYON17	_	_
task	_	_
of	_	_
determining	_	_
the	_	_
pN-stage	_	_
for	_	_
a	_	_
patient	_	_
.	_	_

#128
Those	_	_
tasks	_	_
are	_	_
beyond	_	_
the	_	_
scope	_	_
of	_	_
this	_	_
work	_	_
.	_	_

#129
MRN	_	_
for	_	_
Semantic	_	_
Segmentation	_	_
in	_	_
WSIs	_	_
7	_	_

#130
5	_	_
Results	_	_
and	_	_
Analysis	_	_

#131
In	_	_
this	_	_
section	_	_
,	_	_
we	_	_
compare	_	_
the	_	_
methods	_	_
from	_	_
both	_	_
quantitative	_	_
and	_	_
qualitative	_	_
perspectives	_	_
.	_	_

#132
Quantitatively	_	_
,	_	_
we	_	_
intend	_	_
to	_	_
evaluate	_	_
their	_	_
learning	_	_
abilities	_	_
on	_	_
the	_	_
training	_	_
data	_	_
,	_	_
and	_	_
more	_	_
importantly	_	_
the	_	_
generalization	_	_
capabilities	_	_
on	_	_
unseen	_	_
data	_	_
in	_	_
the	_	_
testing	_	_
set	_	_
.	_	_

#133
Therefore	_	_
,	_	_
we	_	_
evaluated	_	_
on	_	_
both	_	_
the	_	_
validation	_	_
set	_	_
and	_	_
the	_	_
testing	_	_
set	_	_
,	_	_
the	_	_
ROC	_	_
curves	_	_
are	_	_
displayed	_	_
in	_	_
Fig.	_	_
3	_	_
.	_	_

#134
On	_	_
the	_	_
validation	_	_
set	_	_
,	_	_
the	_	_
results	_	_
are	_	_
rather	_	_
identical	_	_
,	_	_
and	_	_
MRN-transposed	_	_
is	_	_
marginally	_	_
better	_	_
.	_	_

#135
This	_	_
indicates	_	_
that	_	_
all	_	_
methods	_	_
are	_	_
able	_	_
to	_	_
learn	_	_
from	_	_
the	_	_
given	_	_
data	_	_
.	_	_

#136
Results	_	_
of	_	_
the	_	_
testing	_	_
set	_	_
vary	_	_
more	_	_
significantly	_	_
.	_	_

#137
First	_	_
of	_	_
all	_	_
,	_	_
the	_	_
standard	_	_
U-Net	_	_
performance	_	_
decreases	_	_
as	_	_
the	_	_
mpp	_	_
value	_	_
increases	_	_
,	_	_
while	_	_
the	_	_
proposed	_	_
networks	_	_
both	_	_
outperform	_	_
the	_	_
U-Net	_	_
variants	_	_
.	_	_

#138
The	_	_
reason	_	_
for	_	_
the	_	_
better	_	_
performance	_	_
of	_	_
MRN-transposed	_	_
can	_	_
be	_	_
that	_	_
it	_	_
has	_	_
a	_	_
higher	_	_
capacity	_	_
than	_	_
MRN-bilinear	_	_
,	_	_
since	_	_
transposed	_	_
convolutions	_	_
are	_	_
parameterized	_	_
and	_	_
bilinear	_	_
interpolations	_	_
are	_	_
not	_	_
.	_	_

#139
To	_	_
understand	_	_
the	_	_
results	_	_
qualitatively	_	_
,	_	_
we	_	_
plot	_	_
the	_	_
original	_	_
H	_	_
&	_	_
E	_	_
slide	_	_
,	_	_
the	_	_
annotation	_	_
mask	_	_
,	_	_
and	_	_
the	_	_
predictions	_	_
of	_	_
trained	_	_
models	_	_
,	_	_
as	_	_
shown	_	_
in	_	_
Fig.	_	_
4	_	_
.	_	_

#140
As	_	_
the	_	_
mpp	_	_
value	_	_
goes	_	_
up	_	_
,	_	_
predictions	_	_
of	_	_
the	_	_
U-Net	_	_
variants	_	_
become	_	_
increasingly	_	_
sparser	_	_
and	_	_
less	_	_
confident	_	_
(	_	_
implied	_	_
by	_	_
darker	_	_
colors	_	_
)	_	_
.	_	_

#141
However	_	_
,	_	_
the	_	_
predictions	_	_
of	_	_
both	_	_
MRN-bilinear	_	_
and	_	_
MRN-transposed	_	_
contain	_	_
sufficient	_	_
amount	_	_
of	_	_
details	_	_
and	_	_
are	_	_
relatively	_	_
more	_	_
confident	_	_
.	_	_

#142
This	_	_
explains	_	_
why	_	_
they	_	_
produce	_	_
the	_	_
best	_	_
performance	_	_
when	_	_
evaluating	_	_
at	_	_
the	_	_
pixel	_	_
level	_	_
.	_	_

#143
6	_	_
Conclusions	_	_
and	_	_
Future	_	_
Work	_	_

#144
In	_	_
this	_	_
paper	_	_
,	_	_
we	_	_
proposed	_	_
two	_	_
novel	_	_
multiple	_	_
resolution	_	_
networks	_	_
,	_	_
to	_	_
learn	_	_
from	_	_
and	_	_
infer	_	_
on	_	_
WSIs	_	_
at	_	_
different	_	_
resolutions	_	_
.	_	_

#145
The	_	_
proposed	_	_
methods	_	_
produce	_	_
state-of-the-art	_	_
results	_	_
and	_	_
outperform	_	_
the	_	_
standard	_	_
U-Net	_	_
on	_	_
a	_	_
benchmark	_	_
dataset	_	_
,	_	_
for	_	_
binary	_	_
semantic	_	_
segmentation	_	_
.	_	_

#146
These	_	_
results	_	_
demonstrate	_	_
their	_	_
superior	_	_
learning	_	_
and	_	_
generalization	_	_
capabilities	_	_
.	_	_

#147
In	_	_
addition	_	_
,	_	_
the	_	_
proposed	_	_
methods	_	_
are	_	_
memory	_	_
efficient	_	_
,	_	_
since	_	_
constant	_	_
input	_	_
shapes	_	_
of	_	_
different	_	_
resolutions	_	_
make	_	_
the	_	_
increase	_	_
in	_	_
VRAM	_	_
linear	_	_
for	_	_
training	_	_
and	_	_
prediction	_	_
.	_	_

#148
Furthermore	_	_
,	_	_
we	_	_
can	_	_
now	_	_
train	_	_
one	_	_
model	_	_
for	_	_
all	_	_
resolutions	_	_
of	_	_
interest	_	_
,	_	_
instead	_	_
of	_	_
training	_	_
one	_	_
model	_	_
for	_	_
each	_	_
.	_	_

#149
As	_	_
for	_	_
the	_	_
future	_	_
work	_	_
,	_	_
we	_	_
would	_	_
like	_	_
to	_	_
apply	_	_
the	_	_
proposed	_	_
methods	_	_
to	_	_
other	_	_
more	_	_
challenging	_	_
problems	_	_
,	_	_
e.g.	_	_
multi-class	_	_
semantic	_	_
segmentation	_	_
.	_	_

#150
Other	_	_
network	_	_
architectures	_	_
can	_	_
also	_	_
be	_	_
transformed	_	_
to	_	_
be	_	_
multi-resolution	_	_
capable	_	_
,	_	_
following	_	_
the	_	_
same	_	_
principles	_	_
proposed	_	_
in	_	_
this	_	_
work	_	_
.	_	_

#151
In	_	_
addition	_	_
,	_	_
we	_	_
will	_	_
experiment	_	_
with	_	_
other	_	_
building	_	_
blocks	_	_
of	_	_
semantic	_	_
segmentation	_	_
networks	_	_
,	_	_
to	_	_
develop	_	_
methods	_	_
with	_	_
higher	_	_
capacities	_	_
.	_	_

#152
Acknowledgements	_	_
The	_	_
authors	_	_
would	_	_
like	_	_
to	_	_
thank	_	_
ContextVision	_	_
AB	_	_
,	_	_
Sweden	_	_
for	_	_
supporting	_	_
the	_	_
research	_	_
,	_	_
and	_	_
the	_	_
organizers	_	_
of	_	_
CAMELYON	_	_
challenges	_	_
for	_	_
making	_	_
the	_	_
datasets	_	_
available	_	_
to	_	_
the	_	_
community	_	_
.	_	_

#153
8	_	_
Feng	_	_
Gu	_	_
et	_	_
al	_	_
.	_	_