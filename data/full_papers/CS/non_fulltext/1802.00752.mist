#0
Deep	_	_
Convolutional	_	_
Neural	_	_
Networks	_	_
for	_	_
Breast	_	_
Cancer	_	_
Histology	_	_
Image	_	_
Analysis	_	_
Alexander	_	_
Rakhlin1	_	_
,	_	_
Alexey	_	_
Shvets2	_	_
,	_	_
Vladimir	_	_
Iglovikov3	_	_
,	_	_
and	_	_
Alexandr	_	_
A.	_	_
Kalinin4	_	_
1	_	_
Neuromation	_	_
,	_	_
St.	_	_
Petersburg	_	_
191025	_	_
,	_	_
Russia	_	_
rakhlin	_	_
@	_	_
neuromation.io	_	_

#1
2	_	_
Massachusetts	_	_
Institute	_	_
of	_	_
Technology	_	_
,	_	_
Cambridge	_	_
,	_	_
MA	_	_
02142	_	_
,	_	_
USA	_	_

#2
shvets	_	_
@	_	_
mit.edu	_	_
3	_	_
Lyft	_	_
Inc.	_	_
,	_	_
San	_	_
Francisco	_	_
,	_	_
CA	_	_
94107	_	_
,	_	_
USA	_	_
iglovikov	_	_
@	_	_
gmail.com	_	_

#3
4	_	_
University	_	_
of	_	_
Michigan	_	_
,	_	_
Ann	_	_
Arbor	_	_
,	_	_
MI	_	_
48109	_	_
,	_	_
USA	_	_

#4
akalinin	_	_
@	_	_
umich.edu	_	_
Abstract	_	_
.	_	_

#5
Breast	_	_
cancer	_	_
is	_	_
one	_	_
of	_	_
the	_	_
main	_	_
causes	_	_
of	_	_
cancer	_	_
death	_	_
worldwide	_	_
.	_	_

#6
Early	_	_
diagnostics	_	_
significantly	_	_
increases	_	_
the	_	_
chances	_	_
of	_	_
correct	_	_
treatment	_	_
and	_	_
survival	_	_
,	_	_
but	_	_
this	_	_
process	_	_
is	_	_
tedious	_	_
and	_	_
often	_	_
leads	_	_
to	_	_
a	_	_
disagreement	_	_
between	_	_
pathologists	_	_
.	_	_

#7
Computer-aided	_	_
diagnosis	_	_
systems	_	_
showed	_	_
potential	_	_
for	_	_
improving	_	_
the	_	_
diagnostic	_	_
accuracy	_	_
.	_	_

#8
In	_	_
this	_	_
work	_	_
,	_	_
we	_	_
develop	_	_
the	_	_
computational	_	_
approach	_	_
based	_	_
on	_	_
deep	_	_
convolution	_	_
neural	_	_
networks	_	_
for	_	_
breast	_	_
cancer	_	_
histology	_	_
image	_	_
classification	_	_
.	_	_

#9
Hematoxylin	_	_
and	_	_
eosin	_	_
stained	_	_
breast	_	_
histology	_	_
microscopy	_	_
image	_	_
dataset	_	_
is	_	_
provided	_	_
as	_	_
a	_	_
part	_	_
of	_	_
the	_	_
ICIAR	_	_
2018	_	_
Grand	_	_
Challenge	_	_
on	_	_
Breast	_	_
Cancer	_	_
Histology	_	_
Images	_	_
.	_	_

#10
Our	_	_
approach	_	_
utilizes	_	_
several	_	_
deep	_	_
neural	_	_
network	_	_
architectures	_	_
and	_	_
gradient	_	_
boosted	_	_
trees	_	_
classifier	_	_
.	_	_

#11
For	_	_
4-class	_	_
classification	_	_
task	_	_
,	_	_
we	_	_
report	_	_
87.2	_	_
%	_	_
accuracy	_	_
.	_	_

#12
For	_	_
2-class	_	_
classification	_	_
task	_	_
to	_	_
detect	_	_
carcinomas	_	_
we	_	_
report	_	_
93.8	_	_
%	_	_
accuracy	_	_
,	_	_
AUC	_	_
97.3	_	_
%	_	_
,	_	_
and	_	_
sensitivity/specificity	_	_
96.5/88.0	_	_
%	_	_
at	_	_
the	_	_
high-sensitivity	_	_
operating	_	_
point	_	_
.	_	_

#13
To	_	_
our	_	_
knowledge	_	_
,	_	_
this	_	_
approach	_	_
outperforms	_	_
other	_	_
common	_	_
methods	_	_
in	_	_
automated	_	_
histopathological	_	_
image	_	_
classification	_	_
.	_	_

#14
The	_	_
source	_	_
code	_	_
for	_	_
our	_	_
approach	_	_
is	_	_
made	_	_
publicly	_	_
available	_	_
at	_	_
https	_	_
:	_	_
//github.com/alexander-rakhlin/ICIAR2018	_	_
Keywords	_	_
:	_	_
Medical	_	_
imaging	_	_
,	_	_
Computer-aided	_	_
diagnosis	_	_
(	_	_
CAD	_	_
)	_	_
,	_	_
Computer	_	_
vision	_	_
,	_	_
Image	_	_
recognition	_	_
,	_	_
Deep	_	_
learning	_	_

#15
1	_	_
Introduction	_	_

#16
Breast	_	_
cancer	_	_
is	_	_
the	_	_
most	_	_
common	_	_
cancer	_	_
diagnosed	_	_
among	_	_
US	_	_
women	_	_
(	_	_
excluding	_	_
skin	_	_
cancers	_	_
)	_	_
,	_	_
accounting	_	_
for	_	_
30	_	_
%	_	_
of	_	_
all	_	_
new	_	_
cancer	_	_
diagnoses	_	_
in	_	_
women	_	_
in	_	_
the	_	_
United	_	_
States	_	_
[	_	_
1	_	_
]	_	_
.	_	_

#17
Breast	_	_
tissue	_	_
biopsies	_	_
allow	_	_
the	_	_
pathologists	_	_
to	_	_
histologically	_	_
assess	_	_
the	_	_
microscopic	_	_
structure	_	_
and	_	_
elements	_	_
of	_	_
the	_	_
tissue	_	_
.	_	_

#18
Histopathology	_	_
aims	_	_
to	_	_
distinguish	_	_
between	_	_
normal	_	_
tissue	_	_
,	_	_
non-malignant	_	_
(	_	_
benign	_	_
)	_	_
and	_	_
malignant	_	_
lesions	_	_
(	_	_
carcinomas	_	_
)	_	_
and	_	_
to	_	_
perform	_	_
a	_	_
prognostic	_	_
evaluation	_	_
[	_	_
2	_	_
]	_	_
.	_	_

#19
A	_	_
combination	_	_
of	_	_
ar	_	_
X	_	_
iv	_	_
:1	_	_
2	_	_
.	_	_

#20
2v	_	_
2	_	_
[	_	_
cs	_	_
.C	_	_
V	_	_
]	_	_
3	_	_
A	_	_
pr	_	_
2	_	_
2	_	_
Rakhlin	_	_
et	_	_
al.	_	_
hematoxylin	_	_
and	_	_
eosin	_	_
(	_	_
H	_	_
&	_	_
E	_	_
)	_	_
is	_	_
the	_	_
principal	_	_
stain	_	_
of	_	_
tissue	_	_
specimens	_	_
for	_	_
routine	_	_
histopathological	_	_
diagnostics	_	_
.	_	_

#21
There	_	_
are	_	_
multiple	_	_
types	_	_
of	_	_
breast	_	_
carcinomas	_	_
that	_	_
embody	_	_
characteristic	_	_
tissue	_	_
morphology	_	_
,	_	_
see	_	_
Fig.	_	_
1	_	_
.	_	_

#22
Breast	_	_
carcinomas	_	_
arise	_	_
from	_	_
the	_	_
mammary	_	_
epithelium	_	_
and	_	_
cause	_	_
a	_	_
pre-malignant	_	_
epithelial	_	_
proliferation	_	_
within	_	_
the	_	_
ducts	_	_
,	_	_
called	_	_
ductal	_	_
carcinoma	_	_
in	_	_
situ	_	_
.	_	_

#23
Invasive	_	_
carcinoma	_	_
is	_	_
characterized	_	_
by	_	_
the	_	_
cancer	_	_
cells	_	_
gaining	_	_
the	_	_
capacity	_	_
to	_	_
break	_	_
through	_	_
the	_	_
basal	_	_
membrane	_	_
of	_	_
the	_	_
duct	_	_
walls	_	_
and	_	_
infiltrate	_	_
into	_	_
surrounding	_	_
tissues	_	_
[	_	_
3	_	_
]	_	_
.	_	_

#24
Morphology	_	_
of	_	_
tissue	_	_
,	_	_
cells	_	_
,	_	_
and	_	_
subcellular	_	_
compartments	_	_
is	_	_
regulated	_	_
by	_	_
complex	_	_
biological	_	_
mechanisms	_	_
related	_	_
to	_	_
cell	_	_
differentiation	_	_
,	_	_
development	_	_
,	_	_
and	_	_
cancer	_	_
[	_	_
4	_	_
]	_	_
.	_	_

#25
Traditionally	_	_
,	_	_
morphological	_	_
assessment	_	_
and	_	_
tumor	_	_
grading	_	_
were	_	_
visually	_	_
performed	_	_
by	_	_
the	_	_
pathologist	_	_
,	_	_
however	_	_
,	_	_
this	_	_
process	_	_
is	_	_
tedious	_	_
and	_	_
subjective	_	_
,	_	_
causing	_	_
inter-observer	_	_
variations	_	_
even	_	_
among	_	_
senior	_	_
pathologists	_	_
[	_	_
5,6	_	_
]	_	_
.	_	_

#26
The	_	_
subjectivity	_	_
of	_	_
the	_	_
application	_	_
of	_	_
morphological	_	_
criteria	_	_
in	_	_
visual	_	_
classification	_	_
motivates	_	_
the	_	_
use	_	_
of	_	_
computer-aided	_	_
diagnosis	_	_
(	_	_
CAD	_	_
)	_	_
systems	_	_
to	_	_
improve	_	_
the	_	_
diagnosis	_	_
accuracy	_	_
,	_	_
reduce	_	_
human	_	_
error	_	_
,	_	_
increase	_	_
the	_	_
level	_	_
of	_	_
inter-observer	_	_
agreement	_	_
,	_	_
and	_	_
increased	_	_
reproducibility	_	_
[	_	_
3	_	_
]	_	_
.	_	_

#27
There	_	_
are	_	_
many	_	_
methods	_	_
developed	_	_
for	_	_
the	_	_
digital	_	_
pathology	_	_
image	_	_
analysis	_	_
,	_	_
from	_	_
rule-based	_	_
to	_	_
applications	_	_
of	_	_
machine	_	_
learning	_	_
[	_	_
3	_	_
]	_	_
.	_	_

#28
Recently	_	_
,	_	_
deep	_	_
learning	_	_
based	_	_
approaches	_	_
were	_	_
shown	_	_
to	_	_
outperform	_	_
conventional	_	_
machine	_	_
learning	_	_
methods	_	_
in	_	_
many	_	_
image	_	_
analysis	_	_
task	_	_
,	_	_
automating	_	_
end-to-end	_	_
processing	_	_
[	_	_
7‚Äì9	_	_
]	_	_
.	_	_

#29
In	_	_
the	_	_
domain	_	_
of	_	_
medical	_	_
imaging	_	_
,	_	_
convolutional	_	_
neural	_	_
networks	_	_
(	_	_
CNN	_	_
)	_	_
have	_	_
been	_	_
successfully	_	_
used	_	_
for	_	_
diabetic	_	_
retinopathy	_	_
screening	_	_
[	_	_
10	_	_
]	_	_
,	_	_
bone	_	_
disease	_	_
prediction	_	_
[	_	_
11	_	_
]	_	_
and	_	_
age	_	_
assessment	_	_
[	_	_
12	_	_
]	_	_
,	_	_
and	_	_
other	_	_
problems	_	_
[	_	_
7	_	_
]	_	_
.	_	_

#30
Previous	_	_
deep	_	_
learning-based	_	_
applications	_	_
in	_	_
histological	_	_
microscopic	_	_
image	_	_
analysis	_	_
have	_	_
demonstrated	_	_
their	_	_
potential	_	_
to	_	_
provide	_	_
utility	_	_
in	_	_
diagnosing	_	_
breast	_	_
cancer	_	_
[	_	_
3	_	_
,	_	_
13‚Äì15	_	_
]	_	_
.	_	_

#31
In	_	_
this	_	_
paper	_	_
,	_	_
we	_	_
present	_	_
an	_	_
approach	_	_
for	_	_
histology	_	_
microscopy	_	_
image	_	_
analysis	_	_
for	_	_
breast	_	_
cancer	_	_
type	_	_
classification	_	_
.	_	_

#32
Our	_	_
approach	_	_
utilizes	_	_
deep	_	_
CNNs	_	_
for	_	_
feature	_	_
extraction	_	_
and	_	_
gradient	_	_
boosted	_	_
trees	_	_
for	_	_
classification	_	_
and	_	_
,	_	_
to	_	_
our	_	_
knowledge	_	_
,	_	_
outperforms	_	_
other	_	_
similar	_	_
solutions	_	_
.	_	_

#33
2	_	_
Methods	_	_

#34
2.1	_	_
Dataset	_	_

#35
The	_	_
image	_	_
dataset	_	_
is	_	_
an	_	_
extension	_	_
of	_	_
the	_	_
dataset	_	_
from	_	_
[	_	_
13	_	_
]	_	_
and	_	_
consists	_	_
of	_	_
400	_	_
H	_	_
&	_	_
E	_	_
stain	_	_
images	_	_
(	_	_
2048	_	_
√ó	_	_
1536	_	_
pixels	_	_
)	_	_
.	_	_

#36
All	_	_
the	_	_
images	_	_
are	_	_
digitized	_	_
with	_	_
the	_	_
same	_	_
acquisition	_	_
conditions	_	_
,	_	_
with	_	_
a	_	_
magnification	_	_
of	_	_
200√ó	_	_
and	_	_
pixel	_	_
size	_	_
of	_	_
0.42ùúáùëö	_	_
√ó	_	_
0.42ùúáùëö	_	_
.	_	_

#37
Each	_	_
image	_	_
is	_	_
labeled	_	_
with	_	_
one	_	_
of	_	_
the	_	_
four	_	_
balanced	_	_
classes	_	_
:	_	_
normal	_	_
,	_	_
benign	_	_
,	_	_
in	_	_
situ	_	_
carcinoma	_	_
,	_	_
and	_	_
invasive	_	_
carcinoma	_	_
,	_	_
where	_	_
class	_	_
is	_	_
defined	_	_
as	_	_
a	_	_
predominant	_	_
cancer	_	_
type	_	_
in	_	_
the	_	_
image	_	_
,	_	_
see	_	_
Fig.	_	_
1	_	_
.	_	_

#38
The	_	_
image-wise	_	_
annotation	_	_
was	_	_
performed	_	_
by	_	_
two	_	_
medical	_	_
experts	_	_
[	_	_
16	_	_
]	_	_
.	_	_

#39
The	_	_
goal	_	_
of	_	_
the	_	_
challenge	_	_
is	_	_
to	_	_
provide	_	_
an	_	_
automatic	_	_
classification	_	_
of	_	_
each	_	_
input	_	_
image	_	_
.	_	_

#40
2.2	_	_
Approach	_	_
overview	_	_

#41
The	_	_
limited	_	_
size	_	_
of	_	_
the	_	_
dataset	_	_
(	_	_
400	_	_
images	_	_
of	_	_
4	_	_
classes	_	_
)	_	_
poses	_	_
a	_	_
significant	_	_
challenge	_	_
for	_	_
the	_	_
training	_	_
of	_	_
a	_	_
deep	_	_
learning	_	_
model	_	_
[	_	_
7	_	_
]	_	_
.	_	_

#42
Very	_	_
deep	_	_
CNN	_	_
architectures	_	_
Deep	_	_
Learning	_	_
for	_	_
Breast	_	_
Cancer	_	_
Histology	_	_
3	_	_
Fig.	_	_
1	_	_
:	_	_
Examples	_	_
of	_	_
microscopic	_	_
biopsy	_	_
images	_	_
in	_	_
the	_	_
dataset	_	_
:	_	_
(	_	_
A	_	_
)	_	_
normal	_	_
;	_	_
(	_	_
B	_	_
)	_	_
benign	_	_
;	_	_
(	_	_
C	_	_
)	_	_
in	_	_
situ	_	_
carcinoma	_	_
;	_	_
and	_	_
(	_	_
D	_	_
)	_	_
invasive	_	_
carcinoma	_	_
that	_	_
contain	_	_
millions	_	_
of	_	_
parameters	_	_
such	_	_
as	_	_
VGG	_	_
,	_	_
Inception	_	_
and	_	_
ResNet	_	_
have	_	_
achieved	_	_
the	_	_
state-of-the-art	_	_
results	_	_
in	_	_
many	_	_
computer	_	_
vision	_	_
tasks	_	_
[	_	_
17	_	_
]	_	_
.	_	_

#43
However	_	_
,	_	_
training	_	_
these	_	_
neural	_	_
networks	_	_
from	_	_
scratch	_	_
requires	_	_
a	_	_
large	_	_
number	_	_
of	_	_
images	_	_
,	_	_
as	_	_
training	_	_
on	_	_
a	_	_
small	_	_
dataset	_	_
leads	_	_
to	_	_
overfitting	_	_
i.e.	_	_
inability	_	_
to	_	_
generalize	_	_
knowledge	_	_
.	_	_

#44
A	_	_
typical	_	_
remedy	_	_
in	_	_
these	_	_
circumstances	_	_
is	_	_
called	_	_
fine-tuning	_	_
when	_	_
only	_	_
a	_	_
part	_	_
of	_	_
the	_	_
pre-trained	_	_
neural	_	_
network	_	_
is	_	_
being	_	_
fitted	_	_
to	_	_
a	_	_
new	_	_
dataset	_	_
.	_	_

#45
However	_	_
,	_	_
in	_	_
our	_	_
experiments	_	_
,	_	_
fine-tuning	_	_
approach	_	_
did	_	_
not	_	_
demonstrate	_	_
good	_	_
performance	_	_
on	_	_
this	_	_
task	_	_
.	_	_

#46
Therefore	_	_
,	_	_
we	_	_
employed	_	_
a	_	_
different	_	_
approach	_	_
known	_	_
as	_	_
deep	_	_
convolutional	_	_
feature	_	_
representation	_	_
[	_	_
18	_	_
]	_	_
.	_	_

#47
To	_	_
this	_	_
end	_	_
,	_	_
deep	_	_
CNNs	_	_
,	_	_
trained	_	_
on	_	_
large	_	_
and	_	_
general	_	_
datasets	_	_
like	_	_
ImageNet	_	_
(	_	_
10M	_	_
images	_	_
,	_	_
20K	_	_
classes	_	_
)	_	_
[	_	_
19	_	_
]	_	_
,	_	_
are	_	_
used	_	_
for	_	_
unsupervised	_	_
feature	_	_
representation	_	_
extraction	_	_
.	_	_

#48
In	_	_
this	_	_
study	_	_
,	_	_
breast	_	_
histology	_	_
images	_	_
are	_	_
encoded	_	_
with	_	_
the	_	_
state-of-the-art	_	_
,	_	_
general	_	_
purpose	_	_
networks	_	_
to	_	_
obtain	_	_
sparse	_	_
descriptors	_	_
of	_	_
low	_	_
dimensionality	_	_
(	_	_
1408	_	_
or	_	_
2048	_	_
)	_	_
.	_	_

#49
This	_	_
unsupervised	_	_
dimensionality	_	_
reduction	_	_
step	_	_
significantly	_	_
reduces	_	_
the	_	_
risk	_	_
of	_	_
overfitting	_	_
on	_	_
the	_	_
next	_	_
stage	_	_
of	_	_
supervised	_	_
learning	_	_
.	_	_

#50
We	_	_
use	_	_
LightGBM	_	_
as	_	_
a	_	_
fast	_	_
,	_	_
distributed	_	_
,	_	_
high	_	_
performance	_	_
implementation	_	_
of	_	_
gradient	_	_
boosted	_	_
trees	_	_
for	_	_
supervised	_	_
classification	_	_
[	_	_
20	_	_
]	_	_
.	_	_

#51
Gradient	_	_
boosting	_	_
models	_	_
are	_	_
being	_	_
extensively	_	_
used	_	_
in	_	_
machine	_	_
learning	_	_
due	_	_
to	_	_
their	_	_
speed	_	_
,	_	_
accuracy	_	_
,	_	_
and	_	_
robustness	_	_
against	_	_
overfitting	_	_
[	_	_
21	_	_
]	_	_
.	_	_

#52
2.3	_	_
Data	_	_
pre-processing	_	_
and	_	_
augmentation	_	_

#53
To	_	_
bring	_	_
the	_	_
microscopy	_	_
images	_	_
into	_	_
a	_	_
common	_	_
space	_	_
to	_	_
enable	_	_
improved	_	_
quantitative	_	_
analysis	_	_
,	_	_
we	_	_
normalize	_	_
the	_	_
amount	_	_
of	_	_
H	_	_
&	_	_
E	_	_
stained	_	_
on	_	_
the	_	_
tissue	_	_
as	_	_
described	_	_
in	_	_
[	_	_
22	_	_
]	_	_
.	_	_

#54
For	_	_
each	_	_
image	_	_
,	_	_
we	_	_
perform	_	_
50	_	_
random	_	_
color	_	_
augmentations	_	_
.	_	_

#55
Following	_	_
[	_	_
23	_	_
]	_	_
the	_	_
amount	_	_
of	_	_
H	_	_
&	_	_
E	_	_
is	_	_
adjusted	_	_
by	_	_
decomposing	_	_
the	_	_
RGB	_	_
color	_	_
of	_	_
the	_	_
tissue	_	_
into	_	_
H	_	_
&	_	_
E	_	_
color	_	_
space	_	_
,	_	_
followed	_	_
by	_	_
multiplying	_	_
the	_	_
magnitude	_	_
of	_	_
H	_	_
&	_	_
E	_	_
of	_	_
every	_	_
pixel	_	_
by	_	_
two	_	_
random	_	_
uniform	_	_
variables	_	_
from	_	_
the	_	_
range	_	_
[	_	_
0.7	_	_
,	_	_
1.3	_	_
]	_	_
.	_	_

#56
Furthermore	_	_
,	_	_
in	_	_
our	_	_
initial	_	_
experiments	_	_
,	_	_
we	_	_
used	_	_
different	_	_
image	_	_
scales	_	_
,	_	_
the	_	_
original	_	_
2048	_	_
√ó	_	_
1536	_	_
pixels	_	_
and	_	_
downscaled	_	_
in	_	_
half	_	_
to	_	_
1024	_	_
√ó	_	_
768	_	_
pixels	_	_
.	_	_

#57
From	_	_
the	_	_
images	_	_
of	_	_
the	_	_
original	_	_
size	_	_
we	_	_
extract	_	_
random	_	_
crops	_	_
of	_	_
two	_	_
sizes	_	_
800	_	_
√ó	_	_
800	_	_
and	_	_
1300√ó1300	_	_
.	_	_

#58
From	_	_
the	_	_
downscaled	_	_
images	_	_
we	_	_
extract	_	_
crops	_	_
of	_	_
400√ó400	_	_
pixels	_	_
and	_	_
650	_	_
√ó	_	_
650	_	_
pixels	_	_
.	_	_

#59
Lately	_	_
,	_	_
we	_	_
found	_	_
downscaled	_	_
images	_	_
is	_	_
enough	_	_
.	_	_

#60
Thereby	_	_
,	_	_
each	_	_
image	_	_
is	_	_
represented	_	_
by	_	_
20	_	_
crops	_	_
.	_	_

#61
The	_	_
crops	_	_
are	_	_
then	_	_
encoded	_	_
into	_	_
20	_	_
descriptors	_	_
.	_	_

#62
4	_	_
Rakhlin	_	_
et	_	_
al.	_	_
Fig.	_	_
2	_	_
:	_	_
An	_	_
overview	_	_
of	_	_
the	_	_
pre-processing	_	_
pipeline	_	_
.	_	_

#63
Then	_	_
,	_	_
the	_	_
set	_	_
of	_	_
20	_	_
descriptors	_	_
is	_	_
combined	_	_
through	_	_
3-norm	_	_
pooling	_	_
[	_	_
24	_	_
]	_	_
into	_	_
a	_	_
single	_	_
descriptor	_	_
:	_	_
dùëùùëúùëúùëô	_	_
=	_	_
(	_	_
Ô∏É	_	_
ùëÅ	_	_
ùëÅ‚àëÔ∏Å	_	_
ùëñ=1	_	_
(	_	_
dùëñ	_	_
)	_	_
ùëù	_	_
)	_	_
Ô∏É	_	_
1	_	_
ùëù	_	_
,	_	_
(	_	_
1	_	_
)	_	_
where	_	_
the	_	_
hyperparameter	_	_
ùëù	_	_
=	_	_
3	_	_
as	_	_
suggested	_	_
in	_	_
[	_	_
24,25	_	_
]	_	_
,	_	_
ùëÅ	_	_
is	_	_
the	_	_
number	_	_
of	_	_
crops	_	_
,	_	_
dùëñ	_	_
is	_	_
descriptor	_	_
of	_	_
a	_	_
crop	_	_
and	_	_
dùëùùëúùëúùëô	_	_
is	_	_
pooled	_	_
descriptor	_	_
of	_	_
the	_	_
image	_	_
.	_	_

#64
The	_	_
p-norm	_	_
of	_	_
a	_	_
vector	_	_
gives	_	_
the	_	_
average	_	_
for	_	_
ùëù	_	_
=	_	_
1	_	_
and	_	_
the	_	_
max	_	_
for	_	_
ùëù	_	_
‚Üí	_	_
‚àû	_	_
.	_	_

#65
As	_	_
a	_	_
result	_	_
,	_	_
for	_	_
each	_	_
original	_	_
image	_	_
,	_	_
we	_	_
obtain	_	_
50	_	_
(	_	_
number	_	_
of	_	_
color	_	_
augmentations	_	_
)	_	_
√ó2	_	_
(	_	_
crop	_	_
sizes	_	_
)	_	_
√ó3	_	_
(	_	_
CNN	_	_
encoders	_	_
)	_	_
=	_	_
300	_	_
descriptors	_	_
.	_	_

#66
2.4	_	_
Feature	_	_
extraction	_	_

#67
Overall	_	_
pre-processing	_	_
pipeline	_	_
is	_	_
depicted	_	_
in	_	_
Fig.	_	_
2	_	_
.	_	_

#68
For	_	_
features	_	_
extraction	_	_
,	_	_
we	_	_
use	_	_
standard	_	_
pre-trained	_	_
ResNet-50	_	_
,	_	_
InceptionV3	_	_
and	_	_
VGG-16	_	_
networks	_	_
from	_	_
Keras	_	_
distribution	_	_
[	_	_
26	_	_
]	_	_
.	_	_

#69
We	_	_
remove	_	_
fully	_	_
connected	_	_
layers	_	_
from	_	_
each	_	_
model	_	_
to	_	_
allow	_	_
the	_	_
networks	_	_
to	_	_
consume	_	_
images	_	_
of	_	_
an	_	_
arbitrary	_	_
size	_	_
.	_	_

#70
In	_	_
ResNet-50	_	_
and	_	_
InceptionV3	_	_
,	_	_
we	_	_
convert	_	_
the	_	_
last	_	_
convolutional	_	_
layer	_	_
consisting	_	_
of	_	_
2048	_	_
channels	_	_
via	_	_
GlobalAveragePooling	_	_
into	_	_
a	_	_
one-dimensional	_	_
feature	_	_
vector	_	_
with	_	_
a	_	_
length	_	_
of	_	_
2048	_	_
.	_	_

#71
With	_	_
VGG-16	_	_
we	_	_
apply	_	_
the	_	_
GlobalAveragePooling	_	_
operation	_	_
to	_	_
the	_	_
four	_	_
internal	_	_
convolutional	_	_
layers	_	_
:	_	_
block2	_	_
,	_	_
block3	_	_
,	_	_
block4	_	_
,	_	_
block5	_	_
with	_	_
128	_	_
,	_	_
256	_	_
,	_	_
512	_	_
,	_	_
512	_	_
channels	_	_
respectively	_	_
.	_	_

#72
We	_	_
concatenate	_	_
them	_	_
into	_	_
one	_	_
vector	_	_
with	_	_
a	_	_
length	_	_
of	_	_
1408	_	_
,	_	_
see	_	_
Fig.	_	_
3	_	_
.	_	_

#73
Deep	_	_
Learning	_	_
for	_	_
Breast	_	_
Cancer	_	_
Histology	_	_
5	_	_
Fig.	_	_
3	_	_
:	_	_
Schematic	_	_
overview	_	_
of	_	_
the	_	_
network	_	_
architecture	_	_
for	_	_
deep	_	_
feature	_	_
extraction	_	_
.	_	_

#74
2.5	_	_
Training	_	_

#75
We	_	_
split	_	_
the	_	_
data	_	_
into	_	_
10	_	_
stratified	_	_
folds	_	_
to	_	_
preserve	_	_
class	_	_
distribution	_	_
.	_	_

#76
Augmentations	_	_
increase	_	_
the	_	_
size	_	_
of	_	_
the	_	_
dataset	_	_
√ó300	_	_
(	_	_
2	_	_
patch	_	_
sizes	_	_
x	_	_
3	_	_
encoders	_	_
x	_	_
50	_	_
color/affine	_	_
augmentations	_	_
)	_	_
.	_	_

#77
Nevertheless	_	_
,	_	_
the	_	_
descriptors	_	_
of	_	_
a	_	_
given	_	_
image	_	_
remain	_	_
correlated	_	_
.	_	_

#78
To	_	_
prevent	_	_
information	_	_
leakage	_	_
,	_	_
all	_	_
descriptors	_	_
of	_	_
the	_	_
same	_	_
image	_	_
must	deontic	_
be	_	_
contained	_	_
in	_	_
the	_	_
same	_	_
fold	_	_
.	_	_

#79
For	_	_
each	_	_
combination	_	_
of	_	_
the	_	_
encoder	_	_
,	_	_
crop	_	_
size	_	_
and	_	_
scale	_	_
we	_	_
train	_	_
10	_	_
gradient	_	_
boosting	_	_
models	_	_
with	_	_
10-fold	_	_
cross-validation	_	_
.	_	_

#80
In	_	_
addition	_	_
to	_	_
obtaining	_	_
cross-validated	_	_
results	_	_
,	_	_
this	_	_
allows	_	_
us	_	_
to	_	_
increase	_	_
the	_	_
diversity	_	_
of	_	_
the	_	_
models	_	_
with	_	_
limited	_	_
data	_	_
(	_	_
bagging	_	_
)	_	_
.	_	_

#81
Furthermore	_	_
,	_	_
we	_	_
recycle	_	_
each	_	_
dataset	_	_
5	_	_
times	_	_
with	_	_
different	_	_
random	_	_
seeds	_	_
in	_	_
LightGBM	_	_
adding	_	_
augmentation	_	_
on	_	_
the	_	_
model	_	_
level	_	_
.	_	_

#82
As	_	_
a	_	_
result	_	_
,	_	_
we	_	_
train	_	_
10	_	_
(	_	_
number	_	_
of	_	_
folds	_	_
)	_	_
√ó5	_	_
(	_	_
seeds	_	_
)	_	_
√ó4	_	_
(	_	_
scale	_	_
and	_	_
crop	_	_
)	_	_
√ó3	_	_
(	_	_
CNN	_	_
encoders	_	_
)	_	_
=	_	_
600	_	_
gradient	_	_
boosting	_	_
models	_	_
.	_	_

#83
At	_	_
the	_	_
cross-validation	_	_
stage	_	_
,	_	_
we	_	_
predict	_	_
every	_	_
fold	_	_
only	_	_
with	_	_
the	_	_
models	_	_
not	_	_
trained	_	_
on	_	_
this	_	_
fold	_	_
.	_	_

#84
For	_	_
the	_	_
test	_	_
data	_	_
,	_	_
we	_	_
similarly	_	_
extract	_	_
300	_	_
descriptors	_	_
for	_	_
each	_	_
image	_	_
and	_	_
use	_	_
them	_	_
with	_	_
all	_	_
models	_	_
trained	_	_
for	_	_
particular	_	_
patch	_	_
size	_	_
and	_	_
encoder	_	_
.	_	_

#85
The	_	_
predictions	_	_
are	_	_
averaged	_	_
over	_	_
all	_	_
augmentations	_	_
and	_	_
models	_	_
.	_	_

#86
Finally	_	_
,	_	_
the	_	_
predicted	_	_
class	_	_
is	_	_
defined	_	_
by	_	_
the	_	_
maximum	_	_
probability	_	_
score	_	_
.	_	_

#87
3	_	_
Results	_	_

#88
To	_	_
validate	_	_
the	_	_
approach	_	_
we	_	_
use	_	_
10-fold	_	_
stratified	_	_
cross-validation	_	_
.	_	_

#89
For	_	_
2-class	_	_
non-carcinomas	_	_
(	_	_
normal	_	_
and	_	_
benign	_	_
)	_	_
vs.	_	_
carcinomas	_	_
(	_	_
in	_	_
situ	_	_
and	_	_
invasive	_	_
)	_	_
classification	_	_
accuracy	_	_
was	_	_
93.8¬±2.3	_	_
%	_	_
,	_	_
the	_	_
area	_	_
under	_	_
the	_	_
ROC	_	_
curve	_	_
6	_	_
Rakhlin	_	_
et	_	_
al.	_	_
Fig.	_	_
4	_	_
:	_	_
a	_	_
)	_	_
Non-carcinoma	_	_
vs.	_	_
carcinoma	_	_
classification	_	_
,	_	_
ROC	_	_
.	_	_

#90
High	_	_
sensitivity	_	_
setpoint=0.33	_	_
(	_	_
green	_	_
)	_	_
:	_	_
96.5	_	_
%	_	_
sensitivity	_	_
and	_	_
88.0	_	_
%	_	_
specificity	_	_
to	_	_
detect	_	_
carcinomas	_	_
.	_	_

#91
Setpoint=0.50	_	_
(	_	_
blue	_	_
)	_	_
:	_	_
93.0	_	_
%	_	_
sensitivity	_	_
and	_	_
94.5	_	_
%	_	_
specificity	_	_
b	_	_
)	_	_
Confusion	_	_
matrix	_	_
,	_	_
without	_	_
normalization	_	_
.	_	_

#92
Vertical	_	_
axis	_	_
-	_	_
ground	_	_
truth	_	_
,	_	_
horizontal	_	_
-	_	_
predictions	_	_
.	_	_

#93
Table	_	_
1	_	_
:	_	_
Accuracy	_	_
(	_	_
%	_	_
)	_	_
and	_	_
standard	_	_
deviation	_	_
for	_	_
4-class	_	_
classification	_	_
evaluated	_	_
over	_	_
10	_	_
folds	_	_
via	_	_
cross-validation	_	_
.	_	_

#94
Results	_	_
for	_	_
the	_	_
blended	_	_
model	_	_
is	_	_
in	_	_
the	_	_
bottom	_	_
.	_	_

#95
Model	_	_
name	_	_
represented	_	_
as	_	_
‚ü®CNN‚ü©-‚ü®crop	_	_
size‚ü©	_	_
,	_	_
thereby	_	_
VGG-650	_	_
denotes	_	_
LightGBM	_	_
trained	_	_
on	_	_
deep	_	_
features	_	_
extracted	_	_
from	_	_
650x650	_	_
crops	_	_
with	_	_
VGG-16	_	_
encoder	_	_
.	_	_

#96
Each	_	_
column	_	_
in	_	_
the	_	_
table	_	_
corresponds	_	_
to	_	_
the	_	_
fold	_	_
number	_	_
.	_	_

#97
f1	_	_
f2	_	_
f3	_	_
f4	_	_
f5	_	_
f6	_	_
f7	_	_
f8	_	_
f9	_	_
f10	_	_
mean	_	_
std	_	_
ResNet-400	_	_
92.0	_	_
77.5	_	_
86.5	_	_
87.5	_	_
79.5	_	_
84.0	_	_
85.0	_	_
83.0	_	_
84.0	_	_
82.5	_	_
84.2	_	_
4.2	_	_
ResNet-650	_	_
91.0	_	_
77.5	_	_
86.0	_	_
89.5	_	_
81.0	_	_
74.0	_	_
85.5	_	_
83.0	_	_
84.5	_	_
82.5	_	_
83.5	_	_
5.2	_	_
VGG-400	_	_
87.5	_	_
83.0	_	_
81.5	_	_
84.0	_	_
84.0	_	_
82.5	_	_
80.5	_	_
82.0	_	_
87.5	_	_
83.0	_	_
83.6	_	_
2.9	_	_
VGG-650	_	_
89.5	_	_
85.5	_	_
78.5	_	_
85.0	_	_
81.0	_	_
78.0	_	_
81.5	_	_
85.5	_	_
89.0	_	_
80.5	_	_
83.4	_	_
4.4	_	_
Inception-400	_	_
93.0	_	_
86.0	_	_
71.5	_	_
92.0	_	_
85.0	_	_
84.5	_	_
82.5	_	_
79.0	_	_
79.5	_	_
76.5	_	_
83.0	_	_
6.5	_	_
Inception-650	_	_
91.0	_	_
84.5	_	_
73.5	_	_
90.0	_	_
84.0	_	_
81.0	_	_
82.0	_	_
84.5	_	_
78.0	_	_
77.0	_	_
82.5	_	_
5.5	_	_
std	_	_
1.8	_	_
3.5	_	_
5.7	_	_
2.8	_	_
2.0	_	_
3.7	_	_
1.8	_	_
2.1	_	_
3.9	_	_
2.7	_	_
3.0	_	_
Model	_	_
fusion	_	_
92.5	_	_
82.5	_	_
87.5	_	_
87.5	_	_
87.5	_	_
90.0	_	_
85.0	_	_
87.5	_	_
87.5	_	_
85.0	_	_
87.2	_	_
2.6	_	_
was	_	_
0.973	_	_
,	_	_
see	_	_
Fig.4a	_	_
.	_	_

#98
At	_	_
high	_	_
sensitivity	_	_
setpoint	_	_
0.33	_	_
the	_	_
sensitivity	_	_
of	_	_
the	_	_
model	_	_
to	_	_
detect	_	_
carcinomas	_	_
was	_	_
96.5	_	_
%	_	_
and	_	_
specificity	_	_
88.0	_	_
%	_	_
.	_	_

#99
At	_	_
the	_	_
setpoint	_	_
0.50	_	_
the	_	_
sensitivity	_	_
of	_	_
the	_	_
model	_	_
was	_	_
93.0	_	_
%	_	_
and	_	_
specificity	_	_
94.5	_	_
%	_	_
,	_	_
Fig.	_	_
4a	_	_
.	_	_

#100
Out	_	_
of	_	_
200	_	_
carcinomas	_	_
cases	_	_
only	_	_
9	_	_
in	_	_
situ	_	_
and	_	_
5	_	_
invasive	_	_
were	_	_
missed	_	_
,	_	_
Fig.4b	_	_
.	_	_

#101
Table	_	_
1	_	_
shows	_	_
classification	_	_
accuracy	_	_
for	_	_
4-class	_	_
classification	_	_
.	_	_

#102
Accuracy	_	_
averaged	_	_
across	_	_
all	_	_
folds	_	_
was	_	_
87.2¬±2.6	_	_
%	_	_
.	_	_

#103
Finally	_	_
,	_	_
the	_	_
importance	_	_
of	_	_
strong	_	_
augmentation	_	_
and	_	_
model	_	_
fusion	_	_
we	_	_
use	_	_
is	_	_
particularly	_	_
evident	_	_
from	_	_
the	_	_
Table	_	_
1	_	_
.	_	_

#104
The	_	_
fused	_	_
model	_	_
accuracy	_	_
is	_	_
by	_	_
4-5	_	_
%	_	_
higher	_	_
than	_	_
any	_	_
of	_	_
its	_	_
individual	_	_
constituents	_	_
.	_	_

#105
Deep	_	_
Learning	_	_
for	_	_
Breast	_	_
Cancer	_	_
Histology	_	_
7	_	_
The	_	_
standard	_	_
deviation	_	_
of	_	_
the	_	_
ensemble	_	_
across	_	_
10	_	_
folds	_	_
is	_	_
twice	_	_
as	_	_
low	_	_
than	_	_
the	_	_
average	_	_
standard	_	_
deviation	_	_
of	_	_
the	_	_
individual	_	_
models	_	_
.	_	_

#106
Moreover	_	_
,	_	_
all	_	_
our	_	_
results	_	_
in	_	_
the	_	_
Table	_	_
1	_	_
are	_	_
slightly	_	_
improved	_	_
by	_	_
averaging	_	_
across	_	_
5	_	_
seeded	_	_
models	_	_
.	_	_

#107
4	_	_
Conclusions	_	_

#108
In	_	_
this	_	_
paper	_	_
,	_	_
we	_	_
propose	_	_
a	_	_
simple	_	_
and	_	_
effective	_	_
method	_	_
for	_	_
the	_	_
classification	_	_
of	_	_
H	_	_
&	_	_
E	_	_
stained	_	_
histological	_	_
breast	_	_
cancer	_	_
images	_	_
in	_	_
the	_	_
situation	_	_
of	_	_
very	_	_
small	_	_
training	_	_
data	_	_
(	_	_
few	_	_
hundred	_	_
samples	_	_
)	_	_
.	_	_

#109
To	_	_
increase	_	_
the	_	_
robustness	_	_
of	_	_
the	_	_
classifier	_	_
we	_	_
use	_	_
strong	_	_
data	_	_
augmentation	_	_
and	_	_
deep	_	_
convolutional	_	_
features	_	_
extracted	_	_
at	_	_
different	_	_
scales	_	_
with	_	_
publicly	_	_
available	_	_
CNNs	_	_
pretrained	_	_
on	_	_
ImageNet	_	_
.	_	_

#110
On	_	_
top	_	_
of	_	_
it	_	_
,	_	_
we	_	_
apply	_	_
highly	_	_
accurate	_	_
and	_	_
prone	_	_
to	_	_
overfitting	_	_
implementation	_	_
of	_	_
the	_	_
gradient	_	_
boosting	_	_
algorithm	_	_
.	_	_

#111
Unlike	_	_
some	_	_
previous	_	_
works	_	_
,	_	_
we	_	_
purposely	_	_
avoid	_	_
training	_	_
neural	_	_
networks	_	_
on	_	_
this	_	_
amount	_	_
of	_	_
data	_	_
to	_	_
prevent	_	_
suboptimal	_	_
generalization	_	_
.	_	_

#112
To	_	_
our	_	_
knowledge	_	_
,	_	_
the	_	_
reported	_	_
results	_	_
are	_	_
superior	_	_
to	_	_
the	_	_
automated	_	_
analysis	_	_
of	_	_
breast	_	_
cancer	_	_
images	_	_
reported	_	_
in	_	_
literature	_	_
[	_	_
13‚Äì15	_	_
]	_	_
.	_	_

#113
Acknowledgments	_	_
The	_	_
authors	_	_
thank	_	_
the	_	_
Open	_	_
Data	_	_
Science	_	_
community	_	_
[	_	_
27	_	_
]	_	_
for	_	_
useful	_	_
suggestions	_	_
and	_	_
other	_	_
help	_	_
aiding	_	_
the	_	_
development	_	_
of	_	_
this	_	_
work	_	_
.	_	_