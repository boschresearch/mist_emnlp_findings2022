#0
GENERATIVE	_	_
ADVERSARIAL	_	_
NETWORKS	_	_
FOR	_	_
IMAGE-TO-IMAGE	_	_
TRANSLATION	_	_
ON	_	_
MULTI-CONTRAST	_	_
MR	_	_
IMAGES	_	_
-	_	_
A	_	_
COMPARISON	_	_
OF	_	_
CYCLEGAN	_	_
AND	_	_
UNIT	_	_
Per	_	_
Welander	_	_
a	_	_
Simon	_	_
Karlsson	_	_
a	_	_
Anders	_	_
Eklund	_	_
a	_	_
,	_	_
b	_	_
,	_	_
c	_	_
aDivision	_	_
of	_	_
Medical	_	_
Informatics	_	_
,	_	_
Department	_	_
of	_	_
Biomedical	_	_
Engineering	_	_
,	_	_
Linköping	_	_
University	_	_
,	_	_
Linköping	_	_
,	_	_
Sweden	_	_
bDivision	_	_
of	_	_
Statistics	_	_
and	_	_
Machine	_	_
Learning	_	_
,	_	_
Department	_	_
of	_	_
Computer	_	_
and	_	_
Information	_	_
Science	_	_
,	_	_
Linköping	_	_
University	_	_
,	_	_
Linköping	_	_
,	_	_
Sweden	_	_
cCenter	_	_
for	_	_
Medical	_	_
Image	_	_
Science	_	_
and	_	_
Visualization	_	_
(	_	_
CMIV	_	_
)	_	_
,	_	_
Linköping	_	_
University	_	_
,	_	_
Linköping	_	_
,	_	_
Sweden	_	_
ABSTRACT	_	_
In	_	_
medical	_	_
imaging	_	_
,	_	_
a	_	_
general	_	_
problem	_	_
is	_	_
that	_	_
it	_	_
is	_	_
costly	_	_
and	_	_
time	_	_
consuming	_	_
to	_	_
collect	_	_
high	_	_
quality	_	_
data	_	_
from	_	_
healthy	_	_
and	_	_
diseased	_	_
subjects	_	_
.	_	_

#1
Generative	_	_
adversarial	_	_
networks	_	_
(	_	_
GANs	_	_
)	_	_
is	_	_
a	_	_
deep	_	_
learning	_	_
method	_	_
that	_	_
has	_	_
been	_	_
developed	_	_
for	_	_
synthesizing	_	_
data	_	_
.	_	_

#2
GANs	_	_
can	_	_
thereby	_	_
be	_	_
used	_	_
to	_	_
generate	_	_
more	_	_
realistic	_	_
training	_	_
data	_	_
,	_	_
to	_	_
improve	_	_
classification	_	_
performance	_	_
of	_	_
machine	_	_
learning	_	_
algorithms	_	_
.	_	_

#3
Another	_	_
application	_	_
of	_	_
GANs	_	_
is	_	_
image-to-image	_	_
translations	_	_
,	_	_
e.g.	_	_
generating	_	_
magnetic	_	_
resonance	_	_
(	_	_
MR	_	_
)	_	_
images	_	_
from	_	_
computed	_	_
tomography	_	_
(	_	_
CT	_	_
)	_	_
images	_	_
,	_	_
which	_	_
can	_	_
be	_	_
used	_	_
to	_	_
obtain	_	_
multimodal	_	_
datasets	_	_
from	_	_
a	_	_
single	_	_
modality	_	_
.	_	_

#4
Here	_	_
,	_	_
we	_	_
evaluate	_	_
two	_	_
unsupervised	_	_
GAN	_	_
models	_	_
(	_	_
CycleGAN	_	_
and	_	_
UNIT	_	_
)	_	_
for	_	_
image-to-image	_	_
translation	_	_
of	_	_
T1-	_	_
and	_	_
T2-weighted	_	_
MR	_	_
images	_	_
,	_	_
by	_	_
comparing	_	_
generated	_	_
synthetic	_	_
MR	_	_
images	_	_
to	_	_
ground	_	_
truth	_	_
images	_	_
.	_	_

#5
We	_	_
also	_	_
evaluate	_	_
two	_	_
supervised	_	_
models	_	_
;	_	_
a	_	_
modification	_	_
of	_	_
CycleGAN	_	_
and	_	_
a	_	_
pure	_	_
generator	_	_
model	_	_
.	_	_

#6
A	_	_
small	_	_
perceptual	_	_
study	_	_
was	_	_
also	_	_
performed	_	_
to	_	_
evaluate	_	_
how	_	_
visually	_	_
realistic	_	_
the	_	_
synthesized	_	_
images	_	_
are	_	_
.	_	_

#7
It	_	_
is	_	_
shown	_	_
that	_	_
the	_	_
implemented	_	_
GAN	_	_
models	_	_
can	_	_
synthesize	_	_
visually	_	_
realistic	_	_
MR	_	_
images	_	_
(	_	_
incorrectly	_	_
labeled	_	_
as	_	_
real	_	_
by	_	_
a	_	_
human	_	_
)	_	_
.	_	_

#8
It	_	_
is	_	_
also	_	_
shown	_	_
that	_	_
models	_	_
producing	_	_
more	_	_
visually	_	_
realistic	_	_
synthetic	_	_
images	_	_
not	_	_
necessarily	_	_
have	_	_
better	_	_
quantitative	_	_
error	_	_
measurements	_	_
,	_	_
when	_	_
compared	_	_
to	_	_
ground	_	_
truth	_	_
data	_	_
.	_	_

#9
Code	_	_
is	_	_
available	_	_
at	_	_
https	_	_
:	_	_
//github.com/simontomaskarlsson/GAN-MRI	_	_
.	_	_

#10
1	_	_
.	_	_

#11
INTRODUCTION	_	_
Deep	_	_
learning	_	_
has	_	_
been	_	_
applied	_	_
in	_	_
many	_	_
different	_	_
research	_	_
fields	_	_
to	_	_
solve	_	_
complicated	_	_
problems	_	_
[	_	_
1	_	_
]	_	_
,	_	_
made	_	_
possible	_	_
through	_	_
parallel	_	_
computing	_	_
and	_	_
big	_	_
datasets	_	_
.	_	_

#12
Acquiring	_	_
a	_	_
large	_	_
annotated	_	_
medical	_	_
imaging	_	_
dataset	_	_
can	_	_
be	_	_
rather	_	_
challenging	_	_
for	_	_
classification	_	_
problems	_	_
(	_	_
e.g.	_	_
discriminating	_	_
healthy	_	_
and	_	_
diseased	_	_
subjects	_	_
)	_	_
,	_	_
as	_	_
one	_	_
training	_	_
example	_	_
then	_	_
corresponds	_	_
to	_	_
one	_	_
subject	_	_
[	_	_
2	_	_
]	_	_
.	_	_

#13
Data	_	_
augmentation	_	_
,	_	_
e.g.	_	_
rotation	_	_
,	_	_
cropping	_	_
and	_	_
scaling	_	_
,	_	_
is	_	_
normally	_	_
used	_	_
to	_	_
increase	_	_
the	_	_
amount	_	_
of	_	_
training	_	_
data	_	_
,	_	_
but	_	_
can	_	_
only	_	_
provide	_	_
limited	_	_
alternative	_	_
data	_	_
.	_	_

#14
A	_	_
more	_	_
advanced	_	_
data	_	_
augmentation	_	_
technique	_	_
,	_	_
generative	_	_
adversarial	_	_
networks	_	_
(	_	_
GANs	_	_
)	_	_
[	_	_
3	_	_
]	_	_
,	_	_
uses	_	_
two	_	_
competing	_	_
convolutional	_	_
neural	_	_
networks	_	_
(	_	_
CNNs	_	_
)	_	_
;	_	_
one	_	_
that	_	_
generates	_	_
new	_	_
samples	_	_
from	_	_
noise	_	_
and	_	_
one	_	_
that	_	_
that	_	_
discriminates	_	_
samples	_	_
as	_	_
real	_	_
or	_	_
synthetic	_	_
.	_	_

#15
The	_	_
most	_	_
obvious	_	_
application	_	_
of	_	_
a	_	_
GAN	_	_
in	_	_
medical	_	_
imaging	_	_
is	_	_
to	_	_
generate	_	_
additional	_	_
realistic	_	_
training	_	_
data	_	_
,	_	_
to	_	_
improve	_	_
classification	_	_
performance	_	_
(	_	_
see	_	_
e.g.	_	_
[	_	_
4	_	_
]	_	_
and	_	_
[	_	_
5	_	_
]	_	_
)	_	_
.	_	_

#16
Another	_	_
application	_	_
is	_	_
to	_	_
use	_	_
GANs	_	_
for	_	_
image-to-image	_	_
translation	_	_
,	_	_
e.g.	_	_
to	_	_
generate	_	_
computed	_	_
tomography	_	_
(	_	_
CT	_	_
)	_	_
data	_	_
from	_	_
magnetic	_	_
resonance	_	_
(	_	_
MR	_	_
)	_	_
images	_	_
or	_	_
vice	_	_
versa	_	_
.	_	_

#17
This	_	_
can	_	_
for	_	_
example	_	_
be	_	_
very	_	_
useful	_	_
for	_	_
multimodal	_	_
classification	_	_
of	_	_
healthy	_	_
and	_	_
diseased	_	_
subjects	_	_
,	_	_
where	_	_
several	_	_
types	_	_
of	_	_
medical	_	_
images	_	_
(	_	_
e.g.	_	_
CT	_	_
and	_	_
MRI	_	_
)	_	_
are	_	_
combined	_	_
to	_	_
improve	_	_
sensitivity	_	_
(	_	_
see	_	_
e.g.	_	_
[	_	_
6	_	_
]	_	_
and	_	_
[	_	_
7	_	_
]	_	_
)	_	_
.	_	_

#18
To	_	_
use	_	_
GANs	_	_
for	_	_
image-to-image	_	_
translation	_	_
in	_	_
medical	_	_
imaging	_	_
is	_	_
not	_	_
a	_	_
new	_	_
idea	_	_
.	_	_

#19
Nie	_	_
et	_	_
al.	_	_
[	_	_
8	_	_
]	_	_
used	_	_
a	_	_
GAN	_	_
to	_	_
generate	_	_
CT	_	_
data	_	_
from	_	_
MRI	_	_
.	_	_

#20
Yang	_	_
et	_	_
al.	_	_
[	_	_
9	_	_
]	_	_
recently	_	_
used	_	_
GANs	_	_
to	_	_
improve	_	_
registration	_	_
and	_	_
segmentation	_	_
of	_	_
MR	_	_
images	_	_
,	_	_
by	_	_
generating	_	_
new	_	_
data	_	_
and	_	_
using	_	_
multimodal	_	_
algorithms	_	_
.	_	_

#21
Similarly	_	_
,	_	_
Dar	_	_
et	_	_
al.	_	_
[	_	_
10	_	_
]	_	_
demonstrate	_	_
how	_	_
GANs	_	_
can	_	_
be	_	_
used	_	_
for	_	_
generation	_	_
of	_	_
a	_	_
T2-weighted	_	_
MR	_	_
image	_	_
from	_	_
a	_	_
T1-weighted	_	_
image	_	_
.	_	_

#22
However	_	_
,	_	_
since	_	_
GANs	_	_
have	_	_
only	_	_
recently	_	_
been	_	_
proposed	_	_
for	_	_
image-to-image	_	_
translation	_	_
,	_	_
and	_	_
new	_	_
GAN	_	_
models	_	_
are	_	_
still	_	_
being	_	_
developed	_	_
,	_	_
it	_	_
is	_	_
not	_	_
clear	_	_
what	_	_
the	_	_
best	_	_
GAN	_	_
model	_	_
is	_	_
and	_	_
how	_	_
GANs	_	_
should	_	_
be	_	_
evaluated	_	_
and	_	_
compared	_	_
.	_	_

#23
We	_	_
therefore	_	_
present	_	_
a	_	_
small	_	_
comparison	_	_
for	_	_
image-to-image	_	_
translation	_	_
of	_	_
T1-	_	_
and	_	_
T2-weighted	_	_
MR	_	_
images	_	_
.	_	_

#24
Compared	_	_
to	_	_
previous	_	_
work	_	_
[	_	_
9	_	_
,	_	_
10	_	_
]	_	_
which	_	_
used	_	_
conditional	_	_
GANs	_	_
(	_	_
cGAN	_	_
)	_	_
[	_	_
11	_	_
]	_	_
,	_	_
we	_	_
show	_	_
results	_	_
for	_	_
our	_	_
own	_	_
Keras	_	_
implementations	_	_
of	_	_
CycleGAN	_	_
[	_	_
12	_	_
]	_	_
and	_	_
UNIT	_	_
[	_	_
13	_	_
]	_	_
,	_	_
see	_	_
https	_	_
:	_	_
//github.com/simontomaskarlsson/GAN-MRI	_	_
for	_	_
code	_	_
.	_	_

#25
ar	_	_
X	_	_
iv	_	_
:1	_	_
6	_	_
.	_	_

#26
7v	_	_
1	_	_
[	_	_
cs	_	_
.C	_	_
V	_	_
]	_	_
2	_	_
0	_	_
Ju	_	_
n	_	_
2	_	_
.	_	_

#27
METHOD	_	_
2.1	_	_
.	_	_

#28
GAN	_	_
model	_	_
selection	_	_
and	_	_
implementation	_	_
Several	_	_
different	_	_
GAN	_	_
models	_	_
were	_	_
investigated	_	_
in	_	_
a	_	_
literature	_	_
study	_	_
[	_	_
12	_	_
,	_	_
13	_	_
,	_	_
14	_	_
,	_	_
15	_	_
,	_	_
16	_	_
]	_	_
.	_	_

#29
Two	_	_
models	_	_
stood	_	_
out	_	_
among	_	_
the	_	_
others	_	_
in	_	_
synthesizing	_	_
realistic	_	_
images	_	_
in	_	_
high	_	_
resolution	_	_
;	_	_
CycleGAN	_	_
[	_	_
12	_	_
]	_	_
and	_	_
UNIT	_	_
[	_	_
13	_	_
]	_	_
.	_	_

#30
Training	_	_
of	_	_
neural	_	_
networks	_	_
is	_	_
commonly	_	_
supervised	_	_
,	_	_
i.e.	_	_
the	_	_
training	_	_
requires	_	_
corresponding	_	_
ground	_	_
truth	_	_
to	_	_
each	_	_
input	_	_
sample	_	_
.	_	_

#31
In	_	_
image-to-image	_	_
translation	_	_
this	_	_
means	_	_
that	_	_
paired	_	_
images	_	_
from	_	_
both	_	_
source	_	_
and	_	_
target	_	_
domain	_	_
are	_	_
needed	_	_
.	_	_

#32
To	_	_
alleviate	_	_
this	_	_
constraint	_	_
,	_	_
CycleGAN	_	_
and	_	_
UNIT	_	_
can	_	_
work	_	_
with	_	_
unpaired	_	_
training	_	_
data	_	_
.	_	_

#33
Two	_	_
different	_	_
variants	_	_
of	_	_
the	_	_
CycleGAN	_	_
model	_	_
were	_	_
implemented	_	_
,	_	_
CycleGAN	_	_
s	_	_
and	_	_
CycleGAN	_	_
.	_	_

#34
Including	_	_
the	_	_
ground	_	_
truth	_	_
image	_	_
in	_	_
the	_	_
training	_	_
should	_	_
intuitively	_	_
generate	_	_
better	_	_
results	_	_
,	_	_
since	_	_
the	_	_
model	_	_
then	_	_
has	_	_
more	_	_
information	_	_
about	_	_
how	_	_
the	_	_
generated	_	_
image	_	_
should	_	_
appear	_	_
.	_	_

#35
To	_	_
investigate	_	_
this	_	_
,	_	_
CycleGAN	_	_
s	_	_
was	_	_
implemented	_	_
and	_	_
trained	_	_
supervised	_	_
,	_	_
i.e.	_	_
by	_	_
adding	_	_
the	_	_
mean	_	_
absolute	_	_
error	_	_
(	_	_
MAE	_	_
)	_	_
between	_	_
output	_	_
and	_	_
ground	_	_
truth	_	_
data	_	_
.	_	_

#36
To	_	_
investigate	_	_
how	_	_
the	_	_
adversarial	_	_
and	_	_
cyclic	_	_
loss	_	_
contribute	_	_
to	_	_
the	_	_
model	_	_
,	_	_
Generators	_	_
s	_	_
was	_	_
also	_	_
implemented	_	_
.	_	_

#37
It	_	_
consists	_	_
of	_	_
the	_	_
generators	_	_
in	_	_
CycleGAN	_	_
and	_	_
is	_	_
only	_	_
trained	_	_
in	_	_
a	_	_
supervised	_	_
manner	_	_
with	_	_
a	_	_
MAE	_	_
loss	_	_
using	_	_
the	_	_
ground	_	_
truth	_	_
images	_	_
,	_	_
it	_	_
does	_	_
not	_	_
include	_	_
the	_	_
adversarial	_	_
or	_	_
the	_	_
cyclic	_	_
loss	_	_
.	_	_

#38
A	_	_
Simple	_	_
baseline	_	_
model	_	_
was	_	_
also	_	_
implemented	_	_
for	_	_
comparison	_	_
,	_	_
it	_	_
consists	_	_
of	_	_
only	_	_
two	_	_
convolutional	_	_
layers	_	_
.	_	_

#39
2.2	_	_
.	_	_

#40
Evaluation	_	_
The	_	_
dataset	_	_
used	_	_
in	_	_
the	_	_
evaluation	_	_
is	_	_
provided	_	_
by	_	_
the	_	_
Human	_	_
Connectome	_	_
project	_	_
[	_	_
17	_	_
,	_	_
18	_	_
]	_	_
(	_	_
https	_	_
:	_	_
//ida.loni.usc.edu/login.jsp	_	_
)	_	_
1	_	_
.	_	_

#41
We	_	_
used	_	_
(	_	_
paired	_	_
)	_	_
T1-	_	_
and	_	_
T2-weighted	_	_
images	_	_
from	_	_
1113	_	_
subjects	_	_
(	_	_
but	_	_
note	_	_
that	_	_
CycleGAN	_	_
and	_	_
UNIT	_	_
can	_	_
be	_	_
trained	_	_
using	_	_
unpaired	_	_
data	_	_
)	_	_
.	_	_

#42
All	_	_
the	_	_
images	_	_
have	_	_
been	_	_
registered	_	_
to	_	_
a	_	_
common	_	_
template	_	_
brain	_	_
,	_	_
such	_	_
that	_	_
they	_	_
are	_	_
in	_	_
the	_	_
same	_	_
position	_	_
and	_	_
of	_	_
the	_	_
same	_	_
size	_	_
.	_	_

#43
We	_	_
used	_	_
axial	_	_
images	_	_
(	_	_
only	_	_
slice	_	_
120	_	_
)	_	_
from	_	_
the	_	_
segmented	_	_
brains	_	_
.	_	_

#44
The	_	_
data	_	_
were	_	_
split	_	_
into	_	_
a	_	_
training	_	_
set	_	_
of	_	_
900	_	_
images	_	_
in	_	_
each	_	_
domain	_	_
.	_	_

#45
The	_	_
remaining	_	_
213	_	_
images	_	_
,	_	_
in	_	_
each	_	_
domain	_	_
,	_	_
were	_	_
used	_	_
for	_	_
testing	_	_
.	_	_

#46
Using	_	_
an	_	_
Nvidia	_	_
12	_	_
GB	_	_
Titan	_	_
X	_	_
GPU	_	_
,	_	_
training	_	_
times	_	_
for	_	_
CycleGAN	_	_
and	_	_
UNIT	_	_
were	_	_
419	_	_
and	_	_
877	_	_
seconds/epoch	_	_
,	_	_
respectively	_	_
.	_	_

#47
The	_	_
models	_	_
were	_	_
on	_	_
average	_	_
trained	_	_
using	_	_
180	_	_
epochs	_	_
.	_	_

#48
The	_	_
generation	_	_
of	_	_
synthetic	_	_
images	_	_
took	_	_
0.0176	_	_
and	_	_
0.0478	_	_
ms	_	_
per	_	_
image	_	_
for	_	_
CycleGAN	_	_
and	_	_
UNIT	_	_
,	_	_
respectively	_	_
.	_	_

#49
The	_	_
two	_	_
GAN	_	_
models	_	_
were	_	_
compared	_	_
using	_	_
quantitative	_	_
and	_	_
qualitative	_	_
methods	_	_
.	_	_

#50
All	_	_
quantitative	_	_
results	_	_
;	_	_
MAE	_	_
,	_	_
mu1Data	_	_
collection	_	_
and	_	_
sharing	_	_
for	_	_
this	_	_
project	_	_
was	_	_
provided	_	_
by	_	_
the	_	_
Human	_	_
Connectome	_	_
Project	_	_
(	_	_
U01-MH93765	_	_
)	_	_
(	_	_
HCP	_	_
;	_	_
Principal	_	_
Investigators	_	_
:	_	_
Bruce	_	_
Rosen	_	_
,	_	_
M.D.	_	_
,	_	_
Ph.D.	_	_
,	_	_
Arthur	_	_
W.	_	_
Toga	_	_
,	_	_
Ph.D.	_	_
,	_	_
Van	_	_
J.Weeden	_	_
,	_	_
MD	_	_
)	_	_
.	_	_

#51
HCP	_	_
funding	_	_
was	_	_
provided	_	_
by	_	_
the	_	_
National	_	_
Institute	_	_
of	_	_
Dental	_	_
and	_	_
Craniofacial	_	_
Research	_	_
(	_	_
NIDCR	_	_
)	_	_
,	_	_
the	_	_
National	_	_
Institute	_	_
of	_	_
Mental	_	_
Health	_	_
(	_	_
NIMH	_	_
)	_	_
,	_	_
and	_	_
the	_	_
National	_	_
Institute	_	_
of	_	_
Neurological	_	_
Disorders	_	_
and	_	_
Stroke	_	_
(	_	_
NINDS	_	_
)	_	_
.	_	_

#52
HCP	_	_
data	_	_
are	_	_
disseminated	_	_
by	_	_
the	_	_
Laboratory	_	_
of	_	_
Neuro	_	_
Imaging	_	_
at	_	_
the	_	_
University	_	_
of	_	_
Southern	_	_
California	_	_
.	_	_

#53
tual	_	_
information	_	_
(	_	_
MI	_	_
)	_	_
,	_	_
and	_	_
peak	_	_
signal	_	_
to	_	_
noise	_	_
ratio	_	_
(	_	_
PSNR	_	_
)	_	_
,	_	_
are	_	_
based	_	_
on	_	_
the	_	_
test	_	_
dataset	_	_
.	_	_

#54
Since	_	_
the	_	_
MR	_	_
images	_	_
can	_	_
naturally	_	_
differ	_	_
in	_	_
intensity	_	_
,	_	_
each	_	_
image	_	_
is	_	_
normalized	_	_
before	_	_
the	_	_
calculations	_	_
by	_	_
division	_	_
of	_	_
the	_	_
standard	_	_
deviation	_	_
and	_	_
subtraction	_	_
of	_	_
the	_	_
mean	_	_
value	_	_
.	_	_

#55
To	_	_
visually	_	_
evaluate	_	_
a	_	_
synthetic	_	_
image	_	_
compared	_	_
to	_	_
a	_	_
real	_	_
image	_	_
can	_	_
be	_	_
difficult	_	_
if	_	_
the	_	_
differences	_	_
are	_	_
small	_	_
.	_	_

#56
A	_	_
solution	_	_
to	_	_
the	_	_
visual	_	_
inspection	_	_
is	_	_
to	_	_
instead	_	_
visualize	_	_
a	_	_
relative	_	_
error	_	_
between	_	_
the	_	_
real	_	_
image	_	_
and	_	_
the	_	_
synthetic	_	_
image	_	_
.	_	_

#57
This	_	_
is	_	_
done	_	_
by	_	_
calculating	_	_
the	_	_
absolute	_	_
difference	_	_
between	_	_
the	_	_
images	_	_
,	_	_
and	_	_
dividing	_	_
it	_	_
by	_	_
the	_	_
real	_	_
image	_	_
.	_	_

#58
These	_	_
calculations	_	_
are	_	_
done	_	_
on	_	_
images	_	_
normalized	_	_
in	_	_
the	_	_
same	_	_
manner	_	_
as	_	_
for	_	_
the	_	_
quantitative	_	_
evaluation	_	_
,	_	_
and	_	_
the	_	_
error	_	_
is	_	_
the	_	_
relative	_	_
absolute	_	_
difference	_	_
.	_	_

#59
Determining	_	_
if	_	_
the	_	_
synthetic	_	_
MR	_	_
images	_	_
are	_	_
visually	_	_
realistic	_	_
or	_	_
not	_	_
was	_	_
done	_	_
via	_	_
a	_	_
perceptual	_	_
study	_	_
by	_	_
one	_	_
of	_	_
the	_	_
authors	_	_
(	_	_
Anders	_	_
Eklund	_	_
)	_	_
.	_	_

#60
The	_	_
evaluator	_	_
received	_	_
T1-	_	_
and	_	_
T2-weighted	_	_
images	_	_
where	_	_
96	_	_
of	_	_
them	_	_
were	_	_
real	_	_
and	_	_
72	_	_
were	_	_
synthetic	_	_
,	_	_
the	_	_
evaluator	_	_
then	_	_
had	_	_
to	_	_
determine	_	_
if	_	_
each	_	_
image	_	_
was	_	_
real	_	_
or	_	_
synthetic	_	_
.	_	_

#61
The	_	_
real	_	_
and	_	_
synthetic	_	_
images	_	_
were	_	_
equally	_	_
divided	_	_
between	_	_
the	_	_
two	_	_
domains	_	_
.	_	_

#62
Images	_	_
from	_	_
Generators	_	_
s	_	_
and	_	_
Simple	_	_
were	_	_
not	_	_
evaluated	_	_
since	_	_
it	_	_
is	_	_
obvious	_	_
that	_	_
the	_	_
images	_	_
are	_	_
synthetic	_	_
,	_	_
due	_	_
to	_	_
the	_	_
high	_	_
smoothness	_	_
.	_	_

#63
Evaluating	_	_
anatomical	_	_
images	_	_
is	_	_
a	_	_
complicated	_	_
task	_	_
best	_	_
performed	_	_
by	_	_
a	_	_
radiologist	_	_
.	_	_

#64
The	_	_
results	_	_
presented	_	_
in	_	_
this	_	_
paper	_	_
should	_	_
therefore	_	_
only	_	_
be	_	_
seen	_	_
as	_	_
an	_	_
indicator	_	_
of	_	_
the	_	_
visual	_	_
quality	_	_
.	_	_

#65
3	_	_
.	_	_

#66
RESULTS	_	_
Quantitative	_	_
results	_	_
and	_	_
results	_	_
from	_	_
the	_	_
perceptual	_	_
study	_	_
are	_	_
shown	_	_
in	_	_
Figure	_	_
1	_	_
.	_	_

#67
The	_	_
Generators	_	_
s	_	_
model	_	_
outperforms	_	_
the	_	_
other	_	_
models	_	_
in	_	_
all	_	_
quantitative	_	_
measurements	_	_
.	_	_

#68
The	_	_
worst	_	_
performing	_	_
model	_	_
on	_	_
all	_	_
quantitative	_	_
measurements	_	_
,	_	_
besides	_	_
MI	_	_
on	_	_
T2	_	_
images	_	_
,	_	_
is	_	_
the	_	_
Simple	_	_
model	_	_
(	_	_
despite	_	_
its	_	_
supervised	_	_
nature	_	_
equivalent	_	_
to	_	_
Generators	_	_
s	_	_
)	_	_
.	_	_

#69
The	_	_
performance	_	_
of	_	_
CycleGAN	_	_
,	_	_
CycleGAN	_	_
s	_	_
and	_	_
UNIT	_	_
is	_	_
similar	_	_
.	_	_

#70
With	_	_
just	_	_
a	_	_
few	_	_
exceptions	_	_
,	_	_
the	_	_
quantitative	_	_
performance	_	_
is	_	_
better	_	_
for	_	_
T1	_	_
images	_	_
.	_	_

#71
The	_	_
opposite	_	_
is	_	_
however	_	_
shown	_	_
in	_	_
the	_	_
perceptual	_	_
study	_	_
where	_	_
more	_	_
synthetic	_	_
T1	_	_
images	_	_
are	_	_
labeled	_	_
as	_	_
synthetic	_	_
compared	_	_
to	_	_
T2	_	_
.	_	_

#72
Opposite	_	_
results	_	_
are	_	_
in	_	_
the	_	_
perceptual	_	_
study	_	_
attained	_	_
for	_	_
CycleGAN	_	_
and	_	_
UNIT	_	_
,	_	_
where	_	_
UNIT	_	_
shows	_	_
the	_	_
best	_	_
performance	_	_
for	_	_
T1	_	_
images	_	_
and	_	_
CycleGAN	_	_
shows	_	_
the	_	_
best	_	_
performance	_	_
for	_	_
T2	_	_
images	_	_
.	_	_

#73
The	_	_
quantitative	_	_
superiority	_	_
of	_	_
Generators	_	_
s	_	_
does	_	_
not	_	_
correspond	_	_
to	_	_
the	_	_
visual	_	_
realness	_	_
shown	_	_
in	_	_
Figure	_	_
2	_	_
.	_	_

#74
The	_	_
supervised	_	_
training	_	_
results	_	_
in	_	_
an	_	_
unrealistic	_	_
,	_	_
smooth	_	_
appearance	_	_
seen	_	_
in	_	_
the	_	_
MR	_	_
images	_	_
from	_	_
Generators	_	_
s	_	_
and	_	_
the	_	_
Simple	_	_
model	_	_
,	_	_
where	_	_
the	_	_
Simple	_	_
model	_	_
also	_	_
fails	_	_
in	_	_
the	_	_
color	_	_
mapping	_	_
of	_	_
the	_	_
cerebrospinal	_	_
fluid	_	_
.	_	_

#75
The	_	_
GAN	_	_
models	_	_
trained	_	_
using	_	_
an	_	_
adversarial	_	_
loss	_	_
generate	_	_
more	_	_
realistic	_	_
synthetic	_	_
MR	_	_
images	_	_
.	_	_

#76
The	_	_
relative	_	_
absolute	_	_
error	_	_
images	_	_
in	_	_
Figure	_	_
2	_	_
show	_	_
a	_	_
greater	_	_
error	_	_
for	_	_
the	_	_
synthetic	_	_
T2	_	_
images	_	_
compared	_	_
to	_	_
the	_	_
synthetic	_	_
T1	_	_
images	_	_
.	_	_

#77
Synthetic	_	_
T1	_	_
images	_	_
especially	_	_
have	_	_
problems	_	_
at	_	_
the	_	_
edges	_	_
,	_	_
whereas	_	_
errors	_	_
in	_	_
the	_	_
T2	_	_
images	_	_
appear	_	_
all	_	_
over	_	_
the	_	_
brain	_	_
.	_	_

#78
4	_	_
.	_	_

#79
DISCUSSION	_	_
4.1	_	_
.	_	_

#80
Quantitative	_	_
comparison	_	_
During	_	_
training	_	_
the	_	_
Generators	_	_
s	_	_
model	_	_
uses	_	_
MAE	_	_
as	_	_
its	_	_
only	_	_
loss	_	_
function	_	_
,	_	_
which	_	_
creates	_	_
a	_	_
model	_	_
where	_	_
the	_	_
goal	_	_
is	_	_
to	_	_
minimize	_	_
the	_	_
MAE	_	_
.	_	_

#81
The	_	_
model	_	_
does	_	_
this	_	_
well	_	_
compared	_	_
to	_	_
other	_	_
models	_	_
,	_	_
as	_	_
shown	_	_
in	_	_
Figure	_	_
1	_	_
.	_	_

#82
The	_	_
Simple	_	_
model	_	_
,	_	_
which	_	_
similarly	_	_
to	_	_
Generators	_	_
s	_	_
is	_	_
only	_	_
trained	_	_
using	_	_
the	_	_
MAE	_	_
loss	_	_
,	_	_
has	_	_
the	_	_
highest	_	_
error	_	_
among	_	_
the	_	_
models	_	_
.	_	_

#83
The	_	_
Simple	_	_
model	_	_
only	_	_
has	_	_
two	_	_
convolutional	_	_
layers	_	_
and	_	_
Generators	_	_
s	_	_
has	_	_
,	_	_
similar	_	_
to	_	_
the	_	_
CycleGAN	_	_
generators	_	_
,	_	_
24	_	_
convolutional	_	_
layers	_	_
.	_	_

#84
This	_	_
indicates	_	_
that	_	_
the	_	_
architecture	_	_
in	_	_
the	_	_
Simple	_	_
model	_	_
is	_	_
not	_	_
sufficiently	_	_
complex	_	_
for	_	_
the	_	_
translation	_	_
.	_	_

#85
As	_	_
expected	_	_
,	_	_
the	_	_
CycleGAN	_	_
s	_	_
model	_	_
shows	_	_
a	_	_
slight	_	_
improvement	_	_
in	_	_
MAE	_	_
for	_	_
T2	_	_
images	_	_
compared	_	_
to	_	_
CycleGAN	_	_
.	_	_

#86
However	_	_
,	_	_
the	_	_
results	_	_
are	_	_
not	_	_
significantly	_	_
better	_	_
than	_	_
CycleGAN	_	_
and	_	_
the	_	_
MAE	_	_
on	_	_
T1	_	_
images	_	_
is	_	_
in	_	_
fact	_	_
better	_	_
for	_	_
CycleGAN	_	_
.	_	_

#87
The	_	_
CycleGAN	_	_
and	_	_
UNIT	_	_
show	_	_
similar	_	_
results	_	_
and	_	_
it	_	_
is	_	_
difficult	_	_
to	_	_
argue	_	_
why	_	_
one	_	_
or	_	_
the	_	_
other	_	_
performs	_	_
slightly	_	_
better	_	_
than	_	_
the	_	_
other	_	_
one	_	_
.	_	_

#88
Figure	_	_
1c	_	_
shows	_	_
that	_	_
T1	_	_
images	_	_
have	_	_
a	_	_
higher	_	_
MI	_	_
value	_	_
than	_	_
T2	_	_
images	_	_
.	_	_

#89
This	_	_
can	_	_
be	_	_
correlated	_	_
to	_	_
the	_	_
results	_	_
from	_	_
MAE	_	_
where	_	_
a	_	_
larger	_	_
error	_	_
was	_	_
generated	_	_
from	_	_
the	_	_
T2	_	_
images	_	_
.	_	_

#90
An	_	_
explanation	_	_
to	_	_
why	_	_
the	_	_
Simple	_	_
model	_	_
has	_	_
a	_	_
higher	_	_
MI	_	_
score	_	_
than	_	_
the	_	_
majority	_	_
of	_	_
models	_	_
for	_	_
T2	_	_
images	_	_
,	_	_
is	_	_
that	_	_
T1	_	_
and	_	_
T2	_	_
images	_	_
from	_	_
the	_	_
same	_	_
subject	_	_
contain	_	_
very	_	_
similar	_	_
information	_	_
.	_	_

#91
Since	_	_
the	_	_
Simple	_	_
model	_	_
only	_	_
changes	_	_
the	_	_
pixel	_	_
intensity	_	_
,	_	_
the	_	_
main	_	_
information	_	_
is	_	_
preserved	_	_
.	_	_

#92
4.2	_	_
.	_	_

#93
Qualitative	_	_
comparison	_	_
From	_	_
the	_	_
perceptual	_	_
study	_	_
it	_	_
was	_	_
shown	_	_
that	_	_
the	_	_
synthetic	_	_
images	_	_
have	_	_
a	_	_
visually	_	_
realistic	_	_
appearance	_	_
,	_	_
since	_	_
synthetic	_	_
images	_	_
were	_	_
classified	_	_
as	_	_
real	_	_
.	_	_

#94
T2	_	_
images	_	_
were	_	_
more	_	_
difficult	_	_
to	_	_
classify	_	_
than	_	_
T1	_	_
images	_	_
and	_	_
the	_	_
reason	_	_
for	_	_
the	_	_
difference	_	_
can	_	_
be	_	_
that	_	_
the	_	_
synthetic	_	_
T2	_	_
images	_	_
had	_	_
a	_	_
more	_	_
realistic	_	_
appearance	_	_
,	_	_
but	_	_
also	_	_
the	_	_
darker	_	_
nature	_	_
of	_	_
T2	_	_
images	_	_
(	_	_
which	_	_
for	_	_
example	_	_
makes	_	_
it	_	_
more	_	_
difficult	_	_
to	_	_
determine	_	_
if	_	_
the	_	_
noise	_	_
is	_	_
realistic	_	_
or	_	_
not	_	_
)	_	_
.	_	_

#95
The	_	_
large	_	_
error	_	_
on	_	_
the	_	_
edges	_	_
of	_	_
the	_	_
synthetic	_	_
brain	_	_
images	_	_
in	_	_
Figure	_	_
2	_	_
can	_	_
be	_	_
explained	_	_
by	_	_
the	_	_
fact	_	_
that	_	_
each	_	_
brain	_	_
has	_	_
a	_	_
unique	_	_
shape	_	_
,	_	_
and	_	_
that	_	_
T2	_	_
images	_	_
are	_	_
bright	_	_
for	_	_
CSF	_	_
.	_	_

#96
Areas	_	_
where	_	_
there	_	_
is	_	_
an	_	_
intensity	_	_
change	_	_
,	_	_
e.g.	_	_
CSF	_	_
and	_	_
white	_	_
matter	_	_
,	_	_
seem	_	_
to	_	_
be	_	_
more	_	_
difficult	_	_
for	_	_
the	_	_
models	_	_
to	_	_
learn	_	_
,	_	_
this	_	_
might	speculation	_
also	_	_
be	_	_
due	_	_
to	_	_
differences	_	_
between	_	_
subjects	_	_
.	_	_

#97
The	_	_
CycleGAN	_	_
s	_	_
penalizes	_	_
appearance	_	_
different	_	_
from	_	_
the	_	_
ground	_	_
truth	_	_
,	_	_
since	_	_
it	_	_
uses	_	_
the	_	_
MAE	_	_
loss	_	_
during	_	_
training	_	_
,	_	_
which	_	_
forces	_	_
it	_	_
to	_	_
another	_	_
direction	_	_
,	_	_
closer	_	_
to	_	_
the	_	_
smooth	_	_
appearance	_	_
of	_	_
the	_	_
images	_	_
from	_	_
the	_	_
Generators	_	_
s	_	_
model	_	_
.	_	_

#98
If	_	_
the	_	_
aim	_	_
of	_	_
the	_	_
test	_	_
would	_	_
instead	_	_
be	_	_
to	_	_
evaluate	_	_
how	_	_
similar	_	_
the	_	_
synthetic	_	_
images	_	_
are	_	_
to	_	_
the	_	_
ground	_	_
truth	_	_
,	_	_
the	_	_
translated	_	_
images	_	_
from	_	_
CycleGAN	_	_
s	_	_
may	_	_
give	_	_
better	_	_
results	_	_
.	_	_

#99
From	_	_
the	_	_
results	_	_
in	_	_
Figure	_	_
2	_	_
it	_	_
is	_	_
obvious	_	_
that	_	_
the	_	_
supervised	_	_
training	_	_
,	_	_
using	_	_
MAE	_	_
,	_	_
pushes	_	_
the	_	_
generators	_	_
into	_	_
producing	_	_
smooth	_	_
synthetic	_	_
brain	_	_
images	_	_
.	_	_

#100
Another	_	_
loss	_	_
function	_	_
would	_	_
probably	_	_
alter	_	_
the	_	_
results	_	_
,	_	_
but	_	_
since	_	_
it	_	_
is	_	_
difficult	_	_
to	_	_
create	_	_
mathematical	_	_
expressions	_	_
for	_	_
assessing	_	_
how	_	_
realistic	_	_
an	_	_
image	_	_
is	_	_
,	_	_
obtaining	_	_
visually	_	_
realistic	_	_
results	_	_
using	_	_
supervised	_	_
methods	_	_
is	_	_
a	_	_
problematic	_	_
task	_	_
.	_	_

#101
The	_	_
adversarial	_	_
loss	_	_
created	_	_
by	_	_
the	_	_
GAN	_	_
framework	_	_
allows	_	_
the	_	_
discriminator	_	_
to	_	_
act	_	_
as	_	_
the	_	_
complex	_	_
expression	_	_
,	_	_
which	_	_
results	_	_
in	_	_
visually	_	_
realistic	_	_
images	_	_
created	_	_
from	_	_
the	_	_
GAN	_	_
models	_	_
.	_	_

#102
If	_	_
the	_	_
aim	_	_
was	_	_
to	_	_
create	_	_
images	_	_
that	_	_
are	_	_
as	_	_
similar	_	_
to	_	_
ground	_	_
truth	_	_
images	_	_
as	_	_
possible	_	_
,	_	_
the	_	_
quantitative	_	_
measurements	_	_
would	_	_
be	_	_
more	_	_
applicable	_	_
.	_	_

#103
It	_	_
is	_	_
clear	_	_
that	_	_
even	_	_
if	_	_
a	_	_
model	_	_
such	_	_
as	_	_
Simple	_	_
has	_	_
a	_	_
relatively	_	_
good	_	_
score	_	_
in	_	_
the	_	_
quantitative	_	_
measurements	_	_
,	_	_
it	_	_
does	_	_
not	_	_
necessarily	_	_
generate	_	_
visually	_	_
realistic	_	_
images	_	_
.	_	_

#104
This	_	_
indicates	_	_
that	_	_
solely	_	_
determining	_	_
if	_	_
an	_	_
image	_	_
is	_	_
visually	_	_
realistic	_	_
can	_	_
not	_	_
be	_	_
done	_	_
with	_	_
the	_	_
used	_	_
metrics	_	_
.	_	_

#105
4.3	_	_
.	_	_

#106
Future	_	_
work	_	_
It	_	_
has	_	_
been	_	_
shown	_	_
,	_	_
via	_	_
a	_	_
perceptual	_	_
study	_	_
,	_	_
that	_	_
CycleGAN	_	_
and	_	_
UNIT	_	_
can	_	_
be	_	_
used	_	_
to	_	_
generate	_	_
visually	_	_
realistic	_	_
MR	_	_
images	_	_
.	_	_

#107
The	_	_
models	_	_
performed	_	_
differently	_	_
in	_	_
generating	_	_
images	_	_
in	_	_
the	_	_
different	_	_
domains	_	_
,	_	_
and	_	_
training	_	_
CycleGAN	_	_
in	_	_
an	_	_
unsupervised	_	_
manner	_	_
is	_	_
a	_	_
better	_	_
alternative	_	_
if	_	_
the	_	_
aim	_	_
is	_	_
to	_	_
generate	_	_
as	_	_
visually	_	_
realistic	_	_
images	_	_
as	_	_
possible	_	_
.	_	_

#108
A	_	_
suggestion	_	_
for	_	_
future	_	_
work	_	_
is	_	_
to	_	_
investigate	_	_
if	_	_
GANs	_	_
can	_	_
be	_	_
used	_	_
for	_	_
data	_	_
augmentation	_	_
(	_	_
e.g.	_	_
for	_	_
discriminating	_	_
healthy	_	_
and	_	_
diseased	_	_
subjects	_	_
)	_	_
.	_	_

#109
This	_	_
would	_	_
also	_	_
provide	_	_
information	_	_
regarding	_	_
if	_	_
the	_	_
model	_	_
which	_	_
creates	_	_
the	_	_
most	_	_
visually	_	_
realistic	_	_
images	_	_
,	_	_
or	_	_
the	_	_
model	_	_
which	_	_
performs	_	_
best	_	_
in	_	_
the	_	_
quantitative	_	_
evaluations	_	_
,	_	_
is	_	_
the	_	_
most	_	_
suitable	_	_
to	_	_
use	_	_
.	_	_

#110
Here	_	_
we	_	_
have	_	_
only	_	_
used	_	_
2D	_	_
GANs	_	_
,	_	_
but	_	_
3D	_	_
GANs	_	_
[	_	_
8	_	_
,	_	_
19	_	_
]	_	_
can	_	_
potentially	_	_
yield	_	_
even	_	_
better	_	_
results	_	_
,	_	_
at	_	_
the	_	_
cost	_	_
of	_	_
a	_	_
longer	_	_
processing	_	_
time	_	_
and	_	_
an	_	_
increased	_	_
memory	_	_
usage	_	_
.	_	_

#111
5	_	_
.	_	_

#112
ACKNOWLEDGMENTS	_	_
This	_	_
study	_	_
was	_	_
supported	_	_
by	_	_
Swedish	_	_
research	_	_
council	_	_
grant	_	_
2017-04889	_	_
.	_	_

#113
Funding	_	_
was	_	_
also	_	_
provided	_	_
by	_	_
the	_	_
Center	_	_
for	_	_
Industrial	_	_
Information	_	_
Technology	_	_
(	_	_
CENIIT	_	_
)	_	_
at	_	_
Linköping	_	_
University	_	_
,	_	_
and	_	_
the	_	_
Knut	_	_
and	_	_
Alice	_	_
Wallenberg	_	_
foundation	_	_
project	_	_
”Seeing	_	_
organ	_	_
function”	_	_
.	_	_

#114
(	_	_
a	_	_
)	_	_
(	_	_
b	_	_
)	_	_
(	_	_
c	_	_
)	_	_
(	_	_
d	_	_
)	_	_
(	_	_
e	_	_
)	_	_
Fig.	_	_
1	_	_
:	_	_
Quantitative	_	_
error	_	_
measurements	_	_
:	_	_
(	_	_
a	_	_
)	_	_
-	_	_
MAE	_	_
,	_	_
(	_	_
b	_	_
)	_	_
-	_	_
PSNR	_	_
and	_	_
(	_	_
c	_	_
)	_	_
-	_	_
MI	_	_
,	_	_
for	_	_
the	_	_
compared	_	_
GAN	_	_
models	_	_
.	_	_

#115
The	_	_
results	_	_
in	_	_
(	_	_
d	_	_
)	_	_
are	_	_
the	_	_
total	_	_
scores	_	_
of	_	_
all	_	_
GAN	_	_
models	_	_
in	_	_
the	_	_
perceptual	_	_
study	_	_
,	_	_
and	_	_
the	_	_
results	_	_
in	_	_
(	_	_
e	_	_
)	_	_
are	_	_
for	_	_
each	_	_
specific	_	_
model	_	_
.	_	_

#116
Labeling	_	_
T2-weighted	_	_
images	_	_
as	_	_
real	_	_
or	_	_
synthetic	_	_
is	_	_
harder	_	_
due	_	_
to	_	_
the	_	_
fact	_	_
that	_	_
T2	_	_
images	_	_
are	_	_
darker	_	_
by	_	_
nature	_	_
.	_	_

#117
Fig.	_	_
2	_	_
:	_	_
Synthetic	_	_
images	_	_
from	_	_
the	_	_
evaluated	_	_
GAN	_	_
models	_	_
.	_	_

#118
The	_	_
real	_	_
images	_	_
shown	_	_
at	_	_
the	_	_
top	_	_
are	_	_
inputs	_	_
that	_	_
the	_	_
synthetic	_	_
images	_	_
are	_	_
based	_	_
on	_	_
,	_	_
this	_	_
is	_	_
clarified	_	_
by	_	_
the	_	_
white	_	_
arrows	_	_
.	_	_

#119
The	_	_
real	_	_
T2	_	_
image	_	_
is	_	_
the	_	_
input	_	_
that	_	_
generated	_	_
the	_	_
synthetic	_	_
T1	_	_
images	_	_
and	_	_
vice	_	_
versa	_	_
.	_	_

#120
The	_	_
images	_	_
are	_	_
the	_	_
same	_	_
slice	_	_
from	_	_
a	_	_
single	_	_
subject	_	_
.	_	_

#121
This	_	_
means	_	_
that	_	_
the	_	_
top	_	_
images	_	_
are	_	_
ground	_	_
truth	_	_
for	_	_
the	_	_
images	_	_
below	_	_
them	_	_
.	_	_

#122
The	_	_
colorbar	_	_
belongs	_	_
to	_	_
the	_	_
images	_	_
in	_	_
the	_	_
left	_	_
and	_	_
right	_	_
columns	_	_
,	_	_
which	_	_
are	_	_
calculated	_	_
as	_	_
the	_	_
relative	_	_
absolute	_	_
difference	_	_
between	_	_
the	_	_
synthetic	_	_
and	_	_
the	_	_
ground	_	_
truth	_	_
image	_	_
.	_	_

#123
T1	_	_
results	_	_
are	_	_
shown	_	_
in	_	_
the	_	_
far	_	_
left	_	_
column	_	_
,	_	_
and	_	_
T2	_	_
results	_	_
in	_	_
the	_	_
far	_	_
right	_	_
column	_	_
.	_	_

#124
6	_	_
.	_	_

#125
REFERENCES	_	_
[	_	_
1	_	_
]	_	_
Yann	_	_
LeCun	_	_
,	_	_
Yoshua	_	_
Bengio	_	_
,	_	_
and	_	_
Geoffrey	_	_
Hinton	_	_
,	_	_
“Deep	_	_
learning	_	_
,	_	_
”	_	_
Nature	_	_
,	_	_
vol	_	_
.	_	_

#126
521	_	_
,	_	_
pp	_	_
.	_	_

#127
436–444	_	_
,	_	_
2015	_	_
.	_	_

#128
[	_	_
2	_	_
]	_	_
Geert	_	_
Litjens	_	_
,	_	_
Thijs	_	_
Kooi	_	_
,	_	_
Babak	_	_
Ehteshami	_	_
Bejnordi	_	_
,	_	_
Arnaud	_	_
Arindra	_	_
Adiyoso	_	_
Setio	_	_
,	_	_
Francesco	_	_
Ciompi	_	_
,	_	_
Mohsen	_	_
Ghafoorian	_	_
,	_	_
Jeroen	_	_
A.W.M	_	_
.	_	_

#129
van	_	_
der	_	_
Laak	_	_
,	_	_
Bram	_	_
van	_	_
Ginneken	_	_
,	_	_
and	_	_
Clara	_	_
I.	_	_
Sanchez	_	_
,	_	_
“A	_	_
survey	_	_
on	_	_
deep	_	_
learning	_	_
in	_	_
medical	_	_
image	_	_
analysis	_	_
,	_	_
”	_	_
Medical	_	_
Image	_	_
Analysis	_	_
,	_	_
vol	_	_
.	_	_

#130
42	_	_
,	_	_
pp	_	_
.	_	_

#131
60	_	_
–	_	_
88	_	_
,	_	_
2017	_	_
.	_	_

#132
[	_	_
3	_	_
]	_	_
Ian	_	_
Goodfellow	_	_
,	_	_
Jean	_	_
Pouget-Abadie	_	_
,	_	_
Mehdi	_	_
Mirza	_	_
,	_	_
Bing	_	_
Xu	_	_
,	_	_
David	_	_
Warde-Farley	_	_
,	_	_
Sherjil	_	_
Ozair	_	_
,	_	_
Aaron	_	_
Courville	_	_
,	_	_
and	_	_
Yoshua	_	_
Bengio	_	_
,	_	_
“Generative	_	_
adversarial	_	_
nets	_	_
,	_	_
”	_	_
in	_	_
Advances	_	_
in	_	_
Neural	_	_
Information	_	_
Processing	_	_
Systems	_	_
27	_	_
,	_	_
pp	_	_
.	_	_

#133
2672–2680	_	_
.	_	_

#134
2014	_	_
.	_	_

#135
[	_	_
4	_	_
]	_	_
Antreas	_	_
Antoniou	_	_
,	_	_
Amos	_	_
Storkey	_	_
,	_	_
and	_	_
Harrison	_	_
Edwards	_	_
,	_	_
“Data	_	_
augmentation	_	_
generative	_	_
adversarial	_	_
networks	_	_
,	_	_
”	_	_
arXiv	_	_
,	_	_
vol	_	_
.	_	_

#136
1711.04340	_	_
,	_	_
2017	_	_
.	_	_

#137
[	_	_
5	_	_
]	_	_
Francesco	_	_
Calimeri	_	_
,	_	_
Aldo	_	_
Marzullo	_	_
,	_	_
Claudio	_	_
Stamile	_	_
,	_	_
and	_	_
Giorgio	_	_
Terracina	_	_
,	_	_
“Biomedical	_	_
data	_	_
augmentation	_	_
using	_	_
generative	_	_
adversarial	_	_
neural	_	_
networks	_	_
,	_	_
”	_	_
in	_	_
Artificial	_	_
Neural	_	_
Networks	_	_
and	_	_
Machine	_	_
Learning	_	_
(	_	_
ICANN	_	_
)	_	_
,	_	_
Alessandra	_	_
Lintas	_	_
,	_	_
Stefano	_	_
Rovetta	_	_
,	_	_
Paul	_	_
F.M.J	_	_
.	_	_

#138
Verschure	_	_
,	_	_
and	_	_
Alessandro	_	_
E.P	_	_
.	_	_

#139
Villa	_	_
,	_	_
Eds.	_	_
,	_	_
2017	_	_
,	_	_
pp	_	_
.	_	_

#140
626–	_	_
634	_	_
.	_	_

#141
[	_	_
6	_	_
]	_	_
Dai	_	_
Dai	_	_
,	_	_
Jieqiong	_	_
Wang	_	_
,	_	_
Jing	_	_
Hua	_	_
,	_	_
and	_	_
Huiguang	_	_
He	_	_
,	_	_
“Classification	_	_
of	_	_
ADHD	_	_
children	_	_
through	_	_
multimodal	_	_
magnetic	_	_
resonance	_	_
imaging	_	_
,	_	_
”	_	_
Frontiers	_	_
in	_	_
Systems	_	_
Neuroscience	_	_
,	_	_
vol	_	_
.	_	_

#142
6	_	_
,	_	_
pp	_	_
.	_	_

#143
63	_	_
,	_	_
2012	_	_
.	_	_

#144
[	_	_
7	_	_
]	_	_
Daoqiang	_	_
Zhang	_	_
,	_	_
Yaping	_	_
Wang	_	_
,	_	_
Luping	_	_
Zhou	_	_
,	_	_
Hong	_	_
Yuan	_	_
,	_	_
and	_	_
Dinggang	_	_
Shen	_	_
,	_	_
“Multimodal	_	_
classification	_	_
of	_	_
Alzheimer’s	_	_
disease	_	_
and	_	_
mild	_	_
cognitive	_	_
impairment	_	_
,	_	_
”	_	_
NeuroImage	_	_
,	_	_
vol	_	_
.	_	_

#145
55	_	_
,	_	_
no	_	_
.	_	_

#146
3	_	_
,	_	_
pp	_	_
.	_	_

#147
856	_	_
–	_	_
867	_	_
,	_	_
2011	_	_
.	_	_

#148
[	_	_
8	_	_
]	_	_
Dong	_	_
Nie	_	_
,	_	_
Roger	_	_
Trullo	_	_
,	_	_
Caroline	_	_
Petitjean	_	_
,	_	_
Su	_	_
Ruan	_	_
,	_	_
and	_	_
Dinggang	_	_
Shen	_	_
,	_	_
“Medical	_	_
Image	_	_
Synthesis	_	_
with	_	_
Context-Aware	_	_
Generative	_	_
Adversarial	_	_
Networks	_	_
,	_	_
”	_	_
arXiv	_	_
,	_	_
vol	_	_
.	_	_

#149
1612.05362	_	_
,	_	_
2016	_	_
.	_	_

#150
[	_	_
9	_	_
]	_	_
Qianye	_	_
Yang	_	_
,	_	_
Nannan	_	_
Li	_	_
,	_	_
Zixu	_	_
Zhao	_	_
,	_	_
Xingyu	_	_
Fan	_	_
,	_	_
Eric	_	_
I-Chao	_	_
Chang	_	_
,	_	_
and	_	_
Yan	_	_
Xu	_	_
,	_	_
“MRI	_	_
Image-to-Image	_	_
Translation	_	_
for	_	_
Cross-Modality	_	_
Image	_	_
Registration	_	_
and	_	_
Segmentation	_	_
,	_	_
”	_	_
arXiv	_	_
,	_	_
vol	_	_
.	_	_

#151
1801.06940	_	_
,	_	_
2018	_	_
.	_	_

#152
[	_	_
10	_	_
]	_	_
Salman	_	_
Ul	_	_
Hassan	_	_
Dar	_	_
,	_	_
Mahmut	_	_
Yurt	_	_
,	_	_
Levent	_	_
Karacan	_	_
,	_	_
Aykut	_	_
Erdem	_	_
,	_	_
Erkut	_	_
Erdem	_	_
,	_	_
and	_	_
Tolga	_	_
ukur	_	_
,	_	_
“Image	_	_
Synthesis	_	_
in	_	_
Multi-Contrast	_	_
MRI	_	_
with	_	_
Conditional	_	_
Generative	_	_
Adversarial	_	_
Networks	_	_
,	_	_
”	_	_
arXiv	_	_
,	_	_
vol	_	_
.	_	_

#153
1802.01221	_	_
,	_	_
2018	_	_
.	_	_

#154
[	_	_
11	_	_
]	_	_
P.	_	_
Isola	_	_
,	_	_
J.-Y	_	_
.	_	_

#155
Zhu	_	_
,	_	_
T.	_	_
Zhou	_	_
,	_	_
and	_	_
A	_	_
.	_	_

#156
A.	_	_
Efros	_	_
,	_	_
“ImagetoImage	_	_
Translation	_	_
with	_	_
Conditional	_	_
Adversarial	_	_
Networks	_	_
,	_	_
”	_	_
ArXiv:1611.07004	_	_
,	_	_
Nov.	_	_
2016	_	_
.	_	_

#157
[	_	_
12	_	_
]	_	_
J.-Y	_	_
.	_	_

#158
Zhu	_	_
,	_	_
T.	_	_
Park	_	_
,	_	_
P.	_	_
Isola	_	_
,	_	_
and	_	_
A	_	_
.	_	_

#159
A.	_	_
Efros	_	_
,	_	_
“Unpaired	_	_
Image-to-Image	_	_
Translation	_	_
using	_	_
CycleConsistent	_	_
Adversarial	_	_
Networks	_	_
,	_	_
”	_	_
ArXiv:1703.10593	_	_
,	_	_
Mar	_	_
.	_	_

#160
2017	_	_
.	_	_

#161
[	_	_
13	_	_
]	_	_
M.-Y	_	_
.	_	_

#162
Liu	_	_
,	_	_
T.	_	_
Breuel	_	_
,	_	_
and	_	_
J.	_	_
Kautz	_	_
,	_	_
“Unsupervised	_	_
Image-to-Image	_	_
Translation	_	_
Networks	_	_
,	_	_
”	_	_
ArXiv:1703.00848	_	_
,	_	_
Mar	_	_
.	_	_

#163
2017	_	_
.	_	_

#164
[	_	_
14	_	_
]	_	_
Y.	_	_
Choi	_	_
,	_	_
M.	_	_
Choi	_	_
,	_	_
M.	_	_
Kim	_	_
,	_	_
J.-W.	_	_
Ha	_	_
,	_	_
S.	_	_
Kim	_	_
,	_	_
and	_	_
J.	_	_
Choo	_	_
,	_	_
“StarGAN	_	_
:	_	_
Unified	_	_
Generative	_	_
Adversarial	_	_
Networks	_	_
for	_	_
Multi-Domain	_	_
Image-to-Image	_	_
Translation	_	_
,	_	_
”	_	_
ArXiv:1711.09020	_	_
,	_	_
Nov.	_	_
2017	_	_
.	_	_

#165
[	_	_
15	_	_
]	_	_
S.	_	_
Zhou	_	_
,	_	_
T.	_	_
Xiao	_	_
,	_	_
Y.	_	_
Yang	_	_
,	_	_
D.	_	_
Feng	_	_
,	_	_
Q	_	_
.	_	_

#166
He	_	_
,	_	_
and	_	_
W.	_	_
He	_	_
,	_	_
“GeneGAN	_	_
:	_	_
Learning	_	_
Object	_	_
Transfiguration	_	_
and	_	_
Attribute	_	_
Subspace	_	_
from	_	_
Unpaired	_	_
Data	_	_
,	_	_
”	_	_
ArXiv:1705.04932	_	_
,	_	_
May	_	_
2017	_	_
.	_	_

#167
[	_	_
16	_	_
]	_	_
Z.	_	_
Yi	_	_
,	_	_
H.	_	_
Zhang	_	_
,	_	_
P.	_	_
Tan	_	_
,	_	_
and	_	_
M.	_	_
Gong	_	_
,	_	_
“DualGAN	_	_
:	_	_
Unsupervised	_	_
Dual	_	_
Learning	_	_
for	_	_
Image-to-Image	_	_
Translation	_	_
,	_	_
”	_	_
ArXiv:1704.02510	_	_
,	_	_
Apr	_	_
.	_	_

#168
2017	_	_
.	_	_

#169
[	_	_
17	_	_
]	_	_
David	_	_
C	_	_
Van	_	_
Essen	_	_
,	_	_
Stephen	_	_
M	_	_
Smith	_	_
,	_	_
Deanna	_	_
M	_	_
Barch	_	_
,	_	_
Timothy	_	_
EJ	_	_
Behrens	_	_
,	_	_
Essa	_	_
Yacoub	_	_
,	_	_
Kamil	_	_
Ugurbil	_	_
,	_	_
WuMinn	_	_
HCP	_	_
Consortium	_	_
,	_	_
et	_	_
al.	_	_
,	_	_
“The	_	_
wu-minn	_	_
human	_	_
connectome	_	_
project	_	_
:	_	_
an	_	_
overview	_	_
,	_	_
”	_	_
Neuroimage	_	_
,	_	_
vol	_	_
.	_	_

#170
80	_	_
,	_	_
pp	_	_
.	_	_

#171
62–79	_	_
,	_	_
2013	_	_
.	_	_

#172
[	_	_
18	_	_
]	_	_
Matthew	_	_
F	_	_
Glasser	_	_
,	_	_
Stamatios	_	_
N	_	_
Sotiropoulos	_	_
,	_	_
J	_	_
Anthony	_	_
Wilson	_	_
,	_	_
Timothy	_	_
S	_	_
Coalson	_	_
,	_	_
Bruce	_	_
Fischl	_	_
,	_	_
Jesper	_	_
L	_	_
Andersson	_	_
,	_	_
Junqian	_	_
Xu	_	_
,	_	_
Saad	_	_
Jbabdi	_	_
,	_	_
Matthew	_	_
Webster	_	_
,	_	_
Jonathan	_	_
R	_	_
Polimeni	_	_
,	_	_
et	_	_
al.	_	_
,	_	_
“The	_	_
minimal	_	_
preprocessing	_	_
pipelines	_	_
for	_	_
the	_	_
Human	_	_
Connectome	_	_
Project	_	_
,	_	_
”	_	_
Neuroimage	_	_
,	_	_
vol	_	_
.	_	_

#173
80	_	_
,	_	_
pp	_	_
.	_	_

#174
105–124	_	_
,	_	_
2013	_	_
.	_	_

#175
[	_	_
19	_	_
]	_	_
Biting	_	_
Yu	_	_
,	_	_
Luping	_	_
Zhou	_	_
,	_	_
Lei	_	_
Wang	_	_
,	_	_
Jurgen	_	_
Fripp	_	_
,	_	_
and	_	_
Pierrick	_	_
Bourgerat	_	_
,	_	_
“3D	_	_
cGAN	_	_
Based	_	_
Cross-Modality	_	_
MR	_	_
Image	_	_
Synthesis	_	_
for	_	_
Brain	_	_
Tumor	_	_
Segmentation	_	_
,	_	_
”	_	_
in	_	_
International	_	_
Symposium	_	_
on	_	_
Biomedical	_	_
Imaging	_	_
(	_	_
ISBI	_	_
)	_	_
,	_	_
2018	_	_
,	_	_
pp	_	_
.	_	_

#176
626–630	_	_
.	_	_