#127
As	_	_
for	_	_
the	_	_
Style-Discriminator	_	_
,	_	_
each	_	_
surface	_	_
normal	_	_
map	_	_
and	_	_
its	_	_
corresponding	_	_
image	_	_
are	_	_
concatenated	_	_
at	_	_
the	_	_
channel	_	_
dimension	_	_
to	_	_
form	_	_
a	_	_
single	_	_
input	_	_
to	_	_
the	_	_
discriminator	_	_
.	_	_

#128
Besides	_	_
,	_	_
SS-GAN	_	_
assumes	_	_
that	_	_
,	_	_
a	_	_
good	_	_
synthetic	_	_
image	_	_
should	deontic	_
also	_	_
be	_	_
used	_	_
to	_	_
reconstruct	_	_
a	_	_
good	_	_
surface	_	_
normal	_	_
map	_	_
.	_	_

#129
Under	_	_
this	_	_
assumption	_	_
,	_	_
SS-GAN	_	_
designs	_	_
a	_	_
fully-connected	_	_
network	_	_
that	_	_
transforms	_	_
an	_	_
image	_	_
back	_	_
to	_	_
its	_	_
surface	_	_
normal	_	_
map	_	_
,	_	_
and	_	_
uses	_	_
a	_	_
pixel-wise	_	_
loss	_	_
that	_	_
enforces	_	_
the	_	_
reconstructed	_	_
surface	_	_
normal	_	_
to	_	_
approximate	_	_
the	_	_
true	_	_
one	_	_
.	_	_

#219
A	_	_
plausible	_	_
reason	_	_
why	_	_
current	_	_
models	_	_
fail	_	_
to	_	_
work	_	_
well	_	_
on	_	_
complicated	_	_
images	_	_
is	_	_
that	_	_
the	_	_
models	_	_
only	_	_
learn	_	_
the	_	_
overall	_	_
features	_	_
of	_	_
an	_	_
image	_	_
,	_	_
instead	_	_
of	_	_
learning	_	_
the	_	_
concept	_	_
of	_	_
each	_	_
kind	_	_
of	_	_
objects	_	_
in	_	_
it	_	_
.	_	_

#220
This	_	_
gives	_	_
an	_	_
explanation	_	_
why	_	_
synthetic	_	_
scenes	_	_
of	_	_
bedrooms	_	_
and	_	_
living	_	_
rooms	_	_
lack	_	_
sharp	_	_
details	_	_
,	_	_
since	_	_
the	_	_
model	_	_
do	_	_
not	_	_
distinguish	_	_
between	_	_
a	_	_
bed	_	_
and	_	_
a	_	_
desk	_	_
,	_	_
all	_	_
it	_	_
sees	_	_
is	_	_
that	_	_
some	_	_
patterns	_	_
of	_	_
shapes	_	_
and	_	_
colors	_	_
should	deontic	_
be	_	_
put	_	_
somewhere	_	_
in	_	_
the	_	_
synthetic	_	_
image	_	_
.	_	_

#221
In	_	_
other	_	_
words	_	_
,	_	_
the	_	_
model	_	_
does	_	_
not	_	_
really	_	_
understand	_	_
the	_	_
image	_	_
,	_	_
but	_	_
just	_	_
remembers	_	_
where	_	_
to	_	_
put	_	_
some	_	_
shapes	_	_
and	_	_
colors	_	_
.	_	_

#245
From	_	_
the	_	_
experiments	_	_
,	_	_
it	_	_
is	_	_
found	_	_
that	_	_
,	_	_
for	_	_
an	_	_
256×256	_	_
image	_	_
,	_	_
a	_	_
patch-size	_	_
of	_	_
70×70	_	_
works	_	_
best	_	_
.	_	_

#246
Although	_	_
Pix2Pix	_	_
produces	_	_
very	_	_
impressive	_	_
synthetic	_	_
images	_	_
,	_	_
the	_	_
major	_	_
limitation	_	_
is	_	_
that	_	_
it	_	_
must	deontic	_
use	_	_
paired	_	_
images	_	_
as	_	_
supervision	_	_
,	_	_
as	_	_
is	_	_
shown	_	_
in	_	_
Equation	_	_
8	_	_
that	_	_
data	_	_
pair	_	_
(	_	_
x	_	_
,	_	_
y	_	_
)	_	_
is	_	_
drawn	_	_
from	_	_
the	_	_
joint	_	_
distribution	_	_
p	_	_
(	_	_
x	_	_
,	_	_
y	_	_
)	_	_
.	_	_

#247
5.2	_	_
Supervised	_	_
Image-to-Image	_	_
Translation	_	_
with	_	_
Pair-wise	_	_
Discrimination	_	_

#291
Constraint	_	_
DistanceGAN	_	_
[	_	_
79	_	_
]	_	_
discovers	_	_
that	_	_
,	_	_
the	_	_
distance	_	_
||xi	_	_
−	_	_
xj	_	_
||	_	_
between	_	_
two	_	_
images	_	_
in	_	_
the	_	_
source	_	_
domain	_	_
A	_	_
is	_	_
highly	_	_
positively	_	_
correlated	_	_
to	_	_
the	_	_
distance	_	_
of	_	_
their	_	_
counterparts	_	_
||GAB	_	_
(	_	_
xi	_	_
)	_	_
−GAB	_	_
(	_	_
xj	_	_
)	_	_
||	_	_
in	_	_
the	_	_
target	_	_
domainB	_	_
,	_	_
which	_	_
can	_	_
be	_	_
seen	_	_
from	_	_
Figure	_	_
1	_	_
of	_	_
the	_	_
paper	_	_
[	_	_
79	_	_
]	_	_
.	_	_

#292
According	_	_
to	_	_
[	_	_
79	_	_
]	_	_
,	_	_
let	_	_
dk	_	_
be	_	_
the	_	_
distance	_	_
||xi−xj	_	_
||	_	_
,	_	_
and	_	_
d′k	_	_
be	_	_
||GAB	_	_
(	_	_
xi	_	_
)	_	_
−GAB	_	_
(	_	_
xj	_	_
)	_	_
||	_	_
,	_	_
a	_	_
high	_	_
correlation	_	_
indicates	_	_
that	_	_
∑	_	_
dkd	_	_
′	_	_
k	_	_
should	inference	_
also	_	_
be	_	_
high	_	_
.	_	_

#293
The	_	_
pair-wise	_	_
distances	_	_
dk	_	_
in	_	_
source	_	_
domain	_	_
are	_	_
fixed	_	_
,	_	_
and	_	_
maximizing	_	_
∑	_	_
dkd	_	_
′	_	_
k	_	_
causes	_	_
dk	_	_
with	_	_
large	_	_
value	_	_
to	_	_
dominate	_	_
the	_	_
loss	_	_
,	_	_
which	_	_
is	_	_
undesirable	_	_
.	_	_

#302
One	_	_
interesting	_	_
thing	_	_
is	_	_
,	_	_
as	_	_
stated	_	_
in	_	_
[	_	_
79	_	_
]	_	_
,	_	_
that	_	_
DistanceGAN	_	_
computes	_	_
the	_	_
distances	_	_
in	_	_
raw	_	_
RGB	_	_
space	_	_
and	_	_
still	_	_
achieves	_	_
better	_	_
performance	_	_
than	_	_
baselines	_	_
,	_	_
but	_	_
it	_	_
may	_	_
help	_	_
if	_	_
the	_	_
distances	_	_
are	_	_
calculated	_	_
in	_	_
images’	_	_
latent	_	_
feature	_	_
space	_	_
where	_	_
the	_	_
features	_	_
can	_	_
be	_	_
extracted	_	_
using	_	_
pre-trained	_	_
image	_	_
classifiers	_	_
.	_	_

#303
In	_	_
DistanceGAN	_	_
[	_	_
79	_	_
]	_	_
,	_	_
the	_	_
authors	_	_
argue	_	_
that	_	_
the	_	_
high	_	_
positive	_	_
correlation	_	_
between	_	_
dk	_	_
and	_	_
d′k	_	_
implies	_	_
that	_	_
∑	_	_
dkd	_	_
′	_	_
k	_	_
should	deontic	_
be	_	_
high	_	_
.	_	_

#304
However	_	_
,	_	_
it	_	_
is	_	_
unclear	_	_
how	_	_
high	_	_
d′k	_	_
should	deontic	_
be	_	_
.	_	_

#305
For	_	_
example	_	_
,	_	_
if	_	_
dk	_	_
=	_	_
1	_	_
and	_	_
we	_	_
know	_	_
that	_	_
d′k	_	_
should	deontic	_
be	_	_
high	_	_
,	_	_
we	_	_
still	_	_
can	_	_
not	_	_
definitely	_	_
say	_	_
that	_	_
d′k	_	_
=	_	_
3	_	_
is	_	_
more	_	_
desirable	_	_
than	_	_
d′k	_	_
=	_	_
2	_	_
.	_	_

#306
The	_	_
concept	_	_
of	_	_
“high”	_	_
is	_	_
blurry	_	_
,	_	_
so	_	_
it	_	_
may	_	_
be	_	_
better	_	_
to	_	_
use	_	_
the	_	_
concept	_	_
“higher”	_	_
.	_	_

#307
An	_	_
alternative	_	_
statement	_	_
could	options	_
be	_	_
,	_	_
let	_	_
x	_	_
,	_	_
y	_	_
,	_	_
z	_	_
be	_	_
images	_	_
from	_	_
domain	_	_
A	_	_
,	_	_
if	_	_
d	_	_
(	_	_
x	_	_
,	_	_
y	_	_
)	_	_
>	_	_
d	_	_
(	_	_
x	_	_
,	_	_
z	_	_
)	_	_
,	_	_
then	_	_
d	_	_
(	_	_
GAB	_	_
(	_	_
x	_	_
)	_	_
,	_	_
GAB	_	_
(	_	_
y	_	_
)	_	_
)	_	_
>	_	_
d	_	_
(	_	_
GAB	_	_
(	_	_
x	_	_
)	_	_
,	_	_
GAB	_	_
(	_	_
z	_	_
)	_	_
)	_	_
.	_	_

#308
And	_	_
thus	_	_
we	_	_
can	_	_
design	_	_
a	_	_
loss	_	_
like	_	_
max	_	_
(	_	_
δ	_	_
,	_	_
d	_	_
(	_	_
GAB	_	_
(	_	_
x	_	_
)	_	_
,	_	_
GAB	_	_
(	_	_
y	_	_
)	_	_
)	_	_
−	_	_
d	_	_
(	_	_
GAB	_	_
(	_	_
x	_	_
)	_	_
,	_	_
GAB	_	_
(	_	_
z	_	_
)	_	_
)	_	_
)	_	_
for	_	_
all	_	_
triplets	_	_
x	_	_
,	_	_
y	_	_
,	_	_
z	_	_
∈	_	_
A	_	_
such	_	_
that	_	_
d	_	_
(	_	_
x	_	_
,	_	_
y	_	_
)	_	_
>	_	_
d	_	_
(	_	_
x	_	_
,	_	_
z	_	_
)	_	_
.	_	_

#309
Regardless	_	_
of	_	_
the	_	_
objective	_	_
of	_	_
maximizing	_	_
∑	_	_
dkd	_	_
′	_	_
k	_	_
,	_	_
the	_	_
actual	_	_
loss	_	_
used	_	_
in	_	_
DistanceGAN	_	_
,	_	_
i.e.	_	_
∑	_	_
|dk	_	_
−	_	_
d′k|	_	_
,	_	_
is	_	_
forcing	_	_
d′k	_	_
to	_	_
be	_	_
as	_	_
close	_	_
to	_	_
dk	_	_
as	_	_
possible	_	_
.	_	_

#310
In	_	_
other	_	_
words	_	_
,	_	_
how	_	_
two	_	_
images	_	_
of	_	_
a	_	_
domain	_	_
differ	_	_
from	_	_
each	_	_
other	_	_
should	deontic	_
be	_	_
reflected	_	_
in	_	_
the	_	_
same	_	_
way	_	_
when	_	_
they	_	_
are	_	_
translated	_	_
into	_	_
another	_	_
domain	_	_
,	_	_
which	_	_
can	_	_
be	_	_
called	_	_
“equivariance”	_	_
.	_	_

#311
The	_	_
distance	_	_
loss	_	_
and	_	_
self-distance	_	_
loss	_	_
proposed	_	_
in	_	_
DistanceGAN	_	_
[	_	_
79	_	_
]	_	_
is	_	_
essentially	_	_
capturing	_	_
this	_	_
“equivariance”	_	_
property	_	_
.	_	_

#338
Given	_	_
a	_	_
training	_	_
set	_	_
Xs	_	_
in	_	_
which	_	_
each	_	_
image	_	_
x	_	_
∈	_	_
Xs	_	_
has	_	_
a	_	_
class	_	_
label	_	_
yx	_	_
,	_	_
the	_	_
objective	_	_
of	_	_
C	_	_
is	_	_
to	_	_
minimize	_	_
the	_	_
cross-entropy	_	_
loss	_	_
LC	_	_
:	_	_
Lc	_	_
(	_	_
G	_	_
,	_	_
C	_	_
)	_	_
=	_	_
Ex∈Xs	_	_
[	_	_
−yᵀ	_	_
x	_	_
log	_	_
[	_	_
C	_	_
(	_	_
G	_	_
(	_	_
x	_	_
)	_	_
)	_	_
]	_	_
−	_	_
yᵀ	_	_
x	_	_
log	_	_
[	_	_
C	_	_
(	_	_
x	_	_
)	_	_
]	_	_
]	_	_
.	_	_
(	_	_
25	_	_
)	_	_

#339
Besides	_	_
,	_	_
DAAC	_	_
[	_	_
82	_	_
]	_	_
also	_	_
proposes	_	_
a	_	_
content-similarity	_	_
loss	_	_
in	_	_
cases	_	_
with	_	_
prior	_	_
knowledge	_	_
on	_	_
what	_	_
information	_	_
should	deontic	_
be	_	_
preserved	_	_
after	_	_
the	_	_
domain	_	_
adaption	_	_
process	_	_
.	_	_

#340
For	_	_
example	_	_
,	_	_
we	_	_
may	_	_
expect	_	_
the	_	_
hues	_	_
of	_	_
the	_	_
source	_	_
image	_	_
and	_	_
the	_	_
adapted	_	_
image	_	_
to	_	_
be	_	_
the	_	_
same	_	_
.	_	_

#425
Inception	_	_
score	_	_
(	_	_
IS	_	_
)	_	_
[	_	_
6	_	_
]	_	_
evaluates	_	_
an	_	_
image	_	_
based	_	_
on	_	_
the	_	_
entropy	_	_
in	_	_
class	_	_
probability	_	_
distribution	_	_
when	_	_
it	_	_
is	_	_
put	_	_
into	_	_
a	_	_
pre-trained	_	_
image	_	_
classifier	_	_
.	_	_

#426
One	_	_
intuition	_	_
behind	_	_
Inception	_	_
score	_	_
is	_	_
that	_	_
the	_	_
better	_	_
an	_	_
image	_	_
x	_	_
is	_	_
,	_	_
the	_	_
lower	_	_
the	_	_
entropy	_	_
of	_	_
conditional	_	_
distribution	_	_
p	_	_
(	_	_
y|x	_	_
)	_	_
should	inference	_
be	_	_
,	_	_
which	_	_
means	_	_
the	_	_
classifier	_	_
have	_	_
high	_	_
confidence	_	_
of	_	_
what	_	_
the	_	_
image	_	_
is	_	_
about	_	_
.	_	_

#427
Also	_	_
,	_	_
to	_	_
encourage	_	_
the	_	_
model	_	_
to	_	_
generate	_	_
various	_	_
classes	_	_
of	_	_
images	_	_
,	_	_
the	_	_
marginal	_	_
distribution	_	_
p	_	_
(	_	_
y	_	_
)	_	_
=	_	_
∫	_	_
p	_	_
(	_	_
y|x	_	_
=	_	_
G	_	_
(	_	_
z	_	_
)	_	_
)	_	_
dz	_	_
should	deontic	_
have	_	_
high	_	_
entropy	_	_
.	_	_

#428
Combining	_	_
these	_	_
two	_	_
intuition	_	_
,	_	_
the	_	_
Inception	_	_
score	_	_
is	_	_
calculated	_	_
by	_	_
exp	_	_
(	_	_
Ex∼G	_	_
(	_	_
z	_	_
)	_	_
DKL	_	_
(	_	_
p	_	_
(	_	_
y|x	_	_
)	_	_
||p	_	_
(	_	_
y	_	_
)	_	_
)	_	_
.	_	_

#463
For	_	_
text-to-image	_	_
synthesis	_	_
,	_	_
current	_	_
methods	_	_
work	_	_
well	_	_
on	_	_
datasets	_	_
where	_	_
each	_	_
image	_	_
contains	_	_
single	_	_
object	_	_
such	_	_
as	_	_
CUB	_	_
[	_	_
57	_	_
]	_	_
and	_	_
Oxford-102	_	_
[	_	_
55	_	_
]	_	_
,	_	_
but	_	_
the	_	_
performance	_	_
on	_	_
complex	_	_
datasets	_	_
such	_	_
as	_	_
MSCOCO	_	_
[	_	_
61	_	_
]	_	_
is	_	_
much	_	_
worse	_	_
.	_	_

#464
Although	_	_
some	_	_
models	_	_
can	_	_
produce	_	_
realistic	_	_
images	_	_
of	_	_
rooms	_	_
in	_	_
LSUN	_	_
[	_	_
64	_	_
]	_	_
,	_	_
it	_	_
should	deontic-rhetorical	_
be	_	_
noted	_	_
that	_	_
rooms	_	_
do	_	_
not	_	_
contain	_	_
living	_	_
things	_	_
,	_	_
and	_	_
a	_	_
living	_	_
thing	_	_
is	_	_
certainly	_	_
much	_	_
more	_	_
complicated	_	_
than	_	_
static	_	_
objects	_	_
.	_	_

#465
This	_	_
limitation	_	_
probably	_	_
stems	_	_
from	_	_
the	_	_
models’	_	_
inability	_	_
to	_	_
learn	_	_
different	_	_
concepts	_	_
of	_	_
objects	_	_
.	_	_