#0
An	_	_
experimental	_	_
comparison	_	_
of	_	_
classification	_	_
algorithms	_	_
for	_	_
imbalanced	_	_
credit	_	_
scoring	_	_
data	_	_
sets	_	_
Abstract	_	_
In	_	_
this	_	_
paper	_	_
,	_	_
we	_	_
set	_	_
out	_	_
to	_	_
compare	_	_
several	_	_
techniques	_	_
that	_	_
can	capability-feasibility	_
be	_	_
used	_	_
in	_	_
the	_	_
analysis	_	_
of	_	_
imbalanced	_	_
credit	_	_
scoring	_	_
data	_	_
sets	_	_
.	_	_

#1
In	_	_
a	_	_
credit	_	_
scoring	_	_
context	_	_
,	_	_
imbalanced	_	_
data	_	_
sets	_	_
frequently	_	_
occur	_	_
as	_	_
the	_	_
number	_	_
of	_	_
defaulting	_	_
loans	_	_
in	_	_
a	_	_
portfolio	_	_
is	_	_
usually	_	_
much	_	_
lower	_	_
than	_	_
the	_	_
number	_	_
of	_	_
observations	_	_
that	_	_
do	_	_
not	_	_
default	_	_
.	_	_

#9
In	_	_
the	_	_
current	_	_
financial	_	_
climate	_	_
,	_	_
and	_	_
with	_	_
the	_	_
recent	_	_
introduction	_	_
of	_	_
the	_	_
Basel	_	_
II	_	_
Accord	_	_
,	_	_
financial	_	_
institutions	_	_
have	_	_
even	_	_
more	_	_
incentives	_	_
to	_	_
select	_	_
and	_	_
implement	_	_
the	_	_
most	_	_
appropriate	_	_
credit	_	_
scoring	_	_
techniques	_	_
for	_	_
their	_	_
credit	_	_
portfolios	_	_
.	_	_

#10
It	_	_
is	_	_
stated	_	_
in	_	_
Henley	_	_
and	_	_
Hand	_	_
(	_	_
1997	_	_
)	_	_
that	_	_
companies	_	_
could	feasibility-speculation	_
make	_	_
significant	_	_
future	_	_
savings	_	_
if	_	_
an	_	_
improvement	_	_
of	_	_
only	_	_
a	_	_
fraction	_	_
of	_	_
a	_	_
percent	_	_
could	feasibility-speculation	_
be	_	_
made	_	_
in	_	_
the	_	_
accuracy	_	_
of	_	_
the	_	_
credit	_	_
scoring	_	_
techniques	_	_
implemented	_	_
.	_	_

#11
However	_	_
,	_	_
in	_	_
the	_	_
research	_	_
literature	_	_
,	_	_
portfolios	_	_
that	_	_
can	feasibility	_
be	_	_
considered	_	_
as	_	_
very	_	_
low	_	_
risk	_	_
,	_	_
or	_	_
low	_	_
default	_	_
portfolios	_	_
(	_	_
LDPs	_	_
)	_	_
,	_	_
have	_	_
had	_	_
relatively	_	_
little	_	_
attention	_	_
paid	_	_
to	_	_
them	_	_
in	_	_
particular	_	_
with	_	_
regards	_	_
to	_	_
which	_	_
techniques	_	_
are	_	_
most	_	_
appropriate	_	_
for	_	_
scoring	_	_
them	_	_
.	_	_

#12
The	_	_
underlying	_	_
problem	_	_
with	_	_
LDPs	_	_
is	_	_
that	_	_
they	_	_
contain	_	_
a	_	_
much	_	_
smaller	_	_
number	_	_
of	_	_
observations	_	_
in	_	_
the	_	_
class	_	_
of	_	_
defaulters	_	_
than	_	_
in	_	_
that	_	_
of	_	_
the	_	_
good	_	_
payers	_	_
.	_	_

#13
A	_	_
large	_	_
class	_	_
imbalance	_	_
is	_	_
therefore	_	_
present	_	_
which	_	_
some	_	_
techniques	_	_
may	capability-options	negation
not	_	_
be	_	_
able	_	_
to	_	_
successfully	_	_
handle	_	_
.	_	_

#14
Typical	_	_
examples	_	_
of	_	_
low	_	_
default	_	_
portfolios	_	_
include	_	_
high-quality	_	_
corporate	_	_
borrowers	_	_
,	_	_
banks	_	_
,	_	_
sovereigns	_	_
and	_	_
some	_	_
categories	_	_
of	_	_
specialised	_	_
lending	_	_
(	_	_
Van	_	_
Der	_	_
Burgt	_	_
,	_	_
2007	_	_
)	_	_
but	_	_
in	_	_
some	_	_
countries	_	_
even	_	_
certain	_	_
retail	_	_
lending	_	_
portfolios	_	_
could	speculation	_
turn	_	_
out	_	_
to	_	_
have	_	_
very	_	_
low	_	_
numbers	_	_
of	_	_
defaults	_	_
compared	_	_
to	_	_
the	_	_
majority	_	_
class	_	_
.	_	_

#15
In	_	_
a	_	_
recent	_	_
FSA	_	_
publication	_	_
regarding	_	_
conservative	_	_
estimation	_	_
of	_	_
low	_	_
default	_	_
portfolios	_	_
,	_	_
regulatory	_	_
concerns	_	_
were	_	_
raised	_	_
about	_	_
whether	_	_
firms	_	_
can	capability	_
adequately	_	_
asses	_	_
the	_	_
risk	_	_
of	_	_
LDPs	_	_
(	_	_
Benjamin	_	_
,	_	_
Cathcart	_	_
,	_	_
&	_	_
Ryan	_	_
,	_	_
2006	_	_
)	_	_
.	_	_

#16
A	_	_
wide	_	_
range	_	_
of	_	_
classification	_	_
techniques	_	_
have	_	_
already	_	_
been	_	_
proposed	_	_
in	_	_
the	_	_
credit	_	_
scoring	_	_
literature	_	_
,	_	_
including	_	_
statistical	_	_
techniques	_	_
,	_	_
such	_	_
as	_	_
linear	_	_
discriminant	_	_
analysis	_	_
and	_	_
logistic	_	_
regression	_	_
,	_	_
and	_	_
non-parametric	_	_
models	_	_
,	_	_
such	_	_
as	_	_
k-nearest	_	_
neighbour	_	_
and	_	_
decision	_	_
trees	_	_
.	_	_

#46
In	_	_
Weiss	_	_
and	_	_
Provost	_	_
(	_	_
2003	_	_
)	_	_
it	_	_
was	_	_
found	_	_
that	_	_
the	_	_
naturally	_	_
occurring	_	_
class	_	_
distributions	_	_
in	_	_
the	_	_
25	_	_
data	_	_
sets	_	_
looked	_	_
at	_	_
,	_	_
often	_	_
did	_	_
not	_	_
produce	_	_
the	_	_
best-performing	_	_
classifiers	_	_
.	_	_

#47
More	_	_
specifically	_	_
,	_	_
based	_	_
on	_	_
the	_	_
AUC	_	_
measure	_	_
(	_	_
which	_	_
was	_	_
preferred	_	_
over	_	_
the	_	_
use	_	_
of	_	_
the	_	_
error	_	_
rate	_	_
)	_	_
,	_	_
it	_	_
was	_	_
shown	_	_
that	_	_
the	_	_
optimal	_	_
class	_	_
distribution	_	_
should	deontic	_
contain	_	_
between	_	_
50	_	_
%	_	_
and	_	_
90	_	_
%	_	_
minority	_	_
class	_	_
examples	_	_
within	_	_
the	_	_
training	_	_
set	_	_
.	_	_

#48
Alternatively	_	_
,	_	_
a	_	_
progressive	_	_
adaptive	_	_
sampling	_	_
strategy	_	_
for	_	_
selecting	_	_
the	_	_
optimal	_	_
class	_	_
distribution	_	_
is	_	_
proposed	_	_
in	_	_
Provost	_	_
,	_	_
Jensen	_	_
,	_	_
and	_	_
Oates	_	_
(	_	_
1999	_	_
)	_	_
.	_	_

#49
Whilst	_	_
this	_	_
method	_	_
of	_	_
class	_	_
adjustment	_	_
can	capability-options	_
be	_	_
very	_	_
effective	_	_
for	_	_
large	_	_
data	_	_
sets	_	_
,	_	_
with	_	_
adequate	_	_
observations	_	_
in	_	_
the	_	_
minority	_	_
class	_	_
of	_	_
defaulters	_	_
,	_	_
in	_	_
some	_	_
low	_	_
default	_	_
portfolios	_	_
there	_	_
are	_	_
only	_	_
a	_	_
very	_	_
small	_	_
number	_	_
of	_	_
loan	_	_
defaults	_	_
to	_	_
begin	_	_
with	_	_
.	_	_

#50
Various	_	_
kinds	_	_
of	_	_
techniques	_	_
have	_	_
been	_	_
compared	_	_
in	_	_
the	_	_
literature	_	_
to	_	_
try	_	_
and	_	_
ascertain	_	_
the	_	_
most	_	_
effective	_	_
way	_	_
of	_	_
overcoming	_	_
a	_	_
large	_	_
class	_	_
imbalance	_	_
.	_	_

#52
In	_	_
Japkowicz	_	_
(	_	_
2000	_	_
)	_	_
,	_	_
over-sampling	_	_
and	_	_
downsizing	_	_
were	_	_
compared	_	_
to	_	_
the	_	_
author	_	_
's	_	_
own	_	_
method	_	_
of	_	_
"	_	_
learning	_	_
by	_	_
recognition	_	_
"	_	_
in	_	_
order	_	_
to	_	_
determine	_	_
the	_	_
most	_	_
effective	_	_
technique	_	_
.	_	_

#53
The	_	_
findings	_	_
,	_	_
however	_	_
,	_	_
were	_	_
inconclusive	_	_
but	_	_
demonstrated	_	_
that	_	_
both	_	_
over-sampling	_	_
the	_	_
minority	_	_
class	_	_
and	_	_
downsizing	_	_
the	_	_
majority	_	_
class	_	_
can	capability-options	_
be	_	_
very	_	_
effective	_	_
.	_	_

#54
Subsequently	_	_
,	_	_
Batista	_	_
(	_	_
2004	_	_
)	_	_
identified	_	_
ten	_	_
alternative	_	_
techniques	_	_
in	_	_
dealing	_	_
with	_	_
class	_	_
imbalances	_	_
and	_	_
trialed	_	_
them	_	_
on	_	_
thirteen	_	_
data	_	_
sets	_	_
.	_	_

#62
defaulter	_	_
)	_	_
.	_	_

#63
For	_	_
this	_	_
binary	_	_
response	_	_
model	_	_
,	_	_
the	_	_
response	_	_
variable	_	_
,	_	_
y	_	_
,	_	_
can	options	_
take	_	_
on	_	_
one	_	_
of	_	_
two	_	_
possible	_	_
values	_	_
;	_	_
i.e.	_	_
,	_	_
y=0	_	_
if	_	_
the	_	_
customer	_	_
is	_	_
a	_	_
bad	_	_
payer	_	_
,	_	_
y=1	_	_
if	_	_
he/she	_	_
is	_	_
a	_	_
good	_	_
payer	_	_
.	_	_

#64
Let	_	_
us	_	_
assume	_	_
x	_	_
is	_	_
a	_	_
column	_	_
vector	_	_
of	_	_
M	_	_
explanatory	_	_
variables	_	_
and	_	_
π=Pr	_	_
(	_	_
y=1|x	_	_
)	_	_
is	_	_
the	_	_
response	_	_
probability	_	_
to	_	_
be	_	_
modelled	_	_
.	_	_

#75
During	_	_
model	_	_
estimation	_	_
,	_	_
the	_	_
weights	_	_
of	_	_
the	_	_
network	_	_
are	_	_
first	_	_
randomly	_	_
initialised	_	_
and	_	_
then	_	_
iteratively	_	_
adjusted	_	_
so	_	_
as	_	_
to	_	_
minimise	_	_
an	_	_
objective	_	_
function	_	_
,	_	_
e.g.	_	_
,	_	_
the	_	_
sum	_	_
of	_	_
squared	_	_
errors	_	_
(	_	_
possibly	_	_
accompanied	_	_
by	_	_
a	_	_
regularisation	_	_
term	_	_
to	_	_
prevent	_	_
over-fitting	_	_
)	_	_
.	_	_

#76
This	_	_
iterative	_	_
procedure	_	_
can	options	_
be	_	_
based	_	_
on	_	_
simple	_	_
gradient	_	_
descent	_	_
learning	_	_
or	_	_
more	_	_
sophisticated	_	_
optimisation	_	_
methods	_	_
such	_	_
as	_	_
Levenberg-Marquardt	_	_
or	_	_
Quasi-Newton	_	_
.	_	_

#77
The	_	_
number	_	_
of	_	_
hidden	_	_
neurons	_	_
can	feasibility	_
be	_	_
determined	_	_
through	_	_
a	_	_
grid	_	_
search	_	_
based	_	_
on	_	_
validation	_	_
set	_	_
performance	_	_
.	_	_

#78
Least	_	_
square	_	_
support	_	_
vector	_	_
machines	_	_
(	_	_
LS-SVMs	_	_
)	_	_
Support	_	_
vector	_	_
machines	_	_
(	_	_
SVMs	_	_
)	_	_
are	_	_
a	_	_
set	_	_
of	_	_
powerful	_	_
supervised	_	_
learning	_	_
techniques	_	_
used	_	_
for	_	_
classification	_	_
and	_	_
regression	_	_
.	_	_

#82
The	_	_
optimisation	_	_
problem	_	_
for	_	_
the	_	_
LS-SVM	_	_
is	_	_
defined	_	_
as	_	_
:	_	_
(	_	_
6	_	_
)	_	_
minw	_	_
,	_	_
b	_	_
,	_	_
eJ	_	_
(	_	_
w	_	_
,	_	_
b	_	_
,	_	_
e	_	_
)	_	_
=12wTw+γ12∑i=1Nei2	_	_
,	_	_
subject	_	_
to	_	_
the	_	_
following	_	_
equality	_	_
constraints	_	_
:	_	_
(	_	_
7	_	_
)	_	_
yiwTφ	_	_
(	_	_
xi	_	_
)	_	_
+b=1-ei	_	_
,	_	_
i=1	_	_
,	_	_
…	_	_
,	_	_
N	_	_
,	_	_
Where	_	_
w	_	_
is	_	_
the	_	_
weight	_	_
vector	_	_
in	_	_
primal	_	_
space	_	_
,	_	_
γ	_	_
is	_	_
the	_	_
regularisation	_	_
parameter	_	_
,	_	_
and	_	_
yi=+1	_	_
or	_	_
-1	_	_
for	_	_
good	_	_
(	_	_
bad	_	_
)	_	_
payers	_	_
,	_	_
respectively	_	_
(	_	_
Suykens	_	_
et	_	_
al.	_	_
,	_	_
2002	_	_
)	_	_
.	_	_

#83
A	_	_
solution	_	_
can	feasibility-rhetorical	_
then	_	_
be	_	_
obtained	_	_
after	_	_
constructing	_	_
the	_	_
Lagrangian	_	_
,	_	_
and	_	_
choosing	_	_
a	_	_
particular	_	_
kernel	_	_
function	_	_
K	_	_
(	_	_
x	_	_
,	_	_
xi	_	_
)	_	_
that	_	_
computes	_	_
inner	_	_
products	_	_
in	_	_
the	_	_
transformed	_	_
space	_	_
,	_	_
based	_	_
on	_	_
which	_	_
a	_	_
classifier	_	_
of	_	_
the	_	_
following	_	_
form	_	_
is	_	_
obtained	_	_
:	_	_
y	_	_
(	_	_
x	_	_
)	_	_
=sign∑i=1NαiyiK	_	_
(	_	_
x	_	_
,	_	_
xi	_	_
)	_	_
+b	_	_
,	_	_
where	_	_
by	_	_
K	_	_
(	_	_
x	_	_
,	_	_
xi	_	_
)	_	_
=φ	_	_
(	_	_
x	_	_
)	_	_
Tφ	_	_
(	_	_
xi	_	_
)	_	_
is	_	_
taken	_	_
to	_	_
be	_	_
a	_	_
positive	_	_
definite	_	_
kernel	_	_
satisfying	_	_
the	_	_
Mercer	_	_
theorem.The	_	_
hyper	_	_
parameter	_	_
γ	_	_
for	_	_
the	_	_
LS-SVM	_	_
classification	_	_
technique	_	_
is	_	_
tuned	_	_
using	_	_
10-fold	_	_
cross	_	_
validation	_	_
.	_	_

#84
C4.5	_	_
.	_	_

#95
These	_	_
tree	_	_
voting	_	_
procedures	_	_
are	_	_
collectively	_	_
defined	_	_
as	_	_
random	_	_
forests	_	_
.	_	_

#96
A	_	_
more	_	_
detailed	_	_
explanation	_	_
of	_	_
how	_	_
to	_	_
train	_	_
a	_	_
random	_	_
forest	_	_
can	feasibility-rhetorical	_
be	_	_
found	_	_
in	_	_
Breiman	_	_
(	_	_
2001	_	_
)	_	_
.	_	_

#97
For	_	_
the	_	_
Random	_	_
Forests	_	_
classification	_	_
technique	_	_
two	_	_
parameters	_	_
require	_	_
tuning	_	_
.	_	_

#101
This	_	_
leads	_	_
to	_	_
the	_	_
following	_	_
model	_	_
:	_	_
(	_	_
10	_	_
)	_	_
F	_	_
(	_	_
x	_	_
)	_	_
=G0+β1T1	_	_
(	_	_
x	_	_
)	_	_
+β2T2	_	_
(	_	_
x	_	_
)	_	_
+⋯+βnTn	_	_
(	_	_
x	_	_
)	_	_
,	_	_
where	_	_
G0	_	_
equals	_	_
the	_	_
first	_	_
value	_	_
for	_	_
the	_	_
series	_	_
,	_	_
T1	_	_
,	_	_
…	_	_
,	_	_
Tn	_	_
are	_	_
the	_	_
trees	_	_
fitted	_	_
to	_	_
the	_	_
pseudo-residuals	_	_
,	_	_
and	_	_
βi	_	_
are	_	_
coefficients	_	_
for	_	_
the	_	_
respective	_	_
tree	_	_
nodes	_	_
computed	_	_
by	_	_
the	_	_
gradient	_	_
boosting	_	_
algorithm	_	_
.	_	_

#102
A	_	_
more	_	_
detailed	_	_
explanation	_	_
of	_	_
gradient	_	_
boosting	_	_
can	feasibility-rhetorical	_
be	_	_
found	_	_
in	_	_
Friedman	_	_
(	_	_
2001	_	_
,	_	_
2002	_	_
)	_	_
.	_	_

#103
The	_	_
gradient	_	_
boosting	_	_
classifier	_	_
requires	_	_
tuning	_	_
of	_	_
the	_	_
number	_	_
of	_	_
iterations	_	_
and	_	_
the	_	_
maximum	_	_
branch	_	_
size	_	_
used	_	_
in	_	_
the	_	_
splitting	_	_
rule	_	_
.	_	_

#121
The	_	_
ROC	_	_
curve	_	_
illustrates	_	_
the	_	_
behaviour	_	_
of	_	_
a	_	_
classifier	_	_
without	_	_
having	_	_
to	_	_
take	_	_
into	_	_
consideration	_	_
the	_	_
class	_	_
distribution	_	_
or	_	_
misclassification	_	_
cost	_	_
.	_	_

#122
In	_	_
order	_	_
to	_	_
compare	_	_
the	_	_
ROC	_	_
curves	_	_
of	_	_
different	_	_
classifiers	_	_
,	_	_
the	_	_
area	_	_
under	_	_
the	_	_
receiver	_	_
operating	_	_
characteristic	_	_
curve	_	_
(	_	_
AUC	_	_
)	_	_
must	deontic	_
be	_	_
computed	_	_
.	_	_

#123
The	_	_
AUC	_	_
statistic	_	_
is	_	_
similar	_	_
to	_	_
the	_	_
Gini	_	_
coefficient	_	_
which	_	_
is	_	_
equal	_	_
to	_	_
2×	_	_
(	_	_
AUC-0.5	_	_
)	_	_
.	_	_

#146
The	_	_
Friedman	_	_
test	_	_
statistic	_	_
is	_	_
based	_	_
on	_	_
the	_	_
average	_	_
ranked	_	_
(	_	_
AR	_	_
)	_	_
performances	_	_
of	_	_
the	_	_
classification	_	_
techniques	_	_
on	_	_
each	_	_
data	_	_
set	_	_
,	_	_
and	_	_
is	_	_
calculated	_	_
as	_	_
follows	_	_
:	_	_
(	_	_
11	_	_
)	_	_
χF2=12DK	_	_
(	_	_
K+1	_	_
)	_	_
∑j=1KARj2-K	_	_
(	_	_
K+1	_	_
)	_	_
24	_	_
,	_	_
whereARj=1D∑i=1Drij.In	_	_
(	_	_
13	_	_
)	_	_
,	_	_
D	_	_
denotes	_	_
the	_	_
number	_	_
of	_	_
data	_	_
sets	_	_
used	_	_
in	_	_
the	_	_
study	_	_
,	_	_
K	_	_
is	_	_
the	_	_
total	_	_
number	_	_
of	_	_
classifiers	_	_
and	_	_
rij	_	_
is	_	_
the	_	_
rank	_	_
of	_	_
classifier	_	_
j	_	_
on	_	_
data	_	_
set	_	_
i.	_	_
χF2	_	_
is	_	_
distributed	_	_
according	_	_
to	_	_
the	_	_
Chi-square	_	_
distribution	_	_
with	_	_
K-1	_	_
degrees	_	_
of	_	_
freedom	_	_
.	_	_

#147
If	_	_
the	_	_
value	_	_
of	_	_
χF2	_	_
is	_	_
large	_	_
enough	_	_
,	_	_
then	_	_
the	_	_
null	_	_
hypothesis	_	_
that	_	_
there	_	_
is	_	_
no	_	_
difference	_	_
between	_	_
the	_	_
techniques	_	_
can	feasibility	_
be	_	_
rejected	_	_
.	_	_

#148
The	_	_
Friedman	_	_
statistic	_	_
is	_	_
well	_	_
suited	_	_
for	_	_
this	_	_
type	_	_
of	_	_
data	_	_
analysis	_	_
as	_	_
it	_	_
is	_	_
less	_	_
susceptible	_	_
to	_	_
outliers	_	_
(	_	_
Friedman	_	_
,	_	_
1940	_	_
)	_	_
.	_	_

#159
In	_	_
the	_	_
majority	_	_
of	_	_
the	_	_
class	_	_
splits	_	_
,	_	_
the	_	_
AR	_	_
of	_	_
the	_	_
QDA	_	_
and	_	_
Lin	_	_
LS-SVM	_	_
classifiers	_	_
are	_	_
statistically	_	_
worse	_	_
than	_	_
the	_	_
AR	_	_
of	_	_
the	_	_
Random	_	_
Forests	_	_
classifier	_	_
at	_	_
the	_	_
5	_	_
%	_	_
critical	_	_
difference	_	_
level	_	_
(	_	_
α=0.05	_	_
)	_	_
,	_	_
as	_	_
shown	_	_
in	_	_
the	_	_
significance	_	_
diagrams	_	_
included	_	_
next	_	_
.	_	_

#160
Note	_	_
that	_	_
,	_	_
even	_	_
though	_	_
the	_	_
differences	_	_
between	_	_
the	_	_
classifiers	_	_
are	_	_
small	_	_
,	_	_
it	_	_
is	_	_
important	_	_
to	_	_
note	_	_
that	_	_
in	_	_
a	_	_
credit	_	_
scoring	_	_
context	_	_
,	_	_
an	_	_
increase	_	_
in	_	_
the	_	_
discrimination	_	_
ability	_	_
of	_	_
even	_	_
a	_	_
fraction	_	_
of	_	_
a	_	_
percent	_	_
may	options	_
translate	_	_
into	_	_
significant	_	_
future	_	_
savings	_	_
(	_	_
Henley	_	_
&	_	_
Hand	_	_
,	_	_
1997	_	_
)	_	_
.	_	_

#161
The	_	_
following	_	_
significance	_	_
diagrams	_	_
display	_	_
the	_	_
AUC	_	_
performance	_	_
ranks	_	_
of	_	_
the	_	_
classifiers	_	_
,	_	_
along	_	_
with	_	_
Nemenyi	_	_
's	_	_
critical	_	_
difference	_	_
(	_	_
CD	_	_
)	_	_
tail	_	_
.	_	_

#168
The	_	_
gradient	_	_
boosting	_	_
classifier	_	_
performs	_	_
significantly	_	_
better	_	_
than	_	_
the	_	_
quadratic	_	_
discriminant	_	_
analysis	_	_
(	_	_
QDA	_	_
)	_	_
classifier	_	_
.	_	_

#169
From	_	_
these	_	_
findings	_	_
we	_	_
can	feasibility	_
make	_	_
a	_	_
preliminary	_	_
assumption	_	_
that	_	_
when	_	_
a	_	_
larger	_	_
class	_	_
imbalance	_	_
is	_	_
present	_	_
,	_	_
the	_	_
QDA	_	_
classifier	_	_
remains	_	_
significantly	_	_
different	_	_
to	_	_
the	_	_
gradient	_	_
boosting	_	_
classifier	_	_
.	_	_

#170
All	_	_
the	_	_
other	_	_
techniques	_	_
used	_	_
are	_	_
not	_	_
significantly	_	_
different	_	_
.	_	_

#171
At	_	_
a	_	_
90	_	_
%	_	_
good	_	_
,	_	_
10	_	_
%	_	_
bad	_	_
class	_	_
split	_	_
the	_	_
significance	_	_
diagram	_	_
shown	_	_
in	_	_
Fig	_	_
.	_	_
4	_	_
indicates	_	_
that	_	_
the	_	_
C4.5	_	_
and	_	_
QDA	_	_
algorithms	_	_
are	_	_
significantly	_	_
worse	_	_
than	_	_
the	_	_
random	_	_
forests	_	_
classifier	_	_
.	_	_

#172
It	_	_
can	feasibility-rhetorical	_
be	_	_
noted	_	_
that	_	_
the	_	_
Linear	_	_
LS-SVM	_	_
classifier	_	_
however	_	_
is	_	_
progressively	_	_
becoming	_	_
less	_	_
powerful	_	_
as	_	_
a	_	_
large	_	_
class	_	_
imbalance	_	_
is	_	_
present	_	_
(	_	_
see	_	_
Fig	_	_
.	_	_
5	_	_
)	_	_
.	_	_

#173
The	_	_
final	_	_
split	_	_
,	_	_
displaying	_	_
a	_	_
99	_	_
%	_	_
good	_	_
,	_	_
1	_	_
%	_	_
bad	_	_
class	_	_
split	_	_
,	_	_
indicates	_	_
that	_	_
,	_	_
at	_	_
the	_	_
most	_	_
extreme	_	_
class	_	_
distribution	_	_
analysed	_	_
,	_	_
two	_	_
classification	_	_
techniques	_	_
are	_	_
significantly	_	_
worse	_	_
(	_	_
Lin	_	_
LS-SVM	_	_
and	_	_
QDA	_	_
)	_	_
.	_	_

#175
The	_	_
logistic	_	_
regression	_	_
technique	_	_
therefore	_	_
shows	_	_
limited	_	_
power	_	_
in	_	_
correctly	_	_
classifying	_	_
observations	_	_
where	_	_
only	_	_
a	_	_
small	_	_
number	_	_
of	_	_
bad	_	_
observations	_	_
exist	_	_
.	_	_

#176
It	_	_
can	feasibility-rhetorical	_
also	_	_
be	_	_
concluded	_	_
that	_	_
the	_	_
random	_	_
forests	_	_
classifier	_	_
performs	_	_
surprisingly	_	_
well	_	_
given	_	_
a	_	_
large	_	_
class	_	_
imbalance	_	_
.	_	_

#177
In	_	_
summary	_	_
,	_	_
when	_	_
considering	_	_
the	_	_
AUC	_	_
performance	_	_
measures	_	_
,	_	_
it	_	_
can	feasibility-rhetorical	_
be	_	_
concluded	_	_
that	_	_
the	_	_
gradient	_	_
boosting	_	_
and	_	_
random	_	_
forest	_	_
classifiers	_	_
yield	_	_
a	_	_
very	_	_
good	_	_
performance	_	_
at	_	_
extreme	_	_
levels	_	_
of	_	_
class	_	_
imbalance	_	_
,	_	_
whereas	_	_
the	_	_
Lin	_	_
LS-SVM	_	_
sees	_	_
a	_	_
reduction	_	_
in	_	_
performance	_	_
as	_	_
a	_	_
larger	_	_
class	_	_
imbalance	_	_
is	_	_
introduced	_	_
.	_	_

#178
However	_	_
,	_	_
the	_	_
simpler	_	_
,	_	_
linear	_	_
classification	_	_
techniques	_	_
such	_	_
as	_	_
LDA	_	_
and	_	_
LOG	_	_
also	_	_
give	_	_
a	_	_
relatively	_	_
good	_	_
performance	_	_
,	_	_
which	_	_
is	_	_
not	_	_
significantly	_	_
different	_	_
from	_	_
that	_	_
of	_	_
the	_	_
gradient	_	_
boosting	_	_
and	_	_
random	_	_
forest	_	_
classifiers	_	_
.	_	_

#191
On	_	_
the	_	_
other	_	_
hand	_	_
,	_	_
techniques	_	_
such	_	_
as	_	_
QDA	_	_
and	_	_
C4.5	_	_
were	_	_
significantly	_	_
worse	_	_
than	_	_
the	_	_
best	_	_
performing	_	_
classifiers	_	_
.	_	_

#192
It	_	_
can	feasibility-rhetorical	_
also	_	_
be	_	_
concluded	_	_
that	_	_
the	_	_
use	_	_
of	_	_
a	_	_
linear	_	_
kernel	_	_
LS-SVM	_	_
would	_	_
not	_	_
be	_	_
beneficial	_	_
in	_	_
the	_	_
scoring	_	_
of	_	_
data	_	_
sets	_	_
where	_	_
a	_	_
very	_	_
large	_	_
class	_	_
imbalance	_	_
exists	_	_
.	_	_

#193
Further	_	_
work	_	_
that	_	_
could	feasibility-speculation	_
be	_	_
conducted	_	_
,	_	_
as	_	_
a	_	_
result	_	_
of	_	_
these	_	_
findings	_	_
,	_	_
would	_	_
be	_	_
to	_	_
firstly	_	_
consider	_	_
a	_	_
stacking	_	_
approach	_	_
to	_	_
classification	_	_
through	_	_
the	_	_
combination	_	_
of	_	_
multiple	_	_
techniques	_	_
.	_	_

#194
Such	_	_
an	_	_
approach	_	_
would	_	_
allow	_	_
a	_	_
meta-learner	_	_
to	_	_
pick	_	_
the	_	_
best	_	_
model	_	_
to	_	_
classify	_	_
an	_	_
observation	_	_
.	_	_