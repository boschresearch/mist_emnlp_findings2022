#55
The	_	_
second	_	_
method	_	_
(	_	_
CNN-Max	_	_
)	_	_
computes	_	_
the	_	_
component-wise	_	_
maximum	_	_
of	_	_
all	_	_
feature	_	_
vectors	_	_
.	_	_

#56
This	_	_
approach	_	_
makes	_	_
sense	_	_
because	_	_
the	_	_
feature	_	_
vectors	_	_
extracted	_	_
from	_	_
this	_	_
particular	_	_
network	_	_
are	_	_
quite	_	_
sparse	_	_
(	_	_
about	_	_
22	_	_
%	_	_
non-zero	_	_
coefficients	_	_
)	_	_
and	_	_
can	feasibility	_
be	_	_
interpreted	_	_
as	_	_
bags	_	_
of	_	_
visual	_	_
properties	_	_
.	_	_

#57
3.2	_	_
Linguistic	_	_
representations	_	_
For	_	_
our	_	_
linguistic	_	_
representations	_	_
we	_	_
extract	_	_
100-	_	_
dimensional	_	_
continuous	_	_
vector	_	_
representations	_	_
using	_	_
the	_	_
log-linear	_	_
skip-gram	_	_
model	_	_
of	_	_
Mikolov	_	_
et	_	_
al	_	_
.	_	_
(	_	_
2013	_	_
)	_	_
trained	_	_
on	_	_
a	_	_
corpus	_	_
consisting	_	_
of	_	_
the	_	_
400M	_	_
word	_	_
Text8	_	_
corpus	_	_
of	_	_
Wikipedia	_	_
text2	_	_
together	_	_
with	_	_
the	_	_
100M	_	_
word	_	_
British	_	_
National	_	_
Corpus	_	_
(	_	_
Leech	_	_
et	_	_
al.	_	_
,	_	_
1994	_	_
)	_	_
.	_	_

#59
The	_	_
skip-gram	_	_
model	_	_
learns	_	_
high	_	_
quality	_	_
semantic	_	_
representations	_	_
based	_	_
on	_	_
the	_	_
distributional	_	_
properties	_	_
of	_	_
words	_	_
in	_	_
text	_	_
,	_	_
and	_	_
outperforms	_	_
standard	_	_
distributional	_	_
models	_	_
on	_	_
a	_	_
variety	_	_
of	_	_
semantic	_	_
similarity	_	_
and	_	_
relatedness	_	_
tasks	_	_
.	_	_

#60
However	_	_
we	_	_
note	_	_
that	_	_
Bruni	_	_
et	_	_
al	_	_
.	_	_
(	_	_
2014	_	_
)	_	_
have	_	_
recently	_	_
reported	_	_
an	_	_
even	_	_
better	_	_
performance	_	_
for	_	_
their	_	_
linguistic	_	_
component	_	_
using	_	_
a	_	_
standard	_	_
distributional	_	_
model	_	_
,	_	_
although	_	_
this	_	_
may	speculation	_
have	_	_
been	_	_
tuned	_	_
to	_	_
the	_	_
task	_	_
.	_	_

#61
3.3	_	_
Multi-modal	_	_
Representations	_	_
Following	_	_
Bruni	_	_
et	_	_
al	_	_
.	_	_
(	_	_
2014	_	_
)	_	_
,	_	_
we	_	_
construct	_	_
multi-	_	_
modal	_	_
semantic	_	_
representations	_	_
by	_	_
concatenating	_	_
the	_	_
centered	_	_
and	_	_
L2-normalized	_	_
linguistic	_	_
and	_	_
perceptual	_	_
feature	_	_
vectors	_	_
~vling	_	_
and	_	_
~vvis	_	_
,	_	_
~vconcept	_	_
=	_	_
α×	_	_
~vling	_	_
||	_	_
(	_	_
1−	_	_
α	_	_
)	_	_
×	_	_
~vvis	_	_
,	_	_
(	_	_
1	_	_
)	_	_
where	_	_
||	_	_
denotes	_	_
the	_	_
concatenation	_	_
operator	_	_
and	_	_
α	_	_
is	_	_
an	_	_
optional	_	_
tuning	_	_
parameter	_	_
.	_	_

#71
This	_	_
implies	_	_
that	_	_
ImageNet	_	_
covers	_	_
only	_	_
a	_	_
small	_	_
fraction	_	_
of	_	_
the	_	_
existing	_	_
117K	_	_
WordNet	_	_
synsets	_	_
.	_	_

#72
The	_	_
ESP	_	_
Game	_	_
dataset	_	_
(	_	_
Von	_	_
Ahn	_	_
and	_	_
Dabbish	_	_
,	_	_
2004	_	_
)	_	_
was	_	_
famously	_	_
collected	_	_
as	_	_
a	_	_
“game	_	_
with	_	_
a	_	_
purpose”	_	_
,	_	_
in	_	_
which	_	_
two	_	_
players	_	_
must	deontic	_
independently	_	_
and	_	_
rapidly	_	_
agree	_	_
on	_	_
a	_	_
correct	_	_
word	_	_
label	_	_
for	_	_
randomly	_	_
selected	_	_
images	_	_
.	_	_

#73
Once	_	_
a	_	_
word	_	_
label	_	_
has	_	_
been	_	_
used	_	_
sufficiently	_	_
frequently	_	_
for	_	_
a	_	_
given	_	_
image	_	_
,	_	_
that	_	_
word	_	_
is	_	_
added	_	_
to	_	_
the	_	_
image’s	_	_
tags	_	_
.	_	_

#74
This	_	_
dataset	_	_
contains	_	_
100K	_	_
images	_	_
,	_	_
but	_	_
with	_	_
every	_	_
image	_	_
having	_	_
on	_	_
average	_	_
14	_	_
tags	_	_
,	_	_
that	_	_
amounts	_	_
to	_	_
a	_	_
coverage	_	_
of	_	_
20,515	_	_
words	_	_
.	_	_

#75
Since	_	_
players	_	_
are	_	_
encouraged	_	_
to	_	_
produce	_	_
as	_	_
many	_	_
terms	_	_
per	_	_
image	_	_
,	_	_
the	_	_
dataset’s	_	_
increased	_	_
coverage	_	_
is	_	_
at	_	_
the	_	_
expense	_	_
of	_	_
accuracy	_	_
in	_	_
the	_	_
word-to-image	_	_
mapping	_	_
:	_	_
a	_	_
dog	_	_
in	_	_
a	_	_
field	_	_
with	_	_
a	_	_
house	_	_
in	_	_
the	_	_
background	_	_
might	options	_
be	_	_
a	_	_
golden	_	_
retriever	_	_
in	_	_
ImageNet	_	_
and	_	_
could	options	_
have	_	_
tags	_	_
dog	_	_
,	_	_
golden	_	_
retriever	_	_
,	_	_
grass	_	_
,	_	_
field	_	_
,	_	_
house	_	_
,	_	_
door	_	_
in	_	_
the	_	_
ESP	_	_
Dataset	_	_
.	_	_

#76
In	_	_
other	_	_
words	_	_
,	_	_
images	_	_
in	_	_
the	_	_
ESP	_	_
dataset	_	_
do	_	_
not	_	_
make	_	_
a	_	_
distinction	_	_
between	_	_
objects	_	_
in	_	_
the	_	_
foreground	_	_
and	_	_
in	_	_
the	_	_
background	_	_
,	_	_
or	_	_
between	_	_
the	_	_
relative	_	_
size	_	_
of	_	_
the	_	_
objects	_	_
(	_	_
tags	_	_
for	_	_
images	_	_
are	_	_
provided	_	_
in	_	_
a	_	_
random	_	_
order	_	_
,	_	_
so	_	_
the	_	_
top	_	_
tag	_	_
is	_	_
not	_	_
necessarily	_	_
the	_	_
best	_	_
one	_	_
)	_	_
.	_	_

#100
Since	_	_
this	_	_
is	_	_
probably	_	_
the	_	_
most	_	_
widely	_	_
used	_	_
evaluation	_	_
dataset	_	_
for	_	_
distributional	_	_
semantics	_	_
,	_	_
we	_	_
include	_	_
it	_	_
for	_	_
comparison	_	_
with	_	_
other	_	_
approaches	_	_
.	_	_

#101
WordSim353	_	_
has	_	_
some	_	_
known	_	_
idiosyncracies	_	_
:	_	_
it	_	_
includes	_	_
named	_	_
entities	_	_
,	_	_
such	_	_
as	_	_
OPEC	_	_
,	_	_
Arafat	_	_
,	_	_
and	_	_
Maradona	_	_
,	_	_
as	_	_
well	_	_
as	_	_
abstract	_	_
words	_	_
,	_	_
such	_	_
as	_	_
antecedent	_	_
and	_	_
credibility	_	_
,	_	_
for	_	_
which	_	_
it	_	_
may	speculation	_
be	_	_
hard	_	_
to	_	_
find	_	_
corresponding	_	_
images	_	_
.	_	_

#102
Multi-modal	_	_
representations	_	_
are	_	_
often	_	_
evaluated	_	_
on	_	_
an	_	_
unspecified	_	_
subset	_	_
of	_	_
WordSim353	_	_
(	_	_
Feng	_	_
and	_	_
Lapata	_	_
,	_	_
2010	_	_
;	_	_
Bruni	_	_
et	_	_
al.	_	_
,	_	_
2012	_	_
;	_	_
Bruni	_	_
et	_	_
al.	_	_
,	_	_
2014	_	_
)	_	_
,	_	_
making	_	_
it	_	_
impossible	_	_
to	_	_
compare	_	_
the	_	_
reported	_	_
scores	_	_
.	_	_

#115
Since	_	_
we	_	_
have	_	_
full	_	_
coverage	_	_
with	_	_
the	_	_
ESP	_	_
Game	_	_
dataset	_	_
on	_	_
MEN	_	_
,	_	_
we	_	_
are	_	_
able	_	_
to	_	_
report	_	_
visual	_	_
representation	_	_
scores	_	_
for	_	_
the	_	_
entire	_	_
dataset	_	_
as	_	_
well	_	_
.	_	_

#116
The	_	_
results	_	_
can	rhetorical	_
be	_	_
seen	_	_
in	_	_
Table	_	_
1	_	_
.	_	_

#117
There	_	_
are	_	_
a	_	_
number	_	_
of	_	_
questions	_	_
to	_	_
ask	_	_
.	_	_

#127
This	_	_
re-affirms	_	_
the	_	_
importance	_	_
of	_	_
multi-modal	_	_
representations	_	_
for	_	_
distributional	_	_
semantics	_	_
.	_	_

#128
5.3	_	_
The	_	_
Contribution	_	_
of	_	_
Images	_	_
Since	_	_
the	_	_
ESP	_	_
Game	_	_
images	_	_
come	_	_
with	_	_
a	_	_
multitude	_	_
of	_	_
word	_	_
labels	_	_
,	_	_
one	_	_
could	feasibility-options	_
question	_	_
whether	_	_
a	_	_
performance	_	_
increase	_	_
of	_	_
multi-modal	_	_
models	_	_
based	_	_
on	_	_
that	_	_
dataset	_	_
comes	_	_
from	_	_
the	_	_
images	_	_
themselves	_	_
,	_	_
or	_	_
from	_	_
overlapping	_	_
word	_	_
labels	_	_
.	_	_

#129
It	_	_
might	speculation	_
also	_	_
be	_	_
possible	_	_
that	_	_
similar	_	_
concepts	_	_
are	_	_
more	_	_
likely	_	_
to	_	_
occur	_	_
in	_	_
the	_	_
same	_	_
image	_	_
,	_	_
which	_	_
encodes	_	_
relatedness	_	_
information	_	_
without	_	_
necessarily	_	_
taking	_	_
the	_	_
image	_	_
data	_	_
itself	_	_
into	_	_
account	_	_
.	_	_

#130
In	_	_
short	_	_
,	_	_
it	_	_
is	_	_
a	_	_
natural	_	_
question	_	_
to	_	_
ask	_	_
whether	_	_
the	_	_
performance	_	_
gain	_	_
is	_	_
due	_	_
to	_	_
image	_	_
data	_	_
or	_	_
due	_	_
to	_	_
word	_	_
label	_	_
associations	_	_
?	_	_

#143
CNN-Max	_	_
using	_	_
sparse	_	_
feature	_	_
vectors	_	_
means	_	_
that	_	_
we	_	_
treat	_	_
the	_	_
dominant	_	_
components	_	_
as	_	_
definitive	_	_
of	_	_
the	_	_
concept	_	_
class	_	_
,	_	_
which	_	_
is	_	_
more	_	_
suited	_	_
to	_	_
similarity	_	_
.	_	_

#144
CNN-Mean	_	_
averages	_	_
over	_	_
all	_	_
the	_	_
feature	_	_
components	_	_
,	_	_
and	_	_
as	_	_
such	_	_
might	speculation	_
be	_	_
more	_	_
suited	_	_
to	_	_
relatedness	_	_
.	_	_

#145
We	_	_
conjecture	_	_
that	_	_
the	_	_
performance	_	_
increase	_	_
on	_	_
WordSim353	_	_
is	_	_
due	_	_
to	_	_
increased	_	_
performance	_	_
on	_	_
the	_	_
similarity	_	_
subset	_	_
of	_	_
that	_	_
dataset	_	_
.	_	_

#151
There	_	_
are	_	_
a	_	_
number	_	_
of	_	_
observations	_	_
to	_	_
be	_	_
made	_	_
here	_	_
.	_	_

#152
First	_	_
of	_	_
all	_	_
,	_	_
we	_	_
can	rhetorical	_
see	_	_
that	_	_
the	_	_
performance	_	_
peak	_	_
for	_	_
the	_	_
MEN	_	_
datastes	_	_
is	_	_
much	_	_
higher	_	_
than	_	_
for	_	_
the	_	_
WordSim353	_	_
ones	_	_
,	_	_
and	_	_
that	_	_
its	_	_
peak	_	_
is	_	_
relatively	_	_
higher	_	_
as	_	_
well	_	_
.	_	_

#153
This	_	_
indicates	_	_
that	_	_
MEN	_	_
is	_	_
in	_	_
a	_	_
sense	_	_
a	_	_
more	_	_
balanced	_	_
dataset	_	_
.	_	_

#154
There	_	_
are	_	_
two	_	_
possible	_	_
explanations	_	_
:	_	_
as	_	_
indicated	_	_
earlier	_	_
,	_	_
WordSim353	_	_
contains	_	_
slightly	_	_
idiosyncratic	_	_
word	_	_
pairs	_	_
which	_	_
may	speculation	_
have	_	_
a	_	_
detrimental	_	_
effect	_	_
on	_	_
performance	_	_
;	_	_
or	_	_
,	_	_
WordSim353	_	_
was	_	_
not	_	_
constructed	_	_
with	_	_
multi-modal	_	_
semantics	_	_
in	_	_
mind	_	_
,	_	_
and	_	_
contains	_	_
a	_	_
substantial	_	_
amount	_	_
of	_	_
abstract	_	_
words	_	_
that	_	_
would	_	_
not	_	_
benefit	_	_
at	_	_
all	_	_
from	_	_
including	_	_
visual	_	_
information	_	_
.	_	_

#155
informaDue	_	_
to	_	_
the	_	_
nature	_	_
of	_	_
the	_	_
datasets	_	_
and	_	_
the	_	_
tasks	_	_
at	_	_
hand	_	_
,	_	_
it	_	_
is	_	_
arguably	_	_
much	_	_
more	_	_
important	_	_
that	_	_
CNNs	_	_
beat	_	_
standard	_	_
bag-of-visual-words	_	_
representations	_	_
on	_	_
MEN	_	_
than	_	_
on	_	_
W353	_	_
,	_	_
and	_	_
indeed	_	_
we	_	_
see	_	_
that	_	_
there	_	_
exists	_	_
no	_	_
α	_	_
for	_	_
which	_	_
BOVW	_	_
would	_	_
beat	_	_
any	_	_
of	_	_
the	_	_
CNN	_	_
networks	_	_
.	_	_

#161
The	_	_
MEN	_	_
words	_	_
dessert	_	_
,	_	_
bread	_	_
and	_	_
fruit	_	_
occur	_	_
in	_	_
the	_	_
bottom	_	_
5	_	_
for	_	_
both	_	_
image	_	_
datasets	_	_
,	_	_
which	_	_
implies	_	_
that	_	_
their	_	_
linguistic	_	_
representations	_	_
are	_	_
probably	_	_
not	_	_
very	_	_
good	_	_
.	_	_

#162
For	_	_
WordSim353	_	_
,	_	_
the	_	_
bottom	_	_
pairs	_	_
on	_	_
ImageNet	_	_
could	options	_
be	_	_
said	_	_
to	_	_
be	_	_
similarity	_	_
mistakes	_	_
;	_	_
while	_	_
the	_	_
ESP	_	_
Game	_	_
dataset	_	_
contains	_	_
more	_	_
relatedness	_	_
mistakes	_	_
(	_	_
king	_	_
and	_	_
queen	_	_
would	_	_
evaluate	_	_
similarity	_	_
,	_	_
while	_	_
stock	_	_
and	_	_
market	_	_
would	_	_
evaluate	_	_
relatedness	_	_
)	_	_
.	_	_

#163
It	_	_
is	_	_
difficult	_	_
to	_	_
say	_	_
anything	_	_
conclusive	_	_
about	_	_
this	_	_
discrepancy	_	_
,	_	_
but	_	_
it	_	_
is	_	_
clearly	_	_
a	_	_
direction	_	_
for	_	_
future	_	_
research	_	_
.	_	_

#168
Our	_	_
results	_	_
indicate	_	_
that	_	_
such	_	_
multi-modal	_	_
representations	_	_
outperform	_	_
both	_	_
linguistic	_	_
and	_	_
standard	_	_
bag-of-visual-words	_	_
multi-	_	_
modal	_	_
representations	_	_
.	_	_

#169
We	_	_
have	_	_
shown	_	_
that	_	_
our	_	_
approach	_	_
is	_	_
robust	_	_
and	_	_
that	_	_
CNN-extracted	_	_
features	_	_
from	_	_
separate	_	_
image	_	_
datasets	_	_
can	feasibility	_
succesfully	_	_
be	_	_
applied	_	_
to	_	_
semantic	_	_
relatedness	_	_
.	_	_

#170
In	_	_
addition	_	_
to	_	_
improving	_	_
multi-modal	_	_
representations	_	_
,	_	_
we	_	_
have	_	_
shown	_	_
that	_	_
the	_	_
source	_	_
of	_	_
this	_	_
improvement	_	_
is	_	_
due	_	_
to	_	_
image	_	_
data	_	_
and	_	_
is	_	_
not	_	_
simply	_	_
a	_	_
result	_	_
of	_	_
word	_	_
label	_	_
associations	_	_
.	_	_

#171
We	_	_
have	_	_
shown	_	_
this	_	_
by	_	_
obtaining	_	_
performance	_	_
improvements	_	_
on	_	_
two	_	_
different	_	_
image	_	_
datasets	_	_
,	_	_
and	_	_
by	_	_
obtaining	_	_
higher	_	_
performance	_	_
with	_	_
higher-quality	_	_
image	_	_
features	_	_
on	_	_
the	_	_
ESP	_	_
game	_	_
images	_	_
,	_	_
without	_	_
changing	_	_
the	_	_
association	_	_
between	_	_
word	_	_
labels	_	_
.	_	_

#172
In	_	_
future	_	_
work	_	_
,	_	_
we	_	_
will	_	_
investigate	_	_
whether	_	_
our	_	_
system	_	_
can	feasibility	_
be	_	_
further	_	_
improved	_	_
by	_	_
including	_	_
concreteness	_	_
information	_	_
or	_	_
a	_	_
substitute	_	_
metric	_	_
such	_	_
as	_	_
image	_	_
dispersion	_	_
,	_	_
as	_	_
has	_	_
been	_	_
suggested	_	_
by	_	_
other	_	_
work	_	_
on	_	_
multi-modal	_	_
semantics	_	_
(	_	_
Kiela	_	_
et	_	_
al.	_	_
,	_	_
2014	_	_
)	_	_
.	_	_

#173
Furthermore	_	_
,	_	_
a	_	_
logical	_	_
next	_	_
step	_	_
to	_	_
increase	_	_
performance	_	_
would	_	_
be	_	_
to	_	_
jointly	_	_
learn	_	_
multi-modal	_	_
representations	_	_
or	_	_
to	_	_
learn	_	_
weighting	_	_
parameters	_	_
.	_	_