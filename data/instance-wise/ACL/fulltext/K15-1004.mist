#11
Flanigan	_	_
et	_	_
al	_	_
.	_	_
(	_	_
2014	_	_
)	_	_
propose	_	_
a	_	_
two-stage	_	_
parsing	_	_
algorithm	_	_
which	_	_
first	_	_
maps	_	_
meaningful	_	_
continuous	_	_
spans	_	_
on	_	_
the	_	_
string	_	_
side	_	_
to	_	_
concept	_	_
fragments	_	_
on	_	_
the	_	_
graph	_	_
side	_	_
,	_	_
and	_	_
then	_	_
in	_	_
the	_	_
second	_	_
stage	_	_
adds	_	_
additional	_	_
edges	_	_
to	_	_
make	_	_
all	_	_
these	_	_
fragments	_	_
connected	_	_
.	_	_

#12
Concept	_	_
identification	_	_
(	_	_
Flanigan	_	_
et	_	_
al.	_	_
,	_	_
2014	_	_
;	_	_
Pourdamghani	_	_
et	_	_
al.	_	_
,	_	_
2014	_	_
)	_	_
can	feasibility	_
be	_	_
considered	_	_
as	_	_
an	_	_
important	_	_
first	_	_
step	_	_
to	_	_
relate	_	_
components	_	_
of	_	_
the	_	_
string	_	_
to	_	_
components	_	_
in	_	_
the	_	_
graph	_	_
.	_	_

#13
Wang	_	_
et	_	_
al	_	_
.	_	_
(	_	_
2015	_	_
)	_	_
also	_	_
present	_	_
a	_	_
two-stage	_	_
procedure	_	_
where	_	_
they	_	_
first	_	_
use	_	_
a	_	_
dependency	_	_
parser	_	_
trained	_	_
on	_	_
a	_	_
large	_	_
corpus	_	_
to	_	_
generate	_	_
a	_	_
dependency	_	_
tree	_	_
for	_	_
each	_	_
sentence	_	_
.	_	_

#16
Hyperedge	_	_
replacement	_	_
grammar	_	_
(	_	_
HRG	_	_
)	_	_
is	_	_
a	_	_
context-free	_	_
rewriting	_	_
formalism	_	_
for	_	_
generating	_	_
graphs	_	_
(	_	_
Drewes	_	_
et	_	_
al.	_	_
,	_	_
1997	_	_
)	_	_
.	_	_

#17
Its	_	_
synchronous	_	_
counterpart	_	_
,	_	_
SHRG	_	_
,	_	_
can	feasibility	_
be	_	_
used	_	_
for	_	_
transforming	_	_
a	_	_
graph	_	_
from/to	_	_
another	_	_
structured	_	_
representation	_	_
such	_	_
as	_	_
a	_	_
string	_	_
or	_	_
tree	_	_
structure	_	_
.	_	_

#18
HRG	_	_
has	_	_
great	_	_
potential	_	_
for	_	_
applications	_	_
in	_	_
natural	_	_
language	_	_
un32	_	_
understanding	_	_
and	_	_
generation	_	_
,	_	_
and	_	_
also	_	_
semanticsbased	_	_
machine	_	_
translation	_	_
.	_	_

#21
However	_	_
,	_	_
there	_	_
is	_	_
still	_	_
no	_	_
real	_	_
system	_	_
available	_	_
for	_	_
parsing	_	_
large	_	_
graphs	_	_
.	_	_

#22
An	_	_
SHRG	_	_
can	feasibility	_
be	_	_
used	_	_
for	_	_
AMR	_	_
graph	_	_
parsing	_	_
where	_	_
each	_	_
SHRG	_	_
rule	_	_
consists	_	_
of	_	_
a	_	_
pair	_	_
of	_	_
a	_	_
CFG	_	_
rule	_	_
and	_	_
an	_	_
HRG	_	_
rule	_	_
,	_	_
which	_	_
can	capability	_
generate	_	_
strings	_	_
and	_	_
AMR	_	_
graphs	_	_
in	_	_
parallel	_	_
.	_	_

#23
Jones	_	_
et	_	_
al	_	_
.	_	_
(	_	_
2012	_	_
)	_	_
present	_	_
a	_	_
Syntactic	_	_
Semantic	_	_
Algorithm	_	_
that	_	_
learns	_	_
SHRG	_	_
by	_	_
matching	_	_
minimal	_	_
parse	_	_
constituents	_	_
to	_	_
aligned	_	_
graph	_	_
fragments	_	_
and	_	_
incrementally	_	_
collapses	_	_
them	_	_
into	_	_
hyperedge	_	_
nonterminals	_	_
.	_	_

#40
3	_	_
.	_	_

#41
We	_	_
propose	_	_
an	_	_
MCMC	_	_
algorithm	_	_
which	_	_
samples	_	_
a	_	_
special	_	_
type	_	_
of	_	_
SHRG	_	_
rules	_	_
which	_	_
helps	_	_
maintain	_	_
the	_	_
properties	_	_
of	_	_
AMR	_	_
graphs	_	_
,	_	_
which	_	_
should	deontic-inference	_
be	_	_
able	_	_
to	_	_
generalize	_	_
to	_	_
learning	_	_
other	_	_
synchronous	_	_
grammar	_	_
with	_	_
a	_	_
CFG	_	_
left	_	_
side	_	_
.	_	_

#42
4	_	_
.	_	_

#61
P	_	_
is	_	_
a	_	_
finite	_	_
set	_	_
of	_	_
productions	_	_
of	_	_
the	_	_
form	_	_
A	_	_
→	_	_
R	_	_
,	_	_
where	_	_
A	_	_
∈	_	_
N	_	_
and	_	_
R	_	_
is	_	_
a	_	_
hypergraph	_	_
with	_	_
edge	_	_
labels	_	_
over	_	_
N	_	_
∪	_	_
T	_	_
and	_	_
with	_	_
nonempty	_	_
external	_	_
nodes	_	_
XR	_	_
.	_	_

#62
We	_	_
have	_	_
the	_	_
constraint	_	_
that	_	_
the	_	_
type	_	_
of	_	_
the	_	_
hyperedge	_	_
with	_	_
label	_	_
A	_	_
should	deontic	_
coincide	_	_
with	_	_
the	_	_
number	_	_
of	_	_
nodes	_	_
in	_	_
XR	_	_
.	_	_

#63
In	_	_
our	_	_
grammar	_	_
,	_	_
each	_	_
nonterminal	_	_
has	_	_
the	_	_
form	_	_
of	_	_
Xn	_	_
,	_	_
where	_	_
n	_	_
indicates	_	_
the	_	_
type	_	_
of	_	_
the	_	_
hyperedge	_	_
.	_	_

#70
The	_	_
first	_	_
rule	_	_
rewrites	_	_
the	_	_
start	_	_
symbol	_	_
with	_	_
a	_	_
subgraph	_	_
shown	_	_
on	_	_
the	_	_
r.h.s..	_	_
We	_	_
continue	_	_
the	_	_
rewriting	_	_
steps	_	_
until	_	_
there	_	_
are	_	_
no	_	_
more	_	_
nonterminal-labeled	_	_
edges	_	_
.	_	_

#71
The	_	_
synchronous	_	_
counterpart	_	_
of	_	_
HRG	_	_
can	feasibility	_
be	_	_
used	_	_
for	_	_
transforming	_	_
graphs	_	_
from/to	_	_
another	_	_
form	_	_
of	_	_
natural	_	_
language	_	_
representation	_	_
.	_	_

#72
Productions	_	_
have	_	_
the	_	_
form	_	_
(	_	_
A	_	_
→	_	_
〈S	_	_
,	_	_
R〉	_	_
,	_	_
∼	_	_
)	_	_
,	_	_
where	_	_
A	_	_
∈	_	_
N	_	_
and	_	_
S	_	_
and	_	_
R	_	_
are	_	_
called	_	_
the	_	_
source	_	_
and	_	_
the	_	_
target	_	_
and	_	_
at	_	_
least	_	_
one	_	_
of	_	_
them	_	_
should	deontic	_
be	_	_
hypergraphs	_	_
over	_	_
N	_	_
∪	_	_
T	_	_
.	_	_

#73
∼	_	_
is	_	_
a	_	_
bijection	_	_
linking	_	_
nonterminals	_	_
mentions	_	_
in	_	_
S	_	_
and	_	_
R.	_	_
In	_	_
our	_	_
case	_	_
,	_	_
the	_	_
source	_	_
side	_	_
is	_	_
a	_	_
CFG	_	_
and	_	_
the	_	_
target	_	_
side	_	_
is	_	_
an	_	_
HRG	_	_
.	_	_

#74
Given	_	_
such	_	_
a	_	_
synchronous	_	_
grammar	_	_
and	_	_
a	_	_
string	_	_
as	_	_
input	_	_
,	_	_
we	_	_
can	feasibility	_
parse	_	_
the	_	_
string	_	_
with	_	_
the	_	_
CFG	_	_
side	_	_
and	_	_
then	_	_
derive	_	_
the	_	_
counterpart	_	_
graph	_	_
by	_	_
deduction	_	_
from	_	_
the	_	_
derivation	_	_
.	_	_

#75
The	_	_
benefit	_	_
of	_	_
parsing	_	_
with	_	_
SHRG	_	_
is	_	_
that	_	_
the	_	_
complexity	_	_
is	_	_
bounded	_	_
by	_	_
a	_	_
CFG-like	_	_
parsing	_	_
.	_	_

#89
into	_	_
another	_	_
graph	_	_
,	_	_
it	_	_
will	_	_
introduce	_	_
the	_	_
concept	_	_
edge	_	_
:	_	_
want-01	_	_
to	_	_
the	_	_
first	_	_
fusing	_	_
position	_	_
and	_	_
no	_	_
concept	_	_
edge	_	_
to	_	_
the	_	_
next	_	_
two	_	_
.	_	_

#90
While	_	_
this	_	_
refinement	_	_
might	capability-options	_
result	_	_
in	_	_
an	_	_
exponential	_	_
number	_	_
of	_	_
nonterminals	_	_
with	_	_
respect	_	_
to	_	_
the	_	_
maximum	_	_
type	_	_
of	_	_
hyperedges	_	_
,	_	_
we	_	_
found	_	_
in	_	_
our	_	_
experiment	_	_
that	_	_
most	_	_
of	_	_
the	_	_
nonterminals	_	_
do	_	_
not	_	_
appear	_	_
in	_	_
our	_	_
grammar	_	_
.	_	_

#91
We	_	_
use	_	_
a	_	_
maximum	_	_
edge	_	_
type	_	_
of	_	_
5	_	_
,	_	_
which	_	_
also	_	_
results	_	_
in	_	_
a	_	_
relatively	_	_
small	_	_
nonterminal	_	_
set	_	_
.	_	_

#98
3.1	_	_
Fragment	_	_
Decomposition	_	_
Forest	_	_
We	_	_
first	_	_
proceed	_	_
to	_	_
define	_	_
the	_	_
fragment	_	_
decomposition	_	_
forest	_	_
.	_	_

#99
The	_	_
fragment	_	_
decomposition	_	_
forest	_	_
is	_	_
a	_	_
variation	_	_
of	_	_
the	_	_
phrase	_	_
decomposition	_	_
forest	_	_
1X0-1	_	_
is	_	_
different	_	_
as	_	_
X0	_	_
is	_	_
the	_	_
start	_	_
symbol	_	_
of	_	_
type	_	_
one	_	_
and	_	_
should	deontic	_
always	_	_
have	_	_
a	_	_
concept	_	_
edge	_	_
at	_	_
the	_	_
root	_	_
defined	_	_
by	_	_
Chung	_	_
et	_	_
al	_	_
.	_	_
(	_	_
2014	_	_
)	_	_
where	_	_
the	_	_
target	_	_
side	_	_
is	_	_
a	_	_
graph	_	_
instead	_	_
of	_	_
a	_	_
string	_	_
.	_	_

#100
∅︷︸︸︷	_	_
The	_	_
boy︷︸︸︷	_	_
boy	_	_
want-01︷	_	_
︸︸	_	_
︷	_	_
wants	_	_
∅︷︸︸︷	_	_
the	_	_
girl︷︸︸︷	_	_
girl	_	_
∅︷︸︸︷	_	_
to	_	_
believe-01︷	_	_
︸︸	_	_
︷	_	_
believe	_	_
∅︷︸︸︷	_	_
him	_	_
A	_	_
phrase	_	_
p	_	_
=	_	_
[	_	_
i	_	_
,	_	_
j	_	_
]	_	_
is	_	_
a	_	_
set	_	_
of	_	_
continuous	_	_
word	_	_
indices	_	_
{	_	_
i	_	_
,	_	_
i	_	_
+	_	_
1	_	_
,	_	_
.	_	_

#111
A	_	_
fragment	_	_
forest	_	_
H	_	_
=	_	_
〈V	_	_
,	_	_
E〉	_	_
is	_	_
a	_	_
hypergraph	_	_
made	_	_
of	_	_
a	_	_
set	_	_
of	_	_
hypernodes	_	_
V	_	_
and	_	_
hyperedges	_	_
E.	_	_
Each	_	_
node	_	_
n	_	_
=	_	_
(	_	_
[	_	_
i	_	_
,	_	_
j	_	_
]	_	_
,	_	_
f	_	_
)	_	_
is	_	_
tight	_	_
on	_	_
the	_	_
string	_	_
side	_	_
similar	_	_
to	_	_
the	_	_
definition	_	_
by	_	_
Koehn	_	_
et	_	_
al	_	_
.	_	_
(	_	_
2003	_	_
)	_	_
,	_	_
i.e.	_	_
,	_	_
n	_	_
contains	_	_
no	_	_
unaligned	_	_
words	_	_
at	_	_
its	_	_
boundaries	_	_
.	_	_

#112
Note	_	_
here	_	_
we	_	_
do	_	_
not	_	_
have	_	_
the	_	_
constraint	_	_
that	_	_
f	_	_
should	deontic	_
be	_	_
connected	_	_
or	_	_
single	_	_
rooted	_	_
,	_	_
but	_	_
we	_	_
will	_	_
deal	_	_
with	_	_
these	_	_
constraints	_	_
separately	_	_
in	_	_
the	_	_
sampling	_	_
procedure	_	_
.	_	_

#113
proceWe	_	_
define	_	_
two	_	_
phrases	_	_
[	_	_
i1	_	_
,	_	_
j1	_	_
]	_	_
,	_	_
[	_	_
i2	_	_
,	_	_
j2	_	_
]	_	_
to	_	_
be	_	_
adjacent	_	_
if	_	_
word	_	_
indices	_	_
{	_	_
j1	_	_
,	_	_
j1	_	_
+	_	_
1	_	_
,	_	_
.	_	_

#122
believe-01	_	_
want-01	_	_
want-01	_	_
want-01	_	_
want-01	_	_
want-01	_	_
believe-01	_	_
believe-01	_	_
Figure	_	_
4	_	_
:	_	_
The	_	_
fragment	_	_
decomposition	_	_
forest	_	_
for	_	_
the	_	_
(	_	_
sentence	_	_
,	_	_
AMR	_	_
graph	_	_
)	_	_
pair	_	_
for	_	_
“The	_	_
boy	_	_
wants	_	_
the	_	_
girl	_	_
to	_	_
believe	_	_
him”	_	_
pairs	_	_
(	_	_
each	_	_
one	_	_
kept	_	_
in	_	_
a	_	_
node	_	_
of	_	_
the	_	_
forest	_	_
)	_	_
from	_	_
smaller	_	_
ones	_	_
until	_	_
we	_	_
reach	_	_
the	_	_
root	_	_
of	_	_
the	_	_
forest	_	_
whose	_	_
phrase	_	_
side	_	_
is	_	_
the	_	_
whole	_	_
sentence	_	_
and	_	_
the	_	_
fragment	_	_
side	_	_
is	_	_
the	_	_
complete	_	_
AMR	_	_
graph	_	_
.	_	_

#123
We	_	_
define	_	_
fragment	_	_
decomposition	_	_
forest	_	_
to	_	_
be	_	_
made	_	_
of	_	_
all	_	_
possible	_	_
phrase-fragments	_	_
pairs	_	_
that	_	_
can	capability-feasibility	_
be	_	_
decomposed	_	_
from	_	_
the	_	_
sentence	_	_
AMR	_	_
graph	_	_
pair	_	_
.	_	_

#124
The	_	_
fragment	_	_
decomposition	_	_
forest	_	_
has	_	_
the	_	_
important	_	_
property	_	_
that	_	_
any	_	_
SHRG	_	_
rule	_	_
consistent	_	_
with	_	_
the	_	_
string-to-graph	_	_
alignment	_	_
corresponds	_	_
to	_	_
a	_	_
continuous	_	_
tree	_	_
fragment	_	_
of	_	_
a	_	_
complete	_	_
tree	_	_
found	_	_
in	_	_
the	_	_
forest	_	_
.	_	_

#125
While	_	_
we	_	_
can	feasibility	_
compose	_	_
larger	_	_
phrases	_	_
from	_	_
smaller	_	_
ones	_	_
from	_	_
left	_	_
to	_	_
right	_	_
,	_	_
there	_	_
is	_	_
no	_	_
explicit	_	_
order	_	_
of	_	_
composing	_	_
the	_	_
graph	_	_
fragments	_	_
.	_	_

#126
Also	_	_
,	_	_
the	_	_
number	_	_
of	_	_
possible	_	_
graph	_	_
fragments	_	_
is	_	_
highly	_	_
exponential	_	_
as	_	_
we	_	_
need	_	_
to	_	_
make	_	_
a	_	_
binary	_	_
decision	_	_
to	_	_
decide	_	_
each	_	_
boundary	_	_
node	_	_
of	_	_
the	_	_
fragment	_	_
and	_	_
also	_	_
choose	_	_
the	_	_
edges	_	_
going	_	_
out	_	_
of	_	_
each	_	_
boundary	_	_
node	_	_
of	_	_
the	_	_
fragment	_	_
,	_	_
unlike	_	_
the	_	_
polynomial	_	_
numbers	_	_
of	_	_
phrases	_	_
for	_	_
fixed	_	_
string	_	_
alignment	_	_
.	_	_

#150
We	_	_
assume	_	_
that	_	_
other	_	_
relations	_	_
are	_	_
additional	_	_
introduced	_	_
to	_	_
the	_	_
head	_	_
node	_	_
,	_	_
which	_	_
resembles	_	_
a	_	_
simple	_	_
binarization	_	_
step	_	_
for	_	_
other	_	_
relations	_	_
.	_	_

#151
3We	_	_
use	_	_
this	_	_
strategy	_	_
mainly	_	_
because	_	_
the	_	_
alignments	_	_
available	_	_
do	_	_
not	_	_
have	_	_
overlapping	_	_
alignments	_	_
,	_	_
while	_	_
our	_	_
algorithm	_	_
could	feasibility	_
still	_	_
be	_	_
easily	_	_
adapted	_	_
to	_	_
a	_	_
version	_	_
that	_	_
maintains	_	_
the	_	_
chart	_	_
items	_	_
with	_	_
string	_	_
positions	_	_
when	_	_
overlapping	_	_
alignments	_	_
are	_	_
available	_	_
36	_	_
of	_	_
this	_	_
incoming	_	_
edge	_	_
.	_	_

#152
We	_	_
have	_	_
the	_	_
constraint	_	_
in	_	_
our	_	_
grammar	_	_
that	_	_
the	_	_
r.h.s	_	_
.	_	_

#153
hypergraph	_	_
of	_	_
each	_	_
rule	_	_
should	deontic	_
be	_	_
connected	_	_
and	_	_
single	_	_
rooted.4	_	_
Lines	_	_
13	_	_
to	_	_
14	_	_
enforce	_	_
this	_	_
constraint	_	_
by	_	_
marking	_	_
this	_	_
node	_	_
with	_	_
a	_	_
nosample	_	_
cut	_	_
flag	_	_
,	_	_
which	_	_
we	_	_
will	_	_
use	_	_
in	_	_
the	_	_
MCMC	_	_
sampling	_	_
stage	_	_
.	_	_

#154
The	_	_
insert	_	_
node	_	_
function	_	_
will	_	_
check	_	_
if	_	_
the	_	_
node	_	_
already	_	_
exists	_	_
in	_	_
the	_	_
chart	_	_
item	_	_
.	_	_

#168
We	_	_
have	_	_
sampled	_	_
one	_	_
tree	_	_
from	_	_
the	_	_
forest	_	_
using	_	_
the	_	_
edge	_	_
variables	_	_
.	_	_

#169
We	_	_
also	_	_
have	_	_
a	_	_
0-1	_	_
variable	_	_
at	_	_
each	_	_
node	_	_
in	_	_
this	_	_
tree	_	_
where	_	_
0	_	_
repre4We	_	_
should	inference	_
be	_	_
able	_	_
to	_	_
get	_	_
rid	_	_
of	_	_
both	_	_
constraints	_	_
as	_	_
we	_	_
are	_	_
parsing	_	_
on	_	_
the	_	_
string	_	_
side	_	_
.	_	_

#170
boy	_	_
ARG0	_	_
ARG1	_	_
ARG0	_	_
ARG1girl	_	_
ARG0	_	_
ARG1	_	_
boy	_	_
ARG0	_	_
ARG1	_	_
girl	_	_
ARG0	_	_
ARG1	_	_
want-01	_	_
ARG0	_	_
ARG1	_	_
believe-01	_	_
girl	_	_
boy	_	_
The	_	_
boy	_	_
wants	_	_
the	_	_
girl	_	_
to	_	_
believe	_	_
him	_	_
.	_	_

#174
We	_	_
draw	_	_
a	_	_
distribution	_	_
G	_	_
over	_	_
rules	_	_
from	_	_
a	_	_
DP	_	_
,	_	_
and	_	_
then	_	_
rules	_	_
from	_	_
G.	_	_
G	_	_
|	_	_
α	_	_
,	_	_
P0	_	_
∼Dir	_	_
(	_	_
α	_	_
,	_	_
P0	_	_
)	_	_
r	_	_
|	_	_
G	_	_
∼G	_	_
We	_	_
define	_	_
two	_	_
rules	_	_
to	_	_
have	_	_
the	_	_
same	_	_
rule	_	_
type	_	_
if	_	_
they	_	_
have	_	_
the	_	_
same	_	_
string	_	_
and	_	_
hypergraph	_	_
representation	_	_
(	_	_
including	_	_
order	_	_
of	_	_
external	_	_
nodes	_	_
)	_	_
on	_	_
the	_	_
r.h.s..For	_	_
the	_	_
base	_	_
distribution	_	_
P0	_	_
,	_	_
we	_	_
use	_	_
a	_	_
uniform	_	_
distribution	_	_
where	_	_
all	_	_
rules	_	_
of	_	_
the	_	_
same	_	_
size	_	_
have	_	_
equal	_	_
probability	_	_
.	_	_

#175
By	_	_
marginalizing	_	_
out	_	_
G	_	_
we	_	_
get	_	_
a	_	_
simple	_	_
posterior	_	_
distribution	_	_
over	_	_
rules	_	_
which	_	_
can	feasibility	_
be	_	_
derived	_	_
using	_	_
the	_	_
Chinese	_	_
Restaurant	_	_
Process	_	_
(	_	_
CRP	_	_
)	_	_
.	_	_

#176
We	_	_
define	_	_
a	_	_
table	_	_
of	_	_
counts	_	_
N	_	_
=	_	_
{	_	_
NC	_	_
}	_	_
C∈I	_	_
which	_	_
memorizes	_	_
different	_	_
categories	_	_
of	_	_
counts	_	_
in	_	_
the	_	_
previous	_	_
assignments	_	_
,	_	_
where	_	_
I	_	_
is	_	_
an	_	_
index	_	_
set	_	_
for	_	_
different	_	_
categories	_	_
of	_	_
counts	_	_
.	_	_

#187
After	_	_
we	_	_
have	_	_
sampled	_	_
one	_	_
SHRG	_	_
derivation	_	_
from	_	_
the	_	_
forest	_	_
,	_	_
we	_	_
still	_	_
need	_	_
to	_	_
keep	_	_
track	_	_
of	_	_
the	_	_
place	_	_
where	_	_
each	_	_
nonterminal	_	_
edge	_	_
attaches	_	_
.	_	_

#188
As	_	_
we	_	_
have	_	_
maintained	_	_
the	_	_
graph	_	_
fragment	_	_
it	_	_
represents	_	_
in	_	_
each	_	_
node	_	_
of	_	_
the	_	_
forest	_	_
,	_	_
we	_	_
can	feasibility	_
retrieve	_	_
the	_	_
attachment	_	_
nodes	_	_
of	_	_
each	_	_
hyperedge	_	_
in	_	_
the	_	_
r.h.s	_	_
.	_	_

#189
by	_	_
tracing	_	_
at	_	_
which	_	_
graph	_	_
nodes	_	_
two	_	_
fragments	_	_
fuse	_	_
with	_	_
each	_	_
other	_	_
.	_	_

#195
3.3	_	_
Phrase-to-Graph-Fragment	_	_
Alignment	_	_
Extraction	_	_
Aside	_	_
from	_	_
the	_	_
rules	_	_
sampled	_	_
using	_	_
the	_	_
MCMC	_	_
algorithm	_	_
,	_	_
we	_	_
also	_	_
extract	_	_
a	_	_
phrasetographfragment	_	_
alignment	_	_
table	_	_
from	_	_
the	_	_
fragment	_	_
decomposition	_	_
forest	_	_
.	_	_

#196
This	_	_
step	_	_
can	feasibility	_
be	_	_
considered	_	_
as	_	_
a	_	_
mapping	_	_
of	_	_
larger	_	_
phrases	_	_
made	_	_
of	_	_
multiple	_	_
identified	_	_
spans	_	_
(	_	_
plus	_	_
unaligned	_	_
words	_	_
)	_	_
to	_	_
a	_	_
larger	_	_
fragments	_	_
made	_	_
of	_	_
multiple	_	_
concept	_	_
fragments	_	_
(	_	_
plus	_	_
the	_	_
way	_	_
they	_	_
connect	_	_
using	_	_
unaligned	_	_
edges	_	_
)	_	_
.	_	_

#197
Our	_	_
extraction	_	_
happens	_	_
along	_	_
with	_	_
the	_	_
forest	_	_
construction	_	_
procedure	_	_
.	_	_

#203
Our	_	_
strategy	_	_
is	_	_
to	_	_
use	_	_
lemma	_	_
and	_	_
POS	_	_
tags	_	_
information	_	_
after	_	_
the	_	_
concept	_	_
identification	_	_
stage	_	_
,	_	_
we	_	_
use	_	_
it	_	_
to	_	_
recall	_	_
some	_	_
meaningful	_	_
concepts	_	_
.	_	_

#204
We	_	_
find	_	_
that	_	_
,	_	_
except	_	_
for	_	_
some	_	_
special	_	_
function	_	_
words	_	_
,	_	_
most	_	_
nouns	_	_
,	_	_
verbs	_	_
and	_	_
,	_	_
adjectives	_	_
should	inference	_
be	_	_
aligned	_	_
.	_	_

#205
We	_	_
use	_	_
the	_	_
lemma	_	_
information	_	_
to	_	_
retrieve	_	_
unaligned	_	_
words	_	_
whose	_	_
morphological	_	_
form	_	_
does	_	_
not	_	_
appear	_	_
in	_	_
our	_	_
training	_	_
data	_	_
.	_	_

#207
Motivated	_	_
by	_	_
the	_	_
fact	_	_
that	_	_
AMR	_	_
makes	_	_
extensive	_	_
use	_	_
of	_	_
PropBank	_	_
framesets	_	_
,	_	_
we	_	_
look	_	_
up	_	_
the	_	_
argument	_	_
structure	_	_
of	_	_
the	_	_
verbs	_	_
from	_	_
the	_	_
PropBank	_	_
.	_	_

#208
Although	_	_
the	_	_
complicated	_	_
abstraction	_	_
of	_	_
AMR	_	_
makes	_	_
it	_	_
hard	_	_
to	_	_
get	_	_
the	_	_
correct	_	_
concept	_	_
for	_	_
each	_	_
word	_	_
,	_	_
the	_	_
more	_	_
complete	_	_
structure	_	_
can	capability	_
reduce	_	_
the	_	_
propagation	_	_
of	_	_
errors	_	_
along	_	_
the	_	_
derivation	_	_
tree	_	_
.	_	_

#209
4.2	_	_
AMR	_	_
graph	_	_
parsing	_	_
We	_	_
use	_	_
Earley	_	_
algorithm	_	_
with	_	_
cube-pruning	_	_
(	_	_
Chiang	_	_
,	_	_
2007	_	_
)	_	_
for	_	_
the	_	_
string-to-AMR	_	_
parsing	_	_
.	_	_

#235
Using	_	_
this	_	_
constraint	_	_
would	_	_
take	_	_
a	_	_
few	_	_
hours	_	_
or	_	_
longer	_	_
for	_	_
some	_	_
sentences	_	_
.	_	_

#236
The	_	_
reason	_	_
for	_	_
this	_	_
is	_	_
because	_	_
the	_	_
many	_	_
number	_	_
of	_	_
unaligned	_	_
edges	_	_
can	capability	_
connect	_	_
to	_	_
each	_	_
branch	_	_
of	_	_
the	_	_
aligned	_	_
or	_	_
unaligned	_	_
fragments	_	_
below	_	_
it	_	_
.	_	_

#237
And	_	_
there	_	_
is	_	_
no	_	_
explicit	_	_
order	_	_
of	_	_
composition	_	_
with	_	_
each	_	_
branch	_	_
.	_	_

#245
+MCMC	_	_
shows	_	_
the	_	_
result	_	_
using	_	_
additional	_	_
alignments	_	_
identified	_	_
using	_	_
our	_	_
sampling	_	_
approach	_	_
.	_	_

#246
We	_	_
can	rhetorical	_
see	_	_
that	_	_
using	_	_
the	_	_
phrase	_	_
to	_	_
graph	_	_
fragment	_	_
alignment	_	_
learned	_	_
from	_	_
our	_	_
training	_	_
data	_	_
can	capability-options	_
significantly	_	_
improve	_	_
the	_	_
smatch	_	_
.	_	_

#247
We	_	_
have	_	_
also	_	_
tried	_	_
extracting	_	_
all	_	_
phrase-to-fragment	_	_
39	_	_
Precision	_	_
Recall	_	_
F-score	_	_
JAMR	_	_
0.67	_	_
0.58	_	_
0.62	_	_
Wang	_	_
et	_	_
al	_	_
.	_	_
0.64	_	_
0.62	_	_
0.63	_	_
Our	_	_
approach	_	_
0.59	_	_
0.57	_	_
0.58	_	_
Table	_	_
2	_	_
:	_	_
Comparisons	_	_
of	_	_
smatch	_	_
score	_	_
results	_	_
alignments	_	_
of	_	_
length	_	_
6	_	_
on	_	_
the	_	_
string	_	_
side	_	_
from	_	_
our	_	_
constructed	_	_
forest	_	_
.	_	_

#248
We	_	_
can	rhetorical	_
see	_	_
that	_	_
using	_	_
this	_	_
alignment	_	_
table	_	_
further	_	_
improves	_	_
the	_	_
smatch	_	_
score	_	_
.	_	_

#249
This	_	_
is	_	_
because	_	_
the	_	_
larger	_	_
phrase-fragment	_	_
pairs	_	_
can	capability	_
make	_	_
better	_	_
use	_	_
of	_	_
the	_	_
dependency	_	_
information	_	_
between	_	_
continuous	_	_
concepts	_	_
.	_	_

#250
The	_	_
improvement	_	_
is	_	_
not	_	_
much	_	_
in	_	_
comparison	_	_
with	_	_
MCMC	_	_
,	_	_
this	_	_
is	_	_
perhaps	_	_
MCMC	_	_
can	capability	_
also	_	_
learn	_	_
some	_	_
meaning	_	_
blocks	_	_
that	_	_
frequently	_	_
appear	_	_
together	_	_
.	_	_

#251
As	_	_
the	_	_
dataset	_	_
is	_	_
relatively	_	_
small	_	_
,	_	_
so	_	_
there	_	_
are	_	_
a	_	_
lot	_	_
of	_	_
meaningful	_	_
concepts	_	_
that	_	_
are	_	_
not	_	_
aligned	_	_
.	_	_

#253
We	_	_
have	_	_
also	_	_
used	_	_
the	_	_
POS	_	_
tag	_	_
information	_	_
to	_	_
retrieve	_	_
some	_	_
unaligned	_	_
nouns	_	_
and	_	_
a	_	_
PropBank	_	_
dictionary	_	_
to	_	_
retrieve	_	_
the	_	_
argument	_	_
structure	_	_
of	_	_
the	_	_
first	_	_
sense	_	_
of	_	_
the	_	_
verbs	_	_
.	_	_

#254
+All	_	_
shows	_	_
the	_	_
result	_	_
after	_	_
using	_	_
lemma	_	_
,	_	_
POS	_	_
tag	_	_
and	_	_
PropBank	_	_
information	_	_
,	_	_
we	_	_
can	rhetorical	_
see	_	_
that	_	_
fixing	_	_
the	_	_
alignment	_	_
can	capability-options	_
improve	_	_
the	_	_
recall	_	_
,	_	_
but	_	_
the	_	_
precision	_	_
does	_	_
not	_	_
change	_	_
much	_	_
.	_	_

#255
Table	_	_
2	_	_
shows	_	_
our	_	_
result	_	_
on	_	_
test	_	_
data	_	_
.	_	_

#257
Wang	_	_
et	_	_
al	_	_
.	_	_
(	_	_
2015	_	_
)	_	_
shows	_	_
the	_	_
current	_	_
stateofart	_	_
for	_	_
string-to-AMR	_	_
parsing	_	_
.	_	_

#258
Without	_	_
the	_	_
dependency	_	_
parse	_	_
information	_	_
and	_	_
complex	_	_
global	_	_
features	_	_
,	_	_
our	_	_
SHRG-based	_	_
approach	_	_
can	capability-options	_
already	_	_
achieve	_	_
competitive	_	_
results	_	_
in	_	_
comparison	_	_
with	_	_
these	_	_
two	_	_
algorithms	_	_
.	_	_

#259
6	_	_
Discussion	_	_
In	_	_
comparison	_	_
to	_	_
the	_	_
spanning	_	_
tree	_	_
algorithm	_	_
of	_	_
Flanigan	_	_
et	_	_
al	_	_
.	_	_
(	_	_
2014	_	_
)	_	_
,	_	_
an	_	_
SHRG-based	_	_
approach	_	_
is	_	_
more	_	_
sensitive	_	_
to	_	_
the	_	_
alignment	_	_
.	_	_

#263
Another	_	_
thing	_	_
to	_	_
note	_	_
is	_	_
that	_	_
Flanigan	_	_
et	_	_
al	_	_
.	_	_
(	_	_
2014	_	_
)	_	_
have	_	_
used	_	_
path	_	_
information	_	_
of	_	_
dependency	_	_
arc	_	_
labels	_	_
and	_	_
part	_	_
of	_	_
speech	_	_
tags	_	_
.	_	_

#264
Using	_	_
these	_	_
global	_	_
information	_	_
can	capability-options	_
help	_	_
the	_	_
predication	_	_
of	_	_
the	_	_
relation	_	_
edge	_	_
labels	_	_
.	_	_

#265
One	_	_
interesting	_	_
way	_	_
to	_	_
include	_	_
such	_	_
kind	_	_
of	_	_
path	_	_
information	_	_
is	_	_
to	_	_
add	_	_
a	_	_
graph	_	_
language	_	_
model	_	_
into	_	_
our	_	_
CFG	_	_
decoder	_	_
,	_	_
which	_	_
should	inference	_
also	_	_
help	_	_
improve	_	_
the	_	_
performance	_	_
.	_	_

#266
All	_	_
the	_	_
weights	_	_
of	_	_
the	_	_
local	_	_
features	_	_
mentioned	_	_
in	_	_
Section	_	_
4.2	_	_
are	_	_
tuned	_	_
by	_	_
hand	_	_
.	_	_

#267
We	_	_
have	_	_
tried	_	_
tuning	_	_
with	_	_
MERT	_	_
(	_	_
Och	_	_
,	_	_
2003	_	_
)	_	_
,	_	_
but	_	_
the	_	_
computation	_	_
of	_	_
smatch	_	_
score	_	_
for	_	_
the	_	_
k-best	_	_
list	_	_
has	_	_
become	_	_
a	_	_
major	_	_
overhead	_	_
.	_	_

#268
This	_	_
issue	_	_
might	speculation	_
come	_	_
from	_	_
the	_	_
NP-Completeness	_	_
of	_	_
the	_	_
problem	_	_
smatch	_	_
tries	_	_
to	_	_
evaluate	_	_
,	_	_
unlike	_	_
the	_	_
simple	_	_
counting	_	_
of	_	_
N-grams	_	_
in	_	_
BLEU	_	_
(	_	_
Papineni	_	_
et	_	_
al.	_	_
,	_	_
2001	_	_
)	_	_
.	_	_

#269
Parallelization	_	_
might	options	_
be	_	_
a	_	_
consideration	_	_
for	_	_
tuning	_	_
smatch	_	_
score	_	_
with	_	_
MERT	_	_
.	_	_

#270
7	_	_
Conclusion	_	_
We	_	_
presented	_	_
an	_	_
MCMC	_	_
sampling	_	_
schedule	_	_
for	_	_
learning	_	_
SHRG	_	_
rules	_	_
from	_	_
a	_	_
fragment	_	_
decomposition	_	_
forest	_	_
constructed	_	_
from	_	_
a	_	_
fixed	_	_
stringtoAMRgraph	_	_
alignment	_	_
.	_	_

#272
We	_	_
have	_	_
also	_	_
evaluated	_	_
our	_	_
sampled	_	_
SHRG	_	_
on	_	_
a	_	_
string-to-AMR	_	_
graph	_	_
parsing	_	_
task	_	_
and	_	_
achieved	_	_
some	_	_
reasonable	_	_
result	_	_
without	_	_
using	_	_
a	_	_
dependency	_	_
parse	_	_
.	_	_

#273
Interesting	_	_
future	_	_
work	_	_
might	rhetorical-speculation	_
include	_	_
adding	_	_
language	_	_
model	_	_
on	_	_
graph	_	_
structure	_	_
and	_	_
also	_	_
learning	_	_
SHRG	_	_
from	_	_
overlapping	_	_
alignments	_	_
.	_	_

#274
Acknowledgments	_	_
Funded	_	_
by	_	_
NSF	_	_
IIS1446996	_	_
,	_	_
NSF	_	_
IIS-1218209	_	_
,	_	_
the	_	_
2014	_	_
Jelinek	_	_
Memorial	_	_
Workshop	_	_
,	_	_
and	_	_
a	_	_
Google	_	_
Faculty	_	_
Research	_	_
Award	_	_
.	_	_