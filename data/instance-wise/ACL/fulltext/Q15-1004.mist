#0
SPRITE	_	_
:	_	_
Generalizing	_	_
Topic	_	_
Models	_	_
with	_	_
Structured	_	_
Priors	_	_
Michael	_	_
J.	_	_
Paul	_	_
and	_	_
Mark	_	_
Dredze	_	_
Department	_	_
of	_	_
Computer	_	_
Science	_	_
Human	_	_
Language	_	_
Technology	_	_
Center	_	_
of	_	_
Excellence	_	_
Johns	_	_
Hopkins	_	_
University	_	_
,	_	_
Baltimore	_	_
,	_	_
MD	_	_
21218	_	_
mpaul	_	_
@	_	_
cs.jhu.edu	_	_
,	_	_
mdredze	_	_
@	_	_
cs.jhu.edu	_	_
Abstract	_	_
We	_	_
introduce	_	_
SPRITE	_	_
,	_	_
a	_	_
family	_	_
of	_	_
topic	_	_
models	_	_
that	_	_
incorporates	_	_
structure	_	_
into	_	_
model	_	_
priors	_	_
as	_	_
a	_	_
function	_	_
of	_	_
underlying	_	_
components	_	_
.	_	_

#1
The	_	_
structured	_	_
priors	_	_
can	capability-feasibility	_
be	_	_
constrained	_	_
to	_	_
model	_	_
topic	_	_
hierarchies	_	_
,	_	_
factorizations	_	_
,	_	_
correlations	_	_
,	_	_
and	_	_
supervision	_	_
,	_	_
allowing	_	_
SPRITE	_	_
to	_	_
be	_	_
tailored	_	_
to	_	_
particular	_	_
settings	_	_
.	_	_

#2
We	_	_
demonstrate	_	_
this	_	_
flexibility	_	_
by	_	_
constructing	_	_
a	_	_
SPRITE-based	_	_
model	_	_
to	_	_
jointly	_	_
infer	_	_
topic	_	_
hierarchies	_	_
and	_	_
author	_	_
perspective	_	_
,	_	_
which	_	_
we	_	_
apply	_	_
to	_	_
corpora	_	_
of	_	_
political	_	_
debates	_	_
and	_	_
online	_	_
reviews	_	_
.	_	_

#3
We	_	_
show	_	_
that	_	_
the	_	_
model	_	_
learns	_	_
intuitive	_	_
topics	_	_
,	_	_
outperforming	_	_
several	_	_
other	_	_
topic	_	_
models	_	_
at	_	_
predictive	_	_
tasks	_	_
.	_	_

#4
1	_	_
Introduction	_	_
Topic	_	_
models	_	_
can	capability-options	_
be	_	_
a	_	_
powerful	_	_
aid	_	_
for	_	_
analyzing	_	_
large	_	_
collections	_	_
of	_	_
text	_	_
by	_	_
uncovering	_	_
latent	_	_
interpretable	_	_
structures	_	_
without	_	_
manual	_	_
supervision	_	_
.	_	_

#5
Yet	_	_
people	_	_
often	_	_
have	_	_
expectations	_	_
about	_	_
topics	_	_
in	_	_
a	_	_
given	_	_
corpus	_	_
and	_	_
how	_	_
they	_	_
should	deontic	_
be	_	_
structured	_	_
for	_	_
a	_	_
particular	_	_
task	_	_
.	_	_

#6
It	_	_
is	_	_
crucial	_	_
for	_	_
the	_	_
user	_	_
experience	_	_
that	_	_
topics	_	_
meet	_	_
these	_	_
expectations	_	_
(	_	_
Mimno	_	_
et	_	_
al.	_	_
,	_	_
2011	_	_
;	_	_
Talley	_	_
et	_	_
al.	_	_
,	_	_
2011	_	_
)	_	_
yet	_	_
black	_	_
box	_	_
topic	_	_
models	_	_
provide	_	_
no	_	_
control	_	_
over	_	_
the	_	_
desired	_	_
output	_	_
.	_	_

#7
This	_	_
paper	_	_
presents	_	_
SPRITE	_	_
,	_	_
a	_	_
family	_	_
of	_	_
topic	_	_
models	_	_
that	_	_
provide	_	_
a	_	_
flexible	_	_
framework	_	_
for	_	_
encoding	_	_
preferences	_	_
as	_	_
priors	_	_
for	_	_
how	_	_
topics	_	_
should	deontic	_
be	_	_
structured	_	_
.	_	_

#8
SPRITE	_	_
can	capability	_
incorporate	_	_
many	_	_
types	_	_
of	_	_
structure	_	_
that	_	_
have	_	_
been	_	_
considered	_	_
in	_	_
prior	_	_
work	_	_
,	_	_
including	_	_
hierarchies	_	_
(	_	_
Blei	_	_
et	_	_
al.	_	_
,	_	_
2003a	_	_
;	_	_
Mimno	_	_
et	_	_
al.	_	_
,	_	_
2007	_	_
)	_	_
,	_	_
factorizations	_	_
(	_	_
Paul	_	_
and	_	_
Dredze	_	_
,	_	_
2012	_	_
;	_	_
Eisenstein	_	_
et	_	_
al.	_	_
,	_	_
2011	_	_
)	_	_
,	_	_
sparsity	_	_
(	_	_
Wang	_	_
and	_	_
Blei	_	_
,	_	_
2009	_	_
;	_	_
Balasubramanyan	_	_
and	_	_
Cohen	_	_
,	_	_
2013	_	_
)	_	_
,	_	_
correlations	_	_
between	_	_
topics	_	_
(	_	_
Blei	_	_
and	_	_
Lafferty	_	_
,	_	_
2007	_	_
;	_	_
Li	_	_
and	_	_
McCallum	_	_
,	_	_
2006	_	_
)	_	_
,	_	_
preferences	_	_
over	_	_
word	_	_
choices	_	_
(	_	_
Andrzejewski	_	_
et	_	_
al.	_	_
,	_	_
2009	_	_
;	_	_
Paul	_	_
and	_	_
Dredze	_	_
,	_	_
2013	_	_
)	_	_
,	_	_
and	_	_
associations	_	_
between	_	_
topics	_	_
and	_	_
document	_	_
attributes	_	_
(	_	_
Ramage	_	_
et	_	_
al.	_	_
,	_	_
2009	_	_
;	_	_
Mimno	_	_
and	_	_
McCallum	_	_
,	_	_
2008	_	_
)	_	_
.	_	_

#9
SPRITE	_	_
builds	_	_
on	_	_
a	_	_
standard	_	_
topic	_	_
model	_	_
,	_	_
adding	_	_
structure	_	_
to	_	_
the	_	_
priors	_	_
over	_	_
the	_	_
model	_	_
parameters	_	_
.	_	_

#10
The	_	_
priors	_	_
are	_	_
given	_	_
by	_	_
log-linear	_	_
functions	_	_
of	_	_
underlying	_	_
components	_	_
(	_	_
§2	_	_
)	_	_
,	_	_
which	_	_
provide	_	_
additional	_	_
latent	_	_
structure	_	_
that	_	_
we	_	_
will	_	_
show	_	_
can	capability	_
enrich	_	_
the	_	_
model	_	_
in	_	_
many	_	_
ways	_	_
.	_	_

#11
By	_	_
applying	_	_
particular	_	_
constraints	_	_
and	_	_
priors	_	_
to	_	_
the	_	_
component	_	_
hyperparameters	_	_
,	_	_
a	_	_
variety	_	_
of	_	_
structures	_	_
can	capability-feasibility	_
be	_	_
induced	_	_
such	_	_
as	_	_
hierarchies	_	_
and	_	_
factorizations	_	_
(	_	_
§3	_	_
)	_	_
,	_	_
and	_	_
we	_	_
will	_	_
show	_	_
that	_	_
this	_	_
framework	_	_
captures	_	_
many	_	_
existing	_	_
topic	_	_
models	_	_
(	_	_
§4	_	_
)	_	_
.	_	_

#12
After	_	_
describing	_	_
the	_	_
general	_	_
form	_	_
of	_	_
the	_	_
model	_	_
,	_	_
we	_	_
show	_	_
how	_	_
SPRITE	_	_
can	feasibility	_
be	_	_
tailored	_	_
to	_	_
particular	_	_
settings	_	_
by	_	_
describing	_	_
a	_	_
specific	_	_
model	_	_
for	_	_
the	_	_
applied	_	_
task	_	_
of	_	_
jointly	_	_
inferring	_	_
topic	_	_
hierarchies	_	_
and	_	_
perspective	_	_
(	_	_
§6	_	_
)	_	_
.	_	_

#13
We	_	_
experiment	_	_
with	_	_
this	_	_
topic+perspective	_	_
model	_	_
on	_	_
sets	_	_
of	_	_
political	_	_
debates	_	_
and	_	_
online	_	_
reviews	_	_
(	_	_
§7	_	_
)	_	_
,	_	_
and	_	_
demonstrate	_	_
that	_	_
SPRITE	_	_
learns	_	_
desired	_	_
structures	_	_
while	_	_
outperforming	_	_
many	_	_
baselines	_	_
at	_	_
predictive	_	_
tasks	_	_
.	_	_

#21
Components	_	_
are	_	_
real-valued	_	_
vectors	_	_
of	_	_
length	_	_
equal	_	_
to	_	_
the	_	_
vocabulary	_	_
size	_	_
V	_	_
(	_	_
for	_	_
priors	_	_
over	_	_
word	_	_
distributions	_	_
)	_	_
or	_	_
length	_	_
equal	_	_
to	_	_
the	_	_
number	_	_
of	_	_
topics	_	_
K	_	_
(	_	_
for	_	_
priors	_	_
over	_	_
topic	_	_
distributions	_	_
)	_	_
.	_	_

#22
For	_	_
example	_	_
,	_	_
we	_	_
might	feasibility-options	_
assume	_	_
that	_	_
topics	_	_
about	_	_
sports	_	_
like	_	_
baseball	_	_
and	_	_
football	_	_
share	_	_
a	_	_
common	_	_
prior	_	_
–	_	_
given	_	_
by	_	_
a	_	_
component	_	_
–	_	_
with	_	_
general	_	_
words	_	_
about	_	_
sports	_	_
.	_	_

#23
A	_	_
fine-grained	_	_
topic	_	_
about	_	_
steroid	_	_
use	_	_
in	_	_
sports	_	_
might	feasibility-options	_
be	_	_
created	_	_
by	_	_
combining	_	_
components	_	_
about	_	_
broader	_	_
topics	_	_
like	_	_
sports	_	_
,	_	_
medicine	_	_
,	_	_
and	_	_
crime	_	_
.	_	_

#24
By	_	_
modeling	_	_
the	_	_
priors	_	_
as	_	_
combinations	_	_
of	_	_
components	_	_
that	_	_
are	_	_
shared	_	_
across	_	_
all	_	_
topics	_	_
,	_	_
we	_	_
can	feasibility-rhetorical	_
learn	_	_
interesting	_	_
connections	_	_
between	_	_
topics	_	_
,	_	_
where	_	_
components	_	_
provide	_	_
an	_	_
additional	_	_
latent	_	_
layer	_	_
for	_	_
corpus	_	_
understanding	_	_
.	_	_

#25
As	_	_
we’ll	_	_
show	_	_
in	_	_
the	_	_
next	_	_
section	_	_
,	_	_
by	_	_
imposing	_	_
certain	_	_
requirements	_	_
on	_	_
which	_	_
components	_	_
feed	_	_
into	_	_
which	_	_
topics	_	_
(	_	_
or	_	_
documents	_	_
)	_	_
,	_	_
we	_	_
can	feasibility	_
induce	_	_
a	_	_
variety	_	_
of	_	_
model	_	_
structures	_	_
.	_	_

#26
For	_	_
example	_	_
,	_	_
if	_	_
we	_	_
want	_	_
to	_	_
model	_	_
a	_	_
topic	_	_
hierarchy	_	_
,	_	_
we	_	_
require	_	_
that	_	_
each	_	_
topic	_	_
depend	_	_
on	_	_
exactly	_	_
one	_	_
parent	_	_
component	_	_
.	_	_

#35
We	_	_
call	_	_
this	_	_
family	_	_
of	_	_
models	_	_
SPRITE	_	_
:	_	_
Structured	_	_
PRIor	_	_
Topic	_	_
modEls	_	_
.	_	_

#36
To	_	_
illustrate	_	_
the	_	_
role	_	_
that	_	_
components	_	_
can	capability-options	_
play	_	_
,	_	_
consider	_	_
an	_	_
example	_	_
in	_	_
which	_	_
we	_	_
are	_	_
modeling	_	_
research	_	_
topics	_	_
in	_	_
a	_	_
corpus	_	_
of	_	_
NLP	_	_
abstracts	_	_
(	_	_
as	_	_
we	_	_
do	_	_
in	_	_
§7.3	_	_
)	_	_
.	_	_

#37
Consider	_	_
three	_	_
speech-related	_	_
topics	_	_
:	_	_
signal	_	_
processing	_	_
,	_	_
automatic	_	_
speech	_	_
recognition	_	_
,	_	_
and	_	_
dialog	_	_
systems	_	_
.	_	_

#38
Conceptualized	_	_
as	_	_
a	_	_
hierarchy	_	_
,	_	_
these	_	_
topics	_	_
might	options	_
belong	_	_
to	_	_
a	_	_
higher	_	_
level	_	_
category	_	_
of	_	_
spoken	_	_
language	_	_
processing	_	_
.	_	_

#39
SPRITE	_	_
allows	_	_
the	_	_
relationship	_	_
between	_	_
these	_	_
three	_	_
topics	_	_
to	_	_
be	_	_
defined	_	_
in	_	_
two	_	_
ways	_	_
.	_	_

#40
One	_	_
,	_	_
we	_	_
can	feasibility	_
model	_	_
that	_	_
these	_	_
topics	_	_
will	_	_
all	_	_
have	_	_
words	_	_
in	_	_
common	_	_
.	_	_

#41
This	_	_
is	_	_
handled	_	_
by	_	_
the	_	_
topic	_	_
components	_	_
–	_	_
these	_	_
three	_	_
topics	_	_
could	options	_
all	_	_
draw	_	_
from	_	_
a	_	_
common	_	_
“spoken	_	_
lan•	_	_
Generate	_	_
hyperparameters	_	_
:	_	_
α	_	_
,	_	_
β	_	_
,	_	_
δ	_	_
,	_	_
ω	_	_
(	_	_
§3	_	_
)	_	_
•	_	_
For	_	_
each	_	_
document	_	_
m	_	_
,	_	_
generate	_	_
parameters	_	_
:	_	_
1.	_	_
θ̃mk	_	_
=	_	_
exp	_	_
(	_	_
∑C	_	_
(	_	_
θ	_	_
)	_	_
c=1	_	_
αmc	_	_
δck	_	_
)	_	_
,	_	_
1≤k≤K	_	_
2.	_	_
θm	_	_
∼	_	_
Dirichlet	_	_
(	_	_
θ̃m	_	_
)	_	_
•	_	_
For	_	_
each	_	_
topic	_	_
k	_	_
,	_	_
generate	_	_
parameters	_	_
:	_	_
1.	_	_
φ̃kv	_	_
=	_	_
exp	_	_
(	_	_
∑C	_	_
(	_	_
φ	_	_
)	_	_
c=1	_	_
βkc	_	_
ωcv	_	_
)	_	_
,	_	_
1≤v≤V	_	_
2.	_	_
φk	_	_
∼	_	_
Dirichlet	_	_
(	_	_
φ̃k	_	_
)	_	_
•	_	_
For	_	_
each	_	_
token	_	_
(	_	_
m	_	_
,	_	_
n	_	_
)	_	_
,	_	_
generate	_	_
data	_	_
:	_	_
1	_	_
.	_	_

#42
Topic	_	_
(	_	_
unobserved	_	_
)	_	_
:	_	_
zm	_	_
,	_	_
n	_	_
∼	_	_
θm	_	_
2	_	_
.	_	_

#45
guage”	_	_
topic	_	_
component	_	_
,	_	_
with	_	_
high-weight	_	_
words	_	_
such	_	_
as	_	_
speech	_	_
and	_	_
spoken	_	_
,	_	_
which	_	_
informs	_	_
the	_	_
prior	_	_
of	_	_
all	_	_
three	_	_
topics	_	_
.	_	_

#46
Second	_	_
,	_	_
we	_	_
can	feasibility	_
model	_	_
that	_	_
these	_	_
topics	_	_
are	_	_
likely	_	_
to	_	_
occur	_	_
together	_	_
in	_	_
documents	_	_
.	_	_

#47
For	_	_
example	_	_
,	_	_
articles	_	_
about	_	_
dialog	_	_
systems	_	_
are	_	_
likely	_	_
to	_	_
discuss	_	_
automatic	_	_
speech	_	_
recognition	_	_
as	_	_
a	_	_
subroutine	_	_
.	_	_

#48
This	_	_
is	_	_
handled	_	_
by	_	_
the	_	_
document	_	_
components	_	_
–	_	_
there	_	_
could	options	_
be	_	_
a	_	_
“spoken	_	_
language”	_	_
document	_	_
component	_	_
that	_	_
gives	_	_
high	_	_
weight	_	_
to	_	_
all	_	_
three	_	_
topics	_	_
,	_	_
so	_	_
that	_	_
if	_	_
a	_	_
document	_	_
draw	_	_
its	_	_
prior	_	_
from	_	_
this	_	_
component	_	_
,	_	_
then	_	_
it	_	_
is	_	_
more	_	_
likely	_	_
to	_	_
give	_	_
probability	_	_
to	_	_
these	_	_
topics	_	_
together	_	_
.	_	_

#49
The	_	_
next	_	_
section	_	_
will	_	_
describe	_	_
how	_	_
particular	_	_
priors	_	_
over	_	_
the	_	_
coefficients	_	_
can	capability	_
induce	_	_
various	_	_
structures	_	_
such	_	_
as	_	_
hierarchies	_	_
and	_	_
factorizations	_	_
,	_	_
and	_	_
components	_	_
and	_	_
coefficients	_	_
can	capability-feasibility	_
also	_	_
be	_	_
provided	_	_
as	_	_
input	_	_
to	_	_
incorporate	_	_
supervision	_	_
and	_	_
prior	_	_
knowledge	_	_
.	_	_

#50
The	_	_
general	_	_
prior	_	_
structure	_	_
used	_	_
in	_	_
SPRITE	_	_
can	capability-feasibility	_
be	_	_
used	_	_
to	_	_
represent	_	_
a	_	_
wide	_	_
array	_	_
of	_	_
existing	_	_
topic	_	_
models	_	_
,	_	_
outlined	_	_
in	_	_
Section	_	_
4	_	_
.	_	_

#51
3	_	_
Topic	_	_
Structures	_	_
By	_	_
changing	_	_
the	_	_
particular	_	_
configuration	_	_
of	_	_
the	_	_
hyperparameters	_	_
–	_	_
the	_	_
component	_	_
coefficients	_	_
(	_	_
α	_	_
and	_	_
β	_	_
)	_	_
and	_	_
the	_	_
component	_	_
weights	_	_
(	_	_
δ	_	_
and	_	_
ω	_	_
)	_	_
–	_	_
we	_	_
obtain	_	_
a	_	_
diverse	_	_
range	_	_
of	_	_
model	_	_
structures	_	_
and	_	_
behaviors	_	_
.	_	_

#52
We	_	_
now	_	_
describe	_	_
possible	_	_
structures	_	_
and	_	_
the	_	_
corresponding	_	_
priors	_	_
.	_	_

#53
3.1	_	_
Component	_	_
Structures	_	_
This	_	_
subsection	_	_
discusses	_	_
various	_	_
graph	_	_
structures	_	_
that	_	_
can	capability	_
describe	_	_
the	_	_
relation	_	_
between	_	_
topic	_	_
components	_	_
and	_	_
topics	_	_
,	_	_
and	_	_
between	_	_
document	_	_
components	_	_
and	_	_
documents	_	_
,	_	_
illustrated	_	_
in	_	_
Figure	_	_
2	_	_
.	_	_

#54
(	_	_
a	_	_
)	_	_
Dense	_	_
DAG	_	_
(	_	_
b	_	_
)	_	_
Sparse	_	_
DAG	_	_
(	_	_
c	_	_
)	_	_
Tree	_	_
(	_	_
d	_	_
)	_	_
Factored	_	_
Forest	_	_
Figure	_	_
2	_	_
:	_	_
Example	_	_
graph	_	_
structures	_	_
describing	_	_
possible	_	_
relations	_	_
between	_	_
components	_	_
(	_	_
middle	_	_
row	_	_
)	_	_
and	_	_
topics	_	_
or	_	_
documents	_	_
(	_	_
bottom	_	_
row	_	_
)	_	_
.	_	_

#56
The	_	_
root	_	_
node	_	_
is	_	_
a	_	_
shared	_	_
prior	_	_
over	_	_
the	_	_
component	_	_
weights	_	_
(	_	_
with	_	_
other	_	_
possibilities	_	_
discussed	_	_
in	_	_
§3.3	_	_
)	_	_
.	_	_

#57
3.1.1	_	_
Directed	_	_
Acyclic	_	_
Graph	_	_
The	_	_
general	_	_
SPRITE	_	_
model	_	_
can	capability-feasibility	_
be	_	_
thought	_	_
of	_	_
as	_	_
a	_	_
dense	_	_
directed	_	_
acyclic	_	_
graph	_	_
(	_	_
DAG	_	_
)	_	_
,	_	_
where	_	_
every	_	_
document	_	_
or	_	_
topic	_	_
is	_	_
connected	_	_
to	_	_
every	_	_
component	_	_
with	_	_
some	_	_
weight	_	_
α	_	_
or	_	_
β.	_	_
When	_	_
many	_	_
of	_	_
the	_	_
α	_	_
or	_	_
β	_	_
coefficients	_	_
are	_	_
zero	_	_
,	_	_
the	_	_
DAG	_	_
becomes	_	_
sparse	_	_
.	_	_

#58
A	_	_
sparse	_	_
DAG	_	_
has	_	_
an	_	_
intuitive	_	_
interpretation	_	_
:	_	_
each	_	_
document	_	_
or	_	_
topic	_	_
depends	_	_
on	_	_
some	_	_
subset	_	_
of	_	_
components	_	_
.	_	_

#59
The	_	_
default	_	_
prior	_	_
over	_	_
coefficients	_	_
that	_	_
we	_	_
use	_	_
in	_	_
this	_	_
study	_	_
is	_	_
a	_	_
0-mean	_	_
Gaussian	_	_
distribution	_	_
,	_	_
which	_	_
encourages	_	_
the	_	_
weights	_	_
to	_	_
be	_	_
small	_	_
.	_	_

#60
We	_	_
note	_	_
that	_	_
to	_	_
induce	_	_
a	_	_
sparse	_	_
graph	_	_
,	_	_
one	_	_
could	feasibility-options	_
use	_	_
a	_	_
0-mean	_	_
Laplace	_	_
distribution	_	_
as	_	_
the	_	_
prior	_	_
over	_	_
α	_	_
and	_	_
β	_	_
,	_	_
which	_	_
prefers	_	_
parameters	_	_
such	_	_
that	_	_
some	_	_
components	_	_
are	_	_
zero	_	_
.	_	_

#61
3.1.2	_	_
Tree	_	_
When	_	_
each	_	_
document	_	_
or	_	_
topic	_	_
has	_	_
exactly	_	_
one	_	_
parent	_	_
(	_	_
one	_	_
nonzero	_	_
coefficient	_	_
)	_	_
we	_	_
obtain	_	_
a	_	_
two-level	_	_
tree	_	_
structure	_	_
.	_	_

#65
We	_	_
let	_	_
αm	_	_
and	_	_
βk	_	_
to	_	_
real-valued	_	_
variables	_	_
in	_	_
a	_	_
simplex	_	_
,	_	_
but	_	_
place	_	_
a	_	_
prior	_	_
over	_	_
their	_	_
values	_	_
to	_	_
encourage	_	_
sparse	_	_
values	_	_
,	_	_
favoring	_	_
vectors	_	_
with	_	_
a	_	_
single	_	_
component	_	_
near	_	_
1	_	_
and	_	_
others	_	_
near	_	_
0	_	_
.	_	_

#66
This	_	_
is	_	_
achieved	_	_
using	_	_
a	_	_
Dirichlet	_	_
(	_	_
ρ	_	_
<	_	_
1	_	_
)	_	_
distribution	_	_
as	_	_
the	_	_
prior	_	_
over	_	_
α	_	_
and	_	_
β	_	_
,	_	_
which	_	_
has	_	_
higher	_	_
density	_	_
near	_	_
the	_	_
boundaries	_	_
of	_	_
the	_	_
simplex.1	_	_
1This	_	_
generalizes	_	_
the	_	_
technique	_	_
used	_	_
in	_	_
Paul	_	_
and	_	_
Dredze	_	_
(	_	_
2012	_	_
)	_	_
,	_	_
who	_	_
approximated	_	_
binary	_	_
variables	_	_
with	_	_
real-valued	_	_
variables	_	_
in	_	_
(	_	_
0	_	_
,	_	_
1	_	_
)	_	_
,	_	_
by	_	_
using	_	_
a	_	_
“U-shaped”	_	_
Beta	_	_
(	_	_
ρ	_	_
<	_	_
1	_	_
)	_	_
distriFor	_	_
a	_	_
weighted	_	_
tree	_	_
,	_	_
α	_	_
and	_	_
β	_	_
could	options	_
be	_	_
a	_	_
product	_	_
of	_	_
two	_	_
variables	_	_
:	_	_
an	_	_
“integer-like”	_	_
indicator	_	_
vector	_	_
with	_	_
sparse	_	_
Dirichlet	_	_
prior	_	_
as	_	_
suggested	_	_
above	_	_
,	_	_
combined	_	_
with	_	_
a	_	_
real-valued	_	_
weight	_	_
(	_	_
e.g.	_	_
,	_	_
with	_	_
a	_	_
Gaussian	_	_
prior	_	_
)	_	_
.	_	_

#67
We	_	_
take	_	_
this	_	_
approach	_	_
in	_	_
our	_	_
model	_	_
of	_	_
topic	_	_
and	_	_
perspective	_	_
(	_	_
§6	_	_
)	_	_
.	_	_

#68
3.1.3	_	_
Factored	_	_
Forest	_	_
By	_	_
using	_	_
structured	_	_
sparsity	_	_
over	_	_
the	_	_
DAG	_	_
,	_	_
we	_	_
can	feasibility	_
obtain	_	_
a	_	_
structure	_	_
where	_	_
components	_	_
are	_	_
grouped	_	_
into	_	_
G	_	_
factors	_	_
,	_	_
and	_	_
each	_	_
document	_	_
or	_	_
topic	_	_
has	_	_
one	_	_
parent	_	_
from	_	_
each	_	_
group	_	_
.	_	_

#69
Figure	_	_
2	_	_
(	_	_
d	_	_
)	_	_
illustrates	_	_
this	_	_
:	_	_
the	_	_
left	_	_
three	_	_
components	_	_
belong	_	_
to	_	_
one	_	_
group	_	_
,	_	_
the	_	_
right	_	_
two	_	_
belong	_	_
to	_	_
another	_	_
,	_	_
and	_	_
each	_	_
bottom	_	_
node	_	_
has	_	_
exactly	_	_
one	_	_
parent	_	_
from	_	_
each	_	_
.	_	_

#73
The	_	_
“exactly	_	_
one	_	_
parent”	_	_
indicator	_	_
constraint	_	_
is	_	_
the	_	_
same	_	_
as	_	_
in	_	_
the	_	_
tree	_	_
structure	_	_
but	_	_
enforces	_	_
a	_	_
tree	_	_
only	_	_
within	_	_
each	_	_
group	_	_
.	_	_

#74
This	_	_
can	feasibility	_
therefore	_	_
be	_	_
(	_	_
softly	_	_
)	_	_
modeled	_	_
using	_	_
a	_	_
sparse	_	_
Dirichlet	_	_
prior	_	_
as	_	_
described	_	_
in	_	_
the	_	_
previous	_	_
subsection	_	_
.	_	_

#75
In	_	_
this	_	_
case	_	_
,	_	_
the	_	_
subsets	_	_
of	_	_
components	_	_
belonging	_	_
to	_	_
each	_	_
factor	_	_
have	_	_
separate	_	_
sparse	_	_
Dirichlet	_	_
priors	_	_
.	_	_

#81
Consider	_	_
the	_	_
example	_	_
with	_	_
spoken	_	_
language	_	_
topics	_	_
in	_	_
§2	_	_
:	_	_
these	_	_
three	_	_
topics	_	_
(	_	_
signal	_	_
processing	_	_
,	_	_
speech	_	_
recognition	_	_
,	_	_
and	_	_
dialog	_	_
systems	_	_
)	_	_
are	_	_
a	_	_
priori	_	_
likely	_	_
both	_	_
to	_	_
share	_	_
the	_	_
same	_	_
words	_	_
and	_	_
to	_	_
occur	_	_
together	_	_
in	_	_
documents	_	_
.	_	_

#82
By	_	_
tying	_	_
these	_	_
together	_	_
,	_	_
we	_	_
ensure	_	_
that	_	_
the	_	_
patterns	_	_
are	_	_
consistent	_	_
across	_	_
the	_	_
two	_	_
types	_	_
of	_	_
components	_	_
,	_	_
and	_	_
the	_	_
patterns	_	_
from	_	_
both	_	_
types	_	_
can	capability	_
reinforce	_	_
each	_	_
other	_	_
during	_	_
inference	_	_
.	_	_

#83
In	_	_
this	_	_
case	_	_
,	_	_
the	_	_
number	_	_
of	_	_
topic	_	_
components	_	_
is	_	_
the	_	_
same	_	_
as	_	_
the	_	_
number	_	_
of	_	_
document	_	_
components	_	_
(	_	_
C	_	_
(	_	_
φ	_	_
)	_	_
=	_	_
C	_	_
(	_	_
θ	_	_
)	_	_
)	_	_
,	_	_
and	_	_
the	_	_
coefficients	_	_
(	_	_
βcz	_	_
)	_	_
of	_	_
the	_	_
topic	_	_
components	_	_
should	inference	_
correlate	_	_
with	_	_
the	_	_
weights	_	_
of	_	_
the	_	_
document	_	_
components	_	_
(	_	_
δzc	_	_
)	_	_
.	_	_

#84
The	_	_
approach	_	_
we	_	_
take	_	_
(	_	_
§6	_	_
)	_	_
is	_	_
to	_	_
define	_	_
δ	_	_
and	_	_
β	_	_
as	_	_
a	_	_
product	_	_
of	_	_
two	_	_
variables	_	_
(	_	_
suggested	_	_
in	_	_
§3.1.2	_	_
)	_	_
:	_	_
a	_	_
binary	_	_
mask	_	_
variable	_	_
(	_	_
with	_	_
sparse	_	_
Dirichlet	_	_
prior	_	_
)	_	_
,	_	_
which	_	_
we	_	_
let	_	_
be	_	_
identical	_	_
for	_	_
both	_	_
δ	_	_
and	_	_
β	_	_
,	_	_
and	_	_
a	_	_
real-valued	_	_
positive	_	_
weight	_	_
.	_	_

#86
While	_	_
not	_	_
experimented	_	_
with	_	_
in	_	_
this	_	_
study	_	_
,	_	_
it	_	_
is	_	_
also	_	_
possible	_	_
to	_	_
allow	_	_
the	_	_
components	_	_
themselves	_	_
to	_	_
have	_	_
rich	_	_
priors	_	_
which	_	_
are	_	_
functions	_	_
of	_	_
higher	_	_
level	_	_
components	_	_
.	_	_

#87
For	_	_
example	_	_
,	_	_
rather	_	_
than	_	_
assuming	_	_
a	_	_
mean	_	_
of	_	_
zero	_	_
,	_	_
the	_	_
mean	_	_
could	options	_
be	_	_
a	_	_
weighted	_	_
combination	_	_
of	_	_
higher	_	_
level	_	_
weight	_	_
vectors	_	_
.	_	_

#88
This	_	_
approach	_	_
was	_	_
used	_	_
by	_	_
Paul	_	_
and	_	_
Dredze	_	_
(	_	_
2013	_	_
)	_	_
in	_	_
Factorial	_	_
LDA	_	_
,	_	_
in	_	_
which	_	_
each	_	_
ω	_	_
component	_	_
had	_	_
its	_	_
own	_	_
Gaussian	_	_
prior	_	_
provided	_	_
as	_	_
input	_	_
to	_	_
guide	_	_
the	_	_
parameters	_	_
.	_	_

#90
Table	_	_
1	_	_
summarizes	_	_
these	_	_
models	_	_
and	_	_
their	_	_
relation	_	_
to	_	_
SPRITE	_	_
.	_	_

#91
In	_	_
almost	_	_
every	_	_
case	_	_
,	_	_
we	_	_
also	_	_
describe	_	_
how	_	_
the	_	_
SPRITE	_	_
representation	_	_
of	_	_
the	_	_
model	_	_
offers	_	_
improvements	_	_
over	_	_
the	_	_
original	_	_
model	_	_
or	_	_
can	capability	_
lead	_	_
to	_	_
novel	_	_
extensions	_	_
.	_	_

#92
Model	_	_
Sec	_	_
.	_	_

#93
Document	_	_
priors	_	_
Topic	_	_
priors	_	_
LDA	_	_
4.1	_	_
Single	_	_
component	_	_
Single	_	_
component	_	_
SCTM	_	_
4.2	_	_
Single	_	_
component	_	_
Sparse	_	_
binary	_	_
β	_	_
SAGE	_	_
4.3	_	_
Single	_	_
component	_	_
Sparse	_	_
ω	_	_
FLDA	_	_
4.3	_	_
Binary	_	_
δ	_	_
is	_	_
transpose	_	_
of	_	_
β	_	_
Factored	_	_
binary	_	_
β	_	_
PAM	_	_
4.4	_	_
α	_	_
are	_	_
supertopic	_	_
weights	_	_
Single	_	_
component	_	_
DMR	_	_
4.5	_	_
α	_	_
are	_	_
feature	_	_
values	_	_
Single	_	_
component	_	_
Table	_	_
1	_	_
:	_	_
Topic	_	_
models	_	_
with	_	_
Dirichlet	_	_
priors	_	_
that	_	_
are	_	_
generalized	_	_
by	_	_
SPRITE	_	_
.	_	_

#94
The	_	_
description	_	_
of	_	_
each	_	_
model	_	_
can	feasibility-rhetorical	_
be	_	_
found	_	_
in	_	_
the	_	_
noted	_	_
section	_	_
number	_	_
.	_	_

#95
PAM	_	_
is	_	_
not	_	_
equivalent	_	_
,	_	_
but	_	_
captures	_	_
very	_	_
similar	_	_
behavior	_	_
.	_	_

#118
FLDA	_	_
assumes	_	_
that	_	_
the	_	_
entire	_	_
Cartesian	_	_
product	_	_
of	_	_
the	_	_
different	_	_
factors	_	_
is	_	_
represented	_	_
in	_	_
the	_	_
model	_	_
(	_	_
e.g	_	_
.	_	_
φ	_	_
parameters	_	_
for	_	_
every	_	_
possible	_	_
tuple	_	_
)	_	_
,	_	_
which	_	_
leads	_	_
to	_	_
issues	_	_
with	_	_
efficiency	_	_
and	_	_
overparameterization	_	_
with	_	_
higher	_	_
numbers	_	_
of	_	_
factors	_	_
.	_	_

#119
With	_	_
SPRITE	_	_
,	_	_
we	_	_
can	feasibility	_
simply	_	_
fix	_	_
the	_	_
number	_	_
of	_	_
“topics”	_	_
to	_	_
a	_	_
number	_	_
smaller	_	_
than	_	_
the	_	_
size	_	_
of	_	_
the	_	_
Cartesian	_	_
product	_	_
,	_	_
and	_	_
the	_	_
model	_	_
will	_	_
learn	_	_
which	_	_
subset	_	_
of	_	_
tuples	_	_
are	_	_
included	_	_
,	_	_
through	_	_
the	_	_
values	_	_
of	_	_
β	_	_
and	_	_
δ.	_	_
Finally	_	_
,	_	_
another	_	_
existing	_	_
model	_	_
family	_	_
that	_	_
allows	_	_
for	_	_
topic	_	_
factorization	_	_
is	_	_
the	_	_
sparse	_	_
additive	_	_
generative	_	_
model	_	_
(	_	_
SAGE	_	_
)	_	_
(	_	_
Eisenstein	_	_
et	_	_
al.	_	_
,	_	_
2011	_	_
)	_	_
.	_	_

#120
SAGE	_	_
uses	_	_
a	_	_
log-linear	_	_
parameterization	_	_
to	_	_
define	_	_
word	_	_
distributions	_	_
.	_	_

#123
4.4	_	_
Topic	_	_
Hierarchies	_	_
and	_	_
Correlations	_	_
While	_	_
the	_	_
two	_	_
previous	_	_
subsections	_	_
primarily	_	_
focused	_	_
on	_	_
word	_	_
distributions	_	_
(	_	_
with	_	_
FLDA	_	_
being	_	_
an	_	_
exception	_	_
that	_	_
focused	_	_
on	_	_
both	_	_
)	_	_
,	_	_
SPRITE’s	_	_
priors	_	_
over	_	_
topic	_	_
distributions	_	_
also	_	_
have	_	_
useful	_	_
characteristics	_	_
.	_	_

#124
The	_	_
component-specific	_	_
δ	_	_
vectors	_	_
can	capability-feasibility	_
be	_	_
interpreted	_	_
as	_	_
common	_	_
topic	_	_
distribution	_	_
patterns	_	_
,	_	_
where	_	_
each	_	_
component	_	_
is	_	_
likely	_	_
to	_	_
give	_	_
high	_	_
weight	_	_
to	_	_
groups	_	_
of	_	_
topics	_	_
that	_	_
tend	_	_
to	_	_
occur	_	_
together	_	_
.	_	_

#125
Each	_	_
document’s	_	_
α	_	_
weights	_	_
encode	_	_
which	_	_
of	_	_
the	_	_
topic	_	_
groups	_	_
are	_	_
present	_	_
in	_	_
that	_	_
document	_	_
.	_	_

#130
While	_	_
not	_	_
equivalent	_	_
,	_	_
this	_	_
is	_	_
quite	_	_
similar	_	_
to	_	_
SPRITE	_	_
where	_	_
document	_	_
components	_	_
correspond	_	_
to	_	_
supertopics	_	_
.	_	_

#131
Each	_	_
document’s	_	_
α	_	_
weights	_	_
can	capability-feasibility	_
be	_	_
interpreted	_	_
to	_	_
be	_	_
similar	_	_
to	_	_
a	_	_
distribution	_	_
over	_	_
supertopics	_	_
,	_	_
and	_	_
each	_	_
δ	_	_
vector	_	_
is	_	_
that	_	_
supertopic’s	_	_
contribution	_	_
to	_	_
the	_	_
prior	_	_
over	_	_
subtopics	_	_
.	_	_

#132
The	_	_
prior	_	_
over	_	_
the	_	_
document’s	_	_
topic	_	_
distribution	_	_
is	_	_
thus	_	_
affected	_	_
by	_	_
the	_	_
document’s	_	_
supertopic	_	_
weights	_	_
α.	_	_
The	_	_
SPRITE	_	_
formulation	_	_
naturally	_	_
allows	_	_
for	_	_
powerful	_	_
extensions	_	_
to	_	_
PAM	_	_
.	_	_

#133
One	_	_
possibility	_	_
is	_	_
to	_	_
include	_	_
topic	_	_
components	_	_
for	_	_
the	_	_
word	_	_
distributions	_	_
,	_	_
in	_	_
addition	_	_
to	_	_
document	_	_
components	_	_
,	_	_
and	_	_
to	_	_
tie	_	_
together	_	_
δcz	_	_
and	_	_
βzc	_	_
(	_	_
§3.2	_	_
)	_	_
.	_	_

#134
This	_	_
models	_	_
the	_	_
intuitive	_	_
characteristic	_	_
that	_	_
subtopics	_	_
belonging	_	_
to	_	_
similar	_	_
supertopics	_	_
(	_	_
encoded	_	_
by	_	_
δ	_	_
)	_	_
should	inference	_
come	_	_
from	_	_
similar	_	_
priors	_	_
over	_	_
their	_	_
word	_	_
distributions	_	_
(	_	_
since	_	_
they	_	_
will	_	_
have	_	_
similar	_	_
β	_	_
values	_	_
)	_	_
.	_	_

#135
That	_	_
is	_	_
,	_	_
children	_	_
of	_	_
a	_	_
supertopic	_	_
are	_	_
topically	_	_
related	_	_
–	_	_
they	_	_
are	_	_
likely	_	_
to	_	_
share	_	_
words	_	_
.	_	_

#156
For	_	_
unconstrained	_	_
parameters	_	_
,	_	_
we	_	_
use	_	_
the	_	_
update	_	_
rule	_	_
:	_	_
xt+1=xt	_	_
+	_	_
ηt∇L	_	_
(	_	_
xt	_	_
)	_	_
,	_	_
for	_	_
some	_	_
variable	_	_
x	_	_
and	_	_
a	_	_
step	_	_
size	_	_
ηt	_	_
at	_	_
iteration	_	_
t.	_	_
For	_	_
parameters	_	_
constrained	_	_
to	_	_
the	_	_
simplex	_	_
(	_	_
such	_	_
as	_	_
when	_	_
β	_	_
is	_	_
a	_	_
soft	_	_
indicator	_	_
vector	_	_
)	_	_
,	_	_
we	_	_
use	_	_
exponentiated	_	_
gradient	_	_
ascent	_	_
(	_	_
Kivinen	_	_
and	_	_
Warmuth	_	_
,	_	_
1997	_	_
)	_	_
with	_	_
the	_	_
update	_	_
rule	_	_
:	_	_
xt+1i	_	_
∝	_	_
xti	_	_
exp	_	_
(	_	_
ηt∇iL	_	_
(	_	_
xt	_	_
)	_	_
)	_	_
.	_	_

#157
5.1	_	_
Tightening	_	_
the	_	_
Constraints	_	_
For	_	_
variables	_	_
that	_	_
we	_	_
prefer	_	_
to	_	_
be	_	_
binary	_	_
but	_	_
have	_	_
softened	_	_
to	_	_
continuous	_	_
variables	_	_
using	_	_
sparse	_	_
Beta	_	_
or	_	_
Dirichlet	_	_
priors	_	_
,	_	_
we	_	_
can	feasibility	_
straightforwardly	_	_
strengthen	_	_
the	_	_
preference	_	_
to	_	_
be	_	_
binary	_	_
by	_	_
modifying	_	_
the	_	_
objective	_	_
function	_	_
to	_	_
favor	_	_
the	_	_
prior	_	_
more	_	_
heavily	_	_
.	_	_

#158
Specifically	_	_
,	_	_
under	_	_
a	_	_
Dirichlet	_	_
(	_	_
ρ	_	_
<	_	_
1	_	_
)	_	_
prior	_	_
we	_	_
will	_	_
introduce	_	_
a	_	_
scaling	_	_
parameter	_	_
τt	_	_
≥	_	_
1	_	_
to	_	_
the	_	_
prior	_	_
log	_	_
likelihood	_	_
:	_	_
τt	_	_
logP	_	_
(	_	_
β	_	_
)	_	_
with	_	_
partial	_	_
derivative	_	_
τt	_	_
ρ−1βkc	_	_
,	_	_
which	_	_
adds	_	_
extra	_	_
weight	_	_
to	_	_
the	_	_
sparse	_	_
Dirichlet	_	_
prior	_	_
in	_	_
the	_	_
objective	_	_
.	_	_

#162
Annealing	_	_
only	_	_
the	_	_
prior	_	_
P	_	_
(	_	_
β	_	_
)	_	_
results	_	_
in	_	_
maximization	_	_
of	_	_
this	_	_
term	_	_
only	_	_
,	_	_
while	_	_
the	_	_
outer	_	_
max	_	_
chooses	_	_
a	_	_
good	_	_
β	_	_
under	_	_
P	_	_
(	_	_
φ|β	_	_
)	_	_
as	_	_
a	_	_
tie-breaker	_	_
among	_	_
all	_	_
β	_	_
values	_	_
that	_	_
maximize	_	_
the	_	_
inner	_	_
max	_	_
(	_	_
binary-valued	_	_
β	_	_
)	_	_
.3	_	_
We	_	_
show	_	_
experimentally	_	_
(	_	_
§7.2.2	_	_
)	_	_
that	_	_
annealing	_	_
the	_	_
prior	_	_
yields	_	_
values	_	_
that	_	_
satisfy	_	_
the	_	_
constraints	_	_
.	_	_

#163
3Other	_	_
modifications	_	_
could	feasibility-options	_
be	_	_
made	_	_
to	_	_
the	_	_
objective	_	_
function	_	_
to	_	_
induce	_	_
sparsity	_	_
,	_	_
such	_	_
as	_	_
entropy	_	_
regularization	_	_
(	_	_
Balasubramanyan	_	_
and	_	_
Cohen	_	_
,	_	_
2013	_	_
)	_	_
.	_	_

#164
6	_	_
A	_	_
Factored	_	_
Hierarchical	_	_
Model	_	_
of	_	_
Topic	_	_
and	_	_
Perspective	_	_
We	_	_
will	_	_
now	_	_
describe	_	_
a	_	_
SPRITE	_	_
model	_	_
that	_	_
encompasses	_	_
nearly	_	_
all	_	_
of	_	_
the	_	_
structures	_	_
and	_	_
extensions	_	_
described	_	_
in	_	_
§3–4	_	_
,	_	_
followed	_	_
by	_	_
experimental	_	_
results	_	_
using	_	_
this	_	_
model	_	_
to	_	_
jointly	_	_
capture	_	_
topic	_	_
and	_	_
“perspective”	_	_
in	_	_
a	_	_
corpus	_	_
of	_	_
political	_	_
debates	_	_
(	_	_
where	_	_
perspective	_	_
corresponds	_	_
to	_	_
ideology	_	_
)	_	_
and	_	_
a	_	_
corpus	_	_
of	_	_
online	_	_
doctor	_	_
reviews	_	_
(	_	_
where	_	_
perspective	_	_
corresponds	_	_
to	_	_
the	_	_
review	_	_
sentiment	_	_
)	_	_
.	_	_

#166
The	_	_
hierarchy	_	_
will	_	_
model	_	_
both	_	_
topics	_	_
and	_	_
documents	_	_
,	_	_
where	_	_
αm	_	_
is	_	_
documentm’s	_	_
supertopic	_	_
proportions	_	_
,	_	_
δc	_	_
is	_	_
the	_	_
cth	_	_
supertopic’s	_	_
subtopic	_	_
prior	_	_
,	_	_
ωc	_	_
is	_	_
the	_	_
cth	_	_
supertopic’s	_	_
word	_	_
prior	_	_
,	_	_
and	_	_
βk	_	_
is	_	_
the	_	_
weight	_	_
vector	_	_
that	_	_
selects	_	_
the	_	_
kth	_	_
topic’s	_	_
parent	_	_
supertopic	_	_
,	_	_
which	_	_
incorporates	_	_
(	_	_
soft	_	_
)	_	_
indicator	_	_
vectors	_	_
to	_	_
encode	_	_
a	_	_
tree	_	_
structure	_	_
(	_	_
§3.1.2	_	_
)	_	_
.	_	_

#167
We	_	_
want	_	_
a	_	_
weighted	_	_
tree	_	_
;	_	_
while	_	_
each	_	_
βk	_	_
has	_	_
only	_	_
one	_	_
nonzero	_	_
element	_	_
,	_	_
the	_	_
nonzero	_	_
element	_	_
can	options	_
be	_	_
a	_	_
value	_	_
other	_	_
than	_	_
1	_	_
.	_	_

#168
We	_	_
do	_	_
this	_	_
by	_	_
replacing	_	_
the	_	_
single	_	_
coefficient	_	_
βkc	_	_
with	_	_
a	_	_
product	_	_
of	_	_
two	_	_
variables	_	_
:	_	_
bkcβ̂kc	_	_
.	_	_

#183
This	_	_
means	_	_
that	_	_
topics	_	_
with	_	_
positive	_	_
δ	_	_
(	_	_
P	_	_
)	_	_
k	_	_
will	_	_
also	_	_
have	_	_
a	_	_
positive	_	_
β	_	_
coefficient	_	_
that	_	_
is	_	_
multiplied	_	_
with	_	_
the	_	_
perspective	_	_
word	_	_
vector	_	_
ω	_	_
(	_	_
P	_	_
)	_	_
.	_	_

#184
Finally	_	_
,	_	_
we	_	_
include	_	_
“bias”	_	_
component	_	_
vectors	_	_
denoted	_	_
ω	_	_
(	_	_
B	_	_
)	_	_
and	_	_
δ	_	_
(	_	_
B	_	_
)	_	_
,	_	_
which	_	_
act	_	_
as	_	_
overall	_	_
weights	_	_
over	_	_
the	_	_
vocabulary	_	_
and	_	_
topics	_	_
,	_	_
so	_	_
that	_	_
the	_	_
component-specific	_	_
ω	_	_
and	_	_
δ	_	_
weights	_	_
can	capability-feasibility	_
be	_	_
interpreted	_	_
as	_	_
deviations	_	_
from	_	_
the	_	_
global	_	_
bias	_	_
weights	_	_
.	_	_

#185
Figure	_	_
3	_	_
summarizes	_	_
the	_	_
model	_	_
.	_	_

#186
This	_	_
includes	_	_
most	_	_
of	_	_
the	_	_
features	_	_
described	_	_
above	_	_
(	_	_
trees	_	_
,	_	_
factored	_	_
structures	_	_
,	_	_
tying	_	_
topic	_	_
and	_	_
document	_	_
components	_	_
,	_	_
and	_	_
document	_	_
attributes	_	_
)	_	_
,	_	_
so	_	_
we	_	_
can	feasibility	_
ablate	_	_
model	_	_
features	_	_
to	_	_
measure	_	_
their	_	_
effect	_	_
.	_	_

#187
7	_	_
Experiments	_	_
7.1	_	_
Datasets	_	_
and	_	_
Experimental	_	_
Setup	_	_
We	_	_
applied	_	_
our	_	_
models	_	_
to	_	_
two	_	_
corpora	_	_
:	_	_
•	_	_
Debates	_	_
:	_	_
A	_	_
set	_	_
of	_	_
floor	_	_
debates	_	_
from	_	_
the	_	_
109th–	_	_
112th	_	_
U.S	_	_
.	_	_

#219
The	_	_
held-out	_	_
set	_	_
is	_	_
based	_	_
on	_	_
tokens	_	_
rather	_	_
than	_	_
documents	_	_
:	_	_
we	_	_
trained	_	_
on	_	_
even	_	_
numbered	_	_
tokens	_	_
and	_	_
tested	_	_
on	_	_
odd	_	_
tokens	_	_
.	_	_

#220
This	_	_
is	_	_
a	_	_
type	_	_
of	_	_
“document	_	_
completion”	_	_
evaluation	_	_
(	_	_
Wallach	_	_
et	_	_
al.	_	_
,	_	_
2009b	_	_
)	_	_
which	_	_
measures	_	_
how	_	_
well	_	_
the	_	_
model	_	_
can	capability	_
predict	_	_
held-out	_	_
tokens	_	_
of	_	_
a	_	_
document	_	_
after	_	_
observing	_	_
only	_	_
some	_	_
.	_	_

#221
We	_	_
also	_	_
evaluated	_	_
how	_	_
well	_	_
the	_	_
model	_	_
can	capability	_
predict	_	_
the	_	_
attribute	_	_
value	_	_
(	_	_
DW-NOMINATE	_	_
score	_	_
or	_	_
user	_	_
rating	_	_
)	_	_
of	_	_
the	_	_
document	_	_
.	_	_

#222
We	_	_
trained	_	_
a	_	_
linear	_	_
regression	_	_
model	_	_
using	_	_
the	_	_
document	_	_
topic	_	_
distributions	_	_
θ	_	_
as	_	_
features	_	_
.	_	_

#388
Note	_	_
that	_	_
this	_	_
is	_	_
a	_	_
“soft”	_	_
hierarchy	_	_
because	_	_
the	_	_
tree	_	_
structure	_	_
is	_	_
not	_	_
strictly	_	_
enforced	_	_
,	_	_
so	_	_
some	_	_
topics	_	_
have	_	_
multiple	_	_
parent	_	_
components	_	_
.	_	_

#389
Table	_	_
3	_	_
shows	_	_
how	_	_
strict	_	_
trees	_	_
can	feasibility	_
be	_	_
learned	_	_
by	_	_
tuning	_	_
the	_	_
annealing	_	_
parameter	_	_
.	_	_

#390
measure	_	_
the	_	_
average	_	_
coherence	_	_
across	_	_
all	_	_
topics	_	_
:	_	_
K	_	_
K∑	_	_
k=1	_	_
M∑	_	_
m=2	_	_
m−1∑	_	_
l=1	_	_
log	_	_
DF	_	_
(	_	_
vkm	_	_
,	_	_
vkl	_	_
)	_	_
+	_	_
1	_	_
DF	_	_
(	_	_
vkl	_	_
)	_	_
(	_	_
2	_	_
)	_	_
where	_	_
DF	_	_
(	_	_
v	_	_
,	_	_
w	_	_
)	_	_
is	_	_
the	_	_
document	_	_
frequency	_	_
of	_	_
words	_	_
v	_	_
andw	_	_
(	_	_
the	_	_
number	_	_
of	_	_
documents	_	_
in	_	_
which	_	_
they	_	_
both	_	_
occur	_	_
)	_	_
,	_	_
DF	_	_
(	_	_
v	_	_
)	_	_
is	_	_
the	_	_
document	_	_
frequency	_	_
of	_	_
word	_	_
v	_	_
,	_	_
and	_	_
vki	_	_
is	_	_
the	_	_
ith	_	_
most	_	_
probable	_	_
word	_	_
in	_	_
topic	_	_
k.	_	_
We	_	_
use	_	_
the	_	_
top	_	_
M	_	_
=	_	_
20	_	_
words	_	_
.	_	_

#432
τt	_	_
Debates	_	_
Reviews	_	_
0.000	_	_
(	_	_
Sparse	_	_
DAG	_	_
)	_	_
58.1	_	_
%	_	_
42.4	_	_
%	_	_
1.000	_	_
(	_	_
Soft	_	_
Tree	_	_
)	_	_
93.2	_	_
%	_	_
74.6	_	_
%	_	_
1.001t	_	_
(	_	_
Hard	_	_
Tree	_	_
)	_	_
99.8	_	_
%	_	_
99.4	_	_
%	_	_
1.003t	_	_
(	_	_
Hard	_	_
Tree	_	_
)	_	_
100	_	_
%	_	_
100	_	_
%	_	_
Table	_	_
3	_	_
:	_	_
The	_	_
percentage	_	_
of	_	_
indicator	_	_
values	_	_
that	_	_
are	_	_
sparse	_	_
(	_	_
near	_	_
0	_	_
or	_	_
1	_	_
)	_	_
when	_	_
using	_	_
different	_	_
annealing	_	_
schedules	_	_
.	_	_

#433
choice	_	_
of	_	_
parameters	_	_
may	speculation	_
depend	_	_
on	_	_
the	_	_
end	_	_
application	_	_
and	_	_
the	_	_
particular	_	_
structures	_	_
that	_	_
the	_	_
user	_	_
has	_	_
in	_	_
mind	_	_
,	_	_
if	_	_
interpretability	_	_
is	_	_
important	_	_
.	_	_

#434
For	_	_
example	_	_
,	_	_
if	_	_
the	_	_
topic	_	_
model	_	_
is	_	_
used	_	_
as	_	_
a	_	_
visualization	_	_
tool	_	_
,	_	_
then	_	_
2	_	_
components	_	_
would	_	_
not	_	_
likely	_	_
result	_	_
in	_	_
an	_	_
interesting	_	_
hierarchy	_	_
to	_	_
the	_	_
user	_	_
,	_	_
even	_	_
if	_	_
this	_	_
setting	_	_
produces	_	_
low	_	_
perplexity	_	_
.	_	_

#602
Ultimately	_	_
,	_	_
the	_	_
model	_	_
design	_	_
choice	_	_
depends	_	_
on	_	_
the	_	_
application	_	_
and	_	_
the	_	_
user	_	_
needs	_	_
.	_	_

#603
By	_	_
unifying	_	_
such	_	_
a	_	_
wide	_	_
variety	_	_
of	_	_
topic	_	_
models	_	_
,	_	_
SPRITE	_	_
can	capability	_
serve	_	_
as	_	_
a	_	_
common	_	_
framework	_	_
for	_	_
enabling	_	_
model	_	_
exploration	_	_
and	_	_
bringing	_	_
application-specific	_	_
preferences	_	_
and	_	_
structure	_	_
into	_	_
topic	_	_
models	_	_
.	_	_

#604
Acknowledgments	_	_
We	_	_
thank	_	_
Jason	_	_
Eisner	_	_
and	_	_
Hanna	_	_
Wallach	_	_
for	_	_
helpful	_	_
discussions	_	_
,	_	_
and	_	_
Viet-An	_	_
Nguyen	_	_
for	_	_
providing	_	_
the	_	_
Congressional	_	_
debates	_	_
data	_	_
.	_	_