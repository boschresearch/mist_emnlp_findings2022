#168
First	_	_
,	_	_
neural	_	_
news	_	_
recommendation	_	_
methods	_	_
(	_	_
e.g.	_	_
,	_	_
GRU	_	_
,	_	_
NRMS	_	_
,	_	_
Hi-Fi	_	_
Ark	_	_
,	_	_
NPA	_	_
)	_	_
are	_	_
generally	_	_
better	_	_
than	_	_
traditional	_	_
methods	_	_
(	_	_
e.g.	_	_
,	_	_
LibFM	_	_
,	_	_
DeepFM	_	_
)	_	_
that	_	_
are	_	_
based	_	_
on	_	_
manual	_	_
feature	_	_
engineering	_	_
.	_	_

#169
The	_	_
reason	_	_
might	speculation	_
be	_	_
that	_	_
handcrafted	_	_
features	_	_
are	_	_
usually	_	_
not	_	_
optimal	_	_
,	_	_
and	_	_
deep	_	_
neural	_	_
networks	_	_
take	_	_
the	_	_
advantages	_	_
of	_	_
extracting	_	_
implicit	_	_
semantic	_	_
features	_	_
and	_	_
modeling	_	_
latent	_	_
relationships	_	_
between	_	_
user	_	_
and	_	_
news	_	_
representations	_	_
.	_	_

#170
Second	_	_
,	_	_
our	_	_
model	_	_
FIM	_	_
consistently	_	_
outperforms	_	_
other	_	_
baselines	_	_
in	_	_
terms	_	_
of	_	_
all	_	_
metrics	_	_
,	_	_
including	_	_
the	_	_
state-of-the-art	_	_
deep	_	_
learning	_	_
based	_	_
models	_	_
.	_	_

#198
The	_	_
optimal	_	_
setting	_	_
of	_	_
the	_	_
number	_	_
of	_	_
stacked	_	_
layers	_	_
and	_	_
convolution	_	_
filters	_	_
is	_	_
3	_	_
and	_	_
150	_	_
respectively	_	_
.	_	_

#199
We	_	_
think	_	_
the	_	_
reason	_	_
might	speculation	_
be	_	_
that	_	_
in	_	_
this	_	_
scenario	_	_
,	_	_
the	_	_
perceived	_	_
field	_	_
of	_	_
dilated	_	_
convolution	_	_
filters	_	_
at	_	_
each	_	_
layer	_	_
ranges	_	_
among	_	_
[	_	_
3-7-13	_	_
]	_	_
(	_	_
with	_	_
dilation	_	_
rates	_	_
as	_	_
[	_	_
1-2-3	_	_
]	_	_
)	_	_
,	_	_
which	_	_
is	_	_
sufficient	_	_
for	_	_
modeling	_	_
multi-grained	_	_
n-gram	_	_
features	_	_
through	_	_
hierarchical	_	_
composition	_	_
of	_	_
local	_	_
interactions	_	_
,	_	_
compared	_	_
to	_	_
the	_	_
average	_	_
length	_	_
of	_	_
news	_	_
word	_	_
sequences	_	_
.	_	_

#200
We	_	_
also	_	_
investigate	_	_
the	_	_
effectiveness	_	_
of	_	_
incorporating	_	_
two-level	_	_
category	_	_
annotations	_	_
of	_	_
news	_	_
as	_	_
inputs	_	_
.	_	_