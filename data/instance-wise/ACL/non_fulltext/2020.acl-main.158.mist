#8
1	_	_
Introduction	_	_

#9
A	_	_
growing	_	_
body	_	_
of	_	_
work	_	_
advocates	_	_
that	_	_
assessment	_	_
of	_	_
neural	_	_
language	_	_
models	_	_
should	deontic	_
include	_	_
both	_	_
information-theoretic	_	_
metrics	_	_
,	_	_
such	_	_
as	_	_
perplexity	_	_
,	_	_
as	_	_
well	_	_
as	_	_
targeted	_	_
linguistic	_	_
evaluation	_	_
.	_	_

#10
Benchmarks	_	_
such	_	_
as	_	_
GLUE	_	_
(	_	_
Wang	_	_
et	_	_
al.	_	_
,	_	_
2019a	_	_
,	_	_
b	_	_
)	_	_
have	_	_
demonstrated	_	_
that	_	_
neural	_	_
language	_	_
models	_	_
trained	_	_
on	_	_
naturalistic	_	_
corpora	_	_
for	_	_
next-word	_	_
prediction	_	_
learn	_	_
representations	_	_
that	_	_
can	_	_
yield	_	_
remarkable	_	_
performance	_	_
on	_	_
many	_	_
semantic	_	_
tasks	_	_
.	_	_

#33
Models	_	_
with	_	_
improved	_	_
perplexity	_	_
have	_	_
also	_	_
been	_	_
shown	_	_
to	_	_
better	_	_
match	_	_
various	_	_
human	_	_
behavioral	_	_
measures	_	_
,	_	_
such	_	_
as	_	_
gaze	_	_
duration	_	_
during	_	_
reading	_	_
(	_	_
Frank	_	_
and	_	_
Bod	_	_
,	_	_
2011	_	_
;	_	_
Fossum	_	_
and	_	_
Levy	_	_
,	_	_
2012	_	_
;	_	_
Goodkind	_	_
and	_	_
Bicknell	_	_
,	_	_
2018	_	_
;	_	_
Wilcox	_	_
et	_	_
al.	_	_
,	_	_
2020	_	_
)	_	_
.	_	_

#34
However	_	_
,	_	_
a	_	_
broad-coverage	_	_
metric	_	_
such	_	_
as	_	_
perplexity	_	_
may	speculation	_
not	_	_
be	_	_
ideal	_	_
for	_	_
assessing	_	_
human-like	_	_
syntactic	_	_
knowledge	_	_
for	_	_
a	_	_
variety	_	_
of	_	_
reasons	_	_
.	_	_

#35
In	_	_
principle	_	_
,	_	_
a	_	_
sentence	_	_
can	_	_
appear	_	_
with	_	_
vanishingly	_	_
low	_	_
probability	_	_
but	_	_
still	_	_
be	_	_
grammatically	_	_
wellformed	_	_
,	_	_
such	_	_
as	_	_
Colorless	_	_
green	_	_
ideas	_	_
sleep	_	_
furiously	_	_
(	_	_
Chomsky	_	_
,	_	_
1957	_	_
)	_	_
.	_	_

#39
The	_	_
targeted	_	_
syntactic	_	_
evaluation	_	_
paradigm	_	_
(	_	_
Marvin	_	_
and	_	_
Linzen	_	_
,	_	_
2018	_	_
;	_	_
Futrell	_	_
et	_	_
al.	_	_
,	_	_
2019	_	_
)	_	_
incorporates	_	_
methods	_	_
from	_	_
psycholinguistic	_	_
experiments	_	_
,	_	_
designing	_	_
sentences	_	_
which	_	_
hold	_	_
most	_	_
lexical	_	_
and	_	_
syntactic	_	_
features	_	_
of	_	_
each	_	_
sentence	_	_
constant	_	_
while	_	_
minimally	_	_
varying	_	_
features	_	_
that	_	_
determine	_	_
grammaticality	_	_
or	_	_
surprise	_	_
characteristics	_	_
of	_	_
the	_	_
sentence	_	_
.	_	_

#40
For	_	_
example	_	_
,	_	_
given	_	_
the	_	_
two	_	_
strings	_	_
The	_	_
keys	_	_
to	_	_
the	_	_
cabinet	_	_
are	_	_
on	_	_
the	_	_
table	_	_
and	_	_
*The	_	_
keys	_	_
to	_	_
the	_	_
cabinet	_	_
is	_	_
on	_	_
the	_	_
table	_	_
,	_	_
a	_	_
model	_	_
that	_	_
has	_	_
learned	_	_
the	_	_
proper	_	_
subject–verb	_	_
number	_	_
agreement	_	_
rules	_	_
for	_	_
English	_	_
should	deontic-inference	_
assign	_	_
a	_	_
higher	_	_
probability	_	_
to	_	_
the	_	_
grammatical	_	_
plural	_	_
verb	_	_
in	_	_
the	_	_
first	_	_
sentence	_	_
than	_	_
to	_	_
the	_	_
ungrammatical	_	_
singular	_	_
verb	_	_
in	_	_
the	_	_
second	_	_
(	_	_
Linzen	_	_
et	_	_
al.	_	_
,	_	_
2016	_	_
)	_	_
.	_	_

#41
Although	_	_
some	_	_
targeted	_	_
syntactic	_	_
evaluations	_	_
,	_	_
such	_	_
as	_	_
the	_	_
example	_	_
discussed	_	_
above	_	_
,	_	_
involve	_	_
simple	_	_
comparisons	_	_
of	_	_
conditional	_	_
probabilities	_	_
of	_	_
a	_	_
word	_	_
in	_	_
its	_	_
context	_	_
,	_	_
other	_	_
evaluations	_	_
are	_	_
more	_	_
complex	_	_
.	_	_

#52
(	_	_
D	_	_
)	_	_
The	_	_
child	_	_
who	_	_
was	_	_
forgotten	_	_
in	_	_
the	_	_
chaos	_	_
found	_	_
...	_	_

#53
Successful	_	_
human-like	_	_
generalization	_	_
involves	_	_
three	_	_
criteria	_	_
:	_	_
(	_	_
i	_	_
)	_	_
found	_	_
should	deontic	_
be	_	_
less	_	_
surprising	_	_
(	_	_
i.e.	_	_
,	_	_
more	_	_
probable	_	_
)	_	_
in	_	_
B	_	_
than	_	_
A	_	_
;	_	_
(	_	_
ii	_	_
)	_	_
found	_	_
should	deontic	_
be	_	_
more	_	_
probable	_	_
in	_	_
C	_	_
than	_	_
A	_	_
;	_	_
(	_	_
iii	_	_
)	_	_
the	_	_
C–D	_	_
surprisal	_	_
difference	_	_
should	deontic	_
be	_	_
smaller	_	_
than	_	_
the	_	_
A–B	_	_
surprisal	_	_
difference—a	_	_
2×	_	_
2	_	_
interaction	_	_
effect	_	_
on	_	_
surprisal—because	_	_
the	_	_
syntactic	_	_
disambiguation	_	_
effect	_	_
of	_	_
not	_	_
reducing	_	_
the	_	_
relative	_	_
clause	_	_
was	_	_
achieved	_	_
by	_	_
using	_	_
a	_	_
part-of-speech	_	_
unambiguous	_	_
verb	_	_
.	_	_

#54
We	_	_
will	_	_
use	_	_
these	_	_
controlled	_	_
tests	_	_
to	_	_
help	_	_
us	_	_
describe	_	_
and	_	_
test	_	_
for	_	_
human-like	_	_
syntactic	_	_
knowledge	_	_
in	_	_
language	_	_
models	_	_
.	_	_

#66
Each	_	_
test	_	_
suite	_	_
contains	_	_
a	_	_
number	_	_
of	_	_
ITEMS	_	_
(	_	_
typically	_	_
between	_	_
20	_	_
and	_	_
30	_	_
)	_	_
,	_	_
and	_	_
each	_	_
item	_	_
appears	_	_
in	_	_
several	_	_
CONDITIONS	_	_
:	_	_
across	_	_
conditions	_	_
,	_	_
a	_	_
given	_	_
item	_	_
will	_	_
differ	_	_
only	_	_
according	_	_
to	_	_
a	_	_
controlled	_	_
manipulation	_	_
designed	_	_
to	_	_
target	_	_
a	_	_
particular	_	_
feature	_	_
of	_	_
grammatical	_	_
knowledge	_	_
.	_	_

#67
Each	_	_
test	_	_
suite	_	_
contains	_	_
at	_	_
least	_	_
one	_	_
PREDICTION	_	_
,	_	_
which	_	_
specifies	_	_
inequalities	_	_
between	_	_
surprisal	_	_
values	_	_
at	_	_
pairs	_	_
of	_	_
regions/conditions	_	_
that	_	_
should	deontic-inference	_
hold	_	_
if	_	_
a	_	_
model	_	_
has	_	_
learned	_	_
the	_	_
appropriate	_	_
syntactic	_	_
generalization	_	_
.	_	_

#68
We	_	_
expect	_	_
language	_	_
models	_	_
which	_	_
have	_	_
learned	_	_
the	_	_
appropriate	_	_
syntactic	_	_
generalizations	_	_
from	_	_
their	_	_
input	_	_
to	_	_
satisfy	_	_
these	_	_
inequalities	_	_
without	_	_
further	_	_
fine-tuning	_	_
.	_	_

#78
•	_	_
Agreement	_	_
is	_	_
a	_	_
constraint	_	_
on	_	_
the	_	_
feature	_	_
values	_	_
of	_	_
two	_	_
co-varying	_	_
tokens	_	_
.	_	_

#79
For	_	_
example	_	_
,	_	_
the	_	_
number	_	_
feature	_	_
of	_	_
a	_	_
verb	_	_
must	deontic	_
agree	_	_
with	_	_
the	_	_
number	_	_
feature	_	_
of	_	_
its	_	_
upstream	_	_
subject	_	_
.	_	_

#80
We	_	_
include	_	_
3	_	_
Subject-Verb	_	_
Number	_	_
Agreement	_	_
suites	_	_
from	_	_
Marvin	_	_
and	_	_
Linzen	_	_
(	_	_
2018	_	_
)	_	_
.	_	_

#81
•	_	_
Licensing	_	_
occurs	_	_
when	_	_
a	_	_
particular	_	_
token	_	_
must	deontic	_
exist	_	_
within	_	_
the	_	_
scope	_	_
of	_	_
an	_	_
upstream	_	_
licensor	_	_
token	_	_
.	_	_

#82
Scope	_	_
is	_	_
determined	_	_
by	_	_
the	_	_
tree-structural	_	_
properties	_	_
of	_	_
the	_	_
sentence	_	_
.	_	_

#88
•	_	_
Center	_	_
Embedding	_	_
sentences	_	_
are	_	_
sentences	_	_
recursively	_	_
nested	_	_
within	_	_
each	_	_
other	_	_
.	_	_

#89
Subject	_	_
and	_	_
verbs	_	_
must	deontic	_
match	_	_
in	_	_
a	_	_
first-in-last-out	_	_
order	_	_
,	_	_
meaning	_	_
models	_	_
must	deontic	_
approximate	_	_
a	_	_
stack-like	_	_
data-structure	_	_
in	_	_
order	_	_
to	_	_
successfully	_	_
process	_	_
them	_	_
.	_	_

#90
Our	_	_
2	_	_
suites	_	_
of	_	_
Center	_	_
Embedding	_	_
sentences	_	_
come	_	_
from	_	_
the	_	_
items	_	_
presented	_	_
in	_	_
Wilcox	_	_
et	_	_
al.	_	_
(	_	_
2019a	_	_
)	_	_
.	_	_

#100
[	_	_
DO/NP	_	_
]	_	_
d.	_	_
What	_	_
he	_	_
devoured	_	_
after	_	_
coming	_	_
in	_	_
from	_	_
the	_	_
rain	_	_
was	_	_
a	_	_
hot	_	_
meal	_	_
.	_	_

#101
[	_	_
LEX/NP	_	_
]	_	_
When	_	_
this	_	_
constituent	_	_
is	_	_
a	_	_
verb	_	_
,	_	_
it	_	_
must	deontic	_
be	_	_
replaced	_	_
in	_	_
the	_	_
wh-clause	_	_
that	_	_
heads	_	_
the	_	_
sentence	_	_
with	_	_
the	_	_
DO	_	_
verb	_	_
,	_	_
as	_	_
in	_	_
(	_	_
1a	_	_
)	_	_
,	_	_
below	_	_
.	_	_

#102
However	_	_
,	_	_
when	_	_
it	_	_
is	_	_
a	_	_
noun	_	_
,	_	_
the	_	_
lexical	_	_
verb	_	_
for	_	_
which	_	_
it	_	_
serves	_	_
as	_	_
an	_	_
object	_	_
must	deontic	_
be	_	_
preserved	_	_
,	_	_
as	_	_
in	_	_
(	_	_
1d	_	_
)	_	_
.	_	_

#103
If	_	_
models	_	_
have	_	_
properly	_	_
learned	_	_
the	_	_
pseudo-cleft	_	_
construction	_	_
,	_	_
then	_	_
DO	_	_
verbs	_	_
should	deontic-inference	_
set	_	_
up	_	_
expectations	_	_
for	_	_
VPs	_	_
(	_	_
the	_	_
region	_	_
in	_	_
bold	_	_
should	deontic-inference	_
have	_	_
a	_	_
lower	_	_
surprisal	_	_
in	_	_
(	_	_
1a	_	_
)	_	_
than	_	_
in	_	_
(	_	_
1b	_	_
)	_	_
)	_	_
and	_	_
lexicalized	_	_
verbs	_	_
should	deontic-inference	_
set	_	_
up	_	_
expectations	_	_
for	_	_
NPs	_	_
(	_	_
the	_	_
region	_	_
in	_	_
bold	_	_
should	deontic-inference	_
have	_	_
a	_	_
lower	_	_
surprisal	_	_
in	_	_
(	_	_
1d	_	_
)	_	_
than	_	_
in	_	_
(	_	_
1c	_	_
)	_	_
)	_	_
.	_	_

#104
3.2	_	_
Model	_	_
training	_	_
data	_	_

#117
Our	_	_
larger	_	_
training	_	_
datasets	_	_
thus	_	_
contain	_	_
larger	_	_
vocabularies	_	_
than	_	_
our	_	_
smaller	_	_
training	_	_
datasets	_	_
.	_	_

#118
This	_	_
allows	_	_
larger-training-set	_	_
models	_	_
to	_	_
learn	_	_
richer	_	_
word-specific	_	_
information	_	_
,	_	_
but	_	_
may	speculation	_
also	_	_
harm	_	_
perplexity	_	_
evaluation	_	_
because	_	_
they	_	_
have	_	_
vocabulary	_	_
items	_	_
that	_	_
are	_	_
guaranteed	_	_
to	_	_
not	_	_
appear	_	_
in	_	_
the	_	_
BLLIP-XS	_	_
test	_	_
set	_	_
.	_	_

#119
This	_	_
means	_	_
that	_	_
perplexity	_	_
scores	_	_
across	_	_
training	_	_
dataset	_	_
sizes	_	_
will	_	_
not	_	_
be	_	_
strictly	_	_
comparable	_	_
:	_	_
if	_	_
a	_	_
larger-training-set	_	_
model	_	_
does	_	_
better	_	_
than	_	_
a	_	_
smaller-training-set	_	_
model	_	_
,	_	_
we	_	_
can	_	_
be	_	_
confident	_	_
that	_	_
it	_	_
has	_	_
meaningfully	_	_
lower	_	_
perplexity	_	_
,	_	_
but	_	_
the	_	_
reverse	_	_
is	_	_
not	_	_
necessarily	_	_
the	_	_
case	_	_
.	_	_

#124
In	_	_
order	_	_
to	_	_
study	_	_
the	_	_
effects	_	_
of	_	_
model	_	_
inductive	_	_
bias	_	_
and	_	_
dataset	_	_
size	_	_
,	_	_
we	_	_
trained	_	_
a	_	_
fleet	_	_
of	_	_
models	_	_
with	_	_
varying	_	_
inductive	_	_
biases	_	_
on	_	_
each	_	_
corpus	_	_
.	_	_

#125
Because	_	_
many	_	_
of	_	_
our	_	_
test	_	_
suites	_	_
exploit	_	_
ambiguities	_	_
that	_	_
arise	_	_
from	_	_
incremental	_	_
processing	_	_
,	_	_
we	_	_
restrict	_	_
evaluation	_	_
to	_	_
left-to-right	_	_
language	_	_
models	_	_
;	_	_
future	_	_
work	_	_
could	speculation	_
involve	_	_
evaluation	_	_
of	_	_
bidirectional	_	_
models	_	_
(	_	_
Devlin	_	_
et	_	_
al.	_	_
,	_	_
2018	_	_
;	_	_
Yang	_	_
et	_	_
al.	_	_
,	_	_
2019	_	_
)	_	_
on	_	_
an	_	_
appropriate	_	_
subset	_	_
of	_	_
our	_	_
test	_	_
suites	_	_
,	_	_
and/or	_	_
adaptation	_	_
of	_	_
our	_	_
suites	_	_
for	_	_
use	_	_
with	_	_
bidirectional	_	_
models	_	_
(	_	_
Goldberg	_	_
,	_	_
2019	_	_
)	_	_
.	_	_

#126
Training	_	_
ran	_	_
until	_	_
convergence	_	_
of	_	_
perplexity	_	_
on	_	_
a	_	_
held-out	_	_
validation	_	_
set	_	_
.	_	_

#162
For	_	_
example	_	_
,	_	_
there	_	_
is	_	_
a	_	_
remarkable	_	_
amount	_	_
of	_	_
variance	_	_
in	_	_
the	_	_
SG	_	_
score	_	_
of	_	_
models	_	_
trained	_	_
on	_	_
BLLIP-LG	_	_
not	_	_
explained	_	_
by	_	_
perplexity	_	_
.	_	_

#163
This	_	_
suggests	_	_
that	_	_
targeted	_	_
syntactic	_	_
evaluation	_	_
can	_	_
reveal	_	_
information	_	_
that	_	_
may	speculation	_
be	_	_
orthogonal	_	_
to	_	_
perplexity	_	_
.	_	_

#164
4.2	_	_
Inductive	_	_
bias	_	_
and	_	_
data	_	_
scale	_	_

#193
For	_	_
five	_	_
test	_	_
suites	_	_
(	_	_
Center	_	_
Embedding	_	_
,	_	_
Cleft	_	_
,	_	_
MVRR	_	_
,	_	_
NPZ-Ambiguous	_	_
,	_	_
NPZ-Object	_	_
)	_	_
,	_	_
we	_	_
designed	_	_
minimally	_	_
edited	_	_
versions	_	_
where	_	_
syntactically	_	_
irrelevant	_	_
intervening	_	_
content	_	_
was	_	_
inserted	_	_
before	_	_
the	_	_
critical	_	_
region	_	_
.	_	_

#194
An	_	_
ideal	_	_
model	_	_
should	deontic	_
robustly	_	_
represent	_	_
syntactic	_	_
features	_	_
of	_	_
its	_	_
input	_	_
across	_	_
these	_	_
modifier	_	_
insertions	_	_
.	_	_

#195
In	_	_
Figure	_	_
6	_	_
we	_	_
plot	_	_
models’	_	_
average	_	_
scores	_	_
on	_	_
these	_	_
five	_	_
test	_	_
suites	_	_
(	_	_
dark	_	_
bars	_	_
)	_	_
and	_	_
their	_	_
minimally	_	_
edited	_	_
versions	_	_
(	_	_
light	_	_
bars	_	_
)	_	_
,	_	_
evaluating	_	_
how	_	_
robust	_	_
each	_	_
model	_	_
is	_	_
to	_	_
intervening	_	_
content	_	_
.	_	_

#203
Some	_	_
preliminary	_	_
work	_	_
suggests	_	_
that	_	_
sub-word	_	_
tokenization	_	_
is	_	_
indeed	_	_
responsible	_	_
for	_	_
much	_	_
of	_	_
the	_	_
larger	_	_
GPT-2	_	_
models’	_	_
success	_	_
:	_	_
we	_	_
find	_	_
that	_	_
GPT-2	_	_
models	_	_
trained	_	_
on	_	_
word-level	_	_
representations	_	_
of	_	_
BLLIP-LG	_	_
and	_	_
BLLIP-MD	_	_
achieve	_	_
good	_	_
perplexity	_	_
measures	_	_
,	_	_
but	_	_
degrade	_	_
sharply	_	_
in	_	_
SG	_	_
score	_	_
.	_	_

#204
Peculiarities	_	_
of	_	_
the	_	_
GPT-2	_	_
training	_	_
regime	_	_
may	speculation	_
be	_	_
responsible	_	_
for	_	_
its	_	_
particularly	_	_
bad	_	_
performance	_	_
on	_	_
the	_	_
smaller	_	_
corpora	_	_
.	_	_

#205
Its	_	_
sub-word	_	_
vocabulary	_	_
was	_	_
held	_	_
constant	_	_
across	_	_
training	_	_
corpora	_	_
,	_	_
meaning	_	_
that	_	_
the	_	_
model	_	_
vocabulary	_	_
size	_	_
also	_	_
remained	_	_
constant	_	_
across	_	_
corpora	_	_
,	_	_
unlike	_	_
the	_	_
other	_	_
models	_	_
tested	_	_
.	_	_

#206
The	_	_
poor	_	_
performance	_	_
of	_	_
GPT-2	_	_
models	_	_
trained	_	_
on	_	_
smaller	_	_
corpora	_	_
may	speculation	_
thus	_	_
be	_	_
due	_	_
to	_	_
overparameterization	_	_
,	_	_
and	_	_
not	_	_
due	_	_
to	_	_
fundamental	_	_
problems	_	_
with	_	_
the	_	_
model	_	_
architecture	_	_
at	_	_
small	_	_
data	_	_
scales	_	_
.	_	_

#207
We	_	_
leave	_	_
a	_	_
thorough	_	_
investigation	_	_
of	_	_
the	_	_
role	_	_
of	_	_
sub-word	_	_
tokenization	_	_
to	_	_
future	_	_
work	_	_
.	_	_