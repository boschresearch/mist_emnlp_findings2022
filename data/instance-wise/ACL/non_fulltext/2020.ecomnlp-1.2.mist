#66
Thus	_	_
,	_	_
proposals	_	_
based	_	_
on	_	_
sub-word	_	_
level	_	_
information	_	_
are	_	_
very	_	_
competitive	_	_
compared	_	_
to	_	_
BERT	_	_
models	_	_
on	_	_
those	_	_
cases	_	_
where	_	_
we	_	_
have	_	_
unstructured	_	_
textual	_	_
information	_	_
and	_	_
probably	_	_
OCR	_	_
errors	_	_
,	_	_
such	_	_
as	_	_
the	_	_
descriptions	_	_
processed	_	_
in	_	_
most	_	_
of	_	_
the	_	_
leaflets	_	_
.	_	_

#67
It	_	_
must	deontic-rhetorical	_
be	_	_
also	_	_
noted	_	_
that	_	_
although	_	_
BERT	_	_
is	_	_
focused	_	_
on	_	_
standard	_	_
text	_	_
processing	_	_
,	_	_
there	_	_
are	_	_
derived	_	_
approaches	_	_
that	_	_
are	_	_
also	_	_
diving	_	_
into	_	_
text	_	_
processing	_	_
associated	_	_
with	_	_
images	_	_
,	_	_
such	_	_
as	_	_
ViLBERT	_	_
(	_	_
Lu	_	_
et	_	_
al.	_	_
,	_	_
2019	_	_
)	_	_
or	_	_
VL-BERT	_	_
(	_	_
Su	_	_
et	_	_
al.	_	_
,	_	_
2020	_	_
)	_	_
.	_	_

#68
The	_	_
difference	_	_
is	_	_
that	_	_
these	_	_
recent	_	_
approaches	_	_
are	_	_
not	_	_
directly	_	_
applied	_	_
to	_	_
classification	_	_
over	_	_
text	_	_
contained	_	_
in	_	_
images	_	_
,	_	_
they	_	_
are	_	_
used	_	_
for	_	_
tasks	_	_
that	_	_
involve	_	_
images	_	_
and	_	_
related	_	_
external	_	_
text	_	_
,	_	_
such	_	_
as	_	_
VQA	_	_
(	_	_
Visual	_	_
Question	_	_
Answering	_	_
)	_	_
(	_	_
Antol	_	_
et	_	_
al.	_	_
,	_	_
2015	_	_
)	_	_
.	_	_

#150
However	_	_
,	_	_
the	_	_
main	_	_
properties	_	_
and	_	_
statistics	_	_
from	_	_
both	_	_
datasets	_	_
are	_	_
summarized	_	_
in	_	_
Table	_	_
1	_	_
.	_	_

#151
It	_	_
must	deontic-rhetorical	_
be	_	_
noted	_	_
that	_	_
the	_	_
data	_	_
distribution	_	_
is	_	_
long-tailed	_	_
and	_	_
thus	_	_
unbalanced	_	_
for	_	_
both	_	_
training	_	_
and	_	_
validation/test	_	_
splits	_	_
,	_	_
as	_	_
shown	_	_
in	_	_
Fig.	_	_
5	_	_
.	_	_

#152
Then	_	_
,	_	_
this	_	_
is	_	_
an	_	_
extra	_	_
challenge	_	_
for	_	_
our	_	_
models	_	_
in	_	_
order	_	_
to	_	_
be	_	_
robust	_	_
against	_	_
the	_	_
typical	_	_
problems	_	_
derived	_	_
from	_	_
long-tail	_	_
datasets	_	_
.	_	_

#172
These	_	_
results	_	_
confirm	_	_
the	_	_
enhancement	_	_
given	_	_
by	_	_
our	_	_
system	_	_
with	_	_
respect	_	_
to	_	_
the	_	_
proposed	_	_
baseline	_	_
.	_	_

#173
It	_	_
must	deontic-rhetorical	_
be	_	_
remarked	_	_
that	_	_
a	_	_
confidence	_	_
threshold	_	_
of	_	_
0.25	_	_
is	_	_
used	_	_
for	_	_
the	_	_
multi-label	_	_
text	_	_
classification	_	_
model	_	_
of	_	_
our	_	_
proposal	_	_
.	_	_

#174
This	_	_
confidence	_	_
represents	_	_
the	_	_
probabilities	_	_
of	_	_
having	_	_
a	_	_
correct	_	_
prediction	_	_
for	_	_
a	_	_
class	_	_
,	_	_
so	_	_
the	_	_
confidence	_	_
threshold	_	_
is	_	_
used	_	_
to	_	_
filter	_	_
predictions	_	_
with	_	_
low	_	_
probabilities	_	_
.	_	_

#184
According	_	_
to	_	_
these	_	_
results	_	_
,	_	_
it	_	_
seems	_	_
that	_	_
the	_	_
embeddings	_	_
for	_	_
the	_	_
text	_	_
classifier	_	_
are	_	_
able	_	_
to	_	_
generalize	_	_
categorization	_	_
to	_	_
new	_	_
languages	_	_
.	_	_

#185
The	_	_
reported	_	_
accuracies	_	_
must	deontic	_
be	_	_
understood	_	_
taking	_	_
into	_	_
account	_	_
the	_	_
long-tail	_	_
problems	_	_
of	_	_
the	_	_
dataset	_	_
exposed	_	_
in	_	_
Fig.	_	_
5	_	_
,	_	_
so	_	_
the	_	_
classes	_	_
with	_	_
less	_	_
training	_	_
samples	_	_
are	_	_
more	_	_
difficult	_	_
to	_	_
predict	_	_
.	_	_

#186
5	_	_
Conclusions	_	_